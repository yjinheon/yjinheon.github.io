<!DOCTYPE html>
<html lang="en">
<head><!-- hexo injector head_begin start --><link href="/css/hexo-widget-tree.css" rel="stylesheet"/><!-- hexo injector head_begin end -->
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css" integrity="sha256-/4UQcSmErDzPCMAiuOiWPVVsNN2s3ZY/NsmXNcj0IFc=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"yjinheon.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.15.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="TensorflowTensor 연산Tensor Concept  tensor : rank :    RankTensorFlow 시스템에서, tensor는 rank라는 차원 단위로 표현된다.Tensor rank는 행렬의 rank와 다르다.Tensor rank(order, degree, -n_dimension 으로도 언급됨)는 tensor의 차원수다.예를 들어,">
<meta property="og:type" content="article">
<meta property="og:title" content="DataMind">
<meta property="og:url" content="https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/index.html">
<meta property="og:site_name" content="DataMind">
<meta property="og:description" content="TensorflowTensor 연산Tensor Concept  tensor : rank :    RankTensorFlow 시스템에서, tensor는 rank라는 차원 단위로 표현된다.Tensor rank는 행렬의 rank와 다르다.Tensor rank(order, degree, -n_dimension 으로도 언급됨)는 tensor의 차원수다.예를 들어,">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-10-27T15:53:30.907Z">
<meta property="article:modified_time" content="2023-02-27T10:08:09.000Z">
<meta property="article:author" content="JinHeon Yoon">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/","path":"2023/10/28/machine-learning/notebook/machine-learning/tensorflow/","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title> | DataMind</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/rss2.xml" title="DataMind" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">DataMind</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensorflow"><span class="nav-number">1.</span> <span class="nav-text">Tensorflow</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor-%EC%97%B0%EC%82%B0"><span class="nav-number">1.1.</span> <span class="nav-text">Tensor 연산</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensor"><span class="nav-number">1.1.1.</span> <span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rank"><span class="nav-number">1.1.2.</span> <span class="nav-text">Rank</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Shape"><span class="nav-number">1.1.3.</span> <span class="nav-text">Shape</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorflow-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%ED%98%84"><span class="nav-number">1.2.</span> <span class="nav-text">Tensorflow 전처리 파이프라인 구현</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%85%94%ED%94%8C%ED%95%98%EA%B8%B0"><span class="nav-number">1.2.1.</span> <span class="nav-text">데이터 셔플하기</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%85%94%ED%94%8C%ED%95%98%EA%B8%B0-1"><span class="nav-number">1.2.2.</span> <span class="nav-text">데이터 셔플하기</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EC%97%AC%EB%9F%AC-%ED%8C%8C%EC%9D%BC%EC%97%90%EC%84%9C-%ED%95%9C%EC%A4%84%EC%94%A9-%EB%B2%88%EA%B0%88%EC%95%84-%EC%9D%BD%EA%B8%B0"><span class="nav-number">1.2.3.</span> <span class="nav-text">여러 파일에서 한줄씩 번갈아 읽기</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%81%EC%9E%AC%EC%99%80-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%95%9C%EB%B2%88%EC%97%90"><span class="nav-number">1.2.4.</span> <span class="nav-text">데이터 적재와 전처리 한번에</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Modeling-with-Keras"><span class="nav-number">2.</span> <span class="nav-text">Modeling with Keras</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Layers-Function"><span class="nav-number">2.1.</span> <span class="nav-text">Layers Function</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Input"><span class="nav-number">2.1.1.</span> <span class="nav-text">Input</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dense"><span class="nav-number">2.1.2.</span> <span class="nav-text">Dense</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Activation"><span class="nav-number">2.1.3.</span> <span class="nav-text">Activation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flatten"><span class="nav-number">2.1.4.</span> <span class="nav-text">Flatten</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conv2d"><span class="nav-number">2.1.5.</span> <span class="nav-text">Conv2d</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sequential-API"><span class="nav-number">2.2.</span> <span class="nav-text">Sequential API</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="JinHeon Yoon"
      src="/images/medium.jpg">
  <p class="site-author-name" itemprop="name">JinHeon Yoon</p>
  <div class="site-description" itemprop="description">my blog</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">103</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yjinheon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yjinheon" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yjinheon@gmail.com" title="E-Mail → mailto:yjinheon@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/ko" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/medium.jpg">
      <meta itemprop="name" content="JinHeon Yoon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DataMind">
      <meta itemprop="description" content="my blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | DataMind">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-28 00:53:30" itemprop="dateCreated datePublished" datetime="2023-10-28T00:53:30+09:00">2023-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-02-27 19:08:09" itemprop="dateModified" datetime="2023-02-27T19:08:09+09:00">2023-02-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/machine-learning/notebook/" itemprop="url" rel="index"><span itemprop="name">notebook</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/machine-learning/notebook/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h2><h3 id="Tensor-연산"><a href="#Tensor-연산" class="headerlink" title="Tensor 연산"></a>Tensor 연산</h3><h4 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h4><hr>
<p><strong><em>Concept</em></strong></p>
<ul>
<li><strong>tensor</strong> :</li>
<li><strong>rank</strong> :</li>
<li></li>
</ul>
<hr>
<h4 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h4><p>TensorFlow 시스템에서, tensor는 <em>rank</em>라는 차원 단위로 표현된다.<br>Tensor rank는 행렬의 rank와 다르다.<br>Tensor rank(<em>order</em>, <em>degree</em>, <em>-n_dimension</em> 으로도 언급됨)는 tensor의 차원수다.<br>예를 들어, 아래 tensor(Python 리스트로 정의)의 rank는 2다.</p>
<pre><code>t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
</code></pre>
<p>rank 2인 tensor는 행렬, rank 1인 tensor는 벡터로 생각할 수 있다.<br>rank 2인 tensor는 <code>t[i, j]</code> 형식으로 원소에 접근할 수 있다.<br>rank 3인 tensor는 <code>t[i, j, k]</code> 형식으로 원소를 지정할 수 있다.</p>
<h4 id="Shape"><a href="#Shape" class="headerlink" title="Shape"></a>Shape</h4><p>TensorFlow 문서는 tensor 차원을 표현할 때 세 가지 기호를 사용한다. rank, shape, Demension number.<br>아래 표는 그 세 가지의 관계를 보여준다:</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Shape</th>
<th>Dimension number</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>A 0-D tensor.  A scalar.</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>A 1-D tensor with shape [5].</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>A 2-D tensor with shape [3, 4].</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>A 3-D tensor with shape [1, 4, 3].</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n-D</td>
<td>A tensor with shape [D0, D1, … Dn-1].</td>
</tr>
</tbody></table>
<h3 id="Tensorflow-전처리-파이프라인-구현"><a href="#Tensorflow-전처리-파이프라인-구현" class="headerlink" title="Tensorflow 전처리 파이프라인 구현"></a>Tensorflow 전처리 파이프라인 구현</h3><p><strong>ref</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">Tensorflow 데이터 로딩 및 전처리 파이프라인 구현하기</a></li>
</ul>
<!--
tensorflow를 사용하면서 가장 까다로운 부분이 입력데이터 파이프라인 처리해서 모델까지 데이터 흐르는 구간을 만드는게 아닌가 싶다. 데이터의 양이 많을때, 적을때, 그리고 형태에 따라 다양하게 구현을 해야하기 때문에 A라는 방법을 써서 구현하다 보면 모델에 데이터를 넣는 부분이 막힐때가 있다. 그래서 텐서플로우에서 입력데이터를 어떻게 처리해야 하는지에 대한 내용을 정리-->

<ul>
<li><strong>Dataset class 확인(tensorflow에서 데이터를 읽을 때 중심이 됨)</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">dir</span>(tf.data.Dataset):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (m.startswith(<span class="string">&quot;_&quot;</span>) <span class="keyword">or</span> m.endswith(<span class="string">&quot;_&quot;</span>)):</span><br><span class="line">        func = <span class="built_in">getattr</span>(tf.data.Dataset, m)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(func, <span class="string">&quot;__doc__&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;● &#123;:21s&#125;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(m + <span class="string">&quot;()&quot;</span>, func.__doc__.split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>tfds 관련함수들</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">X = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices(X)</span><br><span class="line">dataset</span><br><span class="line"></span><br><span class="line">tf.data.Dataset.Range(<span class="number">10</span>) <span class="comment"># 위와 동일</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset: <span class="comment"># Tensor의 형태를 출력</span></span><br><span class="line">  <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># repeat(): 원본 데이터셋의 아이템을 N차례 반복하는 새로운 데이터셋을 반환 (복사하는 것은 아님)</span></span><br><span class="line"><span class="comment"># batch() : 아이템을 N개의 그룹으로 묶는다</span></span><br><span class="line"><span class="comment"># batch(drop_remainder=True): 마지막에 N보다 부족한 길이의 배치는 버림 (=모든 배치의 크기가 동일)</span></span><br><span class="line">dataset = dataset.repeat(<span class="number">3</span>).batch(<span class="number">7</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터에 원하는 전처리 작업에도 적용 (이미지 크기 변환, 회전계산)</span></span><br><span class="line"><span class="comment"># map(num_parallel_calls) 를 하면 여러개의 스레드로 나누어서 속도를 높여 처리 가능</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># map은 각 아이템에 변환을 적용하지만 apply는 데이터셋 전체에 변환을 적용</span></span><br><span class="line"><span class="comment"># dataset = dataset.apply(tf.data.experimental.unbatch()) # deprecated</span></span><br><span class="line">dataset = dataset.unbatch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter 할때</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(labmda x: x &lt;<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋에 있는 몇개의 아이템만 보고싶을때</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset.take(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h4 id="데이터-셔플하기"><a href="#데이터-셔플하기" class="headerlink" title="데이터 셔플하기"></a><strong>데이터 셔플하기</strong></h4><ul>
<li>경사 하강법은 훈련 세트에 있는 샘플이 독립적이고 동일한 분포일때 최고의 성능을 발휘 (&#x3D;shuffle이 필요한 이유)</li>
<li>동작순서<ul>
<li>원본 데이터셋의 처음 아이템을 buffer_size 개수만큼 추출하여 버퍼에 채운다.</li>
<li>새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내 반환</li>
<li>원본 데이터셋에서 새로운 아이템을 추출하여 비워진 버퍼를 채운다.</li>
<li>원본 데이터셋의 모든 아이템이 사용될 때까지 반복</li>
<li>버퍼가 비워질 때까지 계속하여 랜덤하게 아이템을 반환</li>
</ul>
</li>
<li>버퍼의 크기를 충분히 크게 하는 것이 중요하다. (&#x3D;셔플링 효과를 올리기 위해서), 메모리의 크기를 넘지 않도록, 데이터의 크기를 넘지 않도록</li>
<li>완벽한 셔플링을 위해서는 버퍼크기가 데이터셋의 크기와 동일</li>
<li>셔플링되는 순서를 동일하게 만들기 위해 랜덤 시드를 부여<ul>
<li><strong>반드시 suffle을 먼저 한뒤에 repeat를 해야함</strong></li>
<li><strong>일단 아래 순서로 할 것 : shuffle , repeat, map, batch</strong></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51485781/tf-dataset-api-is-the-following-sequence-correct-map-cache-shuffle-batch-repea">순서레퍼런스</a></li>
</ul>
</li>
</ul>
<p><strong>ref</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">Tensorflow 데이터 로딩 및 전처리 파이프라인 구현하기</a></li>
</ul>
<p>tensorflow를 사용하면서 가장 까다로운 부분이 입력데이터 파이프라인 처리해서 모델까지 데이터 흐르는 구간을 만드는게 아닌가 싶다. 데이터의 양이 많을때, 적을때, 그리고 형태에 따라 다양하게 구현을 해야하기 때문에 A라는 방법을 써서 구현하다 보면 모델에 데이터를 넣는 부분이 막힐때가 있다. 그래서 텐서플로우에서 입력데이터를 어떻게 처리해야 하는지에 대한 내용을 정리</p>
<ul>
<li><strong>Dataset class 확인(tensorflow에서 데이터를 읽을 때 중심이 됨)</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">dir</span>(tf.data.Dataset):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (m.startswith(<span class="string">&quot;_&quot;</span>) <span class="keyword">or</span> m.endswith(<span class="string">&quot;_&quot;</span>)):</span><br><span class="line">        func = <span class="built_in">getattr</span>(tf.data.Dataset, m)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(func, <span class="string">&quot;__doc__&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;● &#123;:21s&#125;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(m + <span class="string">&quot;()&quot;</span>, func.__doc__.split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>tfds 관련함수들</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">X = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices(X)</span><br><span class="line">dataset</span><br><span class="line"></span><br><span class="line">tf.data.Dataset.Range(<span class="number">10</span>) <span class="comment"># 위와 동일</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset: <span class="comment"># Tensor의 형태를 출력</span></span><br><span class="line">  <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># repeat(): 원본 데이터셋의 아이템을 N차례 반복하는 새로운 데이터셋을 반환 (복사하는 것은 아님)</span></span><br><span class="line"><span class="comment"># batch() : 아이템을 N개의 그룹으로 묶는다</span></span><br><span class="line"><span class="comment"># batch(drop_remainder=True): 마지막에 N보다 부족한 길이의 배치는 버림 (=모든 배치의 크기가 동일)</span></span><br><span class="line">dataset = dataset.repeat(<span class="number">3</span>).batch(<span class="number">7</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터에 원하는 전처리 작업에도 적용 (이미지 크기 변환, 회전계산)</span></span><br><span class="line"><span class="comment"># map(num_parallel_calls) 를 하면 여러개의 스레드로 나누어서 속도를 높여 처리 가능</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># map은 각 아이템에 변환을 적용하지만 apply는 데이터셋 전체에 변환을 적용</span></span><br><span class="line"><span class="comment"># dataset = dataset.apply(tf.data.experimental.unbatch()) # deprecated</span></span><br><span class="line">dataset = dataset.unbatch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter 할때</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(labmda x: x &lt;<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋에 있는 몇개의 아이템만 보고싶을때</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset.take(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h4 id="데이터-셔플하기-1"><a href="#데이터-셔플하기-1" class="headerlink" title="데이터 셔플하기"></a><strong>데이터 셔플하기</strong></h4><ul>
<li>경사 하강법은 훈련 세트에 있는 샘플이 독립적이고 동일한 분포일때 최고의 성능을 발휘 (&#x3D;shuffle이 필요한 이유)</li>
<li>동작순서<ul>
<li>원본 데이터셋의 처음 아이템을 buffer_size 개수만큼 추출하여 버퍼에 채운다.</li>
<li>새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내 반환</li>
<li>원본 데이터셋에서 새로운 아이템을 추출하여 비워진 버퍼를 채운다.</li>
<li>원본 데이터셋의 모든 아이템이 사용될 때까지 반복</li>
<li>버퍼가 비워질 때까지 계속하여 랜덤하게 아이템을 반환</li>
</ul>
</li>
<li>버퍼의 크기를 충분히 크게 하는 것이 중요하다. (&#x3D;셔플링 효과를 올리기 위해서), 메모리의 크기를 넘지 않도록, 데이터의 크기를 넘지 않도록</li>
<li>완벽한 셔플링을 위해서는 버퍼크기가 데이터셋의 크기와 동일</li>
<li>셔플링되는 순서를 동일하게 만들기 위해 랜덤 시드를 부여<ul>
<li><strong>반드시 suffle을 먼저 한뒤에 repeat를 해야함</strong></li>
<li><strong>일단 아래 순서로 할 것 : shuffle , repeat, map, batch</strong></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51485781/tf-dataset-api-is-the-following-sequence-correct-map-cache-shuffle-batch-repea">순서레퍼런스</a></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.random.set_seed(<span class="number">42</span>) <span class="comment"># 셔플링 순서를 동일하게</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (2) shuffle하고 repeat</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">3</span>, seed=<span class="number">42</span>).repeat(<span class="number">3</span>).batch(<span class="number">7</span>) <span class="comment"># 반복마다 순서가 달라지도록</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h4 id="여러-파일에서-한줄씩-번갈아-읽기"><a href="#여러-파일에서-한줄씩-번갈아-읽기" class="headerlink" title="여러 파일에서 한줄씩 번갈아 읽기"></a>여러 파일에서 한줄씩 번갈아 읽기</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">[[여러]] 파일로 데이터 나누기</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">X_train_full, X_test, y_train_full, y_test = train_test_split(</span><br><span class="line">    housing.data, housing.target.reshape(-<span class="number">1</span>, <span class="number">1</span>), random_state=<span class="number">42</span>)</span><br><span class="line">X_train, X_valid, y_train, y_valid = train_test_split(</span><br><span class="line">    X_train_full, y_train_full, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X_train)</span><br><span class="line">X_mean = scaler.mean_</span><br><span class="line">X_std = scaler.scale_</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_to_multiple_csv_files</span>(<span class="params">data, name_prefix, header=<span class="literal">None</span>, n_parts=<span class="number">10</span></span>):</span><br><span class="line">    housing_dir = os.path.join(<span class="string">&quot;datasets&quot;</span>, <span class="string">&quot;housing&quot;</span>)</span><br><span class="line">    os.makedirs(housing_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    path_format = os.path.join(housing_dir, <span class="string">&quot;my_&#123;&#125;_&#123;:02d&#125;.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    filepaths = []</span><br><span class="line">    m = <span class="built_in">len</span>(data)</span><br><span class="line">    <span class="keyword">for</span> file_idx, row_indices <span class="keyword">in</span> <span class="built_in">enumerate</span>(np.array_split(np.arange(m), n_parts)):</span><br><span class="line">        part_csv = path_format.<span class="built_in">format</span>(name_prefix, file_idx)</span><br><span class="line">        filepaths.append(part_csv)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(part_csv, <span class="string">&quot;wt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">if</span> header <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                f.write(header)</span><br><span class="line">                f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> row_idx <span class="keyword">in</span> row_indices:</span><br><span class="line">                f.write(<span class="string">&quot;,&quot;</span>.join([<span class="built_in">repr</span>(col) <span class="keyword">for</span> col <span class="keyword">in</span> data[row_idx]]))</span><br><span class="line">                f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> filepaths</span><br><span class="line"></span><br><span class="line">train_data = np.c_[X_train, y_train]</span><br><span class="line">valid_data = np.c_[X_valid, y_valid]</span><br><span class="line">test_data = np.c_[X_test, y_test]</span><br><span class="line">header_cols = housing.feature_names + [<span class="string">&quot;MedianHouseValue&quot;</span>]</span><br><span class="line">header = <span class="string">&quot;,&quot;</span>.join(header_cols)</span><br><span class="line"></span><br><span class="line">train_filepaths = save_to_multiple_csv_files(train_data, <span class="string">&quot;train&quot;</span>, header, n_parts=<span class="number">20</span>)</span><br><span class="line">valid_filepaths = save_to_multiple_csv_files(valid_data, <span class="string">&quot;valid&quot;</span>, header, n_parts=<span class="number">10</span>)</span><br><span class="line">test_filepaths = save_to_multiple_csv_files(test_data, <span class="string">&quot;test&quot;</span>, header, n_parts=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">pd.read_csv(train_filepaths[<span class="number">0</span>]).head()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(train_filepaths[<span class="number">0</span>]) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(f.readline(), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">데이터 나눠서 읽기</span><br><span class="line"></span><br><span class="line">filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=<span class="number">42</span>) <span class="comment"># default: shuffle=True</span></span><br><span class="line">n_reader = <span class="number">5</span></span><br><span class="line"><span class="comment"># skip(1): header</span></span><br><span class="line"><span class="comment"># interleave(): filepath_dataset에 있는 다섯개의 파일 경로에서 데이터를 읽는 데이터셋을 생성,TextLineDataset 5개를 순회하면서 한줄씩 읽는다.</span></span><br><span class="line"><span class="comment"># 파일 길이가 동일할때 interleave를 사용하는게 좋음 (각파일에서 한줄씩 읽음)</span></span><br><span class="line"><span class="comment"># num_parallel_calls 매개변수에 원하는 스레드 개수를 지정</span></span><br><span class="line"><span class="comment"># tf.data.experimental.AUTOTUNE: 을 지정하면 텐서플로가 가용한 CPU를 기반으로 동적으로 적절한 스레드 개수를 선택할 수 있다.</span></span><br><span class="line"><span class="comment"># cycle_length: 동시에 처리할 입력 개수를 지정</span></span><br><span class="line">dataset = filepath_dataset.interleave(<span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).sip(<span class="number">1</span>), cycle_length=n_readers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 각 TextLineDataset의 순서가 랜덤으로 첫번째 해당하는 행을 읽음 (순서가 랜덤)</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> dataset.take(<span class="number">5</span>):</span><br><span class="line">  <span class="built_in">print</span>(line.numpy())</span><br></pre></td></tr></table></figure>

<ul>
<li>데이터 전처리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 평균과 표준편차를 미리 계산했다고 가정함</span></span><br><span class="line">X_mean, X_std = [...]</span><br><span class="line">n_inputs = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.fuction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">line</span>):</span><br><span class="line">  defs = [<span class="number">0.</span>] * n_inputs + [tf.constant([], dtype=tf.float32)]</span><br><span class="line">  fields = tf.io.decode_csv(line, record_defaults=defs) <span class="comment"># csv의 한 라인을 받아 파싱</span></span><br><span class="line">  <span class="comment"># stack() 모든 텐서를 쌓아 1D 배열을 생성</span></span><br><span class="line">  x = tf.stack(fields[:-<span class="number">1</span>]) <span class="comment"># &lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)&gt;</span></span><br><span class="line">  y = tf.stack(fields[-<span class="number">1</span>:]) <span class="comment"># &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([7], dtype=int32)&gt;</span></span><br><span class="line">  <span class="keyword">return</span> (x - X_mean) / X_std, y</span><br><span class="line"></span><br><span class="line">preprocess(<span class="string">b&#x27;4.2083, 44.0, 5.332,....&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">record_defaults=[<span class="number">0</span>, np.nan, tf.constant(np.nan, dtype=tf.float64), <span class="string">&quot;Hello&quot;</span>, tf.constant([])]</span><br><span class="line">parsed_fields = tf.io.decode_csv(<span class="string">&#x27;1,2,3,4,5&#x27;</span>, record_defaults)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float64, numpy=3.0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#x27;4&#x27;&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">parsed_fields = tf.io.decode_csv(<span class="string">&#x27;,,,,5&#x27;</span>, record_defaults)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=nan&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float64, numpy=nan&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#x27;Hello&#x27;&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Exception</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    parsed_fields = tf.io.decode_csv(<span class="string">&#x27;,,,,&#x27;</span>, record_defaults) <span class="comment"># case 1</span></span><br><span class="line">    parsed_fields = tf.io.decode_csv(<span class="string">&#x27;1,2,3,4,5,6,7&#x27;</span>, record_defaults) <span class="comment"># case 2</span></span><br><span class="line"><span class="keyword">except</span> tf.errors.InvalidArgumentError <span class="keyword">as</span> ex:</span><br><span class="line">    <span class="built_in">print</span>(ex)</span><br><span class="line"></span><br><span class="line"><span class="comment"># case 1 : Field 4 is required but missing in record 0! [Op:DecodeCSV]</span></span><br><span class="line"><span class="comment"># case 2 : Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]</span></span><br></pre></td></tr></table></figure>

<h4 id="데이터-적재와-전처리-한번에"><a href="#데이터-적재와-전처리-한번에" class="headerlink" title="데이터 적재와 전처리 한번에"></a>데이터 적재와 전처리 한번에</h4><ul>
<li><p>위 코드를 재사용하기 위해서 하나의 함수로 생성</p>
</li>
<li><p>CSV파일에서 캘리포니아 주택 데이터셋을 효율적으로 적재하고 전처리, 셔플링, 반복, 배치를 적용한 데이터셋을 만들어 반환</p>
</li>
<li><p><code>prefetch()</code></p>
<ul>
<li>훈련 속도를 더 빠르게</li>
<li>prefetch(1)을 호출하면 데이터셋은 항상 한 배치가 미리 준비되도록 최선을 (&#x3D;알고리즘이 한 배치로 작업하는 동안 이 데이터셋이 동시에 다음 배치를 준비)</li>
<li>GPU에서 훈련하는 스텝을 수행하는 것보다 짧은 시간안에 한 배치 데이터를 준비할 수 있다. (&#x3D;GPU 100%활용하는 방법)</li>
<li>nterleave와 map에 num_parallel_calls을 함께 사용하면 데이터를 적재하고 전처리할때 CPU의 멀티코어를 사용해 더 빠르게 준비 가능</li>
<li>prefetch는 일반적으로 하나도 충분, tf.data.experimental.AUTOTUNE을 전달하면 텐서플로가 자동으로 결정</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">csv_reader_dataset</span>(<span class="params">filepaths, repeat=<span class="number">1</span>, n_readers=<span class="number">5</span>,</span></span><br><span class="line"><span class="params">                       n_read_threads=<span class="literal">None</span>, shuffle_buffer_size=<span class="number">10000</span>,</span></span><br><span class="line"><span class="params">                       n_parse_threads=<span class="number">5</span>, batch_size=<span class="number">32</span></span>):</span><br><span class="line">    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)</span><br><span class="line">    dataset = dataset.interleave(</span><br><span class="line">        <span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).skip(<span class="number">1</span>),</span><br><span class="line">        cycle_length=n_readers, num_parallel_calls=n_read_threads)</span><br><span class="line">    dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(preprocess, num_parallel_calls=n_parse_threads)</span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> dataset.prefetch(<span class="number">1</span>) <span class="comment"># 학습 성능에 아주 중요한 역할</span></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">train_set = csv_reader_dataset(train_filepaths, batch_size=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> train_set.take(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X =&quot;</span>, X_batch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y =&quot;</span>, y_batch)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>

<ul>
<li>csv_reader_dataset()함수로 훈련 세트로 사용할 데이터셋을 만들기</li>
<li><a target="_blank" rel="noopener" href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/</a></li>
</ul>
<h2 id="Modeling-with-Keras"><a href="#Modeling-with-Keras" class="headerlink" title="Modeling with Keras"></a>Modeling with Keras</h2><h3 id="Layers-Function"><a href="#Layers-Function" class="headerlink" title="Layers Function"></a>Layers Function</h3><ul>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc">Unit,Shape,Input Shape,Dimention에 대한 자세한 설명</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/keras-team/keras-docs-ko/blob/master/sources/layers/core.md">Keras 한국어문서</a></li>
</ul>
<hr>
<p><strong><em>Concept</em></strong></p>
<ul>
<li><strong>shape</strong> : 배열의 각 차원에 몇개의 요소가 있는지에 대한 정보를 담고있는 tuple<ul>
<li><code>(40,4,10)</code> 은 1차원에 40개, 2차원에 4개 , 3차원에 10개의 요소들을 담고있는 3차원 텐서를 의미한다.</li>
</ul>
</li>
<li><strong>input_shape</strong> : 기본적으로 첫번째 차원을 제외한 배열의 차원정보.</li>
<li><strong>unit</strong> : 출력층의 차원 수. output layer의 shape을 결정함.</li>
<li><strong>kernel</strong> : 층에서 만들어진 <code>가중치 행렬weight matrix</code></li>
<li><strong>Dense</strong> :<code>activation(dot(input, kernel) + bias)</code> 계산</li>
<li><strong>Input</strong> : 텐서 생성</li>
<li><strong>Activation</strong> : 출력값에 활성화함수 적용</li>
<li><strong>Dropout</strong> : 입력에 Dropout 적용.Dropout은 노드를 지정한 비율만큼 랜덤으로 드롭해서 너무 많은 노드들이 학습\되어 과적합 되는 것을 방지해 준다.노드를 랜덤으로끄고 나머지 노드를 학습을 더 시켜서 퍼포먼스를 향상시킨다.</li>
<li><strong>Reshape</strong> : 출력을 특정형태로 변환.</li>
<li><strong>Flatten</strong> : 입력을 1차원 텐서로 변환. batch size에는 영향을 주지 않음.</li>
<li><strong>Masking</strong> : 시퀀스를 마스킹. 따로 정리</li>
</ul>
<hr>
<h4 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h4><ul>
<li>케라스 텐서 생성</li>
<li>케라스 텐서는 백엔드(Theano, TensorFlow 혹은 CNTK)에서 사용되는 텐서에 몇가지 속성을 추가한 것으로, 이를 통해 모델의 입력과 출력을 아는 것만으로도 케라스 모델을 만들 수 있습니다.</li>
</ul>
<p>예를 들어 a, b와 c가 케라스 텐서라고 하면 model &#x3D; Model(input&#x3D;[a, b], output&#x3D;c)만으로도 모델을 생성할 수 있습니다.</p>
<p>케라스 텐서에 추가된 속성은 다음과 같습니다.<br><code>_keras_shape: 케라스의 형태 유추를 통해 전파되는 정수 튜플.</code><br><code>_keras_history: 텐서에 적용되는 마지막 층. 해당 층에서 전체 모델 전체의 그래프를 추출할 수 있습니다.</code></p>
<p><strong>인자</strong></p>
<ul>
<li><code>shape</code>: int로 이루어진 튜플. 배치 축을 포함하지 않습니다. 예를 들어 shape&#x3D;(32,)는 입력이 32차원 벡터의 배치라는 것을 나타냅니다.</li>
<li><code>batch_shape</code>: int로 이루어진 튜플. 배치 축을 포함합니다. 예를 들어 batch_shape&#x3D;(10, 32)는 입력이 10개의 32차원 벡터로 이루어진 배치라는 것을 나타냅니다. batch_shape&#x3D;(None, 32)는 임의의 수의 32차원 벡터로 이루어진 배치를 뜻합니다.</li>
<li><code>name</code>: str, 층의 문자열 이름. 모델 내에서 이름은 고유해야 하며 이미 사용한 이름은 다시 사용할 수 없습니다. 따로 지정하지 않을 경우, 자동으로 생성됩니다.</li>
<li><code>dtype</code>: str, 입력 데이터의 자료형(float32, float64, int32…) 입니다.</li>
<li><code>sparse</code>: bool, 생성할 플레이스홀더가 희소sparse한지 여부를 나타냅니다.</li>
<li><code>tensor</code>: 해당 인자가 주어진 경우 Input 층은 해당 텐서의 래퍼로 사용되며, 새로운 플레이스홀더 텐서를 만들지 않습니다.</li>
</ul>
<h4 id="Dense"><a href="#Dense" class="headerlink" title="Dense"></a>Dense</h4><ul>
<li><p><code>output = activation(dot(input, kernel) + bias)을 실행</code> </p>
<ul>
<li><code>activation</code>은 activation 인자로 전달되는 원소별element-wise 활성화 함수 </li>
<li><code>kernel</code>은 층에서 만들어진 <code>가중치 행렬weight matrix</code> </li>
<li><code>bias</code>는 층에서 만들어진 편향bias 벡터이며 ‘use_bias&#x3D;True’인 경우에만 적용 가능</li>
</ul>
</li>
<li><p>layer의 입력텐서의 rank가 2보다 클 경우 가중치 행렬과 내정을 하기 전에 1d 벡터로 형태를 변환해야함</p>
</li>
<li><p><strong>unit(출력층의 차원 수)과 <code>(*,입력층의 차원)</code> 형태의 배열을 인자로 받고 <code>(*,units)</code> 형태의 배열을 출력한다.</strong></p>
</li>
<li><p>input_shape 예시</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input_shape = (<span class="number">50</span>,<span class="number">50</span>,<span class="number">3</span>) <span class="comment"># regardless of how many images I have, each image has this shape  </span></span><br><span class="line">input_shape = (<span class="number">50</span>,<span class="number">50</span>,<span class="number">3</span>)</span><br><span class="line">  [[regardless]] of how many images I have, each image has this shape  </span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- Dense 예시</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">model = Sequential([</span><br><span class="line">                   Dense(32, input_shape = (16,))</span><br><span class="line">                   # (*,16)  형태의 배열을 받아서</span><br><span class="line">                   # (*,32) 형태의 배열을 출력한다.</span><br><span class="line">                   Dense(10)</span><br><span class="line">                   ]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dense(units,</span><br><span class="line"> activation=<span class="literal">None</span>,</span><br><span class="line"> use_bias=<span class="literal">True</span>,</span><br><span class="line"> kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line"> bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line"> kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line"> bias_regularizer=<span class="literal">None</span>, </span><br><span class="line"> activity_regularizer=<span class="literal">None</span>, </span><br><span class="line"> kernel_constraint=<span class="literal">None</span>, </span><br><span class="line"> bias_constraint=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Dense Parameters</strong></p>
<ul>
<li><code>units</code>: 양의 int. 출력값의 차원 크기를 결정.</li>
<li><code>activation</code>: 사용할 활성화 함수. 기본값은 None이며, 이 경우 활성화 함수가 적용되지 않는다.(a(x) &#x3D; x).</li>
<li><code>use_bias</code>: bool. 층의 연산에 편향을 적용할지 여부를 결정.</li>
<li><code>kernel_initializer</code>: kernel 가중치 행렬의 초기화 함수를 결정. 이 가중치는 입력값에 곱해져서 선형변환하는 연산에 사용.</li>
<li><code>bias_initializer</code>: 편향 벡터의 초기화 함수를 결정.</li>
<li><code>kernel_regularizer</code>: kernel 가중치 행렬에 적용할 규제 함수regularizer를 결정.</li>
<li><code>bias_regularizer</code>: 편향 벡터에 적용할 규제 함수를 결정.</li>
<li><code>activity_regularizer</code>: 층의 출력값에 적용할 규제 함수를 결정.</li>
<li><code>kernel_constraint</code>: kernel 가중치 행렬에 적용할 제약constraints을 결정. </li>
<li><code>bias_constraint</code>: 편향 벡터에 적용할 제약을 결정.</li>
<li><code>units</code>: 양의 int. 출력값의 차원 크기를 결정.</li>
</ul>
<h4 id="Activation"><a href="#Activation" class="headerlink" title="Activation"></a>Activation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Activation(activation)</span><br></pre></td></tr></table></figure>

<ul>
<li>출력값에 활성화함수 적용</li>
<li>모델의 첫 번째 층으로 Activation층을 사용하려면 input_shape로 형태를 지정해야 한다.</li>
<li><code>input_shape</code>는 int로 이루어진 튜플로 <strong>배치 축을 포함하지 않는다.</strong></li>
</ul>
<h4 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h4><ul>
<li>input을 1차원으로 바꾼다.</li>
<li>layer의 입력텐서의 rank 가 2보다 클 경우 가중치와 내적을 하기 전에 1차원 배열로 형태를 변환할때 사용한다.</li>
</ul>
<h4 id="Conv2d"><a href="#Conv2d" class="headerlink" title="Conv2d"></a>Conv2d</h4><h3 id="Sequential-API"><a href="#Sequential-API" class="headerlink" title="Sequential API"></a>Sequential API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model1 = keras.Sequential(</span><br><span class="line">                          []</span><br><span class="line"></span><br><span class="line">                          )</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>JinHeon Yoon
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/" title="">https://yjinheon.github.io/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/ko" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/10/28/machine-learning/notebook/machine-learning/unsupervised_learning/" rel="prev" title="">
                  <i class="fa fa-chevron-left"></i> 
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/10/28/machine-learning/notebook/machine-learning/7_model_pipeline/" rel="next" title="">
                   <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JinHeon Yoon</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/yjinheon" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.0/mermaid.min.js","integrity":"sha256-3JloMMI/ZQx6ryuhhZTsQJQmGAkXeni6PkshX7UUO2s="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



<!-- hexo injector body_end start --><script src="/js/hexo-widget-tree.js"></script><div id="widget-tree">
      <ul>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/backend/">
          backend
        </a>
      <span class="tree-list-count">4</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/backend/FastAPI/">
          FastAPI
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/backend/fastapi/back-fastapi-index/" title="[FastAPI]Index"><i class="post-icon gg-file-document"></i>[FastAPI]Index</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/backend/fastapi/back-fastapi-pydantic/" title="[FastAPI]Pydantic  데이터 업데이트"><i class="post-icon gg-file-document"></i>[FastAPI]Pydantic  데이터 업데이트</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/backend/Spring/">
          Spring
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2024/01/08/backend/spring/back-spring-threadlocal/" title="[Spring]threadlocal"><i class="post-icon gg-file-document"></i>[Spring]threadlocal</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2024/01/01/backend/spring/back-spring-troubleshooting/" title="[Spring]트러블슈팅"><i class="post-icon gg-file-document"></i>[Spring]트러블슈팅</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/FrontEnd/">
          FrontEnd
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/frond-end/fe-concepts/" title="프론트엔드 기본개념들"><i class="post-icon gg-file-document"></i>프론트엔드 기본개념들</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/frond-end/fe-javascript-index/" title="자바스크립트 코드스니펫"><i class="post-icon gg-file-document"></i>자바스크립트 코드스니펫</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Infra/">
          Infra
        </a>
      <span class="tree-list-count">5</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Infra/Config/">
          Config
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/08/infra/conda-install/" title="Anaconda 시작시 기본설정"><i class="post-icon gg-file-document"></i>Anaconda 시작시 기본설정</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Infra/git/">
          git
        </a>
      <span class="tree-list-count">4</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/infra/git/git-basic/" title="[Git]간단한 Git 명령어 및 용법 정리"><i class="post-icon gg-file-document"></i>[Git]간단한 Git 명령어 및 용법 정리</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/infra/git/git-commands/" title="[Git]기본적인 컨셉들"><i class="post-icon gg-file-document"></i>[Git]기본적인 컨셉들</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/infra/git/git-log/" title="[Git]commit, push 제외 자주쓰는 git 명령어들"><i class="post-icon gg-file-document"></i>[Git]commit, push 제외 자주쓰는 git 명령어들</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/infra/git/git-private-repo/" title="[Git]Private repository import 하기"><i class="post-icon gg-file-document"></i>[Git]Private repository import 하기</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Tools/">
          Tools
        </a>
      <span class="tree-list-count">4</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Tools/etc/">
          etc
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/03/tools/firefox/firefox-shortcut/" title="[Firefox]FireFox 단축키 정리하기"><i class="post-icon gg-file-document"></i>[Firefox]FireFox 단축키 정리하기</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Tools/Neovim/">
          Neovim
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/tools/nvim-keybinding/" title="[Neovim]NeoVim Keybinding"><i class="post-icon gg-file-document"></i>[Neovim]NeoVim Keybinding</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Tools/Intellij/">
          Intellij
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/tools/intellij/Intellij-shortcut/" title="[Intellij]Intellij 단축키 정리"><i class="post-icon gg-file-document"></i>[Intellij]Intellij 단축키 정리</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/tools/obsidian/obsidian-shortcut/" title="[Obsidian]Obsidian 커스텀 단축키 업데이트"><i class="post-icon gg-file-document"></i>[Obsidian]Obsidian 커스텀 단축키 업데이트</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Data-Engineering/">
          Data Engineering
        </a>
      <span class="tree-list-count">13</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Data-Engineering/Linux/">
          Linux
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/10/08/data-engineering/linux/DE-linux-commandline/" title="[linux]데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음"><i class="post-icon gg-file-document"></i>[linux]데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/11/08/data-engineering/linux/DE-linux-seteditor/" title="[linux]기본 에디터 neovim으로 변경하기"><i class="post-icon gg-file-document"></i>[linux]기본 에디터 neovim으로 변경하기</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Programming/">
          Programming
        </a>
      <span class="tree-list-count">13</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Programming/R/">
          R
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/03/02/programming/R-Programming-operators/" title="[R]특별한 R 연산자들(Binary Oerators)"><i class="post-icon gg-file-document"></i>[R]특별한 R 연산자들(Binary Oerators)</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Programming/Java/">
          Java
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/11/25/programming/java/Java-Action/" title="[Java]기본컨셉들"><i class="post-icon gg-file-document"></i>[Java]기본컨셉들</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2024/01/07/programming/java/Java-Basic/" title="[Java]기본컨셉들"><i class="post-icon gg-file-document"></i>[Java]기본컨셉들</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Programming/Python/">
          Python
        </a>
      <span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/programming/python/Python-Closure/" title="[Python]Closure에 대한 이해"><i class="post-icon gg-file-document"></i>[Python]Closure에 대한 이해</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/30/programming/python/Python-init_call/" title="[Python] init, call method"><i class="post-icon gg-file-document"></i>[Python] init, call method</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2024/01/17/programming/python/Python-Tricks/" title="[Python]간단한 트릭들"><i class="post-icon gg-file-document"></i>[Python]간단한 트릭들</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Preprocessing/">
          Preprocessing
        </a>
      <span class="tree-list-count">8</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-dt-Scaler/" title="[Data Transformation]Feature Scaling의 이해"><i class="post-icon gg-file-document"></i>[Data Transformation]Feature Scaling의 이해</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-numpy-basics/" title="[Python]numpy 연산과 활용법"><i class="post-icon gg-file-document"></i>[Python]numpy 연산과 활용법</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-pandas-collection-to-df/" title="[pandas]기본자료형을 DataFrame으로 변환하기"><i class="post-icon gg-file-document"></i>[pandas]기본자료형을 DataFrame으로 변환하기</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-pandas-remove_col/" title="[pandas]pandas의 특정 열 제외한 모든 컬럼 출력하기"><i class="post-icon gg-file-document"></i>[pandas]pandas의 특정 열 제외한 모든 컬럼 출력하기</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-pandas_groupby/" title="[pandas]Pandas Groupby용법 간단히 정리"><i class="post-icon gg-file-document"></i>[pandas]Pandas Groupby용법 간단히 정리</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-pandas_overview/" title="[pandas]Pandas를 활용한 데이터분석 시작하기"><i class="post-icon gg-file-document"></i>[pandas]Pandas를 활용한 데이터분석 시작하기</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-pandas_tricks/" title="[pandas]pandas 함수와 기초용법들"><i class="post-icon gg-file-document"></i>[pandas]pandas 함수와 기초용법들</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/preprocessing/Preprocessing-sampling-imbalance-data/" title="[Sampling]Class Imbalance 다루기"><i class="post-icon gg-file-document"></i>[Sampling]Class Imbalance 다루기</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Neural-Network/">
          Neural Network
        </a>
      <span class="tree-list-count">7</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/05/machine-learning/DL-RNN/" title="[Neural Network]Recurrent Neural Network"><i class="post-icon gg-file-document"></i>[Neural Network]Recurrent Neural Network</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/09/28/machine-learning/DL-backpropagation/" title="[Neural Network]역전파 알고리즘(backpropagation)"><i class="post-icon gg-file-document"></i>[Neural Network]역전파 알고리즘(backpropagation)</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/30/machine-learning/DL-hyperparameter/" title="[Neural Network]하이퍼파라미터"><i class="post-icon gg-file-document"></i>[Neural Network]하이퍼파라미터</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/15/machine-learning/DL-lossfunction/" title="[Deep Learning]Loss function"><i class="post-icon gg-file-document"></i>[Deep Learning]Loss function</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/10/machine-learning/DL-optimizer/" title="[Deep Learning]Optimizer"><i class="post-icon gg-file-document"></i>[Deep Learning]Optimizer</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/03/machine-learning/DL-perceptron/" title="[Neural Network]Perceptron의 이해"><i class="post-icon gg-file-document"></i>[Neural Network]Perceptron의 이해</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/machine-learning/DL-regularization/" title="[Deep Leearing] 학습 규제하기(Handling Overfitting)"><i class="post-icon gg-file-document"></i>[Deep Leearing] 학습 규제하기(Handling Overfitting)</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Machine-Learning/">
          Machine Learning
        </a>
      <span class="tree-list-count">12</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Machine-Learning/Supervised-Learning/">
          Supervised Learning
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/ML-SP-SVM/" title="[SVM]서포트벡터머신의 이해"><i class="post-icon gg-file-document"></i>[SVM]서포트벡터머신의 이해</a></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/NLP/">
          NLP
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/NLP-NLU/" title="[NLP]NLU & QA task"><i class="post-icon gg-file-document"></i>[NLP]NLU & QA task</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2022/03/02/machine-learning/NLP-wordembedding/" title="[NLP]Word Embedding과 Text Classification"><i class="post-icon gg-file-document"></i>[NLP]Word Embedding과 Text Classification</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Troubleshooting/">
          Troubleshooting
        </a>
      <span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/troubleshooting/TS-R-lib-1/" title="[R]make: gfortran: No such file or directory 해결하기"><i class="post-icon gg-file-document"></i>[R]make: gfortran: No such file or directory 해결하기</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/12/01/troubleshooting/TS-SQL-ts-1/" title="[SQL]ERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides 해결하기"><i class="post-icon gg-file-document"></i>[SQL]ERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides 해결하기</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/troubleshooting/TS-linux-ts-1/" title="[Linux]zsh: corrupt history file 해결"><i class="post-icon gg-file-document"></i>[Linux]zsh: corrupt history file 해결</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Statistics/">
          Statistics
        </a>
      <span class="tree-list-count">5</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/11/26/statistics/Statistics-GLM-test/" title="[GLM]선형모델과 비선형 모델의 차이"><i class="post-icon gg-file-document"></i>[GLM]선형모델과 비선형 모델의 차이</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/statistics/Statistics-Math-derivatives/" title="[Math]미분 기초개념"><i class="post-icon gg-file-document"></i>[Math]미분 기초개념</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/statistics/Statistics-Prob-binary-dist/" title="[Probability]이항분포의 이해"><i class="post-icon gg-file-document"></i>[Probability]이항분포의 이해</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/statistics/Statistics-Prob-chi-square-dist/" title="[Probability]Python을 활용한 카이스퀘어 검정 구현"><i class="post-icon gg-file-document"></i>[Probability]Python을 활용한 카이스퀘어 검정 구현</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/10/statistics/Statistics-Prob-multinomial-dist/" title="[Probability]numpy와 scipy로 다항분포 간단하게 구현하기"><i class="post-icon gg-file-document"></i>[Probability]numpy와 scipy로 다항분포 간단하게 구현하기</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/programming/">
          programming
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/11/12/programming/oop/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/ariflow/">
          ariflow
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/23/data-engineering/airflow/airflow-index/" title="[airflow]Index"><i class="post-icon gg-file-document"></i>[airflow]Index</a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/">
          machine-learning
        </a>
      <span class="tree-list-count">23</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/">
          notebook
        </a>
      <span class="tree-list-count">23</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/machine-learning/">
          machine-learning
        </a>
      <span class="tree-list-count">9</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/3_bias_variance/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/3_distance_based_model/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/7_model_pipeline/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/09/machine-learning/notebook/machine-learning/design_pattern/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/template/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/unsorted/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/unsupervised_learning/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/machine-learning/xai/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/assets/">
          assets
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/assets/References/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/preprocessing/">
          preprocessing
        </a>
      <span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/preprocessing/Preprocessing/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/preprocessing/deal/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/statitsics/">
          statitsics
        </a>
      <span class="tree-list-count">4</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/statitsics/1-probability/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/statitsics/3-parameter-estimation/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/statitsics/glm/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/statitsics/survival-analisis/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/timeseries/">
          timeseries
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/timeseries/TimeSeries/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/machine-learning/notebook/visualization/">
          visualization
        </a>
      <span class="tree-list-count">4</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/visualization/Visualization/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/10/28/machine-learning/notebook/visualization/mpl-seaborn/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/09/machine-learning/notebook/visualization/olap/" title=""><i class="post-icon gg-file-document"></i></a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/09/machine-learning/notebook/visualization/plotly/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li></ul></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/frond-end/">
          frond-end
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/frond-end/react/">
          react
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2023/12/16/frond-end/react/react-index/" title=""><i class="post-icon gg-file-document"></i></a></li></ul></li></ul></li></ul>
        <div id="widget-tree-button">
          <i class="gg-chevron-right"></i>
        </div>
      </div><!-- hexo injector body_end end --></body>
</html>
