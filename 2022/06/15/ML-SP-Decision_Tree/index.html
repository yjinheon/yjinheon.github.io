<!DOCTYPE html>
<html lang="en">
    <!-- title -->


    

<!-- keywords -->



<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="JinHeon Yoon">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="JinHeon Yoon">
    
        <meta name="keywords" content="Machine Learning,NLP,Recommendation System,Neural Network,Psychology">
    
    <meta name="description" content="">
    <meta name="description" content="Decision Tree의 이해 Concept  Decision Tree(결정트리): 질문을 던지고 답을 하는 과정을 연쇄적으로 반복해 집단을 분류하거나 예측하는 분석방법. threshold : 결정트리에서의 학습대상. 정확히는 데이터를 나누는 best feature의 best threshold를 찾는 것이 학습의 목적이다, full tree : 모든">
<meta property="og:type" content="article">
<meta property="og:title" content="[Tree]Decision Tree의 이해">
<meta property="og:url" content="https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/index.html">
<meta property="og:site_name" content="DataMind">
<meta property="og:description" content="Decision Tree의 이해 Concept  Decision Tree(결정트리): 질문을 던지고 답을 하는 과정을 연쇄적으로 반복해 집단을 분류하거나 예측하는 분석방법. threshold : 결정트리에서의 학습대상. 정확히는 데이터를 나누는 best feature의 best threshold를 찾는 것이 학습의 목적이다, full tree : 모든">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://miro.medium.com/max/888/1*FYEZGG-gEijSb87KuxSE_Q.png">
<meta property="og:image" content="https://miro.medium.com/max/750/1*M15RZMSk8nGEyOnD8haF-A.png">
<meta property="og:image" content="https://tensorflowkorea.files.wordpress.com/2018/03/overview-plot.png">
<meta property="article:published_time" content="2022-06-15T10:04:43.820Z">
<meta property="article:modified_time" content="2022-04-14T22:10:22.000Z">
<meta property="article:author" content="JinHeon Yoon">
<meta property="article:tag" content="Decision Tree">
<meta property="article:tag" content="Supervised Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://miro.medium.com/max/888/1*FYEZGG-gEijSb87KuxSE_Q.png">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <link rel="icon" href="/assets/medium.ico">
    
    <title>[Tree]Decision Tree의 이해 · Datamind&#39;s Studio</title>
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
    (function (w) {
        'use strict'
        // rel=preload support test
        if (!w.loadCSS) {
            w.loadCSS = function () {}
        }
        // define on the loadCSS obj
        var rp = (loadCSS.relpreload = {})
        // rel=preload feature support test
        // runs once and returns a function for compat purposes
        rp.support = (function () {
            var ret
            try {
                ret = w.document.createElement('link').relList.supports('preload')
            } catch (e) {
                ret = false
            }
            return function () {
                return ret
            }
        })()

        // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
        // then change that media back to its intended value on load
        rp.bindMediaToggle = function (link) {
            // remember existing media attr for ultimate state, or default to 'all'
            var finalMedia = link.media || 'all'

            function enableStylesheet() {
                link.media = finalMedia
            }

            // bind load handlers to enable media
            if (link.addEventListener) {
                link.addEventListener('load', enableStylesheet)
            } else if (link.attachEvent) {
                link.attachEvent('onload', enableStylesheet)
            }

            // Set rel and non-applicable media type to start an async request
            // note: timeout allows this to happen async to let rendering continue in IE
            setTimeout(function () {
                link.rel = 'stylesheet'
                link.media = 'only x'
            })
            // also enable media after 3 seconds,
            // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
            setTimeout(enableStylesheet, 3000)
        }

        // loop through link elements in DOM
        rp.poly = function () {
            // double check this to prevent external calls from running
            if (rp.support()) {
                return
            }
            var links = w.document.getElementsByTagName('link')
            for (var i = 0; i < links.length; i++) {
                var link = links[i]
                // qualify links to those with rel=preload and as=style attrs
                if (
                    link.rel === 'preload' &&
                    link.getAttribute('as') === 'style' &&
                    !link.getAttribute('data-loadcss')
                ) {
                    // prevent rerunning on link
                    link.setAttribute('data-loadcss', true)
                    // bind listeners to toggle media back
                    rp.bindMediaToggle(link)
                }
            }
        }

        // if unsupported, run the polyfill
        if (!rp.support()) {
            // run once at least
            rp.poly()

            // rerun poly on an interval until onload
            var run = w.setInterval(rp.poly, 500)
            if (w.addEventListener) {
                w.addEventListener('load', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            } else if (w.attachEvent) {
                w.attachEvent('onload', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            }
        }

        // commonjs
        if (typeof exports !== 'undefined') {
            exports.loadCSS = loadCSS
        } else {
            w.loadCSS = loadCSS
        }
    })(typeof global !== 'undefined' ? global : this)
</script>

    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>

    <link rel="preload" href="/css/style.css?v=20211217" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="/css/dark.css?v=20211217" as="style">
    <link rel="stylesheet" href="/css/dark.css">
    <link rel="stylesheet" href="/css/mobile.css?v=20211217" media="(max-width: 960px)">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" as="script">
    <link rel="preload" href="/scripts/main.js?v=20211217" as="script">
    <link rel="preload" href="/scripts/dark.js?v=20211217" as="script">
    <link rel="preload" href="/font/Oswald-Regular.ttf" as="font" crossorigin>
    <link rel="preload" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" as="font" crossorigin>
    <!-- algolia -->
    
        <script>
            var hits = JSON.parse('{"per_page":10}')
            var labels = JSON.parse('{"input_placeholder":"Search for Posts","hits_empty":"We did not find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}')

            var algolia = {
                applicationID: '8FYPUQLMYX',
                apiKey: '8a27997f6a477d9531b0129e125ccbed',
                indexName: 'my_blog',
                hits: hits,
                labels: labels
            }
        </script>
    
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PVGMWSW');</script>
    <!-- End Google Tag Manager -->
<meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/rss2.xml" title="DataMind" type="application/rss+xml">
</head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZLLXQWC87"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-8ZLLXQWC87');
</script><!-- End Google Analytics -->


    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ == undefined) {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js" />')
        }
    </script>
    
        <body class="post-body">
    
        <!-- header -->
        <header class="header header-mobile">
    <!-- top read progress line -->
    <div class="header-element">
        <div class="read-progress"></div>
    </div>
    <!-- sidebar menu button -->
    <div class="header-element">
        
            <div class="header-sidebar-menu">
        
            
                <div style="padding-left: 1px;">&#xe775;</div>
            
        </div>
    </div>
    <!-- header actions -->
    <div class="header-actions">
        <!-- theme mode switch button -->
        <span class="header-theme-btn header-element">
            <i class="fas fa-adjust"></i>
        </span>
        <!-- back to home page text -->
        <span class="home-link header-element">
            <a href=/>Datamind's Studio</a>
        </span>
    </div>
    <!-- toggle banner for post layout -->
    
        
            <div class="banner">
        
            <div class="blog-title header-element">
                <a href="/">Datamind&#39;s Studio</a>
            </div>
            <div class="post-title header-element">
                <a href="#" class="post-name">[Tree]Decision Tree의 이해</a>
            </div>
        </div>
    
</header>

        <!-- fixed footer -->
        <footer class="footer-fixed">
    <!-- back to top button -->
    <div class="footer-fixed-element">
        
            <div class="back-top back-top-hidden">
        
        
            <div>&#xe639;</div>
        
        </div>
    </div>
</footer>

        <!-- wrapper -->
        <div class="wrapper">
            <div class="site-intro" style="







    height:50vh;

">
    
    <!-- 主页  -->
    
        
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/post-bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
                [Tree]Decision Tree의 이해
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
                
            <!-- 404 -->
            
        </p>
        <!-- 文章页 meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
    
        <a class="post-tag" href="javascript:void(0);" data-tags="Decision Tree">Decision Tree</a>
    
        <a class="post-tag" href="javascript:void(0);" data-tags="Supervised Learning">Supervised Learning</a>
    
</div>

                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">2k</span>Reading time: <span class="post-count reading-time">12 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <!-- 撰写日期 -->
                    <span class="iconfont-archer post-intro-calander">&#xe676;</span>
                    <span class="post-intro-time">2022/06/15</span>
                    <!-- busuanzi -->
                    
                    <!-- 文章分享 -->
                    <span class="share-wrapper">
                        <span class="iconfont-archer share-icon">&#xe71d;</span>
                        <span class="share-text">Share</span>
                        <ul class="share-list">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>

            <script>
  // get user agent
  function getBrowserVersions() {
    var u = window.navigator.userAgent
    return {
      userAgent: u,
      trident: u.indexOf('Trident') > -1, //IE内核
      presto: u.indexOf('Presto') > -1, //opera内核
      webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
      gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
      mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
      ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
      android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
      iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
      iPad: u.indexOf('iPad') > -1, //是否为iPad
      webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
      weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
      uc: u.indexOf('UCBrowser') > -1, //是否为android下的UC浏览器
    }
  }
  var browser = {
    versions: getBrowserVersions(),
  }
  console.log('userAgent: ' + browser.versions.userAgent)

  // callback
  function fontLoaded() {
    console.log('font loaded')
    if (document.getElementsByClassName('site-intro-meta')) {
      document
        .getElementsByClassName('intro-title')[0]
        .classList.add('intro-fade-in')
      document
        .getElementsByClassName('intro-subtitle')[0]
        .classList.add('intro-fade-in')
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in')
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb() {
    if (browser.versions.uc) {
      console.log('UCBrowser')
      fontLoaded()
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular'],
        },
        loading: function () {
          // 所有字体开始加载
          // console.log('font loading');
        },
        active: function () {
          // 所有字体已渲染
          fontLoaded()
        },
        inactive: function () {
          // 字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout')
          fontLoaded()
        },
        timeout: 5000, // Set the timeout to two seconds
      })
    }
  }

  function asyncErr() {
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0]
    o.src = u
    if (cb) {
      o.addEventListener(
        'load',
        function (e) {
          cb(null, e)
        },
        false
      )
    }
    if (err) {
      o.addEventListener(
        'error',
        function (e) {
          err(null, e)
        },
        false
      )
    }
    s.parentNode.insertBefore(o, s)
  }

  var asyncLoadWithFallBack = function (arr, success, reject) {
    var currReject = function () {
      reject()
      arr.shift()
      if (arr.length) async(arr[0], success, currReject)
    }

    async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack(
    [
      'https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js',
      'https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js',
      "/lib/webfontloader.min.js",
    ],
    asyncCb,
    asyncErr
  )
</script>

            <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
            <div class="container container-unloaded">
                <main class="main post-page">
    <article class="article-entry">
        <!--

<center>Kaggle Customer Score Dataset</center>

- Machine Learning
- Statistics , Math
- Data Engineering
- Programming
- EDA & Visualization
- Preprocessing


#신경망이란 무엇인가?

https://www.youtube.com/watch?v=aircAruvnKk


#참고

https://cinema4dr12.tistory.com/1016?category=515283

https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html
-->

<h2 id="Decision-Tree의-이해"><a href="#Decision-Tree의-이해" class="headerlink" title="Decision Tree의 이해"></a>Decision Tree의 이해</h2><hr>
<p><strong><em>Concept</em></strong></p>
<ul>
<li><strong>Decision Tree(결정트리)</strong>: 질문을 던지고 답을 하는 과정을 연쇄적으로 반복해 집단을 분류하거나 예측하는 분석방법.</li>
<li><strong>threshold</strong> : 결정트리에서의 학습대상. 정확히는 데이터를 나누는 best feature의 best threshold를 찾는 것이 학습의 목적이다,</li>
<li><strong>full tree</strong> : 모든 학습데이터에 대해 분기한 상태.</li>
<li><strong>Entropy</strong> : Entropy 는 데이터셋의 불순도와 무질서한 정도를 나타내는 측정치</li>
<li><strong>지니 불순도</strong> : 데이터 집합에서 클래스 분포에 따라 무작위로 라벨이 지정된 경우 무작위로 선택한 요소들을 잘못 분류할 확률이다.(Chance of being incorrect if you randomly assign a label to an example in the same set)</li>
<li><strong>정보 이득</strong> : 정보 이득은 단순히 부모 노드의 불순도와 자식 노드의 불순도 합의 차이.</li>
<li><strong>Root Node</strong> : 초기노드. 데이터셋 혹은 샘플 전체. </li>
<li><strong>Leaf Node(Terminal Node)</strong> : 자식이 없는 노드.하위노드가 없다.</li>
<li><strong>Pure Node</strong> : 노드의 모든 데이터포인트가 하나의 클래스에 할당되어 있을 경우. 타깃 한개로만 이루어진 Leaf Node.</li>
<li><strong>Branch</strong> : sub-section of an entire tree.</li>
<li><strong>Splitting</strong> : 특정 노드를 나눠 하위노드를 생성하는 것.</li>
<li><strong>Pruning</strong> : 특정 노드의 하위노드를 날리는 것(삭제).</li>
<li><strong>Pre-prune</strong>: When you stop growing DT branches when information becomes unreliable.</li>
<li><strong>Post-prune</strong>: When you take a fully grown DT and then remove leaf nodes only if it results in a better model performance. This way, you stop removing nodes when no further improvements can be made.</li>
</ul>
<p><img src="https://miro.medium.com/max/888/1*FYEZGG-gEijSb87KuxSE_Q.png"></p>
<hr>
<h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><hr>
<ul>
<li>SVM처럼 <strong>분기점(threshold)을 학습한다.</strong></li>
<li>기본적으로 정보이득량이 가장 커지는 방식으로 반복적으로 분할을 진행(recursive partitioning)한다.</li>
<li><strong>분기의 기준이 정보이득이라는 것이 핵심이다.</strong></li>
<li>과적합을 방지하기 위해 pruning이 필요하다.</li>
<li>선형모델과 달리 비선형(non-linear), 비단조(non-monotonic), 특성상호작용(feature interactions) 특징을 가지고 있는 데이터 분석에 용이하다.</li>
<li>특성을 해석하기 좋아 많이 쓰임</li>
<li><strong>샘플에 민감해 트리 고저가 자주 바뀐다.</strong></li>
<li>앙상블 방법의 기초가 된다.</li>
<li><strong>결정트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예&#x2F;아니오 질문 목록을 학습한다는 것이다. 이러한 질문들을 test라고 한다.</strong></li>
<li>학습 데이터셋에 과대적합되는 경향이 있다.</li>
<li>결정트리의 트리를 제어하지 않으면 트리는 무한정 깁어지고 복잡해진다.(일반화 성능이 낮아진다.)</li>
<li>따라서 사전&#x2F;사후 가지치기를 통해 과대적합을 방지한다.</li>
<li>알고리즘 특성상 feature scaling이 필요하지 않지만 주로 다른 알고리즘과의 비교(시각화)를 위해 scaling을 해주는 경우도 있다.</li>
</ul>
<h3 id="불순도-지표"><a href="#불순도-지표" class="headerlink" title="불순도 지표"></a>불순도 지표</h3><hr>
<h4 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h4><hr>
<p><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/11/[]entropy-a-key-concept-for-all-data-science-beginners/">엔트로피 중요개념</a></p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8">매우중요</a></p>
<ul>
<li>Entropy 는 데이터셋의 불순도와 무질서한 정도를 나타내는 측정치이다.(measure disorder)</li>
<li>0~1의 값을 가진다.<ul>
<li>클래스가 완전히 균일하게 분포되어있을 경우(0.5) Entropy가 최대인 1이된다. </li>
<li>데이터셋의 요소의 분포가 특정 클래스에 치우쳐있을수록 Entropy가 0에 가까워진다.</li>
</ul>
</li>
<li>트리를 만들때 알고리즘은 가능한 모든 테스트에서 타깃값에 대해 가장 많은 정보를 가진 것을 고른다. -&gt; 엔트로피가 최소화되는 방향으로 학습을 진행한다.</li>
</ul>
<p align="center">
<img src="https://miro.medium.com/max/750/1*M15RZMSk8nGEyOnD8haF-A.png" alt="drawing" width="400"/>
</p>

<ul>
<li><strong>정보이득은 엔트로피의 변화량으로 계산된다.(1-엔트로피)</strong></li>
<li>N은 범주의 개수</li>
<li>$p_{i}$ 는 p 영역에 속한 데이터 중 i 범주에 속하는 데이터의 비율.</li>
</ul>
<p>$$\text { Entropy }(p)&#x3D;-\sum_{i&#x3D;1}^{N} p_{i} \log <em>{2} p</em>{i}$$</p>
<h4 id="지니불순도"><a href="#지니불순도" class="headerlink" title="지니불순도"></a>지니불순도</h4><hr>
<ul>
<li><strong>잘못 분류될 확률을 최소화하기 위한 기준이다.</strong><ul>
<li>정확히는 <code>데이터 집합에서 클래스 분포에 따라 무작위로 라벨이 지정된 경우 무작위로 선택한 요소들을 잘못 분류할 확률이다.(Chance of being incorrect if you randomly assign a label to an example in the same set)</code></li>
<li>기본적으로 Single Node에 대해 계산한 값이다,</li>
</ul>
</li>
<li>클래스의 비율이 완벽히 균등할 때 최대가 된다.</li>
<li>기본적으로 노드가 중요할수록 불순도가 크게 감소한다.</li>
<li>범주형데이터가 라벨이라면 카디널리티가 적을 수록 불순도는 낮아진다.</li>
<li><strong>Entropy와 지니불순도의 차이는 불순도의 max가 Entopy가 보다 높다는 것이다.</strong></li>
<li><strong>지니불순도가 가장 낮은 Feature statement를 의사결정 트리의 가장 위에 놓는다.</strong>(지니인덱스가 낮으면 불순도가 낮기 때문에 루트노드에 올 가능성이 높아진다.)<ul>
<li>불순도가 낮다는 것은 해당 Feature statement로 인한 정보이득이 높다는 것이다.</li>
</ul>
</li>
<li>최초 노드의 impurity(unsertainty)에서 마지막 노드의 uncertainty를 뺀 값이 information Gain 이다.</li>
<li>Entropy와 달리 식에 log가 없어 계산시 약간 유리하다.</li>
<li>Gain이 가장 큰쪽으로 가지치기를 반복하는 것이 기본적인 의사결정 트리 알고리즘이다.</li>
</ul>
<p>$$\text{Gini Impurity}&#x3D;\sum_{i&#x3D;1}^{N} p(i) *(1-p(i))$$</p>
<h4 id="information-Gain"><a href="#information-Gain" class="headerlink" title="information Gain"></a>information Gain</h4><hr>
<ul>
<li>leaf의 결과는 기본적으로 majority 를 반환한다.</li>
<li><strong>정보 이득은 단순히 부모 노드의 불순도와 자식 노드의 불순도 합의 차이이다.</strong><ul>
<li>이진트리의 경우 자식트리인 왼쪽,오른쪽 트리의 불순도의 합을 부모노드에서 뺀다.</li>
</ul>
</li>
<li>Information Gain is calculated for a split by subtracting the weighted entropies of each branch from the original entropy. When training a Decision Tree using these metrics, the best split is chosen by maximizing Information Gain.</li>
</ul>
<p>$$IG(Parent,Children) &#x3D; E(Parent) - E(Parent | Children)$$</p>
<ul>
<li><strong>자식 노드의 불순도가 낮을수록 정보 이득이 커진다.</strong> </li>
<li>보통 모듈에서 이진 결정 트리를 사용하므로 부모노드는 두 개의 자식 노드로 나눠진다.</li>
</ul>
<p>$$\text {E(parent)} - [\text {weighted average}] * E(children)$$</p>
<p><img src="https://tensorflowkorea.files.wordpress.com/2018/03/overview-plot.png"></p>
<ul>
<li>엔트로피보다 지니 불순도 방식이 불순도 값을 줄이기 위해 더 클래스 확률을 낮추어야 한다.</li>
<li>엔트로피를 불순도 지표로 사용할 경우 지니불순도를 사용하는 것보다 더 균형잡힌 트리를 만들 가능성이 높다.</li>
</ul>
<h3 id="결정트리의-최적화-문제"><a href="#결정트리의-최적화-문제" class="headerlink" title="결정트리의 최적화 문제"></a>결정트리의 최적화 문제</h3><hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://data-notes.co/decision-trees-how-to-optimize-my-decision-making-process-e1f327999c7a">최적화 원리와 코드</a></li>
</ul>
<p><strong>Training algorithm</strong></p>
<ul>
<li><p><strong>기본적으로 Best Threshold를 찾는 문제이다</strong></p>
</li>
<li><p>Start at the top node and at each node select the best split based o the best information gain</p>
</li>
<li><p>Greedy Search : Loop over all features and over all thresholds (<strong>all possible feature values</strong>)</p>
</li>
<li><p>Save the best split features and split threshold at each node</p>
</li>
<li><p>Build the tree recursively</p>
</li>
<li><p>Apply some stopping criteria to stop growing</p>
<ul>
<li>maximum depth</li>
<li>minimum samples</li>
<li>etc..</li>
</ul>
</li>
<li><p>When we have a leaf node, store the most common class label of this node</p>
</li>
</ul>
<p><strong>Predict :&#x3D; Traverse tree</strong></p>
<ul>
<li>Traverse the tree recursively.</li>
<li>At each node look at the best split feature of the test feature vector x and go left or right <strong>depending on x[feature idx] &lt;&#x3D; threshold</strong></li>
<li>When we reach the leaf node we return the stored most common class label</li>
</ul>
<h3 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h3><hr>
<p><strong>Put limits in How trees grow</strong></p>
<h4 id="PrePruning"><a href="#PrePruning" class="headerlink" title="PrePruning"></a>PrePruning</h4><hr>
<ul>
<li><p>트리의 최대 깊이 제한하기(max_depth)</p>
</li>
<li><p>리프의 최대 개수 제한하기</p>
</li>
<li><p>노드가 분할하기 위한 데이터 포인트의 최소 개수 지정</p>
</li>
<li><p>sklearn에서 제공하는 관련 Hyperparameter</p>
<ul>
<li>max_depth : 일반화 성능관련. 트리의 최대깊이<ul>
<li>min_sample_splite</li>
<li>max_feature : 최대 피처 사용수</li>
<li>random_state : random state</li>
<li>class_weight : 가중치 balance 맟추기</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="PostPruning"><a href="#PostPruning" class="headerlink" title="PostPruning"></a>PostPruning</h4><hr>
<p>Post-pruning is also known as backward pruning. In this, first generate the decision tree and then remove non-significant branches. Post-pruning a decision tree implies that we begin by generating the (complete) tree and then adjust it with the aim of improving the accuracy on unseen instances. There are two principal methods of doing this. One method that is widely used begins by converting the tree to an equivalent set of rules. Another commonly used approach aims to retain the decision tree but to replace some of its subtrees by leaf nodes, thus converting a complete tree to a smaller pruned one which predicts the classification of unseen instances at least as accurately. There are various methods for the post pruning.</p>
<h3 id="Feature-Importance-in-Decision-Tree"><a href="#Feature-Importance-in-Decision-Tree" class="headerlink" title="Feature Importance in Decision Tree"></a>Feature Importance in Decision Tree</h3><hr>
<h3 id="More-to-learn"><a href="#More-to-learn" class="headerlink" title="More to learn"></a>More to learn</h3><hr>
<ul>
<li>Pruning</li>
<li>Handling missing data</li>
<li>Building Trees for regression</li>
<li>Using trees to explore datasets</li>
</ul>
<p><strong>more</strong></p>
<ul>
<li>Gini-Index is providing us with the highest accuracy with max depth &#x3D; 6.</li>
<li>Entropy and Gini-index can behave similarly with appropriately selected min_weight_fraction_leaf.</li>
<li>With min_samples_split as 7, Entropy is outperforming Gini for a rudimentary assumption that More samples will provide more information gain and tend to skew the Gini index as the impurity increases.</li>
</ul>
<p>Therefore with taking the criteria as Gini and max_depth &#x3D; 6, we obtained the accuracy as 32% which is an 18% increase from without using parametric optimization. Hence, Optimizing the parameter rightfully, will increase the model accuracy and provide better results.</p>
<p><strong>결정트리의 장점</strong></p>
<ul>
<li>설명가능성</li>
</ul>
<p><strong>결정트리의 단점</strong></p>
<ul>
<li>과적합</li>
</ul>
<h3 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h3><hr>
<ul>
<li>numpy로 구현</li>
<li><strong>기본적으로 Best Split Threshold를 찾는 것이 목적이다.</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropy</span>(<span class="params">y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the entropy of a label vector</span></span><br><span class="line"><span class="string">    :param y: label vector</span></span><br><span class="line"><span class="string">    :return: entropy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    hist = np.bincount(y) <span class="comment"># class distribution # 0부터 max까지 class label의 빈도</span></span><br><span class="line">    ps = hist / <span class="built_in">len</span>(y) <span class="comment"># probability of each class</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> -np.<span class="built_in">sum</span>([p * np.log2(p) <span class="keyword">for</span> p <span class="keyword">in</span> ps <span class="keyword">if</span> p != <span class="number">0</span>]) <span class="comment"># 음수에 대해서는 정의하지 않음</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,feature=<span class="literal">None</span>,threshold=<span class="literal">None</span>,left=<span class="literal">None</span>,right=<span class="literal">None</span>,*,value=<span class="literal">None</span></span>):</span><br><span class="line">        self.feature = feature</span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line">        self.value = value</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_leaf</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="comment"># leaf node의 경우 value가 있다.</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecisionTree</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, min_samples_split=<span class="number">2</span>, max_depth=<span class="number">100</span>, n_feats = <span class="literal">None</span></span>):</span><br><span class="line">        self.min_samples_split = min_samples_split</span><br><span class="line">        self.max_depth = max_depth</span><br><span class="line">        self.n_feats = n_feats</span><br><span class="line">        self.root = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># grow tree</span></span><br><span class="line">        <span class="comment"># X.shape[1] : feature의 개수</span></span><br><span class="line">        </span><br><span class="line">        self.n_feats = X.shape[<span class="number">1</span>] <span class="keyword">if</span> <span class="keyword">not</span> self.n_feats <span class="keyword">else</span> <span class="built_in">min</span>(self.n_feats, X.shape[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># if not self.n_feats -&gt; n.feats가 정의되있지 않을 경우  min(self.n_feats,X.shape[1]) </span></span><br><span class="line">        <span class="comment"># input의 feature 수보다 n_feats기 커지지 않게끔하는 </span></span><br><span class="line">        self.root = self._grow_tree(X, y)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_grow_tree</span>(<span class="params">self, X, y, depth=<span class="number">0</span></span>):</span><br><span class="line">        n_sample, n_feats = X.shape</span><br><span class="line">        n_labels = <span class="built_in">len</span>(np.unique(y))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># stopping criteria # 더 이상 분류할 수 없는 경우 혹은 pruning 기준에 도달한 경우</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (</span><br><span class="line">            depth &gt;= self.max_depth </span><br><span class="line">            <span class="keyword">or</span> n_labels == <span class="number">1</span> </span><br><span class="line">            <span class="keyword">or</span> n_sample &lt; self.min_samples_split</span><br><span class="line">        ):</span><br><span class="line">            leaf_value = self._most_common_label(y)</span><br><span class="line">            <span class="keyword">return</span> Node(value=leaf_value)</span><br><span class="line">        </span><br><span class="line">        feat_idxs = np.random.choice(n_feats, self.n_feats, replace=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># calculate information gain</span></span><br><span class="line">        best_feat, best_threshold = self._best_criteria(X, y, feat_idxs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># grow the children that result from splitting on the best feature</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 정보이득을 계산한 best_feature와 best threshold 기준으로 분할</span></span><br><span class="line">        left_idxs , right_idxs = self._split(X[:,best_feat], best_threshold)</span><br><span class="line">        left = self._grow_tree(X[left_idxs,:], y[left_idxs], depth+<span class="number">1</span>) <span class="comment"># depth+1</span></span><br><span class="line">        right = self._grow_tree(X[right_idxs,:], y[right_idxs], depth+<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> Node(best_feat, best_threshold, left, right) </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_best_criteria</span>(<span class="params">self,X,y,feat_idxs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Find the best criteria to split the data</span></span><br><span class="line"><span class="string">        :param X: input data</span></span><br><span class="line"><span class="string">        :param y: label</span></span><br><span class="line"><span class="string">        :param feat_idxs: indices of features to consider</span></span><br><span class="line"><span class="string">        :return: best feature index, best threshold</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        best_gain = -<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        split_idx, split_threshold = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> feat_idx <span class="keyword">in</span> feat_idxs:</span><br><span class="line">            X_col = X[:,feat_idx] <span class="comment"># X의 각 feature</span></span><br><span class="line">            thresholds = np.unique(X_col) <span class="comment"># 각 feature의 cardianlity</span></span><br><span class="line">            <span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">                gain = self._information_gain(y,X_col,threshold) <span class="comment"># 각 feuture의 모든 threshold에 대해서 gain을 계산</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> gain &gt; best_gain:</span><br><span class="line">                    best_gain = gain</span><br><span class="line">                    split_idx = feat_idx</span><br><span class="line">                    split_threshold = threshold</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> split_idx, split_threshold</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_information_gain</span>(<span class="params">self,y,X_column,split_threshold</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Calculate information gain</span></span><br><span class="line"><span class="string">        E(parent) - [weight average] * E(Children)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># parent entropy</span></span><br><span class="line">        </span><br><span class="line">        parent_entropy = entropy(y)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># generate split</span></span><br><span class="line">        left_idxs, right_idxs = self._split(X_column, split_threshold)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 더이상 분할이 안될 경우 정보이득이 0</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(left_idxs) == <span class="number">0</span>) <span class="keyword">or</span> (<span class="built_in">len</span>(right_idxs)) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the weighted avg. of the loss for the children</span></span><br><span class="line">        n = <span class="built_in">len</span>(y)</span><br><span class="line">        n_l, n_r = <span class="built_in">len</span>(left_idxs), <span class="built_in">len</span>(right_idxs)</span><br><span class="line">        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])</span><br><span class="line">        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r</span><br><span class="line"></span><br><span class="line">        <span class="comment"># information gain is difference in loss before vs. after split</span></span><br><span class="line">        ig = parent_entropy - child_entropy</span><br><span class="line">        <span class="keyword">return</span> ig</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_split</span>(<span class="params">self, X_column, split_threshold</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Split data according to the threshold</span></span><br><span class="line"><span class="string">        :param X_column: input data</span></span><br><span class="line"><span class="string">        :param split_threshold: threshold to split</span></span><br><span class="line"><span class="string">        :return: left and right indices</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># np.argwhere을 사용 조건에 해당하는 인덱스 반환.</span></span><br><span class="line">        left_idxs = np.argwhere(X_column &lt;= split_threshold).flatten()</span><br><span class="line">        right_idxs = np.argwhere(X_column &gt; split_threshold).flatten()</span><br><span class="line">        <span class="keyword">return</span> left_idxs, right_idxs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_most_common_label</span>(<span class="params">self, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Find the most common label in the dataset</span></span><br><span class="line"><span class="string">        :param y: labels</span></span><br><span class="line"><span class="string">        :return: most common label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        counter = Counter(y)</span><br><span class="line">        <span class="comment"># counter.most_common(1) -&gt; [(label, count)] # 리스트 안에 튜플</span></span><br><span class="line">        most_common = counter.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> most_common <span class="comment"># Counter(y) : Counter(&#123;0: 2, 1: 2&#125;) #value과 count중 value만 반환 </span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># traverse the tree</span></span><br><span class="line">        <span class="keyword">return</span> np.array([self._traverse_tree(x,self.root) <span class="keyword">for</span> x <span class="keyword">in</span> X]) <span class="comment"># X의 각 데이터포인트에 대해서 트리를 순회하며 각 데이터포인트에 대한 결과를 반환</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_traverse_tree</span>(<span class="params">self, x, node</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Traverse the tree from the root</span></span><br><span class="line"><span class="string">        :param x: input data</span></span><br><span class="line"><span class="string">        :param node: root node</span></span><br><span class="line"><span class="string">        :return: label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> node.is_leaf(): <span class="comment"># check if leaf node</span></span><br><span class="line">            <span class="keyword">return</span> node.value</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> x[node.feature] &lt;= node.threshold:</span><br><span class="line">            <span class="keyword">return</span> self._traverse_tree(x, node.left)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self._traverse_tree(x, node.right)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y,y_pred</span>):</span><br><span class="line">        acc = np.<span class="built_in">sum</span>(y == y_pred) / <span class="built_in">len</span>(y)</span><br><span class="line">        <span class="keyword">return</span> acc</span><br><span class="line">    </span><br><span class="line">    data = datasets.load_breast_cancer()</span><br><span class="line">    X, y = data.data, data.target</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    </span><br><span class="line">    clf = DecisionTree(max_depth=<span class="number">10</span>)</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    y_pred = clf.predict(X_test)</span><br><span class="line">    acc = accuracy(y_test, y_pred)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Accuracy : <span class="subst">&#123;acc&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html">결정트리의 최적화 문제</a></li>
<li><a target="_blank" rel="noopener" href="https://machinelearningmastery.com/information-gain-and-mutual-information/">정보이득</a></li>
<li><a target="_blank" rel="noopener" href="https://victorzhou.com/blog/gini-impurity/">지니불순도</a></li>
<li><a target="_blank" rel="noopener" href="https://tensorflow.blog/tag/%EC%A7%80%EB%8B%88-%EB%B6%88%EC%88%9C%EB%8F%84/">불순도 지표들</a></li>
<li><a href="-https://xzz201920.medium.com/post-pruning-techniques-in-decision-tree-4be56636172b">Post_Pruning</a></li>
</ul>

        <h4>Related Posts</h4>
        <ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><h3><a href="/2022/06/15/ML-SP-Main-Decision-Tree-Algorithms/" title="[Tree]주요 Decision Tree 알고리즘" rel="bookmark">[Tree]주요 Decision Tree 알고리즘</a></h3></div></li><li class="popular-posts-item"><div class="popular-posts-title"><h3><a href="/2022/06/15/ML-SP-Random_Forest/" title="[Tree]Random Forest의 이해" rel="bookmark">[Tree]Random Forest의 이해</a></h3></div></li><li class="popular-posts-item"><div class="popular-posts-title"><h3><a href="/2022/06/15/ML-SP-logistic_regression/" title="[Classification]로지스틱 회귀와 크로스엔트로피" rel="bookmark">[Classification]로지스틱 회귀와 크로스엔트로피</a></h3></div></li><li class="popular-posts-item"><div class="popular-posts-title"><h3><a href="/2022/06/15/ML-SP-optimization/" title="[Regression]머신러닝 관정에서의 회귀" rel="bookmark">[Regression]머신러닝 관정에서의 회귀</a></h3></div></li><li class="popular-posts-item"><div class="popular-posts-title"><h3><a href="/2021/06/08/ML-SP-simple_regression/" title="[Python]단순선형회귀 구현하기(Simple Regression)" rel="bookmark">[Python]단순선형회귀 구현하기(Simple Regression)</a></h3></div></li></ul>
    </article>
    <!-- license -->
    
        <div class="license-wrapper">
          <!-- <p>Author：<a href="https://yjinheon.github.io">JinHeon Yoon</a> -->
          <!-- <p>Link：<a href="https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/">https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/</a> -->
            <p>Publish date：<a href="https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/">June 15th 2022, 7:04:43 pm</a>
            <p>Update date：<a href="https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/">April 15th 2022, 7:10:22 am</a>
            <p>License：<p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></p>
        </div>
    
    <!-- paginator -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href="/2022/06/15/ML-SP-Main-Decision-Tree-Algorithms/" title="[Tree]주요 Decision Tree 알고리즘">
                    <div class="nextTitle">[Tree]주요 Decision Tree 알고리즘</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href="/2022/06/15/ML-SP-Random_Forest/" title="[Tree]Random Forest의 이해">
                    <div class="prevTitle">[Tree]Random Forest의 이해</div>
                </a>
            
        </li>
    </ul>
    <!-- comment -->
    
        <div class="post-comment">
            <!-- 来必力 City 版安装代码 -->


            
    <div id="disqus_thread"></div>
    <script>
        /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
        
        var disqus_config = function () {
        this.page.url = "https://yjinheon.github.io/2022/06/15/ML-SP-Decision_Tree/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "[Tree]Decision Tree의 이해"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        
        (function () { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://yjinheon-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


            

            

            <!-- utteranc评论 -->


            <!-- partial('_partial/comment/changyan') -->
            <!--PC版-->


            
            

            

        </div>
    
    <!-- timeliness note -->
    <!-- idea from: https://hexo.fluid-dev.com/posts/hexo-injector/#%E6%96%87%E7%AB%A0%E6%97%B6%E6%95%88%E6%80%A7%E6%8F%90%E7%A4%BA -->
    
    <!-- Mathjax -->
    
        
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>


    
</main>

                <!-- profile -->
                
            </div>
            <footer class="footer footer-unloaded">
    <!-- social  -->
    
        <div class="social">
            
    
        
            
                <a href="mailto:yjinheon@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/yjinheon" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="https://www.linkedin.com/in/jin-heon-yoon-583842178/" class="iconfont-archer linkedin" target="_blank" title=linkedin></a>
            
        
    
        
    
        
    
        
    


        </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Copyright © 2021-2022 DataMind </span>
    </div>
    <!-- website approve for Chinese user -->
    
    <!-- 不蒜子  -->
    	
</footer>

        </div>
        <!-- toc -->
        
            <div class="toc-wrapper toc-wrapper-loding" style=







    top:50vh;

>
                <div class="toc-catalog">
                    <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
                </div>
                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Decision-Tree%EC%9D%98-%EC%9D%B4%ED%95%B4"><span class="toc-number">1.</span> <span class="toc-text">Decision Tree의 이해</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Note"><span class="toc-number">1.1.</span> <span class="toc-text">Note</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EB%B6%88%EC%88%9C%EB%8F%84-%EC%A7%80%ED%91%9C"><span class="toc-number">1.2.</span> <span class="toc-text">불순도 지표</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Entropy"><span class="toc-number">1.2.1.</span> <span class="toc-text">Entropy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EC%A7%80%EB%8B%88%EB%B6%88%EC%88%9C%EB%8F%84"><span class="toc-number">1.2.2.</span> <span class="toc-text">지니불순도</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#information-Gain"><span class="toc-number">1.2.3.</span> <span class="toc-text">information Gain</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%AC%EC%9D%98-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%AC%B8%EC%A0%9C"><span class="toc-number">1.3.</span> <span class="toc-text">결정트리의 최적화 문제</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pruning"><span class="toc-number">1.4.</span> <span class="toc-text">Pruning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PrePruning"><span class="toc-number">1.4.1.</span> <span class="toc-text">PrePruning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PostPruning"><span class="toc-number">1.4.2.</span> <span class="toc-text">PostPruning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-Importance-in-Decision-Tree"><span class="toc-number">1.5.</span> <span class="toc-text">Feature Importance in Decision Tree</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#More-to-learn"><span class="toc-number">1.6.</span> <span class="toc-text">More to learn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EA%B5%AC%ED%98%84"><span class="toc-number">1.7.</span> <span class="toc-text">구현</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References-amp-annotation"><span class="toc-number">2.</span> <span class="toc-text">References &amp; annotation</span></a></li></ol>
            </div>
        
        <!-- sidebar -->
        <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
        <div class="sidebar-panel-archives">
    <!-- 在 ejs 中将 archive 按照时间排序 -->
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 57
        </div>
        <!-- search  -->
        
            <div class="site-search site-search-loading popup-trigger">
                <span class="iconfont-archer search-icon">&#xe627;</span>
            </div>
        
    </div>
    
    <div class="post-archive">
    
        
            
            
            <div class="archive-year"> 2022 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/22</span>
            <a class="archive-post-title" href="/2022/06/22/DE-Pyspark-Hadoop.md/">[Pyspark]하둡의 컨셉 이해하기</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2021 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/08</span>
            <a class="archive-post-title" href="/2021/10/08/DE-Linux-commandline/">[Unix]데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/05</span>
            <a class="archive-post-title" href="/2021/07/05/DE-SQL-DDL-tables/">[DDL]Table 구조 다루기</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DE-SQL-Where/">[SQL]WHERE절의 이해</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DE-SQL-case-when/">[SQL]간단한 CASE WHEN 용법</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DE-SQL-subquery/">[SQL]서브쿼리 정리</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-RNN/">[Neural Network]Recurrent Neural Network</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2021 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/28</span>
            <a class="archive-post-title" href="/2021/09/28/DL-backpropagation/">[Neural Network]역전파 알고리즘(backpropagation)</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-hyperparameter/">[Neural Network]하이퍼파라미터</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-lossfunction/">[Deep Learning]Loss function</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-optimizer/">[Deep Learning]Optimizer</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-perceptron/">[Neural Network]Perceptron의 이해</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/DL-regularization/">[Deep Leearing] 학습 규제하기(Handling Overfitting)</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-Metrics-Regression/">[Metrics]회귀모델의 평가지표</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-Main-Decision-Tree-Algorithms/">[Tree]주요 Decision Tree 알고리즘</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-Decision_Tree/">[Tree]Decision Tree의 이해</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-Random_Forest/">[Tree]Random Forest의 이해</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2022 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/16</span>
            <a class="archive-post-title" href="/2022/06/16/Statistics-GLM-1/">[GLM]선형모델과 비선형 모델의 차이</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-unpacking/">[Python] asterisk를 활용한 unpacking</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-zip-enumerate/">[Python]for-loop관련 함수들</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Statistics-Math-derivatives/">[Math]미적분 기초개념</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Statistics-Prob-multinomial-dist/">[Probability]numpy와 scipy로 다항분포 간단하게 구현하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Statistics-Prob-chi-square-dist/">[Probability]Python을 활용한 카이스퀘어 검정 구현</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/TS-R-lib-1/">[R]make: gfortran: No such file or directory 해결하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/TS-SQL-ts-1/">[SQL]ERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides 해결하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/TS-linux-ts-1/">[Linux]zsh: corrupt history file 해결</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/thoughts-1/">[Unsorted]머신러닝과 통계학의 차이</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/tools-docker-basic/">[Tools]Docker 기본개념(작성중)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/tools-git-log/">[Git]commit, push 제외 자주쓰는 git 명령어들</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/tools-git-private-repo/">[Git]Private repository import 하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-pandas-remove_col/">[pandas]pandas의 특정 열 제외한 모든 컬럼 출력하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-pandas_tricks/">[pandas]pandas 함수와 기초용법들</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-Generator/">[Python]Iterator,Generator,yield에 대한 정리</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-sampling-imbalance-data/">[Sampling]Class Imbalance 다루기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-hash-table/">[Algorithm]Hash Table과 Hash에 대한 이해</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-Graph-basic/">[Python]Graph와 Graph Representation의 이해</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-Python-lambda-highorder/">[Python]자주쓰는 High Order 함수 정리(lambda,map,filter,apply..)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Programming-python-regex/">[Python]Regex 정리</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/ML-XAI-PDP/">[XAI]PDP Plot의 이해와 구현</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/NLP-NLU/">[NLP]NLU & QA task</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/ML-XAI-shap/">[XAI]Shap을 활용한 모델해석</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-dt-Scaler/">[Data Transformation]Feature Scaling의 이해</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-numpy-basics/">[Python]numpy 연산과 활용법</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-pandas-collection-to-df/">[pandas]기본자료형을 DataFrame으로 변환하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-pandas_groupby/">[pandas]Pandas Groupby용법 간단히 정리</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/ML-US-knn/">[Unsupervised Learning]KNN을 활용한 분류</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-SVM/">[SVM]서포트벡터머신의 이해</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-logistic_regression/">[Classification]로지스틱 회귀와 크로스엔트로피</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/06/15/ML-SP-optimization/">[Regression]머신러닝 관정에서의 회귀</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2022 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/15</span>
            <a class="archive-post-title" href="/2022/06/15/Preprocessing-pandas_overview/">[pandas]Pandas를 활용한 데이터분석 시작하기</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/02</span>
            <a class="archive-post-title" href="/2022/03/02/NLP-wordembedding/">[NLP]Word Embedding과 Text Classification</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2021 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/17</span>
            <a class="archive-post-title" href="/2021/07/17/tools-git-basic/">[Git]간단한 Git 명령어 및 용법 정리</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/08</span>
            <a class="archive-post-title" href="/2021/07/08/tools-conda-install/">[Tools]Anaconda 시작시 기본설정</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/08</span>
            <a class="archive-post-title" href="/2021/06/08/ML-SP-simple_regression/">[Python]단순선형회귀 구현하기(Simple Regression)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/29</span>
            <a class="archive-post-title" href="/2021/05/29/ML-US-PCA/">[Unsupervised Learning]주성분분석(PCA)의 이해</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/02</span>
            <a class="archive-post-title" href="/2021/03/02/R-Programming-operators/">[R]특별한 R 연산자들(Binary Oerators)</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> Invalid date </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span>
            <a class="archive-post-title" href="/2022/07/09/Statistics-Prob-binary-dist/">[Probability]이항분포의 이해</a>
        </li>
    
    </div>
</div>

        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
        
            <span class="sidebar-tag-name" data-tags="commandline">
                <span class="iconfont-archer">&#xe606;</span>
                commandline
            </span>
        
            <span class="sidebar-tag-name" data-tags="Linux">
                <span class="iconfont-archer">&#xe606;</span>
                Linux
            </span>
        
            <span class="sidebar-tag-name" data-tags="SQL">
                <span class="iconfont-archer">&#xe606;</span>
                SQL
            </span>
        
            <span class="sidebar-tag-name" data-tags="Subquery">
                <span class="iconfont-archer">&#xe606;</span>
                Subquery
            </span>
        
            <span class="sidebar-tag-name" data-tags="RNN">
                <span class="iconfont-archer">&#xe606;</span>
                RNN
            </span>
        
            <span class="sidebar-tag-name" data-tags="Optimizer">
                <span class="iconfont-archer">&#xe606;</span>
                Optimizer
            </span>
        
            <span class="sidebar-tag-name" data-tags="Regression">
                <span class="iconfont-archer">&#xe606;</span>
                Regression
            </span>
        
            <span class="sidebar-tag-name" data-tags="Metrics">
                <span class="iconfont-archer">&#xe606;</span>
                Metrics
            </span>
        
            <span class="sidebar-tag-name" data-tags="Decision Tree">
                <span class="iconfont-archer">&#xe606;</span>
                Decision Tree
            </span>
        
            <span class="sidebar-tag-name" data-tags="Supervised Learning">
                <span class="iconfont-archer">&#xe606;</span>
                Supervised Learning
            </span>
        
            <span class="sidebar-tag-name" data-tags="Random Forest">
                <span class="iconfont-archer">&#xe606;</span>
                Random Forest
            </span>
        
            <span class="sidebar-tag-name" data-tags="SVM">
                <span class="iconfont-archer">&#xe606;</span>
                SVM
            </span>
        
            <span class="sidebar-tag-name" data-tags="hyperplane">
                <span class="iconfont-archer">&#xe606;</span>
                hyperplane
            </span>
        
            <span class="sidebar-tag-name" data-tags="Logistic Regression">
                <span class="iconfont-archer">&#xe606;</span>
                Logistic Regression
            </span>
        
            <span class="sidebar-tag-name" data-tags="Cross Entropy">
                <span class="iconfont-archer">&#xe606;</span>
                Cross Entropy
            </span>
        
            <span class="sidebar-tag-name" data-tags="Python">
                <span class="iconfont-archer">&#xe606;</span>
                Python
            </span>
        
            <span class="sidebar-tag-name" data-tags="Unsupervised Learning">
                <span class="iconfont-archer">&#xe606;</span>
                Unsupervised Learning
            </span>
        
            <span class="sidebar-tag-name" data-tags="PCA">
                <span class="iconfont-archer">&#xe606;</span>
                PCA
            </span>
        
            <span class="sidebar-tag-name" data-tags="KNN">
                <span class="iconfont-archer">&#xe606;</span>
                KNN
            </span>
        
            <span class="sidebar-tag-name" data-tags="XAI">
                <span class="iconfont-archer">&#xe606;</span>
                XAI
            </span>
        
            <span class="sidebar-tag-name" data-tags="NLP">
                <span class="iconfont-archer">&#xe606;</span>
                NLP
            </span>
        
            <span class="sidebar-tag-name" data-tags="NLU">
                <span class="iconfont-archer">&#xe606;</span>
                NLU
            </span>
        
            <span class="sidebar-tag-name" data-tags="QA">
                <span class="iconfont-archer">&#xe606;</span>
                QA
            </span>
        
            <span class="sidebar-tag-name" data-tags="Deep Learning">
                <span class="iconfont-archer">&#xe606;</span>
                Deep Learning
            </span>
        
            <span class="sidebar-tag-name" data-tags="WordEmbedding">
                <span class="iconfont-archer">&#xe606;</span>
                WordEmbedding
            </span>
        
            <span class="sidebar-tag-name" data-tags="numpy">
                <span class="iconfont-archer">&#xe606;</span>
                numpy
            </span>
        
            <span class="sidebar-tag-name" data-tags="pandas">
                <span class="iconfont-archer">&#xe606;</span>
                pandas
            </span>
        
            <span class="sidebar-tag-name" data-tags="Sampling">
                <span class="iconfont-archer">&#xe606;</span>
                Sampling
            </span>
        
            <span class="sidebar-tag-name" data-tags="Algorithm">
                <span class="iconfont-archer">&#xe606;</span>
                Algorithm
            </span>
        
            <span class="sidebar-tag-name" data-tags="Data Structure">
                <span class="iconfont-archer">&#xe606;</span>
                Data Structure
            </span>
        
            <span class="sidebar-tag-name" data-tags="regex">
                <span class="iconfont-archer">&#xe606;</span>
                regex
            </span>
        
            <span class="sidebar-tag-name" data-tags="GLM">
                <span class="iconfont-archer">&#xe606;</span>
                GLM
            </span>
        
            <span class="sidebar-tag-name" data-tags="R">
                <span class="iconfont-archer">&#xe606;</span>
                R
            </span>
        
            <span class="sidebar-tag-name" data-tags="Probability">
                <span class="iconfont-archer">&#xe606;</span>
                Probability
            </span>
        
            <span class="sidebar-tag-name" data-tags="Unsorted">
                <span class="iconfont-archer">&#xe606;</span>
                Unsorted
            </span>
        
            <span class="sidebar-tag-name" data-tags="Git">
                <span class="iconfont-archer">&#xe606;</span>
                Git
            </span>
        
            <span class="sidebar-tag-name" data-tags="Pyspark">
                <span class="iconfont-archer">&#xe606;</span>
                Pyspark
            </span>
        
            <span class="sidebar-tag-name" data-tags="Hadoop">
                <span class="iconfont-archer">&#xe606;</span>
                Hadoop
            </span>
        
            <span class="sidebar-tag-name" data-tags="Probability Distribution">
                <span class="iconfont-archer">&#xe606;</span>
                Probability Distribution
            </span>
        
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
        缺失模块，请参考主题文档进行安装配置：https://github.com/fi3ework/hexo-theme-archer#%E5%AE%89%E8%A3%85%E4%B8%BB%E9%A2%98
    </div> 
    <div class="sidebar-tags-list"></div>
</div>

        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Data Engineering">
            <span class="iconfont-archer">&#xe60a;</span>
            Data Engineering
        </span>
    
        <span class="sidebar-category-name" data-categories="Linux">
            <span class="iconfont-archer">&#xe60a;</span>
            Linux
        </span>
    
        <span class="sidebar-category-name" data-categories="Neural Network">
            <span class="iconfont-archer">&#xe60a;</span>
            Neural Network
        </span>
    
        <span class="sidebar-category-name" data-categories="Machine Learning">
            <span class="iconfont-archer">&#xe60a;</span>
            Machine Learning
        </span>
    
        <span class="sidebar-category-name" data-categories="PCA">
            <span class="iconfont-archer">&#xe60a;</span>
            PCA
        </span>
    
        <span class="sidebar-category-name" data-categories="NLP">
            <span class="iconfont-archer">&#xe60a;</span>
            NLP
        </span>
    
        <span class="sidebar-category-name" data-categories="Preprocessing">
            <span class="iconfont-archer">&#xe60a;</span>
            Preprocessing
        </span>
    
        <span class="sidebar-category-name" data-categories="Supervised Learning">
            <span class="iconfont-archer">&#xe60a;</span>
            Supervised Learning
        </span>
    
        <span class="sidebar-category-name" data-categories="Programming">
            <span class="iconfont-archer">&#xe60a;</span>
            Programming
        </span>
    
        <span class="sidebar-category-name" data-categories="Statistics">
            <span class="iconfont-archer">&#xe60a;</span>
            Statistics
        </span>
    
        <span class="sidebar-category-name" data-categories="Troubleshooting">
            <span class="iconfont-archer">&#xe60a;</span>
            Troubleshooting
        </span>
    
        <span class="sidebar-category-name" data-categories="Unsorted">
            <span class="iconfont-archer">&#xe60a;</span>
            Unsorted
        </span>
    
        <span class="sidebar-category-name" data-categories="Tools">
            <span class="iconfont-archer">&#xe60a;</span>
            Tools
        </span>
    
        <span class="sidebar-category-name" data-categories="Probability">
            <span class="iconfont-archer">&#xe60a;</span>
            Probability
        </span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>

    </div>
</div>

        <!-- site-meta -->
        <script>
    var siteMetaRoot = "/"
    if (siteMetaRoot === "undefined") {
        siteMetaRoot = '/'
    }
    var siteMeta = {
        url: "https://yjinheon.github.io",
        root: siteMetaRoot,
        author: "JinHeon Yoon"
    }
</script>

        <!-- import experimental options here -->
        <!-- Custom Font -->


        <!-- main func -->
        <script src="/scripts/main.js?v=20211217"></script>
        <!-- dark mode -->
        <script src="/scripts/dark.js?v=20211217"></script>
        <!-- fancybox -->
        <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>
        <!-- algolia -->
        
            <div class="site-search site-search-loading">
    <div class="algolia-popup popup">
        <div class="algolia-search">
            <div class="algolia-search-input-icon">
                <i class="fa fa-search"></i>
            </div>
            <div class="algolia-search-input" id="algolia-search-input"></div>
            <div class="popup-btn-close">
                <i class="iconfont-archer">&#xe609;</i>
            </div>
        </div>

        <div class="algolia-results">
            <div id="algolia-stats" class="algolia-stats"></div>
            <div id="algolia-hits"></div>
            <div id="algolia-pagination" class="algolia-pagination"></div>
        </div>
    </div>
</div>

            <script src="/scripts/search.js?v=20211217" defer></script>
        
        <!-- busuanzi -->
        
        <!-- CNZZ -->
        
        <!-- async load share.js -->
        
            <script src="/scripts/share.js?v=20211217" async></script>
        
        <!-- mermaid -->
        
            <script src='https://cdn.jsdelivr.net/npm/mermaid@8.11.0/dist/mermaid.min.js'></script>
            <script>
                if (window.mermaid) {
                    mermaid.initialize({theme: 'dark'});
                }
            </script>
        
    </body>
</html>
