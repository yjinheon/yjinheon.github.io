관련해서 알아야 하는 개념들


sample

population

probability


random variable

이산확률 변수



probability distribtion

pmf

pdf

cdf


parameter

모수를 찾는다는 것의 의미

In a statistical model, a parameter is a numerical quantity that describes some aspect of the population or process being studied. Parameters are typically unknown and need to be estimated from sample data. 

For example, in a simple linear regression model, the parameter is the slope of the line that best fits the data. In a normal distribution, the parameters are the mean and standard deviation of the distribution. In a logistic regression model, the parameters are the coefficients that describe the relationship between the predictor variables and the outcome variable.

The choice of parameters in a statistical model depends on the specific problem and the assumptions made about the data-generating process. In some cases, the parameters may be well-defined and have a clear interpretation in terms of the underlying process being studied. In other cases, the parameters may be more abstract and reflect a combination of multiple factors that are difficult to disentangle.

Estimating the parameters of a statistical model is a fundamental task in statistical inference. The goal is to find the values of the parameters that best explain the observed data and generalize well to new, unseen data. There are many different methods for estimating parameters, including maximum likelihood estimation, Bayesian estimation, and method of moments, among others. The choice of estimation method depends on the specific problem, the nature of the data, and the assumptions made about the underlying process.


우도의 의미

In statistics, likelihood refers to the probability of observing a set of data given a particular parameter value or set of parameter values in a statistical model. More specifically, the likelihood function is a function of the parameters of a statistical model that measures how well the model explains the observed data.

For example, consider a simple coin-flipping experiment. Suppose we have a coin and we want to estimate the probability of getting heads when we flip the coin. We can model this as a binomial distribution with a single parameter, p, representing the probability of getting heads. The likelihood function for this model would be the probability of observing the data we actually observed (i.e., the number of heads and tails) given a particular value of p.

The likelihood function is an important concept in statistical inference, as it is often used to estimate the parameters of a statistical model. Specifically, the maximum likelihood estimate (MLE) is the value of the parameter(s) that maximize(s) the likelihood function, meaning that it is the value(s) that make the observed data most likely to have been generated by the model.

It's important to note that likelihood is not the same thing as probability. Probability refers to the chance of a future event happening, while likelihood refers to the degree of compatibility between the observed data and a particular model or set of parameter values.


베이즈 정리

odd 


사전확률 

사후 확률

likelyhood

mle

map

gradient descent

statistical model



log-likelyhood

negative loglikeyhood

https://paul-hyun.github.io/nlp-tutorial-02-04-negative-log-likelihood/

cross entropy loss

activation funtion

softmax function

entropy

gini impurity


기울기 소실
