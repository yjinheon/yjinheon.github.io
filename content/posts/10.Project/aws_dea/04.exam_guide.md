---
tags:
  - project
  - aws
  - dea
  - status/in_progress
created: 2024-01-04T09:22
updated: 2024-07-21T14:07
draft: true
---

aws 시험안내서 참고
: https://d1.awsstatic.com/ko_KR/training-and-certification/docs-data-engineer-associate/AWS-Certified-Data-Engineer-Associate_Exam-Guide.pdf

# 1. 데이터 수집 및 변환

## 1.1 데이터 수집

- 데이터를 수집하는 AWS 서비스의 처리량 및 지연시간 특성
- 데이터 수집 패턴(빈도 및 데이터 기록 등)
- 스트리밍 데이터 수집
- 배치 데이터 수집
  - 예약된 수집
  - 이벤트 기반 수집
- 데이터 수집 파이프라인의 재사용가능성
- Stateful 및 Stateless 데이터 트랜잭션

**기술예제**

- 스트리밍 소스에서 데이터 읽기
  - Amazon Kinesis
  - Amazon Managed Streaming for Apache Kafka(Amazon MSK)
  - Amazon DynamoDB Streams
  - AWS Database Migration Service (AWS DMS)
  - AWS Glue
  - Amazon Redshift
- 배치 소스에서 데이터 읽기
  - Amazon S3
  - AWS Glue
  - Amazon EMR
  - AWS DMS
  - AWS Redshift
  - AWS Lambda
  - AWS AppFlow
- 배치 수집을 위한 Config 구현
- 데이터 API 사용
- Amazon EventBridge, Apache Airflow 또는 작업 및 크롤러에 대한 시간 기반 일정을 사용해 스케줄러 설정
- 이벤트 트리거 설정(ex) Amazon S3 이벤트 알림, EventBridge)
- Amazon Kinesis에서 Lambda 함수 호출
- 데이터 원본에 연결할 수 있도록 ip 주소에 대한 허용 목록 만들기
- 스로틀링 구현 및 속도 제한 극복(DynamoDB, Amazon RDS, Kinesis)
- 스트리밍 데이터 배포를 위한 팬인 및 팬아웃 관리

## 1.2 데이터 변환 및 처리

- 비즈니스 요구사항에 따른 ETL 파이프라인 생성
- 데이터의 볼륨, 속도 및 다양성(정형 데이터, 비정형데이터)
- 클라우드 컴퓨팅, 분산 컴퓨팅
- Apache Spark를 사용한 데이터 처리
- 중간 데이터 스테이징 위치

**기술예제**

- 성능 요구 사항에 맞게 컨테이너 사용 최적화(Amazon EKS, Amazon ECS)
- 다양한 데이터소스에 연결(JDBC, ODBC)
- 여러 소스의 데이터 통합
- 데이터 처리 중 비용 최적화
- 요구 사항에 따라 데이터 변환 구현 (Amazon EMR, AWS Glue, Lambda, Amazon Redshift)
- 데이터 형식간 데이터 변환 (ex-> csv to parquet)
- 일반적인 변환 실패 및 성능 문제 해결 및 디버깅
- AWS 서비스를 활용하여 다른 시스템에서 데이터를 사용할 수 있도록 데이터 API 만들기

## 1.3 데이터 파이프라인 오케스트레이션

- 다양한 AWS 서비스를 통합하여 ETL 파이프라인을 만드는 방법
- 이벤트 기반 아키텍처
- 일정 또는 의존성 기반 데이터 파이프라인에 대한 AWS 서비스를 구성하는 방법

**기술예제**

- 오케스트레이션 서비스를 사용하여 데이터 ETL 파이프라인의 워크플로 구축
  - Lambda
  - EventBridge
  - Amazon MWAA
  - Amazon Step Functions
  - AWS Glue workflow
- 성능 , 가용성, 확장성 , 복원성 및 내결함성이 우수한 데이터 파이프라인 구축
- 서버리스 워크플로 구현 및 유지관리
- 알림 서비스를 사용하여 알림보내기
  - Amazon Simple Notification Service
  - Amazon Simple Queue Service

## 1.4 프로그래밍 개념 적용

- CI/CD
- SQL
- 반복가능한 배포를 위한 코드형 인프라(IaC)
  - AWS Cloud Development Kit(AWS CDK)
  - AWS CloudFormation
  - 분산 컴퓨팅
  - 다양한 데이터 구조 및 알고리즘
  - 쿼리 최적화

**기술예제**

- 코드 최적화를 통한 데이터 수집 및 변환 런타임 단축
- 동시성 및 성능 요구사항을 충족하도록 Lambda 함수 구성
- SQL 쿼리를 수행한 데이터 변환(프로시저)
- 데이터 파이프라인 요구사항을 충족하는 SQL 쿼리 구조화
- Git 기본적인 작업 수행
- AWS SAM(Serverless Application Model)을 사용한 서버리스 데이터 파이프라인 패키징 및 배포
  - Lambda 함수
  - AWS Step Functions
  - Amazon DynamoDB 테이블

# 2. 데이터 저장소 관리

## 2.1 데이터 저장소 선택

- 스토리지 플랫폼 및 특성
- 특정 성능 요구사항을 위한 스토리지 서비스 및 구성
- 데이터 마이그레이션 요구사항에 맞게 데이터 스토리지 정렬
- 특정 엑세스 패턴에 적합한 스토리지 솔루션 결정
- 데이터 액세스 방지 위한 잠금 관리 (Amazon Redshift, Amazon RDS)

**기술예제**

- 특정 비용 및 성능 요구 사항에 따라 적합한 스토리지 서비스 구현

  - Amazon Redshift
  - Amazon EMR
  - AWS Lake Formation
  - Amazon RDS
  - DynamoDB
  - Amazon Kinesis Data Streams : 대규모 레코드 처리, 스트림을 실시간 처리, 수집
  - Amazon MSK : Amazon Managed Stream for Apache Kafka

- 특정 엑세스 패턴 및 요구사항에 따라 적합한 스토리지 서비스 구현
- 적절한 유스케이스에 스토리지 서비스 적용(Amazon S3)
- 마이그레이션 도구를 데이터 처리 시스템에 통합(AWS Transfer Family)
- 데이터 마이그레이션 또는 원격 엑세스 방법 구현 (Amazon Redshift 페더레이션 쿼리)

## 2.2 데이터 카탈로그 시스템 이해

- 데이터 카탈로그를 만드는 방법
- 요구 사항에 따른 데이터 분류
- 메타데이터 및 데이터 카탈로그의 구성요소

**기술예제**

- 데이터 카탈로그를 사용하여 데이터 원본의 데이터 사용
- 데이터 카탈로그 구축 및 참고(AWS Glue 데이터 카탈로그, Apache Hive MetaStore)
- 스키마 검색 및 AWS Glue 크롤러를 사용하여 데이터 카탈로그 채우기
- Partition 을 데이터 카탈로그와 동기화
- 카탈로그 구축을 위한 새 소스 또는 대상 연결 만들기(AWS Glue)

## 2.3 데이터 수명주기 관리

- 핫 및 콜드 데이터 요구사항을 해결하는 적절한 스토리지 솔루션
- 데이터 수명 주기를 기반으로 스토리지 비용을 최적화 하는 방법
- 비즈니스 및 법적 요구사항을 충족하기 위해 데이터를 삭제하는 방법
- 데이터 보존정책 및 보관전략
- 적절한 복원성 및 가용성으로 데이터를 보호하는 방법

**기술예제**

- 로드 및 언로드 작업을 수행하여 Amazon S3와 Amazon Redshift 간의 데이터 이동
- S3 수명주기 정책을 관리하여 S3의 데이터 스토리지 계층 변경
- S3 수명주기 정책을 관리하여 데이터가 특정 기간에 도달하면 데이터 만료
- S3 버전관리 및 DynamoDB TTL 관리

## 2.4 데이터 모델링 및 스키마 설계

- 데이터 모델링
- 데이터 Lineage를 사용해 데이터의 정확성과 신뢰성 보장
- indexing, Partitioning 전략, 압축 및 기타 데이터 최적화 기술에 대한 모범사례
- 정형 , 반정형 및 비정형 데이터 모델링 방법

**기술예제**

- Amazon Redshift, DynamoDB, Lake Formation 을 위한 스키마 설계
- 스키마 변환 수행(AWS Schema Conversion)
- Data Lineage 구축 (Amazon SageMaker ML Lineage tracking)

# 3. 데이터 운영 및 지원

## 3.1 AWS 서비스를 이용한 데이터 처리 자동화

- 재사용가능한 비즈니스 성과를 위해 데이터처리를 유지관리하고 문제를 해결하는 방법
- 데이터처리를 위한 API 호출
- 스크립팅을 허용하는 서비스(Amazon EMR, Amazon Redshift, AWS Glue)

**기술예제**

- 데이터 파이프라인 오케스트레이션
- Amazon 관리형 workflow 문제해결
- SDK를 호출하여 코드로 Amazon 기능에 엑세스
- AWS 서비스의 기능을 사용하여 데이터 처리
  - Amazon EMR
  - Amazon Redshift
  - Amazon Glue
- 데이터 API 사용 및 유지관리
- 데이터 변환 준비(AWS Glue Databrew)
- 데이터 쿼리(Amazon Athena)
- Lambda를 활용한 데이터 처리 자동화
- 이벤트 및 스케줄러 관리(EventBridge)

## 3.2 AWS 서비스를 이용한 데이터 분석

- 프로비저닝된 서비스와 서버리스 서비스간 절충점
- SQL 쿼리
- 분석을 위한 데이터 시각화
- 집계, 롤링 평균, 그룹화 , 피벗

**기술예제**

- AWS 서비스 및 도구를 사용하여 데이터 시각화
  - AWS Glue Databrew
  - Amazon QuickSight
  - 데이터 확인 및 정리
    - Lambda
    - Athena
    - QuickSight

## 3.3 데이터 파이프라인 유지 관리 및 모니터링

- 어플리케이션 데이터 로깅
- 성능 튜닝
- AWS 서비스에 대한 엑세스 로깅
- 로그 추출
- 감사 및 추적 지원 로깅 및 모니터링 솔루션 배포
- 모니터링 중 알림을 사용하여 경고 보내기
- 성능문제 해결
- CloudTrail 사용하여 API 호출 추적


## 3.4: 데이터 품질을 보장합니다

- 데이터 샘플링 기법
- 데이터 스큐 메커니즘 구현 방법
- 데이터 유효성 검사(데이터 완전성, 일관성, 정확성 및 무결성)
- 데이터 프로파일링

**기술예제**

- 데이터를 처리하는 동안 데이터 품질 검사 실행(예: 빈 필드 확인)
- 데이터 품질 규칙 정의(예: AWS Glue DataBrew)
- 데이터 일관성 조사(예: AWS Glue DataBrew)

# 4. 데이터 보안 및 거버넌스

## 4.1: 인증 메커니즘을 적용합니다.

• VPC 보안 네트워킹 개념
• 관리형 서비스와 비관리형 서비스의 차이점
• 인증 방법(암호 기반, 인증서 기반 및 역할 기반)
• AWS 관리형 정책과 고객 관리형 정책의 차이점

**기술예졔**

• VPC 보안 그룹 업데이트
• IAM 그룹, 역할, 엔드포인트 및 서비스의 만들기 및 업데이트
• 암호 관리를 위한 자격 증명 만들기 및 교체(예: AWS Secrets Manager)
• 액세스를 위한 IAM 역할 설정(예: Lambda, Amazon API Gateway, AWS CLI,  CloudFormation)
• 역할, 엔드포인트 및 서비스에 IAM 정책 적용(예: S3 액세스 포인트, AWS  PrivateLink)

## 4.2: 인가 메커니즘을 적용합니다.

• 권한 부여 방법(역할 기반, 정책 기반, 태그 기반 및 속성 기반)
• AWS 보안에 적용되는 최소 권한의 원칙
• 역할 기반 액세스 제어 및 예상 액세스 패턴
• 서비스 전반에서 무단 액세스로부터 데이터를 보호하는 방법

**기술예졔**

• 관리형 정책이 요구 사항을 충족하지 못하면 사용자 지정 IAM 정책 만들기
• 애플리케이션 및 데이터베이스 자격 증명 저장(예: Secrets Manager 및 AWS  Systems Manager Parameter Store)
• 데이터베이스 사용자, 그룹 및 역할에 데이터베이스 액세스 및 권한 제공(예:  Amazon Redshift)
• Lake Formation 을 통한 권한 관리(Amazon Redshift, Amazon EMR, Athena,  Amazon S3 의 경우)

# 시험범위에 포함되는 AWS 서비스
