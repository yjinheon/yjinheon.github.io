---
created: 2024-01-04T09:22
updated: 2024-07-20T20:58
tags:
  - project
  - dea
  - status/in_progress
draft: true
---


# SAA의 기본적인 4가지 도메인

# DEA의 기본적인 4가지 도메인

- 01 데이터 수집 및 변환
- 02 데이터 스토어 관리
- 03
- 04 데이터 보안 및 거버넌스

# Exam concepts


---
**_Concept_**

- **Latency** : 네트워크 지연시간. 데이터 패킷이 한 지점에서 다른 지점으로 이동하는데 걸리는 시간. : AWS | WEB
- **Throughput** : 단위 시간당 처리량. 웹 어플리케이션 성능지표로 쓰일 경우 보통 단위시간 당 처리하는 요청의 수. 데이터 전송률 : AWS | WEB
- **IOPS** : Input Output Operation Per Second. 초당 처리하는 IO의 개수로 보통 스토리지의 속도를 의미. 스토리지의 Throughput은 IOPS로서 스토리지 성능을 대표한다. : AWS | WEB
- **Bandwidth** : 네트워크에서 특정 시간 내에 전송될 수 있는 데이터의 최대 용량을 의미 : AWS | WEB

---


### AWS Glue

### Amazon Redshift

data warehouse

### Amazon Athena

### Amazon S3


### Amazon EMR


# Data Engineering

Data engineering is the development, implementation, and maintenance of processes and systems that ingest raw data and produce high quality and consistent data to be used for analysis
, machine learning, and more.
As a data engineer, you must incorporate security, data management, orchestration, data architecture, software engineering
, and operations to manage the lifecycle of data.
The goal is to take raw data and make it easy and reliable to work with and to integrate across datasets and domains.
To accomplish this goal, you use methods, tools, and services such as streaming, extract, transform, and load, or ETL, data warehouses, and data lakes.


# Domain 1 Data Ingestion and Transformation

- Throughput
- latency
- cost efficiency
- high availability

## 1.1 Performing Data ingestion

### Data engineering life cycle

Generation -> Storage -> Ingestion -> Transformation -> Serving

#### Generation

### Ingestion

Ingestion: data ingestion is moving data from one place to another.

- Gather and Ingest data
- Batch and stream
- Push and Pull

#### Data Ingestion pipelines

- Reprocess
  : S3, Amazon Kinesis, Amazon EventBridge
- Idempotent
- Checkpoints
- Versioning
- Compliance and governance
- Logging and Monitoring
- Tools

#### Transactional Data

- Dynamo DB
- Amazon RDS
- AWS DataBase Migration Service (AWS DMS)

#### Streaming Data

- Kinesis
  - Amazon Kinesis Data Firehose
  - Amazon Kinesis Data Streams
  - Amazon Kinesis Videos Streams

- Amazon Managed Service for Apache Flink
- Amazon MSK
- Amazon AppFlow

#### Scenario question

- Kinesis Data Streams
  - Each stream = 1 or more shards
  - Hot Shards
- Pipelines expeted data flow
  - Capacity
  - Partition key strategy


**solution**
- UpdateShardCount
- Random partition keys
- Distribute hash key evenly across shards


#### Data Ingestion using protocols

**AWS Transfer Family**

- File Transfer Protocol(FTP)
- Secure File Transfer Protocol(SFTP)

**AWS DataSync**

- Network File System(NFS)
- Server Message Block(SMB)

**Large amounts of data**
- AWS Snow Family

#### Batch data ingestion

Batch는 기본적으로 연,분,초 등 특정 단위에 bounded 된 데이터이다.

#### Stateful vs Stateless

Stateful : Stateful data transaction store information about the current state

- Amazon ElasticCache
- Amazon RDS

Stateless data transactions do not store data or sessions and do not rely on the past state.

- Lambda
- Amazon API Gateway
- Amazon S3.

## 1.2 Transform and process data

Transformation means to change the data from its original form into some other form that can be useful for downstream use cases.

### Query

### Data Modeling

#### OLTP(Online transaction processing)

- Latest State of Data
- 1~ 3 정규화
- Optimize for point queries
- Query latency matters
- Common Table Expressions can cause latency

#### OLAP(Online Analytical Process)

- Latest state and historical data
- 정규화를 할 경우 느려질 수있다.
- Optimized for Group by
- use CTE instead of subqueries

### AWS Service for transformations

#### Computing

- Lamda
- Amazon EMR
- AWS Glue : Fully managed ETL service. Data Cleansing, enrichment, and movement
- Amazon Redshift

#### Distributed Computing

- Amazon EMR : Full-featured, distributed Hadoop environment.
- AWS Batch
- AWS Step Functions

### 데이터 수집 및 처리 시나리오

#### Kinesis

####

### Troubleshooting

트러블 슈팅 절차

- check logs
- Verify data.  Identify the following :
  - Bottlenecks
  - High-processing times , memory usage or higher I/O operations
  - Algorithms, partition strategy, or parallel processing is needes
  - Resource allocation
  - Caching is needed
- Implement incremental processing
- Add retries
- Test

**AWS Glue**

- built-in debugging capabilities for programming language and framworks

###  Secure connections

#### JDBC

- Prepare the JDBC driver
- Configure the security groups
- Use a URL, user name and password

#### ODBC

- Select an ODBC driver
- Install an ODBC driver
- Set up an ODBC data source name (DSN)
- Specify a DSN

### Creating data APIs

#### 01 Where is your data stored?

데이터 저장소는 어디인가?

- Amazon RDS
- Dynamo DB
- Amazon S3

#### 02 How do you perform data processing and transformation?


-


## 1.3

## 1.4
