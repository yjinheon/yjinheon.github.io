---
modified: 2023-12-31T12:43:11+09:00
tags:
  - project
  - dea
  - status/in_progress
created: 2024-01-04T09:22
updated: 2024-07-20T21:57
draft: true
---

# Goal

- [ ] AWS DEA CERTIFICATION 합격


Data engineering is the development, implementation, and maintenance of processes and systems that ingest raw data and produce high quality and consistent data to be used for analysis, machine learning, and more. 


As a data engineer, you must incorporate security, data management, orchestration, data architecture, software engineering, and operations to manage the lifecycle of data. 

  

The goal is to take raw data and make it easy and reliable to work with and to integrate across datasets and domains. To accomplish this goal, you use methods, tools, and services such as streaming, extract, transform, and load, or ETL, data warehouses, and data lakes.

# Fundamentals of Data Engineering

## Types of Data

- Stuctured Data
- Unstructured Data
- Semi-Structured Data

## Properties of Data

- Volume
- Velocity
- Variety

## Data Warehouse and Data Lake

### Data Warehouse :

A centralized repository optimized for analysis where data from different sources is stored in Stuctured format

- Amazon Redshift
- Google Bigquery
- MS Aure Data Warehouse

### Data Lake :

A storage repository that holds vast amount of raw data in its native format, including Stuctured, Semi-Structured, Unstructured data


## Data Modeling, Data Lineage

---
**_Concept_**

- **Data Modeling** : 논리적 데이터 모델을 구성하는 작업. 산출물은 보통 ERD.
- **Data Lineage** : a Visual representation that traces the flow and transformation of data through its lifecycle
- **Schema Evolution** : ablity to adapt and change the schema of a datset over time without disrupting existing process or systems . ex) Glue Schema Registry
---

## Database Performance Optimization

### indexing

- Avoid full table scan

### Partitioning

- 샤딩과 같이 큰 데이터셋을 서브셋으로 분리하여 관리
- 매우 큰 테이블을 여러 테이블로 분할
- 기본적으로 스캔하는 데이터의 양을 줄임
- 병렬처리 용이

- 샤딩은 기본적으로 수평 파티셔닝. -> 로우 단위로 움직인다.


### Compression

- Speed up data transfer, reduce storage , disk reads
- GZIP , LZOP , BZIP, ZSTD -> various tradeoffs between compression and speed
- 열 압축(Columnar compression)


## Data Sampling Techniques

---
**_Concept_**

- **Random Sampling** : 모든 샘플이 같은 추출 확률을 가지는 것
- **Stratified Sampling** : 층화추출. 카테고리별 서브셋 안에서 각각 랜덤추출
- **Systemic Sampling** : 계통추출. 일정한 순서를 정하고 매번 그 순서에 해당하는 요소를 표본으로 추출
---


## Data Skew Mechanism

---
**_Concept_**
- **Data skew** : 편포된 데이터. unequal distribution or imbalance of data across various nodes or partitions in distributed computing systems.
---

### Addressing Data Skew

1. Adaptive Partitioning : Dynamically adjust Partitioning based on data characteristics to ensure a more balanced distribution

2. Salting : Introduce a random factor or salt to the data to distribute it more uniformly

3. Repartitioning: Regularly redistribute the data based on its current distribution characteristic

4. Sampling : Use a sample of the data to determine the distribution and adjust the processing strategy accordingly

## Data Validation and Profiling

### Data Validation

- **Data Completeness** : all required data is present and no essential parts are missing
- **Data Consistency** : data values are consistentt across datasets and do not contradict each other
- **Data Accuracy** : Ensure data is correct and reliable
- **Data Integritty** : Ensure data maintains its correctness and consistency over its lifecycle and across systems.

## SQL Review

aggregation

```sql
SELECT AVG(Survived) AS overall_rate FROM titanic;
-- 0 : dead, 1 : survived
SELECT AVG(Survived) AS women_children_rate FROM titanic WHERE Age <= 12 OR Sex = 'female';
SELECT AVG(Survived) AS others_rate FROM titanic WHERE Sex != 'female' AND Age > 12;
```

## Git Review

### undoing changes

- git reset : staging area
- git reset --hard : reset the staging area and working directory
- git revert


git stash : temporarily save changes that are not yet ready for commite
git rebase <branch>
git cherry-pick

git blame file
git diff
git fetch


git fsck : check the database for errors
git gc : clean u and optimize the local repository

# Storages(S3)

## Amazon S3

### Buckets

- Buckets must have a globally unique name
- Buckets are defined at the region level

### Objects

- in S3, Objects are files with key
- the key is the full path of a file
- s3://my-bucket/my-file.txt
- the key is composed of prefix + object name
- Object values are the content of the body
- there's no copcept of directories within bucket

### S3 Security

#### User-Based

- IAM Policies : which API calls should be allowed for a specific user from IAM

#### Resource-Based

- Bucket Policies : bucket wide rules from S3 console
- Object Access Control List
- Bucket Access Control List

#### Encryption
encrypt objects in Amazon S3 using encryption keys

### S3 Bucket Policies


JSON based policies

- Resources: buckets and objects • Effect: Allow / Deny
- Actions: Set of API to Allow or Deny
- Principal: The account or user to apply  the policy to

### S3 Versioning

- Version files

### S3 Replication

- Must enable Versioning in source and destination buckets
- Cross-Region Replication (CRR)
- Same-Region Replication (SRR)
- Buckets can be in different AWS acounts
- Copying is asynchronous

- **S3 Batch Replication** : Replicates existing objects and objects that failed replication

## S3 Storage Classes

- Durability : high durability of objects across multiple AZ
- Availability : measures how readily available a service is

### S3 Standard

- General Purpose

### S3 Infrequent Access

### S3 Infrequent Access
