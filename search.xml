<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>[Python]간단한 트릭들</title>
      <link href="/2024/01/17/programming/python/Python-Tricks/"/>
      <url>/2024/01/17/programming/python/Python-Tricks/</url>
      
        <content type="html"><![CDATA[<!--categories- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing>goal## 개요### 특정개념이란### 선행지식## 특정개념을 언제 쓰는가## 특정개념 종류(있을 경우) , 옵션들,## 이미 작성한 다른 개념과 차이점## 특정개념 선택 방법론, 할 수 잇는 것들## 구현--><h3 id="1-리스트-값을-기준으로-다른-리스트-분리하기"><a href="#1-리스트-값을-기준으로-다른-리스트-분리하기" class="headerlink" title="1. 리스트 값을 기준으로 다른 리스트 분리하기"></a>1. 리스트 값을 기준으로 다른 리스트 분리하기</h3>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Closure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spring]threadlocal</title>
      <link href="/2024/01/08/backend/spring/back-spring-threadlocal/"/>
      <url>/2024/01/08/backend/spring/back-spring-threadlocal/</url>
      
        <content type="html"><![CDATA[<h3 id="동시성-이슈"><a href="#동시성-이슈" class="headerlink" title="동시성 이슈"></a>동시성 이슈</h3><blockquote><p>같은 인스턴스의 필드를 여러 쓰레드가 접근할 경우 발생</p></blockquote><h3 id="Thread-Local"><a href="#Thread-Local" class="headerlink" title="Thread Local"></a>Thread Local</h3><blockquote><p><code>Thread Local</code>  :  멀티쓰레딩에서 각각의 쓰레드가  전용 데이터 저장소를 가지는 것</p></blockquote><h4 id="주의사항"><a href="#주의사항" class="headerlink" title="주의사항"></a>주의사항</h4><p>웹 어플리케이션의 경우 보통 Thread Pool을 사용하기 때문에 이전에 사용되었고 값이 반환되지 않은 쓰레드가 할당된다면  다른 쓰레드의 리턴값 을 반환하게 될 수 있다.  따라서 사용 후  <code>Thread Local.remove</code>를 통해 반드시 제거해야 한다.</p>]]></content>
      
      
      <categories>
          
          <category> backend </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Java]기본컨셉들</title>
      <link href="/2024/01/07/programming/java/Java-Basic/"/>
      <url>/2024/01/07/programming/java/Java-Basic/</url>
      
        <content type="html"><![CDATA[<h1 id="Java-관련"><a href="#Java-관련" class="headerlink" title="Java 관련"></a>Java 관련</h1><h2 id="Java-구동방식"><a href="#Java-구동방식" class="headerlink" title="Java 구동방식"></a>Java 구동방식</h2><ul><li>1차적으로 컴파일러를 통해 .java 파일을 .class 파일로 변환한다.(바이트 코드)</li><li>2차적으로 JVM을 통해 .class 파일을 실행한다.(JVM은 OS에 종속적이다.)</li></ul><h2 id="변수-자료형-할당-리터럴"><a href="#변수-자료형-할당-리터럴" class="headerlink" title="변수, 자료형, 할당, 리터럴"></a>변수, 자료형, 할당, 리터럴</h2><ul><li>변수 : 데이터를 저장할 수 있는 메모리 공간. 변수를 선언한다는 것은 기본적으로 메모리에 기억 공간을 할당한다는 것이다.</li><li>자료형 : 변수에 저장되는 데이터의 타입을 결정</li><li>할당 : 변수에 값을 대입하는 것</li><li>리터럴 : 변수에 할당되는 값</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Variable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> a ,b,c;</span><br><span class="line">        a = <span class="number">1</span>;</span><br><span class="line">        b = <span class="number">2</span>;</span><br><span class="line">        c = a + b;</span><br><span class="line">        System.out.println(c);</span><br><span class="line">        <span class="type">float</span> <span class="variable">f</span> <span class="operator">=</span> <span class="number">3.14f</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h2><h3 id="Primitive-Type"><a href="#Primitive-Type" class="headerlink" title="Primitive Type"></a>Primitive Type</h3><h3 id="User-Defined-Type"><a href="#User-Defined-Type" class="headerlink" title="User Defined Type"></a>User Defined Type</h3><h3 id="클래스"><a href="#클래스" class="headerlink" title="클래스"></a>클래스</h3><p>기본적으로 제공되는 자료형을 Primitive Type이라고 한다.</p><p>자료형이 기본적으로 제공되는 것이 아닌 사용자가 직접 만들어서 사용하는 것을 Reference Type이라고 한다.</p><p>클래스는 사용자가 직접 만들어서 사용하는 Reference Type이다.</p><h2 id="배열"><a href="#배열" class="headerlink" title="배열"></a>배열</h2><blockquote><p> 배열은 동일한 타입의 데이터를 여러개 저장하기 위한 연속적인 메모리 구조이다.</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"><span class="type">int</span>[] arr = <span class="keyword">new</span> <span class="title class_">int</span> [<span class="number">3</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="접근제어자"><a href="#접근제어자" class="headerlink" title="접근제어자"></a>접근제어자</h2><h2 id="객체지향-프로그래밍"><a href="#객체지향-프로그래밍" class="headerlink" title="객체지향 프로그래밍"></a>객체지향 프로그래밍</h2><h3 id="상속-Inheritance"><a href="#상속-Inheritance" class="headerlink" title="상속(Inheritance)"></a>상속(Inheritance)</h3><h3 id="다형성-Polymorphism"><a href="#다형성-Polymorphism" class="headerlink" title="다형성(Polymorphism)"></a>다형성(Polymorphism)</h3><blockquote><p>다형성이란 하나의 변수명, 함수명 등이 상황에 따라 다른 의미로 해석될 수 있는 것을 말한다.<br>자바에서 Overloading과 Overriding이 다형성의 예이다.</p></blockquote><ul><li>다형성의 본질은 인터페이스를 구현한 객체 인스턴스를 실행 시점에 유연하게 변경할 수 있다는 점이다.</li></ul><h2 id="객체지향-설계-원칙"><a href="#객체지향-설계-원칙" class="headerlink" title="객체지향 설계 원칙"></a>객체지향 설계 원칙</h2><h3 id="SRP-Single-Responsibility-Principle"><a href="#SRP-Single-Responsibility-Principle" class="headerlink" title="SRP(Single Responsibility Principle)"></a>SRP(Single Responsibility Principle)</h3><h3 id="OCP-Open-Closed-Principle"><a href="#OCP-Open-Closed-Principle" class="headerlink" title="OCP(Open-Closed Principle)"></a>OCP(Open-Closed Principle)</h3><h3 id="LSP-Liskov-Substitution-Principle"><a href="#LSP-Liskov-Substitution-Principle" class="headerlink" title="LSP(Liskov Substitution Principle)"></a>LSP(Liskov Substitution Principle)</h3><h3 id="ISP-Interface-Segregation-Principle"><a href="#ISP-Interface-Segregation-Principle" class="headerlink" title="ISP(Interface Segregation Principle)"></a>ISP(Interface Segregation Principle)</h3><h3 id="DIP-Dependency-Inversion-Principle"><a href="#DIP-Dependency-Inversion-Principle" class="headerlink" title="DIP(Dependency Inversion Principle)"></a>DIP(Dependency Inversion Principle)</h3><h2 id="호출방식"><a href="#호출방식" class="headerlink" title="호출방식"></a>호출방식</h2><h3 id="Call-by-Value"><a href="#Call-by-Value" class="headerlink" title="Call by Value"></a>Call by Value</h3><h3 id="Call-by-Reference"><a href="#Call-by-Reference" class="headerlink" title="Call by Reference"></a>Call by Reference</h3><blockquote><p>Call by Reference는 메서드 호출 시에 사용되는 인자의 메모리에 저장되어 있는 값(value)의 주소(Address)를 복사하여 보낸다. 따라서 메서드 내에서 인자의 값을 변경하게 되면, 그 값은 인자로 사용된 변수의 메모리에 저장되어 있기 때문에 변수의 값이 변경된다.</p></blockquote><h2 id="메모리"><a href="#메모리" class="headerlink" title="메모리"></a>메모리</h2><h3 id="Stack-Memory"><a href="#Stack-Memory" class="headerlink" title="Stack Memory"></a>Stack Memory</h3><blockquote><p>Stack Memory는 메서드가 호출될 때마다 Frame이 추가되고, 메서드가 종료되면 해당 Frame이 제거되는 메모리 영역이다.</p></blockquote><h3 id="Heap-Memory"><a href="#Heap-Memory" class="headerlink" title="Heap Memory"></a>Heap Memory</h3><blockquote><p>Heap Memory는 프로그램이 사용하는 동적 메모리 영역이다. </p></blockquote><ul><li>자바에서는 new 연산자를 통해 생성되는 모든 객체는 Heap Memory에 저장된다.</li><li>Heap Memory는 JVM이 시작할 때 생성되고, 모든 스레드가 공유한다.</li><li>Heap Memory는 가비지 컬렉터에 의해 관리된다.</li></ul><h2 id="Thread에-대한-이해"><a href="#Thread에-대한-이해" class="headerlink" title="Thread에 대한 이해"></a>Thread에 대한 이해</h2><blockquote><p>#Java #concept <code>Thread</code> : 프로그램의 가장 작은 실행단위</p></blockquote><h3 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h3><blockquote><p>Thread는 프로그램의 실행 흐름이다. </p></blockquote><h3 id="Main-Thread"><a href="#Main-Thread" class="headerlink" title="Main Thread"></a>Main Thread</h3><h3 id="Thread-Local"><a href="#Thread-Local" class="headerlink" title="Thread Local"></a>Thread Local</h3><h3 id="Thread-의-상태"><a href="#Thread-의-상태" class="headerlink" title="Thread 의 상태"></a>Thread 의 상태</h3><ul><li>New : Thread가 생성되고 아직 start()가 호출되지 않은 상태</li><li>Runnable : 실행 중 또는 실행 가능한 상태</li><li>Blocked : 동기화 블럭에 의해서 일시정지된 상태</li><li>Waiting, Timed Waiting : Thread의 작업이 종료되지는 않았지만 실행가능하지 않은 일시정지 상태</li></ul><h3 id="Thread-구현"><a href="#Thread-구현" class="headerlink" title="Thread 구현"></a>Thread 구현</h3><h3 id="Runnnable"><a href="#Runnnable" class="headerlink" title="Runnnable"></a>Runnnable</h3><blockquote><p><code>Runnable</code> : #concept </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java_basic </tag>
            
            <tag> thread </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spring]트러블슈팅</title>
      <link href="/2024/01/01/backend/spring/back-spring-troubleshooting/"/>
      <url>/2024/01/01/backend/spring/back-spring-troubleshooting/</url>
      
        <content type="html"><![CDATA[<h3 id="Buiilder-초기화-필드-적용"><a href="#Buiilder-초기화-필드-적용" class="headerlink" title="@Buiilder 초기화 필드 적용"></a>@Buiilder 초기화 필드 적용</h3><ul><li>@Builder는 클래스를 빌더 패턴으로 생성할 수 있게 만드는 Annotation</li><li>필드에서 초기화된 상태는  @Builder 에서 무시된다.</li><li>초기화를   @Builder로 하던가 따로 @Builder.Default 를 필드에 명시해준다.</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Builder.Default  </span><br><span class="line">@Column(name = &quot;delete_yn&quot;)  </span><br><span class="line">private Boolean deleteYn = false;  </span><br><span class="line">public void delete()     &#123;  </span><br><span class="line">    this.deleteYn = true;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> backend </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> troubleshooting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Neovim]NeoVim Keybinding</title>
      <link href="/2023/12/30/tools/nvim-keybinding/"/>
      <url>/2023/12/30/tools/nvim-keybinding/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>간단한 파이썬 코딩을 할 경우에는 주로 Neovim을 사용하고 있다. Neovim은<br>플러그인을 이것저것 설치하면서 자신만의 IDE를 만들 수 있다는 장점이 있지만 나는<br>아직 그런 커스텀에 익숙하지 않아서 <code>Nvchad</code> 라는 Neovim 기반 유사 IDE 플러그인을<br>깔고 거기에 필요한 플러그인을 추가하는 방식으로 사용하고 있다.</p><p>이 글에서는 내가 주로 사용하는 Nvim 키 바인딩을 정리하고 업데이트 할 예정이다.</p><h2 id="자주-사용하는-단축키"><a href="#자주-사용하는-단축키" class="headerlink" title="자주 사용하는 단축키"></a>자주 사용하는 단축키</h2><ul><li><code>:sp</code> : 현재 파일을 가로로 분할</li><li><code>:vsp</code> : 현재 파일을 세로로 분할</li><li><code>&lt;leader&gt; + b</code> : 새 버퍼 생성</li><li><code>&lt;leader&gt; + x</code> : 현재 버퍼 닫기</li><li><code>&lt;leader&gt; + ch </code>: 치트시트 확인</li><li><code>&lt;leader&gt; + fm</code> : 현재 파일에 black, prettier 등의 formatter 적용</li><li><code>&lt;leader&gt; + ff</code> : 현재 프로젝트 범위에서 파일 탐색. fzf 적용</li><li><code>:Vista </code> :  파일 스트럭쳐 확인</li><li><code>&lt;leader&gt; + h</code> : 가로 터미널 열기</li></ul><h3 id="필요한-기능"><a href="#필요한-기능" class="headerlink" title="필요한 기능"></a>필요한 기능</h3><ul><li>열편집 (sublimetext같은거)</li><li>다중 편집</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://github.com/folke/which-key.nvim">https://github.com/folke/which-key.nvim</a></li><li><a href="https://github.com/nvim-neo-tree/neo-tree.nvim">https://github.com/nvim-neo-tree/neo-tree.nvim</a> file structure 확인</li><li><a href="https://github.com/liuchengxu/vista.vim">https://github.com/liuchengxu/vista.vim</a></li><li><a href="https://learnbyexample.github.io/tips/vim-tip-14/">https://learnbyexample.github.io/tips/vim-tip-14/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
          <category> Neovim </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeoVim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[FastAPI]Index</title>
      <link href="/2023/12/30/backend/fastapi/back-fastapi-index/"/>
      <url>/2023/12/30/backend/fastapi/back-fastapi-index/</url>
      
        <content type="html"><![CDATA[<h2 id="Operation-Description"><a href="#Operation-Description" class="headerlink" title="Operation Description"></a>Operation Description</h2><h3 id="Status-Code"><a href="#Status-Code" class="headerlink" title="Status Code"></a>Status Code</h3><h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><h3 id="Summary-and-Description"><a href="#Summary-and-Description" class="headerlink" title="Summary and Description"></a>Summary and Description</h3><h3 id="Response-description"><a href="#Response-description" class="headerlink" title="Response description"></a>Response description</h3><h2 id="Routers"><a href="#Routers" class="headerlink" title="Routers"></a>Routers</h2><h3 id="Routers-1"><a href="#Routers-1" class="headerlink" title="Routers"></a>Routers</h3><h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><h3 id="Request-body"><a href="#Request-body" class="headerlink" title="Request body"></a>Request body</h3><h3 id="Path-and-Query-parameters"><a href="#Path-and-Query-parameters" class="headerlink" title="Path and Query parameters"></a>Path and Query parameters</h3><h3 id="Parameter-metadata"><a href="#Parameter-metadata" class="headerlink" title="Parameter metadata"></a>Parameter metadata</h3><h3 id="Validators"><a href="#Validators" class="headerlink" title="Validators"></a>Validators</h3><h3 id="Multiple-values"><a href="#Multiple-values" class="headerlink" title="Multiple values"></a>Multiple values</h3><h3 id="Number-validators"><a href="#Number-validators" class="headerlink" title="Number validators"></a>Number validators</h3><h3 id="Complex-subtypes"><a href="#Complex-subtypes" class="headerlink" title="Complex subtypes"></a>Complex subtypes</h3>]]></content>
      
      
      <categories>
          
          <category> backend </category>
          
          <category> FastAPI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FastAPI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Intellij]Intellij 단축키 정리</title>
      <link href="/2023/12/30/tools/intellij/Intellij-shortcut/"/>
      <url>/2023/12/30/tools/intellij/Intellij-shortcut/</url>
      
        <content type="html"><![CDATA[<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><ul><li>자주 쓰는 Intellij 단축키를 생각날때마다 추가한다.</li><li>VScode Keymap 기준으로 추가한다.</li></ul><h2 id="단축키"><a href="#단축키" class="headerlink" title="단축키"></a>단축키</h2><h3 id="뷰-관련"><a href="#뷰-관련" class="headerlink" title="뷰 관련"></a>뷰 관련</h3><ul><li><code>ctrl+w</code> : 현재 편집기 닫기</li></ul><h3 id="편집-관련"><a href="#편집-관련" class="headerlink" title="편집 관련"></a>편집 관련</h3><ul><li><code>alt+insert</code> -&gt; <code>ctrl+shift+]</code> :  커서 멈춤이슈로 변경</li><li><code>ctrl+e</code> : window switcher 열기</li><li><code>ctrl+enter</code> : window switcher에서 파일 선택</li><li><code>ctrl+shift+R</code> : 선택한 부분 리팩토링 옵션 표시</li><li><code>shift+shift</code> :  전체 검색</li><li><code>ctrl+alt+v</code> :  introduce variable</li><li><code>ctrl+space</code> : 만능 단축키</li><li><code>alt+insert</code>  : 편집기에서 사용()</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
          <category> Intellij </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Python] init, call method</title>
      <link href="/2023/12/30/programming/python/Python-init_call/"/>
      <url>/2023/12/30/programming/python/Python-init_call/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><ul><li><code>__init__</code> method를 이해한다.</li><li><code>__call__</code> method를 이해한다.</li></ul><h2 id="init-method"><a href="#init-method" class="headerlink" title="__init__ method"></a><code>__init__</code> method</h2><p>init은 생성자(Constructor)라고도 불리며, 객체가 생성될 때 자동으로 호출된다.<br>기본적으로 객체를 생성할 때, 객체의 속성을 초기화하는 역할을 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, color</span>):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.color = color</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">car = Car(<span class="string">&#x27;BMW&#x27;</span>, <span class="string">&#x27;red&#x27;</span>) <span class="comment"># __init__ method가 호출된다.</span></span><br></pre></td></tr></table></figure><h2 id="call-method"><a href="#call-method" class="headerlink" title="__call__ method"></a><code>__call__</code> method</h2><p>call은 호출자(Invoker)라고도 불리며, 객체를 함수처럼 호출할 때 자동으로 호출된다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">class Car:</span><br><span class="line">    def __init__(self, name, color):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.color = color</span><br><span class="line"></span><br><span class="line">    def __call__(self,size):</span><br><span class="line">        print(f&#x27;&#123;self.name&#125; is &#123;self.color&#125; and &#123;size&#125; size&#x27;)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">car() # __call__ method가 호출된다.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> init </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Obsidian]Obsidian 커스텀 단축키 업데이트</title>
      <link href="/2023/12/30/tools/obsidian/obsidian-shortcut/"/>
      <url>/2023/12/30/tools/obsidian/obsidian-shortcut/</url>
      
        <content type="html"><![CDATA[<h2 id="단축키"><a href="#단축키" class="headerlink" title="단축키"></a>단축키</h2><h3 id="커스텀-단축키"><a href="#커스텀-단축키" class="headerlink" title="커스텀 단축키"></a>커스텀 단축키</h3><ul><li><code>ctrl + y</code> : 라이브 프리뷰 &lt;-&gt; 소스코드 토글</li><li><code>alt + q</code> :  백틱으로 단어 감싸기</li><li><code>ctrl+shift+L</code> :  개요 창 표시</li></ul><h2 id="추가-필요기능"><a href="#추가-필요기능" class="headerlink" title="추가 필요기능"></a>추가 필요기능</h2><ul><li>수정날짜기준 Sort 기능(플러그인을 찾거나 다른 방법을 찾기)</li><li>파일링크 단순화</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
          <category> Intellij </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[FastAPI]Pydantic  데이터 업데이트</title>
      <link href="/2023/12/30/backend/fastapi/back-fastapi-pydantic/"/>
      <url>/2023/12/30/backend/fastapi/back-fastapi-pydantic/</url>
      
        <content type="html"><![CDATA[<h2 id="Pydantic"><a href="#Pydantic" class="headerlink" title="Pydantic"></a>Pydantic</h2><p>pydantic은 FastApi에서 사용하는 데이터 모델링 라이브러리로 기본 python에서 제공하는 <code>dataclass</code>보다 데이터 검증 측면에서 나은 모습을  보인다.</p><ol><li>Data Parsing : 데이터 타입 추론 및 형변환 </li><li>Data Validation: 데이터 유효성 검사</li></ol><h2 id="Pydantic-데이터-모델-업데이트"><a href="#Pydantic-데이터-모델-업데이트" class="headerlink" title="Pydantic 데이터 모델 업데이트"></a>Pydantic 데이터 모델 업데이트</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">int</span></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    email: <span class="built_in">str</span> = <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>id 와 name 필드를 가지는 user를 생성한다</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user = User(<span class="built_in">id</span>=<span class="number">1</span>, name=<span class="string">&#x27;Jack&#x27;</span>)</span><br></pre></td></tr></table></figure><p>데이터를 직렬화 하여 출력하면 아래와 같이 나온다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">json.dumps(user.<span class="built_in">dict</span>())</span><br><span class="line"><span class="comment"># Output: &#x27;&#123;&quot;id&quot;: 1, &quot;name&quot;: &quot;Jack&quot;, &quot;email&quot;: null&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>user를 생성시 email field에 값을 넣지 않았기에 null이 출력된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">int</span></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    email: <span class="built_in">str</span> = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Config</span>:</span><br><span class="line">        <span class="comment"># use exclude_unset=True</span></span><br><span class="line">        exclude_unset = <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">json.dumps(user.<span class="built_in">dict</span>())</span><br><span class="line"><span class="comment"># Output: &#x27;&#123;&quot;id&quot;: 1, &quot;name&quot;: &quot;John&quot;&#125;&#x27; </span></span><br><span class="line"><span class="comment"># email field가 출력되지 않는다.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Config class에 <code>exclude_unset</code> 옵션을 추가해 정의되지 않은 옵션은 객체 생성시 필드 자체를 만들지 않게끔 할 수있다.</p><ul><li>pydantic model에서 <code>exclude_unset</code> 옵션을 통해 명시적으로 값을 지정하지 않은 필드를 객체 생성시 제외시킬 수 있다.</li><li><code>exclude_unset=True</code>는 기본적으로 partial update를 위해 사용.</li><li>request에서 받은 요청 중 item의 초기값을 제외한 입력값만 추려서 dict를 구성해줌</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://fastapi.tiangolo.com/tutorial/body-updates/#__tabbed_1_2">https://fastapi.tiangolo.com/tutorial/body-updates/#__tabbed_1_2</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> backend </category>
          
          <category> FastAPI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FastAPi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[airflow]Index</title>
      <link href="/2023/12/23/data-engineering/airflow/airflow-index/"/>
      <url>/2023/12/23/data-engineering/airflow/airflow-index/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
          <category> ariflow </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/12/16/frond-end/react/react-index/"/>
      <url>/2023/12/16/frond-end/react/react-index/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> frond-end </category>
          
          <category> react </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/12/09/machine-learning/notebook/visualization/plotly/"/>
      <url>/2023/12/09/machine-learning/notebook/visualization/plotly/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> visualization </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/12/09/machine-learning/notebook/machine-learning/design_pattern/"/>
      <url>/2023/12/09/machine-learning/notebook/machine-learning/design_pattern/</url>
      
        <content type="html"><![CDATA[<p>머신러닝 디자인 패턴 책 읽고 정리</p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/12/09/machine-learning/notebook/visualization/olap/"/>
      <url>/2023/12/09/machine-learning/notebook/visualization/olap/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> visualization </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Firefox]FireFox 단축키 정리하기</title>
      <link href="/2023/12/03/tools/firefox/firefox-shortcut/"/>
      <url>/2023/12/03/tools/firefox/firefox-shortcut/</url>
      
        <content type="html"><![CDATA[<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><p>자주 쓰는 Firefox 단축키를 생각날때마다 추가한다.</p><h2 id="단축키"><a href="#단축키" class="headerlink" title="단축키"></a>단축키</h2><h3 id="탭관련"><a href="#탭관련" class="headerlink" title="탭관련"></a>탭관련</h3><ul><li><code>ctrl+w</code> : 현재 탭 닫기</li><li><code>ctrl+tab</code> : 다음 탭으로 이동</li><li><code>ctrl+pageup</code> : 다음 탭으로 이동</li><li><code>ctrl+shift+tab</code> : 이전 탭으로 이동</li><li><code>ctrl+pagedown</code> : 이전 탭으로 이동</li><li><code>ctrl+t</code> : 새 탭 열기</li><li><code>ctrl+w</code> : 현재 탭 닫기</li><li><code>ctrl+shift+t</code> : 닫은 탭 다시 열기</li><li><code>ctrl+1,2,3,4,5,6,7,8,9</code> : 1번부터 9번까지 탭으로 이동</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
          <category> etc </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Firefox </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[GLM]선형모델과 비선형 모델의 차이</title>
      <link href="/2023/11/26/statistics/Statistics-GLM-test/"/>
      <url>/2023/11/26/statistics/Statistics-GLM-test/</url>
      
        <content type="html"><![CDATA[<!--추가 렉카 및 업데이트https://velog.io/@ithingv/%EC%84%A0%ED%98%95%EB%AA%A8%ED%98%95%EA%B3%BC-%EB%B9%84%EC%84%A0%ED%98%95%EB%AA%A8%ED%98%95-%ED%8C%90%EB%B3%84-Linear-model-nonlinear-modelhttps://velog.io/@ithingv/%EB%8B%A4%EC%A4%91%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80-Multiple-Linear-Regression-Analysis--><p>모델링과 관련하여 선형 및 비선형적인 일반적인 정의에서 중요한 측면은 예측 변수에 대한 선형성이 아니라 매개 변수에 대한 선형성이다. 비선형 모형은 기본적으로 모수가 선형적이지 않기 때문에 비선형적이다.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://stats.stackexchange.com/questions/71437/distinction-between-linear-and-nonlinear-model">https://stats.stackexchange.com/questions/71437/distinction-between-linear-and-nonlinear-model</a></li><li><a href="https://brunch.co.kr/@gimmesilver/18">https://brunch.co.kr/@gimmesilver/18</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Statistics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Java]기본컨셉들</title>
      <link href="/2023/11/25/programming/java/Java-Action/"/>
      <url>/2023/11/25/programming/java/Java-Action/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/11/12/programming/oop/"/>
      <url>/2023/11/12/programming/oop/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> programming </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Docker]Docker 기본개념</title>
      <link href="/2023/10/28/data-engineering/de-docker-basic/"/>
      <url>/2023/10/28/data-engineering/de-docker-basic/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h2 id="Docker개념"><a href="#Docker개념" class="headerlink" title="Docker개념"></a>Docker개념</h2><ul><li>도커 이미지는 다른 이미지 위에 쌓는게 가능하다.</li><li>VM은 독립적으로 운영되고 독립적인 자원을 사용하기 때문에 그 경우에 효율적일 수 있다.</li><li>도커의 Layer는 설계도이다.</li><li>이미지는 기본적으로 아직 실행되지 않은 컨테이너이다.</li></ul><p>Docker Container는 가상환경과 다르다.</p><p>가상환경은 python version만 폴더안에 있는걸 쓰는 것이고 Docker Container는 아예 독립된 환경이다.</p><h2 id="Doker-명령어들"><a href="#Doker-명령어들" class="headerlink" title="Doker 명령어들"></a>Doker 명령어들</h2><p>도커 빌드하기</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /path/to/Dockerfile</span><br><span class="line">$ sudo docker build .</span><br></pre></td></tr></table></figure><p>현재 실행되고 있는 도커 프로세스들확인</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker ps</span><br></pre></td></tr></table></figure><p>전체 도커 프로세스 확인</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker ps -a</span><br></pre></td></tr></table></figure><p>Run an image in a new container daemonized</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -d &lt;image_name&gt;</span><br></pre></td></tr></table></figure><p>Run an image in interactive mode with the command <code>/bin/bash</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t &lt;image_name&gt; /bin/bash</span><br></pre></td></tr></table></figure><p>Run an image in interactive mode with the command <code>/bin/bash</code> and link the ports.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t --link &lt;docker_container_name&gt;:&lt;docker_container_alias&gt; &lt;image_name&gt; /bin/bash</span><br></pre></td></tr></table></figure><p>Run an image with an ENTRYPOINT command in interactive mode with the command <code>/bin/bash</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --entrypoint /bin/bash -i -t &lt;image_name&gt;</span><br></pre></td></tr></table></figure><p>Run an image in interactive mode with the command <code>/bin/bash</code> mounting the host director <code>/var/app/current</code> to the container directory <code>/usr/src/app</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t -v /var/app/current:/usr/src/app/ &lt;image_name&gt; /bin/bash</span><br></pre></td></tr></table></figure><p>Run an image in interactive mode with the command <code>/bin/bash</code> setting the environments variables <code>FOO</code> and <code>BAR</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t -e FOO=foo -e BAR=bar &lt;image_name&gt; /bin/bash</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://gist.github.com/dwilkie/f8d6526edc5f1a8aca385df5113567e4">https://gist.github.com/dwilkie/f8d6526edc5f1a8aca385df5113567e4</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math]미분 기초개념</title>
      <link href="/2023/10/28/statistics/Statistics-Math-derivatives/"/>
      <url>/2023/10/28/statistics/Statistics-Math-derivatives/</url>
      
        <content type="html"><![CDATA[<blockquote><p>미분의 정의, Data Science에서 미분이 필요한 이유, 미분 공식들에 대해 알아보자.</p></blockquote><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="미분"><a href="#미분" class="headerlink" title="미분"></a>미분</h2><ul><li>함수의 input인 x에 대해서 나오는 결과값이 변화하는 정도를(0에 근사하는 부분을 탐색) 계산하는 것</li><li>실제로 계산하는 것은 x의 변화량인 delta_x가 한없이 0에 가까워 질 때의 기울기이다.</li><li><strong>Data Science에서 미분이 필요한 이유는 기본적으로 모델의 오차함수가 최소화되는 지점(오차함수의 변화율이 0이 되는 지점)을 찾을 때 미분이 활용되기 때문이다.(최적화 문제)</strong></li></ul><h2 id="미분-공식"><a href="#미분-공식" class="headerlink" title="미분 공식"></a>미분 공식</h2><p>numerical method만큼은 확실히 이해하고 넘어가자.</p><h3 id="numerical-method"><a href="#numerical-method" class="headerlink" title="numerical  method"></a>numerical  method</h3><p>실제로 0으로 나눌 수는 없기 때문에 Delta_x를 0에 근사한 값인 1e-5로 나눠준다.이를 numerical method라 한다.</p><h4 id="미분-기본공식"><a href="#미분-기본공식" class="headerlink" title="미분 기본공식"></a>미분 기본공식</h4><p>$$ f’(x) &#x3D; {f(x + \Delta x) - f(x) \over \Delta x}, \Delta x \rightarrow 0~ $$</p><h3 id="power-rule"><a href="#power-rule" class="headerlink" title="power rule"></a><strong>power rule</strong></h3><p>멱함수의 도함수를 구하는 미분규칙</p><p>$ \frac{d} { {dx} }x^n&#x3D;nx^{n-1} $ </p><h4 id="chain-rule"><a href="#chain-rule" class="headerlink" title="chain rule"></a><strong>chain rule</strong></h4><p>합성함수에 대한 미분규칙. 바깥함수의 도함수에 안쪽함수를 인자로 넣어주고 안쪽함수의 도함수를 곱해주면 된다.</p><p>$$ \frac{dy} {dx} &#x3D; \frac{dy} {du} \times \frac{du} {dx} $$</p><p>좀 더 이해하기 쉽게 나타내면 아래와 같다.</p><p>$$F(x) &#x3D; f(g(x))$$</p><p>$$F’(x) \rightarrow f’((g(x)) \cdot g’(x)$$</p><h4 id="Exponential"><a href="#Exponential" class="headerlink" title="Exponential"></a><strong>Exponential</strong></h4><p>지수함수에 대한 미분규칙. 지수함수의 경우 도함수도 지수함수이다.</p><p>$$ f(x) &#x3D; e^x \rightarrow f’(x) &#x3D; e^x $$</p><h4 id="Logarithmic"><a href="#Logarithmic" class="headerlink" title="Logarithmic"></a><strong>Logarithmic</strong></h4><p>자연로그에 대한 미분규칙.Logistic Regression이나 Section sigmoid 함수를 미분하는데 도움을 준다.</p><p>$$f(x) &#x3D; lnx \rightarrow f’(x) &#x3D; { {1} \over {x} } $$</p><h4 id="product-rule"><a href="#product-rule" class="headerlink" title="product rule"></a><strong>product rule</strong></h4><p>두 함수의 곱으로 이루어진 함수에 대한 미분규칙.</p><p>$$\frac{d}{ {dx} }\left( {f\left( x \right)g\left( x \right)} \right) &#x3D; f\left( x \right)\frac{d} { {dx} }g\left( x \right) + \frac{d}{ {dx} }f\left( x \right)g\left( x \right)$$</p><h4 id="quotinent-rule"><a href="#quotinent-rule" class="headerlink" title="quotinent rule"></a><strong>quotinent rule</strong></h4><p>분수형태로 생긴 합성함수에 대한 미분규칙. 시그모이드 함수의 도함수를 구할 때 사용된다.</p><p>$$\frac{d}{ {dx} }\left( {\frac{ {f\left( x \right)} } { {g\left( x \right)} } } \right) &#x3D; \frac{ {\frac{d} { {dx} }f\left( x \right)g\left( x \right) - f\left( x \right)\frac{d}{ {dx} }g\left( x \right)} } { {g^2 \left( x \right)} }$$</p><h3 id="편미분-Partial-Derivtives"><a href="#편미분-Partial-Derivtives" class="headerlink" title="편미분(Partial Derivtives)"></a><strong>편미분(Partial Derivtives)</strong></h3><ul><li>편미분은 다변수 함수의 특정 변수를 제외한 나머지 변수를 상수로 간주하여 미분하는 것이다.</li><li>최적화 관점에서 보면 파라미터가 2개 이상인 Error 함수에 대해 <strong>우선 1개의 파라미터에 대해서만 미분을 한다</strong>는 것이다.</li><li>편미분은 ${\partial y} \over {\partial x}$ 와 같이 나타내며 이 경우 x에 대해 편미분한다 하며 x를 제외한 나머지 변수는 상수취급하고 미분한다.</li><li><strong>선형회귀에서 오차함수의 최소값을 유도할때 사용된다</strong>.</li><li>ex) x에 대해 편미분할 경우</li></ul><p>$$ f(x,y) &#x3D; x^2 + 2xy + y^2$$</p><p>$${ {\partial f(x,y)} \over {\partial x} } &#x3D; { {\partial {(x^2 + 2xy + y^2)} } \over {\partial x}} &#x3D; 2x + 2y$$</p><h2 id="sympy를-활욯한-미분계산"><a href="#sympy를-활욯한-미분계산" class="headerlink" title="sympy를 활욯한 미분계산"></a>sympy를 활욯한 미분계산</h2><p>실무에서 이런식으로 따로 미분을 할 일은 없지만 구현한다는 것에 의의를 두자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#import sympy</span></span><br><span class="line"><span class="keyword">from</span> sympy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># Symbol정의하기</span></span><br><span class="line">x = Symbol(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 함수 정의하기</span></span><br><span class="line">f = x**<span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#도함수 계산하기</span></span><br><span class="line">derivative_f = f.diff(x)</span><br><span class="line"></span><br><span class="line">derivative_f</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.askpython.com/python/examples/derivatives-in-python-sympy#:~:text=Derivatives%20of%20Multivariable%20Functions%20using%20sympy&amp;text=Such%20derivatives%20are%20generally%20referred,all%20other%20variables%20held%20constant">https://www.askpython.com/python/examples/derivatives-in-python-sympy#:~:text=Derivatives%20of%20Multivariable%20Functions%20using%20sympy&amp;text=Such%20derivatives%20are%20generally%20referred,all%20other%20variables%20held%20constant</a>.</li><li><a href="https://youtu.be/H-ybCx8gt-8">https://youtu.be/H-ybCx8gt-8</a></li><li><a href="https://ko.wikipedia.org/wiki/%ED%8E%B8%EB%AF%B8%EB%B6%84">https://ko.wikipedia.org/wiki/%ED%8E%B8%EB%AF%B8%EB%B6%84</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Statistics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Probability]이항분포의 이해</title>
      <link href="/2023/10/28/statistics/Statistics-Prob-binary-dist/"/>
      <url>/2023/10/28/statistics/Statistics-Prob-binary-dist/</url>
      
        <content type="html"><![CDATA[<!--진짜 refhttps://www.statology.org/multinomial-distribution-in-python/https://boxnwhis.kr/2015/06/04/multinomial_dist_for_gachas.html다항로지스틱 머신러닝https://machinelearningmastery.com/multinomial-logistic-regression-with-python/확륳함수로부터 나오는 확률들의 패턴을 확률분포라 한다https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h3 id="이항분포-Binary-Distribution"><a href="#이항분포-Binary-Distribution" class="headerlink" title="이항분포(Binary Distribution)"></a>이항분포(Binary Distribution)</h3><blockquote><p>n번의 독립시행에서 성공 확률이 p일 때의 이산확률분포</p></blockquote><ul><li><p>확률변수 K가 n과 p를 가지는 이항분포를 따른다면, K ~ B(n,p)로 나타낸다.</p></li><li><p>n번 시행 중에 k번 성공할 확률은 확률질량함수로 주어진다</p></li><li><p>이항분포는 n이 일정수준 이상으로 커질 경우 정규분포에 근사한다.</p></li><li><p><strong>n&#x3D;1일 경우 이항분포는 베르누이 시행이다.</strong></p></li><li><p>심플하게 생각하면 <strong>성공과 실패 두 가지 결과가 있는 확률적 사건을 n번 반복했을때 성공이 몇번 나타날지를 확률분포로 나타낸것이다.</strong></p></li><li><p>ex) 성공확률이 주어졌을 때 특정 리뷰데이터가 나올 확률</p></li></ul><p><strong>이항분포 공식</strong></p><ul><li>이항분포를 따르는 확률변수 K가 있을때 n번시행에서 k번 성공할 확률을 나타내는 PMF는 다음과 같다.</li></ul><ul><li><p>$\binom{n}{k}$는 단순히 가능한 조합의 수를 나타낸다.</p></li><li><p>n이 6이고 k가 2일 경우 2번 성공하고 n-k번 실패할 확률를 곱해서 계산한다.(독립시행)</p></li></ul><p>$$P(X &#x3D; k) &#x3D; \binom{n}{k} p^k (1-p)^{n-k}$$</p><ul><li>이항분포의 기댓값은 다음과 같다.</li></ul><p>$E(K) &#x3D; np$</p><ul><li>분산은 다음과 같다. 단순히 n번의 독립적인 베르누이 시행의 분산을 더한 것이다,</li></ul><p>$Var(K) &#x3D; np(1-p)$</p><p><strong>이항분포의 PMF</strong></p><p align="center"><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtoZzt%2FbtqVdebL4pt%2FmrdViwxudFPtOMDqVmyb2K%2Fimg.png" alt="drawing" width="500"/></p>  <p><strong>이항분포 구현</strong></p><p>R에서 제공하는 dbinom() 함수를 사용하여 이항분포를 구현할 수 있다.</p><ul><li><p>dbinom(k,n,p) : 이항분포의 확률값</p></li><li><p>pbinom(k,n,p) : 이항분포의 누적확률 값</p></li><li><p>qbinom(p,size,prob) : 이항분포의 백분위수. pbinom의 역수</p></li><li><p>rbinom(n,size,prob) : 이항분포를 따르는 난수생성</p></li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 주사위를 10번 던져서 원하는 값이 2번 나올 확률</span></span><br><span class="line"></span><br><span class="line">df <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>dice <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> prob <span class="operator">=</span> dbinom<span class="punctuation">(</span>x <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> size <span class="operator">=</span> <span class="number">10</span><span class="punctuation">,</span> prob <span class="operator">=</span> <span class="number">1</span><span class="operator">/</span><span class="number">6</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">df <span class="operator">%&gt;%</span></span><br><span class="line"></span><br><span class="line">mutate<span class="punctuation">(</span>Dice <span class="operator">=</span> ifelse<span class="punctuation">(</span>dice <span class="operator">==</span> <span class="number">2</span><span class="punctuation">,</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span> <span class="string">&quot;other&quot;</span><span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">%&gt;%</span></span><br><span class="line"></span><br><span class="line">ggplot<span class="punctuation">(</span>aes<span class="punctuation">(</span>x <span class="operator">=</span> factor<span class="punctuation">(</span>dice<span class="punctuation">)</span><span class="punctuation">,</span> y <span class="operator">=</span> prob<span class="punctuation">,</span> fill <span class="operator">=</span> Dice<span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line"></span><br><span class="line">geom_col<span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line"></span><br><span class="line">geom_text<span class="punctuation">(</span></span><br><span class="line"></span><br><span class="line">aes<span class="punctuation">(</span>label <span class="operator">=</span> <span class="built_in">round</span><span class="punctuation">(</span>prob<span class="punctuation">,</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span> y <span class="operator">=</span> prob <span class="operator">+</span> <span class="number">0.01</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">position <span class="operator">=</span> position_dodge<span class="punctuation">(</span><span class="number">0.9</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">size <span class="operator">=</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">vjust <span class="operator">=</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line"></span><br><span class="line">labs<span class="punctuation">(</span>title <span class="operator">=</span> <span class="string">&quot;Probability of X = 2 successes.&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">x <span class="operator">=</span> <span class="string">&quot;Successes&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">y <span class="operator">=</span> <span class="string">&quot;probability&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/images/binary_distribution_r.png"></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 이항분포가 B(10,0.5)를 따를 경우 P[X&gt;3] 계산</span></span><br><span class="line"></span><br><span class="line">pbinom<span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span> <span class="number">10</span><span class="punctuation">,</span> <span class="number">0.5</span><span class="punctuation">,</span> lower.tail<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span> <span class="comment"># 1-pbinom(3, 10, 0.5) 과 같은 값이 나온다.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://youtu.be/nMsCHfrt3Cw">https://youtu.be/nMsCHfrt3Cw</a></li><li><a href="https://en.wikipedia.org/wiki/Binomial_distribution#">https://en.wikipedia.org/wiki/Binomial_distribution#</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Statistics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Probability </tag>
            
            <tag> Distribution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Git]Private repository import 하기</title>
      <link href="/2023/10/28/infra/git/git-private-repo/"/>
      <url>/2023/10/28/infra/git/git-private-repo/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programmingdf- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>보안이나 기타 이유로 private repository에서 관리하는 패키지를 써야할 경우가 있다.</strong></p><p><strong>나중에도 자주 쓸거 같으니까 개인용 패키지를 pandas나 sklearn처럼 설치하고 사용하는 법을 정리해두자.</strong></p><hr><h2 id="작업용-repository-만들기"><a href="#작업용-repository-만들기" class="headerlink" title="작업용 repository 만들기"></a>작업용 repository 만들기</h2><p>적당한 이름의 private repository를 만들고 패키지를 넣을 디렉터리를 만들어준다. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> some_package</span><br></pre></td></tr></table></figure><h2 id="init-py-만들기"><a href="#init-py-만들기" class="headerlink" title="__init__.py 만들기"></a><code>__init__.py</code> 만들기</h2><p><code>__init__.py</code> 파일을 디렉터리에 넣으면 pip에서 해당 디렉토리를 패키지로 인식한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example 패키지(디렉토리)의 broadcast 파일에서  전부 가져오기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> example.broadcast <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><h2 id="패키지에-함수-넣기"><a href="#패키지에-함수-넣기" class="headerlink" title="패키지에 함수 넣기"></a>패키지에 함수 넣기</h2><p>패키지 디렉토리에 포함될 함수를 넣어준다.</p><p>여기서는 numpy의 broadcast를 구현하는 함수를 넣어주었다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># broadcast.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">m1 = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">m2 = np.array([<span class="number">10</span>,<span class="number">20</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m1 * m2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="setup-py-만들기"><a href="#setup-py-만들기" class="headerlink" title="setup.py 만들기"></a><code>setup.py</code> 만들기</h2><p>setup.py에는 패키지의 메타데이터를 넣어준다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Python package setup info</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> setuptools</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;README.md&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> fh:</span><br><span class="line">    long_description = fh.read()</span><br><span class="line"></span><br><span class="line">setuptools.setup(</span><br><span class="line">    name=<span class="string">&#x27;레포이름&#x27;</span>,</span><br><span class="line">    version=<span class="string">&#x27;0.0.1&#x27;</span>,</span><br><span class="line">    author=<span class="string">&#x27;jinheonyoon&#x27;</span>,</span><br><span class="line">    author_email=<span class="string">&#x27;yjinheon@gmail.com&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;Package 설치 확인&#x27;</span>,</span><br><span class="line">    long_description=long_description,</span><br><span class="line">    long_description_content_type=<span class="string">&quot;text/markdown&quot;</span>,</span><br><span class="line">    url=<span class="string">&#x27;https://github.com/yjinheon/레포이름.git&#x27;</span>,</span><br><span class="line">    project_urls = &#123;</span><br><span class="line">        <span class="string">&quot;Bug Tracker&quot;</span>: <span class="string">&quot;https://github.com/yjinheon/레포이름/issues&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    license=<span class="string">&#x27;jinheonyoon&#x27;</span>,</span><br><span class="line">    zip_safe = <span class="literal">False</span>,</span><br><span class="line">    packages = [<span class="string">&#x27;설치한 패키지 명&#x27;</span>],</span><br><span class="line">    install_requires = [</span><br><span class="line">        <span class="string">&#x27;numpy==1.20.1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pandas==1.3&#x27;</span></span><br><span class="line">        ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="token-생성하기"><a href="#token-생성하기" class="headerlink" title="token 생성하기"></a>token 생성하기</h2><p>Github 계정의 <code>Setting</code>의 <code>developer settings</code>에서 token을 생성할 수 있다.</p><p><a href="https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token">여기</a> 참조</p><h2 id="설치하기"><a href="#설치하기" class="headerlink" title="설치하기"></a>설치하기</h2><p>생성한 토큰을 로컬에 변수로 넣어준다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export token=생성한 토큰</span><br></pre></td></tr></table></figure><p>$token으로 토큰을 불러와서 일반 package처럼 private repository의 package를 설치할 수 있다.</p><p>설치할 때는 <code>powershell</code>이나 <code>git</code>을 관리자 모드로 열어야한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://&#123;<span class="variable">$token</span>&#125;@github.com/yjinheon/toolbox</span><br></pre></td></tr></table></figure><h2 id="사용하기-amp-결론"><a href="#사용하기-amp-결론" class="headerlink" title="사용하기 &amp; 결론"></a>사용하기 &amp; 결론</h2><p>repository로 설치를 하고 불러올 때는 package명으로 불러와줘야 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> eda <span class="keyword">import</span> glimpse <span class="comment"># 최근에 넣어둔 eda용 헬퍼함수</span></span><br><span class="line"></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;penguins&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">glimpse(df)</span><br><span class="line">Shape:  (<span class="number">344</span>, <span class="number">7</span>)</span><br><span class="line">species           <span class="built_in">object</span>   <span class="number">0</span> (<span class="number">0</span>%) NAs : Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie</span><br><span class="line">island            <span class="built_in">object</span>   <span class="number">0</span> (<span class="number">0</span>%) NAs : Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torg</span><br><span class="line">bill_length_mm    float64  <span class="number">2</span> (<span class="number">1</span>%) NAs : <span class="number">39.1</span>, <span class="number">39.5</span>, <span class="number">40.3</span>, nan, <span class="number">36.7</span>, <span class="number">39.3</span>, <span class="number">38.9</span>, <span class="number">39.2</span>, <span class="number">34.1</span>, <span class="number">42.0</span></span><br><span class="line">bill_depth_mm     float64  <span class="number">2</span> (<span class="number">1</span>%) NAs : <span class="number">18.7</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, nan, <span class="number">19.3</span>, <span class="number">20.6</span>, <span class="number">17.8</span>, <span class="number">19.6</span>, <span class="number">18.1</span>, <span class="number">20.2</span></span><br><span class="line">flipper_length_mm float64  <span class="number">2</span> (<span class="number">1</span>%) NAs : <span class="number">181.0</span>, <span class="number">186.0</span>, <span class="number">195.0</span>, nan, <span class="number">193.0</span>, <span class="number">190.0</span>, <span class="number">181.0</span>, <span class="number">195.0</span>, <span class="number">193.0</span>, <span class="number">190.0</span></span><br><span class="line">body_mass_g       float64  <span class="number">2</span> (<span class="number">1</span>%) NAs : <span class="number">3750.0</span>, <span class="number">3800.0</span>, <span class="number">3250.0</span>, nan, <span class="number">3450.0</span>, <span class="number">3650.0</span>, <span class="number">3625.0</span>, <span class="number">4675.0</span>, <span class="number">3475.0</span>, <span class="number">4</span></span><br><span class="line">sex               <span class="built_in">object</span>  <span class="number">11</span> (<span class="number">3</span>%) NAs : Male, Female, Female, nan, Female, Male, Female, Male, nan, nan</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>아직 패키지만 만든 상태라서 편한지 어떤지는 모르겠다. 몇주 써보고 좀 익숙해져야 할 것 같다.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token">Personal access token 만들기</a></li><li><a href="https://docs.readthedocs.io/en/stable/guides/private-python-packages.html">private-python-package</a></li><li><a href="https://towardsdatascience.com/create-your-custom-python-package-that-you-can-pip-install-from-your-git-repository-f90465867893">custom-package</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Infra </category>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Bash]Direction Operators</title>
      <link href="/2023/10/28/data-engineering/de-bash-direction_operators/"/>
      <url>/2023/10/28/data-engineering/de-bash-direction_operators/</url>
      
        <content type="html"><![CDATA[<h2 id="Direction-Operators"><a href="#Direction-Operators" class="headerlink" title="Direction Operators"></a>Direction Operators</h2><p>리눅스에서 데이터의 입출력방향을 다루는 연산자는 Direction Operators이다.</p><p>Direction Operators에는 <code>&gt;</code>와 <code>&gt;&gt;</code>가 있다.</p><p><code>&gt;</code>와 <code>&gt;&gt;</code> 의 차이점은 Linux에서의 데이터의 출력방향이다.</p><p><code>&gt;</code> : 기존 파일을 덮어쓰거나 지정한 이름의 파일이 디렉토리에 없는 경우 파일을<br>생성한다 <code>&gt;&gt;</code> : 기존 파일에 추가하거나 지정한 이름의 파일이 디렉토리에 없는 경우<br>파일을 생성한다.</p><p>정리하면 다음과 같다.</p><ul><li>파일을 수정하고 기존 데이터를 덮어쓰려면 <code>&gt;</code> 사용.</li><li>파일에 무언가를 추가하려면 <code>&gt;&gt;</code> 연산자를 사용.</li></ul><h2 id="예제"><a href="#예제" class="headerlink" title="예제"></a>예제</h2><ol><li><code>&gt;</code> 연산자 사용</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># a.txt 파일에 &quot;Hello World&quot;를 출력한다.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello World&quot;</span> &gt; a.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li><code>&gt;&gt;</code> 연산자 사용</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a.txt 파일에 <span class="string">&quot;Goodbye World&quot;</span>를 추가한다.</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Goodbye World&quot;</span> &gt;&gt; a.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> a.txt</span><br><span class="line"></span><br><span class="line">Hello World</span><br><span class="line">Goodbye World</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.tutorialspoint.com/unix/unix-io-redirections.htm">https://www.tutorialspoint.com/unix/unix-io-redirections.htm</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Docker]Docker 자주쓰는 명령어</title>
      <link href="/2023/10/28/data-engineering/de-docker-commands/"/>
      <url>/2023/10/28/data-engineering/de-docker-commands/</url>
      
        <content type="html"><![CDATA[<h2 id="도커-이미지"><a href="#도커-이미지" class="headerlink" title="도커 이미지"></a>도커 이미지</h2><h3 id="docker-images"><a href="#docker-images" class="headerlink" title="docker images"></a>docker images</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure><h2 id="도커-컨테이너"><a href="#도커-컨테이너" class="headerlink" title="도커 컨테이너"></a>도커 컨테이너</h2><h3 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h3><p>: 도커 이미지 실행</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v [로컬경로]:/[컨테이너경로] -d -p 8080:8080 yjinheon/test:latest</span><br></pre></td></tr></table></figure><h3 id="docker-ps"><a href="#docker-ps" class="headerlink" title="docker ps"></a>docker ps</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모든 컨테이너를 보여준다</span></span><br><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실행중인 docker containner id 전부 가져오기</span></span><br><span class="line">docker ps | awk <span class="string">&#x27;NR &gt; 1 &#123;print $1&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 맨위의 docker container 하나만 가져오기</span></span><br><span class="line">docker ps | awk <span class="string">&#x27;NR &gt; 1 &#123;print $1; exit&#125;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="docker-rm"><a href="#docker-rm" class="headerlink" title="docker rm"></a>docker rm</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 컨테이너 ID로 삭제</span></span><br><span class="line">docker <span class="built_in">rm</span> [컨테이너 ID]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 컨테이너 명으로 삭제</span></span><br><span class="line">docker <span class="built_in">rm</span> [컨네이너 명]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실행중인 컨테이너 강제삭제</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">rm</span> -f [컨테이너명]</span><br></pre></td></tr></table></figure><ul><li>id가 none인 도커 이미지 전부 삭제</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi $(docker images -a|grep <span class="string">&quot;&lt;none&gt;&quot;</span>|awk <span class="string">&#x27;$1==&quot;&lt;none&gt;&quot; &#123;print $3&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="도커-볼륨"><a href="#도커-볼륨" class="headerlink" title="도커 볼륨"></a>도커 볼륨</h2><h3 id="docker-volume"><a href="#docker-volume" class="headerlink" title="docker volume"></a>docker volume</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker create volume [볼륨명]</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.docker.com/engine/reference/commandline/ps/#filtering">https://docs.docker.com/engine/reference/commandline/ps/#filtering</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Docker]YAML 파일 작성시 key의 의미</title>
      <link href="/2023/10/28/data-engineering/de-docker-compose-yaml-keys/"/>
      <url>/2023/10/28/data-engineering/de-docker-compose-yaml-keys/</url>
      
        <content type="html"><![CDATA[<h2 id="YAML-파일-작성시-key의-의미"><a href="#YAML-파일-작성시-key의-의미" class="headerlink" title="YAML 파일 작성시 key의 의미"></a>YAML 파일 작성시 key의 의미</h2><p>docker-compose.yml 파일을 작성하다 보면 가끔 특수한 key들을 볼 수 있다.<br>이들을 yaml 파일에서 사용되는 일종의 Operator이며 의미를 알고 있으면 yaml 파일을 해석하거나 docker-compose 파일 작성시 유용하게 활용할 수 있다. </p><h3 id="amp-와"><a href="#amp-와" class="headerlink" title="&amp; 와 *"></a><code>&amp;</code> 와 <code>*</code></h3><ul><li><p><code>&amp;</code> : <code>&amp;</code>는 anchor를 설정해주는 기호이다.</p></li><li><p><code>*</code> : <code>*</code>는 anchor를 참조하는 기호이다.</p></li><li><p>아래 예제에서 foo는 anchor이고 bar는 anchor를 참조하는 것이다.</p></li><li><p>bar 가 foo를 참조하기 때문에 bar의 key1, key2는 foo의 key1, key2와 같은 값을 가지게 된다.</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">foo:</span> <span class="meta">&amp;myanchor</span></span><br><span class="line">  <span class="attr">key1:</span> <span class="string">&quot;val1&quot;</span></span><br><span class="line">  <span class="attr">key2:</span> <span class="string">&quot;val2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">bar:</span> <span class="meta">*myanchor</span></span><br></pre></td></tr></table></figure><h3 id="lt-lt"><a href="#lt-lt" class="headerlink" title="&lt;&lt; "></a><code>&lt;&lt; </code></h3><ul><li><code>&lt;&lt;</code>는 merge를 의미한다</li><li><code>&lt;&lt;</code> Operator를 사용해서 anchor로 정의 한 변수를 merge 할 수 있다.</li><li>anchor에서 쓰던 키에 새로운 값을 넣어서 변수를 오버라이딩할 수 있다.</li><li>아래 예제에서는 bar의 key2를 foo의 key2로 오버라이딩한다.</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">foo:</span> <span class="meta">&amp;myanchor</span></span><br><span class="line">  <span class="attr">key1:</span> <span class="string">&quot;val1&quot;</span></span><br><span class="line">  <span class="attr">key2:</span> <span class="string">&quot;val2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">bar:</span></span><br><span class="line">  <span class="string">&lt;&lt;</span> <span class="string">:</span> <span class="meta">*myanchor</span></span><br><span class="line">  <span class="attr">key2:</span> <span class="string">&quot;val2-new&quot;</span></span><br><span class="line">  <span class="attr">key3:</span> <span class="string">&quot;val3&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a></li><li><a href="https://stackoverflow.com/questions/50072810/whats-the-double-arrow-django-mean-in-a-docker-compose-file">https://stackoverflow.com/questions/50072810/whats-the-double-arrow-django-mean-in-a-docker-compose-file</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Data Transformation]Feature Scaling의 이해</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-dt-Scaler/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-dt-Scaler/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h2><!--진짜 렉카standar- https://datascience.stackexchange.com/questions/45900/when-to-use-standard-scaler-and-when-normalizer조건수의 의미- https://datascienceschool.net/03%20machine%20learning/04.03%20%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81.html조건수가 크면 약간의 오차만 있어도 해가 전혀 다른 값을 가진다. 따라서 조건수가 크면 회귀분석을 사용한 예측값도 오차가 커지게 된다.회귀분석에서 조건수가 커지는 경우는 크게 두 가지가 있다.1) 변수들의 단위 차이로 인해 숫자의 스케일이 크게 달라지는 경우. 이 경우에는 스케일링(scaling)으로 해결한다.2) 다중 공선성 즉, 상관관계가 큰 독립 변수들이 있는 경우, 이 경우에는 변수 선택이나 PCA를 사용한 차원 축소 등으로 해결한다.다음의 경우- 데이터가 편포된 경우- 독립변수와 예측치가 비선형인 경우https://deepinsight.tistory.com/113--><h3 id="Feature-Scaling에서-overflow와-underflow의-의미"><a href="#Feature-Scaling에서-overflow와-underflow의-의미" class="headerlink" title="Feature Scaling에서 overflow와 underflow의 의미"></a>Feature Scaling에서 overflow와 underflow의 의미</h3><p><strong>no blog</strong></p><p>A common pre-processing step is to normalize&#x2F;rescale inputs so that they are not too high or low.</p><p>However, even on normalized inputs, overflows and underflows can occur:</p><p>Underflow: Joint probability distribution often involves multiplying small individual probabilities. Many probabilistic algorithms involve multiplying probabilities of individual data points that leads to underflow. Example : Suppose you have 1000 data points, where the probability of each is &lt; 1 lets say around 0.8, we have 0.8 ^ 1000 &#x3D; 1.2302319e-97 which is close to 0. This is underflow.<br>A common way to combat this is to work in the log probability space: <a href="http://blog.smola.org/post/987977550/log-probabilities-semirings-and-floating-point">http://blog.smola.org/post/987977550/log-probabilities-semirings-and-floating-point</a></p><p>Overflow: Imagine you have a deep network, error gradients an keep accumulating and often become  vary large gradients. This results in an overflow where the values of the gradients become NAN. Weight regularization and gradient clipping are some common ways of dealing with this problem.</p><h3 id="Scaling을-하는-이유"><a href="#Scaling을-하는-이유" class="headerlink" title="Scaling을 하는 이유"></a>Scaling을 하는 이유</h3><hr><p>feature scaling을 하는 가장 직관적인 이유는 <strong>분석 단위(크기)를 맟줘주기 위해서이다.</strong> 모델 학습시 각 feature의 크기를 맟줘 줌으로서 학습 시 특정 feature의 영향이 너무 커지는 것을 방지할 수 있다.</p><p><strong>scaling은 공분산행렬의 조건수(condition number)를 감소시킨다.</strong></p><p>조건수는 행렬에서 eigen value와 가장 작은 eigen value의 비율을 말한다.</p><p>$$\text{condition number} &#x3D; \dfrac{\lambda_{\text{max}}}{\lambda_{\text{min}}}$$</p><p>조건수가 커질수록 약간의 오차에 대해서도 회귀방정식의 해의 오차가 민감하게 변하기 때문에 회귀식의 에러가 커진다.</p><p>조건수의 eigen value는 분산을 바탕으로 구해지기 때문에 scaling을 통해 condition number를 줄일 수 있다.</p><p>feature가 scaling이 되지 않을 경우 조건수가 커져서 에러가 증폭된다.</p><p><strong>scaling은 데이터의 크기와 범위를 제한해서 Gradient Explode나 Gradient Vanishing을 제한한다.</strong></p><ul><li>feature마다 </li><li>데이터의 범의를 줄여서 Neural network의 최적화 과정에서 수렴속도를 빠르게 한다.  </li><li>Neural network model에서 sigmoid 활성화 함수의 <code>saturation</code>(포화) 문제를 완화한다.(Gradient Vanishing)</li></ul><p><strong>정리하면 Scaling의 핵심은 데이터가 유사한 범위를 가지도록 데이터의 범위를 제한한다는 것이다.</strong></p><ol><li>데이터의 범위를 제한해서 조건수를 낮춰 예측오차에 덜 민감해게끔 만든다.</li><li>데이터의 범위를 제한해서 기울기 폭발,소실 문제를 완화한다.</li></ol><h3 id="어떤-경우에-Feature-Scaling을-고려해야-하는가"><a href="#어떤-경우에-Feature-Scaling을-고려해야-하는가" class="headerlink" title="어떤 경우에 Feature Scaling을 고려해야 하는가?"></a>어떤 경우에 Feature Scaling을 고려해야 하는가?</h3><hr><p><strong>거리 기반 모델의 경우 Scaling이 매우 중요하다</strong></p><ul><li>KNN,K-means clausturing : 유클리디안 거리를 기반으로 데이터 유사성을 결정하기 때문에 Scaling의 영향을 크게 받는다.</li><li>SVM : margin(거리)를 최대화하는 것이 최적화 문제에 포함된 </li><li>PCA : 알고리즘의 목적 자체가 분산이 가장 큰 방향을 가지는 고유벡터를 찾는 것이기 때문에 Scaling의 영향을 크게 받는다. 따라서 반드시 사전에 모든 수치형 변수들의 Scaling을 해줘야 한다.</li></ul><p><strong>Gradient Descent 기반 모델의 경우</strong></p><p>신경망을 기반으로 하는 모델의 경우 loss function을 최소화 하는 방식으로 최적화를 진행한다.<br>이는 각 feature의 범위와 크기가 다를 경우 feature 마다 다른 step size를 적용해야 한다는 것을 뜻한다.<br>따라서 scaling를 통해 범위를 맞춰줄 경우 gradient descent의 수렴이 보다 빠르게 이루어진다.</p><p><strong>tree기반 알고리즘의 경우 Scaling에 따라 성능에 영향받지 않는다.</strong></p><p>대표적으로 tree기반 알고리즘에 해당하는 CART,RandomForest 등은 학습의 대상이 거리와 관련이 없기 때문에 (학습의 대상이 일종의 분기점) Scaling을 해줄 필요가 없다. Scaling을 해주는 경우가 가끔 있지만 이는 Scailng을 요구하는 다른 알고리즘과의 비교를 위해서이다.</p><p><strong>언제 Scaling을 하는가?</strong></p><p><strong>반드시 학습데이터와 검증 데이터를 나눈 이후에 Scaling을 시행한다.</strong></p><p>이는 data leakage로 인해 test data의 정보가 모델링에 포함 될 수 있기 때문이다.</p><ul><li>train test split 이후의 Scaling 예시</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">normalizer = preprocessing.Normalizer().fit(X_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train = normalizer.transform(X_train) </span><br><span class="line">X_test = normalizer.transform(X_test) </span><br></pre></td></tr></table></figure><!--언제 scaling을 하는가?렉카https://datascience.stackexchange.com/questions/54908/data-normalization-before-or-after-train-test-splithttps://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-dataNormalization across instances should be done after splitting the data between training and test set, using only the data from the training set.This is because the test set plays the role of fresh unseen data, so it's not supposed to be accessible at the training stage. Using any information coming from the test set before or during training is a potential bias in the evaluation of the performance.[Precision thanks to Neil's comment] When normalizing the test set, one should apply the normalization parameters previously obtained from the training set as-is. Do not recalculate them on the test set, because they would be inconsistent with the model and this would produce wrong predictions.Gradient Descent의 의미Gradient descent is an iterative optimisation algorithm that takes us to the minimum of a function.Machine learning algorithms like linear regression and logistic regression rely on gradient descent to minimise their loss functions or in other words, to reduce the error between the predicted values and the actual values.Having features with varying degrees of magnitude and range will cause different step sizes for each feature. Therefore, to ensure that gradient descent converges more smoothly and quickly, we need to scale our features so that they share a similar scale.Check out this video where Andrew Ng explains the gradient descent algorithm in more detail.Data leakage와 싸우기 위한 5가지 팁!-일시적 제거 : 관찰이 일어난 시간보다 사실이나 관찰에 대해 배운 시간에 초점을 맞추어 관심 이벤트 직전의 모든 데이터를 제거하십시오.-소음 추가. 입력 데이터에 임의의 노이즈를 추가하여 누출 가능성이있는 변수의 영향을 부드럽게합니다.-누출 변수를 제거하십시오. 간단한 규칙 기반 모델을 평가하려면 OneR에 계좌 번호 및 ID 등과 같은 변수를 사용하여 이러한 변수가 누출인지 확인하고 누락 된 경우이를 제거하십시오. 변수가 누설 된 것으로 의심되면 제거하는 것을 고려하십시오.-파이프 라인을 사용하십시오. R의 caret 패키지 및 scikit-learn의 파이프 라인과 같은 교차 검증 폴드 내에서 일련의 데이터 준비 단계를 수행 할 수있는 파이프 라인 아키텍처를 많이 사용합니다.-데이터를 따로 보유하십시요. validation데이터 셋을 따로 보유한후 마지막에 최종적으로 모델을 평가하는데 사용하면 됩니다.--><h3 id="Scaler의-종류"><a href="#Scaler의-종류" class="headerlink" title="Scaler의 종류"></a>Scaler의 종류</h3><hr><p>Scaling 대표적인 기법</p><ul><li><strong>Normalization(정규화)</strong></li></ul><p>보통 값을 0,1 사이로 고정시킨다.</p><ul><li><strong>Standardization(표준화)</strong></li></ul><h4 id="MinMaxScaler"><a href="#MinMaxScaler" class="headerlink" title="MinMaxScaler"></a>MinMaxScaler</h4><ul><li>대부분의 Scaler가 그런 것 처럼 이상치에 민감하다.</li><li>데이터가 가우시안 분포가 아니고 사이즈가 작을 경우 유용하다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 직접 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x-<span class="built_in">min</span>(x))/(<span class="built_in">max</span>(x)-<span class="built_in">min</span>(x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn 에서 제공하는 MinMazScaler</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"></span><br><span class="line">X_train_new = scaler.fit_transform(X_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Robust-Scaler"><a href="#Robust-Scaler" class="headerlink" title="Robust Scaler"></a>Robust Scaler</h4><ul><li>중앙값과 IQR을 사용해 이상치의 영향을 줄인 Scaler</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn 구현</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line">rbs = RobustScaler()</span><br><span class="line">rbs.fit_transform(X_train)</span><br></pre></td></tr></table></figure><h4 id="StandardScaler"><a href="#StandardScaler" class="headerlink" title="StandardScaler"></a>StandardScaler</h4><ul><li>기본적으로 정규분포를 가정한다.</li><li>평균을 0, 분산은 1인 분포로 feature를 변환</li><li>이상치의 영향이 크기 때문에 이상치가 많을 경우 사전에 제거해주거나 다른 Scaler를 고려해야함</li><li>데이터의 최소 최대를 모르는 경우 사용</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 직접구현</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_standard</span>(<span class="params">x</span>):</span><br><span class="line">    mean = np.mean(x)</span><br><span class="line">    rescale = x-mean/np.std(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rescale</span><br><span class="line"></span><br><span class="line"><span class="comment"># slearn</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line">X_train_new = scaler.fit_transform(X_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Normalizer"><a href="#Normalizer" class="headerlink" title="Normalizer"></a>Normalizer</h4><ul><li>column-wise가 아니라 row wise로 정규화를 적용</li><li>최적화 과정에서 gradient exlosion이나 gradient vanishing을 막기 위해 사용</li></ul><p><strong>Reference &amp; Annotaion</strong></p><ul><li><a href="https://www.quora.com/What-are-condition-numbers-and-poor-conditioning-How-are-they-related-to-deep-learning">condition number의 의미</a></li><li><a href="https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1">importance of feature scaling</a></li><li><code>saturation</code>은 sigmoid 활성화 함수의 특정구간에서 gradient가 0에 가까워지는 것이다.(Gradient Vanishing 문제)</li><li><a href="https://www.youtube.com/watch?v=F6GSRDoB-Cg&t=74s">https://www.youtube.com/watch?v=F6GSRDoB-Cg&amp;t=74s</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Python]numpy 연산과 활용법</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-numpy-basics/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-numpy-basics/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h2><p><strong>numpy 기능들</strong></p><ul><li>벡터 배열상에서 데이터 가공, 정제, 부분집합 필터링, 변형 및 기타연산</li><li>정렬, unique 탐색, 집합연산같은 일반적인 배열처리 알고리즘</li></ul><p>numpy의 중요한 특징은 <strong>파이썬 반복문을 사용하지 않고</strong> 대용량 배열에 대한 복잡한 연산이 가능하다는 것이다.</p><p>기본적으로 C랑 포트란 기반으로 짜여졌기 때문에 같은 연산이라면 pandas랑 비교도 안되게 빠르게 수행할 수 있다.</p><hr><h3 id="numpy-basics"><a href="#numpy-basics" class="headerlink" title="numpy basics"></a>numpy basics</h3><ul><li>배열 생성<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">5</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">   ...: arr = np.arange(<span class="number">0</span>,<span class="number">10</span>) <span class="comment"># 0에서 9까지 의 </span></span><br><span class="line">   ...:</span><br><span class="line">   ...: arr.reshape(<span class="number">2</span>,<span class="number">5</span>) <span class="comment"># 배열 형태 변환</span></span><br><span class="line">Out[<span class="number">5</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">   ...: arr = np.arange(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: arr=arr.reshape(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>배열 형태 확인(ndim,shape,len)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: arr.ndim <span class="comment"># 차원 수</span></span><br><span class="line">Out[<span class="number">7</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: arr.shape <span class="comment"># 모양</span></span><br><span class="line">Out[<span class="number">8</span>]: (<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: <span class="built_in">len</span>(arr)</span><br><span class="line">Out[<span class="number">9</span>]: <span class="number">10</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>배열 데이터 타입 확인(dtype)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">15</span>]: arr_2 = np.random.rand(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: arr_2</span><br><span class="line">Out[<span class="number">16</span>]: array([<span class="number">0.55155657</span>, <span class="number">0.32745746</span>, <span class="number">0.92681611</span>, <span class="number">0.04614794</span>, <span class="number">0.17832697</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: arr_2.dtype</span><br><span class="line">Out[<span class="number">17</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: arr_3 = np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype = np.float64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: arr_3.dtype</span><br><span class="line">Out[<span class="number">19</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>배열 데이터 타입 변환(astype)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: arr_2=arr_2.astype(np.int64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: arr_2.dtype</span><br><span class="line">Out[<span class="number">25</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: arr_3=arr_3.astype(np.int64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: arr_3.dtype</span><br><span class="line">Out[<span class="number">27</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>배열 생성함수들</strong></p><ul><li><p><code>array</code> : 입력데이터를 다차원 배열로 변환.</p></li><li><p><code>arange</code> : <code>range</code>와 동일하지만 다차원 배열을 반환.</p></li><li><p><code>np.empty(a)</code> ,<code>np.empty_like(M)</code> : 0 이나 1로 값을 초기화하지 않은 배열을 반환.</p></li><li><p><code>np.ones(a)</code> : a 크기의 1으로 채워진 배열을 반환 </p></li><li><p><code>np.ones_like(M)</code> M 배열의 사이즈와 같은 1으로 채워진 배열을 반환</p></li><li><p><code>np.zeros(a)</code> : a 크기의 0으로 채워진 배열을 반환 </p></li><li><p><code>np.zeros_like(M)</code> M 배열의 사이즈와 같은 0으로 채워진 배열을 반환</p></li><li><p><strong><code>np.full</code> :인자로 값과 형태를 받고. 인자로 받은 형태에 값을 채운다.(자주쓴다.)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np full 용법</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p><code>np.full_like</code> : 인자로 값과 형태를 받고. 인자로 받은 형태에 값을 채운다.</p></li><li><p><code>eye</code> , <code>identity</code>: N * N 크기의 단위행렬생성</p></li><li><p><code>np.random.rand(n)</code> : n 크기 난수 배열 생성</p></li></ul><h3 id="numpy-indexing"><a href="#numpy-indexing" class="headerlink" title="numpy indexing"></a>numpy indexing</h3><ul><li>기본 파이썬 list indexing과 유사하지만 차원이 복잡해지면 어려워진다.</li></ul><h4 id="기초-슬라이싱과-인덱싱"><a href="#기초-슬라이싱과-인덱싱" class="headerlink" title="기초 슬라이싱과 인덱싱"></a>기초 슬라이싱과 인덱싱</h4><ul><li>기본적으로 list의 그것과 다를 건 없다.</li><li><code>i:j:k</code> 형태로 인덱싱한다.<ul><li>i는 starting index </li><li>j는 stopping index(j-1 까지 슬라이싱된다.)</li><li>k는 step</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: x = np.array(<span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: x[<span class="number">1</span>:<span class="number">7</span>:<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">3</span>]: array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: x[-<span class="number">2</span>:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">4</span>]: array([<span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: x[-<span class="number">3</span>:<span class="number">3</span>:-<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">5</span>]: array([<span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: x[<span class="number">5</span>:]</span><br><span class="line">Out[<span class="number">6</span>]: array([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>인덱스 리스트를 통해 쉽게 배열의 값에 접근할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: arr_2d = np.arange(<span class="number">1</span>,<span class="number">10</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: arr_2d</span><br><span class="line">Out[<span class="number">51</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: arr_2d[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">52</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 보통 두 번째 방법을 많이 사용한다.</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: arr_2d[<span class="number">0</span>,<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">53</span>]: <span class="number">3</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>다차원 슬라이싱하기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: arr_2d[:<span class="number">2</span>,<span class="number">1</span>:]</span><br><span class="line">Out[<span class="number">54</span>]:</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>좀 복잡한 형태의 다차원 슬라이싱</li></ul><p><img src="https://media.geeksforgeeks.org/wp-content/uploads/Numpy1.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 다차원 배열 인덱싱 예시</span></span><br><span class="line"> [[<span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>] </span><br><span class="line">  [<span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span>]</span><br><span class="line">  [<span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> <span class="number">16</span> <span class="number">17</span>]</span><br><span class="line">  [<span class="number">18</span> <span class="number">19</span> <span class="number">20</span> <span class="number">21</span> <span class="number">22</span> <span class="number">23</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">25</span> <span class="number">26</span> <span class="number">27</span> <span class="number">28</span> <span class="number">29</span>]</span><br><span class="line">  [<span class="number">30</span> <span class="number">31</span> <span class="number">32</span> <span class="number">33</span> <span class="number">34</span> <span class="number">35</span>]]</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>, <span class="number">3</span>:<span class="number">5</span>]  =  [<span class="number">3</span> <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">a[<span class="number">4</span>:, <span class="number">4</span>:] = [[<span class="number">28</span> <span class="number">29</span>],</span><br><span class="line">             [<span class="number">34</span> <span class="number">35</span>]]</span><br><span class="line"></span><br><span class="line">a[:, <span class="number">2</span>] =  [<span class="number">2</span> <span class="number">8</span> <span class="number">14</span> <span class="number">20</span> <span class="number">26</span> <span class="number">32</span>]</span><br><span class="line"></span><br><span class="line">a[<span class="number">2</span>:;<span class="number">2</span>, ::<span class="number">2</span>] = [[<span class="number">12</span> <span class="number">14</span> <span class="number">16</span>],</span><br><span class="line">                [<span class="number">24</span> <span class="number">26</span> <span class="number">28</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>:</code> 연산자를 통해  <code>:</code> 가 위치하는 축의 모든 값에 접근할 수 있다.</li><li>배열 자체에 <code>[:]</code> 를 사용할 경우 배열의 모든 값이 할당된다.<ul><li><strong>기본적으로 데이터가 복사되지 않는다.</strong></li><li>데이터를 복사해야 할 경우 <code>copy</code> 함수를 따로 사용한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">44</span>]: arr</span><br><span class="line">Out[<span class="number">44</span>]:</span><br><span class="line">array([[<span class="number">0.23061655</span>, <span class="number">0.86734388</span>, <span class="number">0.27967631</span>],</span><br><span class="line">       [<span class="number">0.63734555</span>, <span class="number">0.47048728</span>, <span class="number">0.04833744</span>],</span><br><span class="line">       [<span class="number">0.99362969</span>, <span class="number">0.87636748</span>, <span class="number">0.59988875</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: arr[:,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">45</span>]: array([<span class="number">0.86734388</span>, <span class="number">0.47048728</span>, <span class="number">0.87636748</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: arr[:,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">46</span>]: array([<span class="number">0.86734388</span>, <span class="number">0.47048728</span>, <span class="number">0.87636748</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: arr[:]</span><br><span class="line">Out[<span class="number">47</span>]:</span><br><span class="line">array([[<span class="number">0.23061655</span>, <span class="number">0.86734388</span>, <span class="number">0.27967631</span>],</span><br><span class="line">       [<span class="number">0.63734555</span>, <span class="number">0.47048728</span>, <span class="number">0.04833744</span>],</span><br><span class="line">       [<span class="number">0.99362969</span>, <span class="number">0.87636748</span>, <span class="number">0.59988875</span>]])</span><br></pre></td></tr></table></figure><ul><li><strong>배열의 일부는 원본배열의 View 이기 때문에 파이썬 <code>list</code> 와 달리 배열의 일부에 대한 변경은 그대로 원본배열에 반영된다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">28</span>]: arr_new = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: arr_new[<span class="number">4</span>:<span class="number">7</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: arr_new</span><br><span class="line">Out[<span class="number">30</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br></pre></td></tr></table></figure><h4 id="boolen-indexing"><a href="#boolen-indexing" class="headerlink" title="boolen indexing"></a>boolen indexing</h4><ul><li>실질적으로 가장 자주쓰는 인덱싱이다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: temp=np.random.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: temp[temp&gt;<span class="number">0.5</span>]</span><br><span class="line">Out[<span class="number">63</span>]:</span><br><span class="line">array([<span class="number">0.77402793</span>, <span class="number">0.59064775</span>, <span class="number">0.67170741</span>, <span class="number">0.51967736</span>, <span class="number">0.75161734</span>,</span><br><span class="line">       <span class="number">0.98559447</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="fancy-indexing"><a href="#fancy-indexing" class="headerlink" title="fancy indexing"></a>fancy indexing</h4><ul><li>인덱싱과 슬라이싱의 차이는 입력된 범위의 값을 가져오느냐 연속된 값들을 가져오느냐의 차이밖에 없다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">56</span>]: array = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">    ...:</span><br><span class="line">    ...: </span><br><span class="line">    ...: array[[<span class="number">0</span>, <span class="number">2</span>], :<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">56</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><h3 id="numpy-배열-변형하기-array-transformation"><a href="#numpy-배열-변형하기-array-transformation" class="headerlink" title="numpy 배열 변형하기(array transformation)"></a>numpy 배열 변형하기(array transformation)</h3><h4 id="Transpose"><a href="#Transpose" class="headerlink" title="Transpose"></a>Transpose</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i = np.transpose(b) Permute array dimensions</span><br><span class="line">i.T Permute array dimensions</span><br></pre></td></tr></table></figure><h4 id="Changing-Array-Shape"><a href="#Changing-Array-Shape" class="headerlink" title="Changing Array Shape"></a>Changing Array Shape</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b.ravel() <span class="comment">#Flatten the array</span></span><br><span class="line">g.reshape(<span class="number">3</span>,-<span class="number">2</span>) <span class="comment">#Reshape, but don’t change data</span></span><br><span class="line">b.flatten() <span class="comment"># rabel() 과 같지만 배열의 copy를 생</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Adding-x2F-Removing-Elements"><a href="#Adding-x2F-Removing-Elements" class="headerlink" title="Adding&#x2F;Removing Elements"></a>Adding&#x2F;Removing Elements</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">h.resize((<span class="number">2</span>,<span class="number">6</span>)) Return a new array <span class="keyword">with</span> shape (<span class="number">2</span>,<span class="number">6</span>)</span><br><span class="line">np.append(h,g) Append items to an array</span><br><span class="line">np.insert(a, <span class="number">1</span>, <span class="number">5</span>) Insert items <span class="keyword">in</span> an array</span><br><span class="line">np.delete(a,[<span class="number">1</span>]) Delete items <span class="keyword">from</span> an array</span><br></pre></td></tr></table></figure><h4 id="Combine-array"><a href="#Combine-array" class="headerlink" title="Combine array"></a>Combine array</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: arr_1 = np.arange(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: arr_2 = np.arange(<span class="number">6</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: np.concatenate((arr_1,arr_2),axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">13</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: np.vstack((arr_1,arr_2))</span><br><span class="line">Out[<span class="number">14</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: np.r_[arr_1,arr_2]</span><br><span class="line">Out[<span class="number">15</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: np.hstack((arr_1,arr_2))</span><br><span class="line">Out[<span class="number">16</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: np.c_[arr_1,arr_2]</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Split-array"><a href="#Split-array" class="headerlink" title="Split array"></a>Split array</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: np.hsplit(arr_1,<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">19</span>]: [array([<span class="number">1</span>, <span class="number">2</span>]), array([<span class="number">3</span>, <span class="number">4</span>])]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: arr_3 = np.arange(<span class="number">1</span>,<span class="number">10</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 행 단위 split</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: np.vsplit(arr_3,<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">25</span>]: [array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]), array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]), array([[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="numpy-method"><a href="#numpy-method" class="headerlink" title="numpy method"></a>numpy method</h3><h4 id="np-where"><a href="#np-where" class="headerlink" title="np.where"></a>np.where</h4><ul><li><code>np.where(조건,if true 값,else 값)</code> 방식으로 사용한다.</li><li>기본적으로 조건에 기반해 새로운 배열을 생성한다.</li><li><strong>logical statement를 vectorize한다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Out[<span class="number">63</span>]: df</span><br><span class="line">   A   B   C     D</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: df[<span class="string">&quot;E&quot;</span>] = np.where((df[<span class="string">&quot;B&quot;</span>] &gt; <span class="number">10</span>) &amp; (df[<span class="string">&quot;C&quot;</span>] &gt; <span class="number">10</span>), <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    ...: df</span><br><span class="line">Out[<span class="number">64</span>]:</span><br><span class="line">   A   B   C     D  E</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span>  <span class="number">1</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span>  <span class="number">0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span>  <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="np-select"><a href="#np-select" class="headerlink" title="np.select"></a>np.select</h4><ul><li><code>np.where</code>의 multiple condition 버전이다.</li><li>2개 이상의 조건을 한번에 처리해야 할경우 pandas를 사용하는 것 보다 <code>np.select</code>를 활용해 한번에 처리하는 것이 낫다.</li></ul><p><img src="https://i.imgur.com/Z3XHteT.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np select 예시</span></span><br><span class="line">In [<span class="number">65</span>]: conditions = [</span><br><span class="line">    ...:   (df[<span class="string">&quot;B&quot;</span>] &gt;= <span class="number">10</span>) &amp; (df[<span class="string">&quot;A&quot;</span>] == <span class="number">0</span>),</span><br><span class="line">    ...:   (df[<span class="string">&quot;B&quot;</span>] &gt;= <span class="number">10</span>) &amp; (df[<span class="string">&quot;A&quot;</span>] == <span class="number">8</span>)</span><br><span class="line">    ...: ]</span><br><span class="line">    ...: values = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    ...: df[<span class="string">&quot;F&quot;</span>] = np.select(conditions, values, default=<span class="number">0</span>)</span><br><span class="line">    ...: df</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">65</span>]:</span><br><span class="line">   A   B   C     D  E  F</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span>  <span class="number">0</span>  <span class="number">0</span></span><br></pre></td></tr></table></figure><h4 id="np-log"><a href="#np-log" class="headerlink" title="np.log"></a>np.log</h4><ul><li>자연로그를 리턴한다.<ul><li>np.log(np.e) 는 1을 리턴한다.</li></ul></li><li>데이터 정규화시 사용.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.log([<span class="number">1</span>, np.e, np.e**<span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">array([  <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">2.</span>, -Inf])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="np-sort-배열-정렬하기"><a href="#np-sort-배열-정렬하기" class="headerlink" title="np.sort(배열 정렬하기)"></a>np.sort(배열 정렬하기)</h4><ul><li><code>np.sort(M)</code> 로 배열을 정렬한다.<ul><li>M.sort() 는 배열 자체를 정렬한 결과를 리턴하지만 <code>np.sort(M)</code>은 배열의 복사본을 정렬해 리턴한다,</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">39</span>]: arr_1d = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">    ...:</span><br><span class="line">    ...: arr_2d = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    ...:</span><br><span class="line">    ...: <span class="built_in">print</span>(arr_1d)</span><br><span class="line">    ...: <span class="built_in">print</span>(arr_2d)</span><br><span class="line">[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">8</span> <span class="number">5</span> <span class="number">2</span> <span class="number">8</span> <span class="number">0</span> <span class="number">3</span> <span class="number">9</span>]</span><br><span class="line">[[<span class="number">8</span> <span class="number">4</span> <span class="number">3</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: <span class="built_in">print</span>(np.sort(arr_1d))</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span> <span class="number">5</span> <span class="number">8</span> <span class="number">8</span> <span class="number">9</span>]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>np.sort(M)[::-1]</code> : 역순 정렬</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: <span class="built_in">print</span>(np.sort(arr_1d)[::-<span class="number">1</span>])</span><br><span class="line">[<span class="number">9</span> <span class="number">8</span> <span class="number">8</span> <span class="number">5</span> <span class="number">3</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>행과 열 기준으로 정렬이 가능하다.<ul><li><code>np.sort(x, axis=1)</code> : 열 기준</li><li><code>np.sort(x, axis=0)</code> : 행 기준</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: <span class="built_in">print</span>(np.sort(arr_2d, axis=<span class="number">0</span>))</span><br><span class="line">    ...: <span class="built_in">print</span>(np.sort(arr_2d, axis=<span class="number">1</span>))</span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">4</span> <span class="number">3</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">8</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]]</span><br><span class="line">[[<span class="number">1</span> <span class="number">3</span> <span class="number">4</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure><h4 id="np-pad"><a href="#np-pad" class="headerlink" title="np.pad"></a>np.pad</h4><ul><li>배열을 일정한 고정길이로 만들기 위해 특정한 값으로 채우는 함수.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Z = np.ones((<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">Z.pad(pad_width=<span class="number">1</span>, </span><br><span class="line">      mode=<span class="string">&#x27;constant&#x27;</span>, <span class="comment"># 특정한 값을 지정해서 패딩할 경우</span></span><br><span class="line">      constant_values=<span class="number">0</span>) <span class="comment"># 값 지정</span></span><br><span class="line"></span><br><span class="line">Z      </span><br><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>2차원 배열 패딩</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: m = np.arange(<span class="number">1</span>,<span class="number">9</span>).reshape(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: m</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 행과 열 모두 2개씩 0으로 패딩 </span></span><br><span class="line">In [<span class="number">20</span>]: np.pad(m,((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>)),<span class="string">&#x27;constant&#x27;</span>,constant_values =<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">20</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: np.pad(m,((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>)),<span class="string">&#x27;constant&#x27;</span>,constant_values =<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">21</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="numpy-broadcasting"><a href="#numpy-broadcasting" class="headerlink" title="numpy broadcasting"></a>numpy broadcasting</h3><ul><li><p>numpy의 연산은 기본적으로 같은 크기의 배열간의 연산을 전제한다.</p></li><li><p>하지만 특정 조건을 만족했을 때 numpy는 자동적으로 크기가 다른 배열간의 연산을 수행하기도 하는데 이를 <code>broadcasting</code>이라 한다.</p></li><li><p><code>broadcasting</code> 연산이 성립되기 위한 다음의 3가지 규칙이 존재한다.</p><ul><li><strong>규칙 1: 두 배열의 차원 수가 다를 경우, 크기가 작은 배열의 모양은 맨 앞(왼쪽)에 패딩됨</strong></li><li><strong>규칙 2: 두 배열의 모양이 임의의 차원에서 일치하지 않으면 해당 차원에서 모양이 1인 배열은 다른 모양과 일치하도록 확장됨</strong></li><li><strong>규칙 3: 어떤 차원에서든 크기가 일치하지 않고 둘 다 1과 같지 않으면 오류가 발생.</strong></li></ul></li><li><p><strong>단순히 한쪽의 크기를 맞춰서 연산이 가능하게끔 만드는 것이라고 생각하면 이해하기 쉽다.</strong></p></li></ul><p><img src="https://jakevdp.github.io/PythonDataScienceHandbook/figures/02.05-broadcasting.png"></p><ul><li><code>a</code> 의 차원이 더 작기 때문에 규식 1,2 에 따라 연산시 <code>a</code> 가 padding 되고 확장됨.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: M = np.ones((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">   ...: a = np.arange(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="built_in">print</span>(M.shape)</span><br><span class="line">(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: <span class="built_in">print</span>(a.shape)</span><br><span class="line">(<span class="number">3</span>,)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: M + a</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: a.shape</span><br><span class="line">Out[<span class="number">9</span>]: (<span class="number">3</span>,)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>References</strong></p><ul><li><a href="https://numpy.org/doc/stable/index.html">Numpy 공식문서</a></li><li><a href="https://www.datacamp.com/community/blog/python-numpy-cheat-sheet">numpy array transfrormation</a></li><li><a href="https://www.geeksforgeeks.org/numpy-indexing/">numpy indexing</a></li><li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html">numpy broadcasting</a></li><li><a href="https://sparrow.dev/numpy-pad/">numpy padding</a></li><li><a href="https://towardsdatascience.com/3-numpy-functions-to-facilitate-data-analysis-with-pandas-b1ad342a569">numpy select</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[pandas]기본자료형을 DataFrame으로 변환하기</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-pandas-collection-to-df/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-pandas-collection-to-df/</url>
      
        <content type="html"><![CDATA[<!--- ML- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling<center>Kaggle Customer Score Dataset</center>#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p>Python으로 데이터 분석을 하다보면 pandas를 찾게 되는 경우가 많다.<br>Python 기본 자료형을 pandas에서 제공하는 자료형으로 변환하는 데 익숙해지면 전처리작업을 보다 수월할게 할 수 있다.</p><p> <strong>여기서는 작업을 하면서 자주쓰게 되는 자료형 변환 방법들을 정리하였다</strong></p><hr><p>아래 데이터를 사용해서 연습해보자</p><table><thead><tr><th align="right">Age</th><th align="right">CustomerID</th><th align="left">Genre</th></tr></thead><tbody><tr><td align="right">19</td><td align="right">1</td><td align="left">Male</td></tr><tr><td align="right">21</td><td align="right">2</td><td align="left">Male</td></tr><tr><td align="right">20</td><td align="right">3</td><td align="left">Female</td></tr><tr><td align="right">23</td><td align="right">4</td><td align="left">Female</td></tr><tr><td align="right">31</td><td align="right">5</td><td align="left">Female</td></tr></tbody></table><h2 id="Collection-to-DataFrame"><a href="#Collection-to-DataFrame" class="headerlink" title="Collection to DataFrame"></a>Collection to DataFrame</h2><h3 id="Dictionary-to-DataFrame"><a href="#Dictionary-to-DataFrame" class="headerlink" title="Dictionary to DataFrame"></a>Dictionary to DataFrame</h3><p>기본적으로 하나의 row가 하나의 dictionary형태로 list에 들어간다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data=&#123;<span class="string">&#x27;Age&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">19</span>, <span class="number">1</span>: <span class="number">21</span>, <span class="number">2</span>: <span class="number">20</span>, <span class="number">3</span>: <span class="number">23</span>, <span class="number">4</span>: <span class="number">31</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;CustomerID&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">1</span>, <span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">3</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">5</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;Genre&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;Female&#x27;</span>&#125;&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Tuple-to-DataFrame"><a href="#Tuple-to-DataFrame" class="headerlink" title="Tuple to DataFrame"></a>Tuple to DataFrame</h3><p>Tuple은 분석단계에서보다는 DataBase와 연결해서 CRUD할 일이 있을 경우 자주 사용된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data=[(<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data, columns=[<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;ID&#x27;</span>, <span class="string">&#x27;Gender&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="List-to-DataFrame"><a href="#List-to-DataFrame" class="headerlink" title="List to DataFrame"></a>List to DataFrame</h3><p>list의 경우 <code>list(zip(lst, lst2, lst3))</code> 로 tuple 형태로 데이터를 변환해준 뒤 DF를 만든다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df = pd.DataFrame(list(zip(lst, lst2, lst3)),</span><br><span class="line">               columns=[&#x27;Age&#x27;, &#x27;ID&#x27;, &#x27;Gender&#x27;])</span><br><span class="line">df</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="DataFrame-to-Collection"><a href="#DataFrame-to-Collection" class="headerlink" title="DataFrame to Collection"></a>DataFrame to Collection</h2><p>반대로 DataFrame에서 Python 기본 자료형을 받아야와 할 경우도 있다.</p><p>이 경우는 pandas library에서 제공하는 함수들을 통해 쉽게 해결할 수 있다.</p><h3 id="Dataframe-to-Ditonary"><a href="#Dataframe-to-Ditonary" class="headerlink" title="Dataframe to Ditonary"></a>Dataframe to Ditonary</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df.to_dict()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&#123;<span class="string">&#x27;Age&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">19</span>, <span class="number">1</span>: <span class="number">21</span>, <span class="number">2</span>: <span class="number">20</span>, <span class="number">3</span>: <span class="number">23</span>, <span class="number">4</span>: <span class="number">31</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;CustomerID&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">1</span>, <span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">3</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">5</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;Genre&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;Female&#x27;</span>&#125;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Dataframe-to-Tuple"><a href="#Dataframe-to-Tuple" class="headerlink" title="Dataframe to Tuple"></a>Dataframe to Tuple</h3><p><code>itertuple()</code>을 사용할 시 name을 default로 넣으면 컬럼명도 같이 반환된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>(df.itertuples(index=<span class="literal">False</span>,name=<span class="literal">None</span>)) <span class="comment"># df to tuple</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;[(<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>)]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="DataFrame-to-List"><a href="#DataFrame-to-List" class="headerlink" title="DataFrame to List"></a>DataFrame to List</h3><p>컬럼을 list로 변환</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.columns.values.tolist()</span><br></pre></td></tr></table></figure><p>값을 list로 변환</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.values.tolist()</span><br><span class="line"></span><br><span class="line">&gt;&gt;[[<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line"> [<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line"> [<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line"> [<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line"> [<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>]]</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.geeksforgeeks.org/create-a-pandas-dataframe-from-lists/">https://www.geeksforgeeks.org/create-a-pandas-dataframe-from-lists/</a></li><li><a href="https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples">https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[pandas]pandas의 특정 열 제외한 모든 컬럼 출력하기</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-pandas-remove_col/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-pandas-remove_col/</url>
      
        <content type="html"><![CDATA[<!--- ML- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling## trickshttps://towardsdatascience.com/30-examples-to-master-pandas-f8a2da751fa4#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>DataFrame의 특정 열 제외하기</strong></p><hr><h2 id="하나의-컬럼을-DF에서-제거할-결우"><a href="#하나의-컬럼을-DF에서-제거할-결우" class="headerlink" title="하나의 컬럼을 DF에서 제거할 결우"></a>하나의 컬럼을 DF에서 제거할 결우</h2><p>기본적으로 두 가지 방법이 있다.</p><p><strong>drop 활용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.drop(column_name, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><strong>.loc 활용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.loc[:, df.columns != col]</span><br></pre></td></tr></table></figure><p>drop이 익숙하다보니 좀 더 많이 사용하게 된다.</p><h2 id="여러-컬럼을-DF에서-제거할-경우"><a href="#여러-컬럼을-DF에서-제거할-경우" class="headerlink" title="여러 컬럼을 DF에서 제거할 경우"></a>여러 컬럼을 DF에서 제거할 경우</h2><p><strong>indexing 사용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df.columns[~df.columns.isin([<span class="string">&#x27;지울&#x27;</span>,<span class="string">&#x27;컬럼&#x27;</span>])]]</span><br></pre></td></tr></table></figure><p><strong>difference 사용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[df.columns.difference([<span class="string">&#x27;지울&#x27;</span>, <span class="string">&#x27;칼럼&#x27;</span>])]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>difference가 있는걸 모르고 계속 isin을 써왔다.<br>difference에도 익숙해져야 겠다.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://datascience.stackexchange.com/questions/46434/dataframe-columns-difference-use">https://datascience.stackexchange.com/questions/46434/dataframe-columns-difference-use</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[pandas]Pandas Groupby용법 간단히 정리</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-pandas_groupby/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-pandas_groupby/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>pandas에서 제공하는 groupby는 기본적으로 데이터 범주별 요약통계량을 계산하는 일을 한다. sql의 groupby나 R dplyr의 groupby와 유사하다고 생각하면 된다.<br>여기서는 전처리과정에서 자주쓰게 되는 groupby 용법을 살펴본다.</p><hr><h2 id="기본적인-용법들"><a href="#기본적인-용법들" class="headerlink" title="기본적인 용법들"></a>기본적인 용법들</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">drinks = pd.read_csv(<span class="string">&#x27;http://bit.ly/drinksbycountry&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>country</th>      <th>beer_servings</th>      <th>spirit_servings</th>      <th>wine_servings</th>      <th>total_litres_of_pure_alcohol</th>      <th>continent</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Afghanistan</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>Asia</td>    </tr>    <tr>      <th>1</th>      <td>Albania</td>      <td>89</td>      <td>132</td>      <td>54</td>      <td>4.9</td>      <td>Europe</td>    </tr>    <tr>      <th>2</th>      <td>Algeria</td>      <td>25</td>      <td>0</td>      <td>14</td>      <td>0.7</td>      <td>Africa</td>    </tr>    <tr>      <th>3</th>      <td>Andorra</td>      <td>245</td>      <td>138</td>      <td>312</td>      <td>12.4</td>      <td>Europe</td>    </tr>    <tr>      <th>4</th>      <td>Angola</td>      <td>217</td>      <td>57</td>      <td>45</td>      <td>5.9</td>      <td>Africa</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기초적인 용법 : 대륙별 beer_servings 평균</span></span><br><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).beer_servings.mean()</span><br></pre></td></tr></table></figure><pre><code>continentAfrica            61.471698Asia              37.045455Europe           193.777778North America    145.434783Oceania           89.687500South America    175.083333Name: beer_servings, dtype: float64</code></pre><p>.agg()와 같은 집계함수를 사용해 한 변수의 여러 요약통계량을 구하는 것이 가능하다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks[drinks.continent==<span class="string">&#x27;Asia&#x27;</span>].beer_servings.agg([<span class="string">&#x27;count&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>count     44.000000mean      37.045455max      247.000000min        0.000000Name: beer_servings, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).beer_servings.agg([<span class="string">&#x27;count&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>])</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>count</th>      <th>mean</th>      <th>max</th>      <th>min</th>    </tr>    <tr>      <th>continent</th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Africa</th>      <td>53</td>      <td>61.471698</td>      <td>376</td>      <td>0</td>    </tr>    <tr>      <th>Asia</th>      <td>44</td>      <td>37.045455</td>      <td>247</td>      <td>0</td>    </tr>    <tr>      <th>Europe</th>      <td>45</td>      <td>193.777778</td>      <td>361</td>      <td>0</td>    </tr>    <tr>      <th>North America</th>      <td>23</td>      <td>145.434783</td>      <td>285</td>      <td>1</td>    </tr>    <tr>      <th>Oceania</th>      <td>16</td>      <td>89.687500</td>      <td>306</td>      <td>0</td>    </tr>    <tr>      <th>South America</th>      <td>12</td>      <td>175.083333</td>      <td>333</td>      <td>93</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 분석할 칼럼을 지정해주지 않으면 모든 numeric의 평균을 그룹별로 반환한다.</span></span><br><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).mean()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>beer_servings</th>      <th>spirit_servings</th>      <th>wine_servings</th>      <th>total_litres_of_pure_alcohol</th>    </tr>    <tr>      <th>continent</th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Africa</th>      <td>61.471698</td>      <td>16.339623</td>      <td>16.264151</td>      <td>3.007547</td>    </tr>    <tr>      <th>Asia</th>      <td>37.045455</td>      <td>60.840909</td>      <td>9.068182</td>      <td>2.170455</td>    </tr>    <tr>      <th>Europe</th>      <td>193.777778</td>      <td>132.555556</td>      <td>142.222222</td>      <td>8.617778</td>    </tr>    <tr>      <th>North America</th>      <td>145.434783</td>      <td>165.739130</td>      <td>24.521739</td>      <td>5.995652</td>    </tr>    <tr>      <th>Oceania</th>      <td>89.687500</td>      <td>58.437500</td>      <td>35.625000</td>      <td>3.381250</td>    </tr>    <tr>      <th>South America</th>      <td>175.083333</td>      <td>114.750000</td>      <td>62.416667</td>      <td>6.308333</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># m</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).mean().plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/KvoD6CS.png">    </p><h2 id="응용하기"><a href="#응용하기" class="headerlink" title="응용하기"></a>응용하기</h2><ul><li>Groupby에서 특정 그룹에 접근하기</li><li>Groupby에서 특정 그룹에 접근 후 필터링 하기 (filter 사용)</li><li>pd.cut 을 사용한 파생변수 만들기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 아시아 그룹만 </span></span><br><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).get_group(<span class="string">&#x27;Asia&#x27;</span>).head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>country</th>      <th>beer_servings</th>      <th>spirit_servings</th>      <th>wine_servings</th>      <th>total_litres_of_pure_alcohol</th>      <th>continent</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Afghanistan</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>Asia</td>    </tr>    <tr>      <th>12</th>      <td>Bahrain</td>      <td>42</td>      <td>63</td>      <td>7</td>      <td>2.0</td>      <td>Asia</td>    </tr>    <tr>      <th>13</th>      <td>Bangladesh</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>Asia</td>    </tr>    <tr>      <th>19</th>      <td>Bhutan</td>      <td>23</td>      <td>0</td>      <td>0</td>      <td>0.4</td>      <td>Asia</td>    </tr>    <tr>      <th>24</th>      <td>Brunei</td>      <td>31</td>      <td>2</td>      <td>1</td>      <td>0.6</td>      <td>Asia</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 여러 그룹의 통계량을 조건걸어서 구할 경우</span></span><br><span class="line">drinks.groupby([<span class="string">&#x27;wine_servings&#x27;</span>, <span class="string">&#x27;continent&#x27;</span>]).get_group((<span class="number">0</span>, <span class="string">&#x27;Asia&#x27;</span>)).total_litres_of_pure_alcohol.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>6.2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pd.cut을 활용한 연속형 변수의 구간화 변수생성</span></span><br><span class="line">drinks[<span class="string">&#x27;Range&#x27;</span>] = drinks.groupby(<span class="string">&#x27;country&#x27;</span>).beer_servings.apply(pd.cut, bins=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>country</th>      <th>beer_servings</th>      <th>spirit_servings</th>      <th>wine_servings</th>      <th>total_litres_of_pure_alcohol</th>      <th>continent</th>      <th>Range</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Afghanistan</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>Asia</td>      <td>(-0.001, 0.0]</td>    </tr>    <tr>      <th>1</th>      <td>Albania</td>      <td>89</td>      <td>132</td>      <td>54</td>      <td>4.9</td>      <td>Europe</td>      <td>(88.911, 89.0]</td>    </tr>    <tr>      <th>2</th>      <td>Algeria</td>      <td>25</td>      <td>0</td>      <td>14</td>      <td>0.7</td>      <td>Africa</td>      <td>(24.975, 25.0]</td>    </tr>    <tr>      <th>3</th>      <td>Andorra</td>      <td>245</td>      <td>138</td>      <td>312</td>      <td>12.4</td>      <td>Europe</td>      <td>(244.755, 245.0]</td>    </tr>    <tr>      <th>4</th>      <td>Angola</td>      <td>217</td>      <td>57</td>      <td>45</td>      <td>5.9</td>      <td>Africa</td>      <td>(216.783, 217.0]</td>    </tr>  </tbody></table></div><p>TF를 반환하는 lamba 함수를 작성할 경우 any()나 all()을 써서 값을 반환해줄 필요가 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## filter를 사용한 조건식. 위의 결과와 같은 값을 리턴한다.</span></span><br><span class="line">drinks.groupby([<span class="string">&#x27;wine_servings&#x27;</span>,<span class="string">&#x27;continent&#x27;</span>]).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x : ((x.wine_servings == <span class="number">0</span>) &amp; (x.continent==<span class="string">&#x27;Asia&#x27;</span>) ).<span class="built_in">any</span>()).total_litres_of_pure_alcohol.<span class="built_in">sum</span>()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>6.2</code></pre><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.youtube.com/watch?v=qy0fDqoMJx8">https://www.youtube.com/watch?v=qy0fDqoMJx8</a></li><li><a href="https://pandas.pydata.org/docs/reference/groupby.html">https://pandas.pydata.org/docs/reference/groupby.html</a></li></ul><h2 id="다음에-정리할-것"><a href="#다음에-정리할-것" class="headerlink" title="다음에 정리할 것"></a>다음에 정리할 것</h2><ul><li>any()와 all() 관련 함수</li><li>filter</li><li>assign</li><li>pd.cut과 np.digitize를 활용한 연속형 변수의 구간화</li><li>pandas query as dplyr filter</li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[pandas]Pandas를 활용한 데이터분석 시작하기</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-pandas_overview/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-pandas_overview/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><ul><li><strong>알아야 하는 것</strong><ul><li>pandas data structure</li><li>reading data</li><li>dealing with missing data</li><li>slicing &amp; indexing<ul><li>loc &amp; iloc</li></ul></li><li>map<ul><li>map</li><li>apply.map</li><li>apply</li></ul></li><li>groupby</li><li>pandas eda<ul><li>info()</li><li>head()</li><li>value_counts()</li><li>describe</li><li>dtypes()</li></ul></li></ul></li></ul><hr><h2 id="pandas-자료구조"><a href="#pandas-자료구조" class="headerlink" title="pandas 자료구조"></a>pandas 자료구조</h2><h3 id="Sereies"><a href="#Sereies" class="headerlink" title="Sereies"></a>Sereies</h3><blockquote><p><strong>Series는 일련의 객체를 담을 수 있고 인덱스를 가지고 있는 1차원 배열의 자료구조이다.</strong>  </p></blockquote><ul><li>기본적으로 고정길이의 Ordered Dictionary라고 생각하면 편하다.(사전형을 대체하여 쓸수 있다)</li><li>index를 지정하지 않을 경우 기본색인인 정수에서 n-1까지의 숫자가 표시된다.</li><li>Series의 배열과 색인 객체는 value와 index속성을 통해 얻을 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Series 생성</span></span><br><span class="line">s = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: s</span><br><span class="line">Out[<span class="number">4</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1</span></span><br><span class="line"><span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">2</span>    <span class="number">3</span></span><br><span class="line"><span class="number">3</span>    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br><span class="line"><span class="comment"># Series 객체반환</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: s.values</span><br><span class="line">Out[<span class="number">6</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]) <span class="comment"># 1차원 배열형태로 반환됨</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: s.index</span><br><span class="line">Out[<span class="number">7</span>]: RangeIndex(start=<span class="number">0</span>, stop=<span class="number">4</span>, step=<span class="number">1</span>) <span class="comment"># range(4) 반환</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Series 생성(index 지정)</span></span><br><span class="line"></span><br><span class="line">s2 = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],index = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>사전형을 대체하여 Series 사용하기</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 조건 반환</span></span><br><span class="line"><span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> s2</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;e&#x27;</span> <span class="keyword">in</span> s2</span><br><span class="line"></span><br><span class="line"><span class="comment"># dictionary로 부터 Series 생성하기</span></span><br><span class="line">sdic = &#123;<span class="string">&quot;A&quot;</span>:<span class="number">10</span>,<span class="string">&quot;B&quot;</span>:<span class="number">20</span>,<span class="string">&quot;C&quot;</span>:<span class="number">40</span>&#125;</span><br><span class="line">s3 = pd.Series(sdic)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: s3</span><br><span class="line">Out[<span class="number">9</span>]: </span><br><span class="line">A    <span class="number">10</span></span><br><span class="line">B    <span class="number">20</span></span><br><span class="line">C    <span class="number">40</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p><strong>Series에서 누락된 데이터 찾기</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pd.isnull(s) <span class="comment"># null인 값 찾기</span></span><br><span class="line"></span><br><span class="line">pd.notnull(s) <span class="comment"># null 아닌 값 찾기</span></span><br><span class="line"></span><br><span class="line">s.isnull() <span class="comment"># 인스턴스 메서드로 null값 찾기</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>Series의 name속성</strong></p><ul><li>Series 객체와 index 모두 name 속성을 가질 수 있다<ul><li>DF인덱싱, 슬라이싱에 쓸 수 있다.</li></ul></li><li>리스트 객체를 대입하여 Series의 index를 변경할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># name 속성 부여하기</span></span><br><span class="line">s.name  = <span class="string">&#x27;population&#x27;</span></span><br><span class="line">obj.index.name = <span class="string">&#x27;state&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># index 대입하기</span></span><br><span class="line">df.index = [<span class="string">&#x27;H&#x27;</span>,<span class="string">&#x27;J&#x27;</span>,<span class="string">&#x27;K&#x27;</span>,<span class="string">&#x27;L&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><blockquote><p><strong>R의 데이터 프레임의 pandas버전이다.<br>로우와 칼럼에 대한 인덱스를 가지고 있다.</strong></p></blockquote><ul><li>단순히 인덱스와 모양이 같은 Series 객체들을 담고있는 Dictionary라고 생각하면 된다.</li></ul><p><strong>DF 생성하기</strong></p><ul><li>dictionary를 이용해 쉽게 DF를 만들 수 있다.</li><li>인스탄스 메서드 head()를 이용해 상위 5개 값을 출력할 수 있다.</li><li>dictionary에 없는 값을 넘길 경우 Nan으로 저장된다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 생성</span></span><br><span class="line">data = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line"> <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line"> <span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line"></span><br><span class="line">df = DataFrame(data)</span><br><span class="line"></span><br><span class="line">df.head() <span class="comment"># 상위 5개 출력</span></span><br><span class="line"></span><br><span class="line">Out[<span class="number">13</span>]: </span><br><span class="line">    state  year  pop</span><br><span class="line"><span class="number">0</span>    Ohio  <span class="number">2000</span>  <span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>    Ohio  <span class="number">2001</span>  <span class="number">1.7</span></span><br><span class="line"><span class="number">2</span>    Ohio  <span class="number">2002</span>  <span class="number">3.6</span></span><br><span class="line"><span class="number">3</span>  Nevada  <span class="number">2001</span>  <span class="number">2.4</span></span><br><span class="line"><span class="number">4</span>  Nevada  <span class="number">2002</span>  <span class="number">2.9</span></span><br><span class="line"></span><br><span class="line">df2 = pd.DataFrame(data,</span><br><span class="line">                     columns=[<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>, <span class="string">&#x27;debt&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>, <span class="string">&#x27;five&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><strong>loc속성과 iloc속성 활용 Series, 행열 접근하기</strong></li></ul><ol><li>행번호로 접근하기 (iloc)(index location)</li></ol><ul><li><strong>: 는 ‘전체’ 를 의미한다. (중요!)</strong></li><li>인덱싱 범위에 따라 반환되는 객체의 타입이 달라질 수 있다(DF,Series)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 행 접근</span></span><br><span class="line">df2.iloc[<span class="number">0</span>] <span class="comment"># 첫번째</span></span><br><span class="line">df2.iloc[<span class="number">2</span>] <span class="comment"># 세번째</span></span><br><span class="line">df2.iloc[-<span class="number">1</span>] <span class="comment"># 마지막 행</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 열 접근</span></span><br><span class="line">df2.iloc[:,<span class="number">0</span>] <span class="comment"># 첫번째 열</span></span><br><span class="line">df2.iloc[:,<span class="number">2</span>] <span class="comment"># 세번째 열</span></span><br><span class="line">df2.iloc[:,-<span class="number">1</span>] <span class="comment"># 마지막 열</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># indexing with iloc</span></span><br><span class="line">df2.iloc[<span class="number">0</span>:<span class="number">4</span>] <span class="comment"># 첫 4개행</span></span><br><span class="line">df2.iloc[:,<span class="number">0</span>:<span class="number">2</span>] <span class="comment"># 첫 2개 열</span></span><br><span class="line">df2.iloc[[<span class="number">0</span>,<span class="number">2</span>]:,[<span class="number">0</span>,<span class="number">2</span>]]  <span class="comment"># 1,3 행, 1,3 열</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>label이나 조건으로 접근하기 (loc)(location)</li></ol><ul><li>범위지정시 loc는 포함이고 iloc나 기타 python은 포함되지 않음</li><li>iloc의 경우 기본적으로 인덱스 기반 슬라이싱이고 loc는 이름기반 슬라이싱이어서 범위 지정시 주의 필요<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 행접근</span></span><br><span class="line">df2.loc[:,<span class="string">&#x27;year&#x27;</span>]</span><br><span class="line"><span class="comment"># 열접근</span></span><br><span class="line">df2.loc[:,<span class="string">&#x27;year&#x27;</span>]</span><br><span class="line"><span class="comment"># 특정 값 접근</span></span><br><span class="line">df2.loc[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;year&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 인덱스가 숫자일 경우</span></span><br><span class="line"></span><br><span class="line">df2.loc[<span class="number">2</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>loc를 활용한 조건문</li></ol><ul><li>조건문을 사용해 배열이나 Series, DF를 반환할 수 있다</li><li>values를 사용해 배열을 추출할 수 있다</li><li><strong>loc가 반환하는 결과는 기본적으로 copy가 아니라 view이기 때문에 값을 대입하거나 수정 할 수 있다</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [randint(<span class="number">1</span>, <span class="number">9</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)],</span><br><span class="line">                   <span class="string">&#x27;B&#x27;</span>: [randint(<span class="number">1</span>, <span class="number">9</span>)*<span class="number">10</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)],</span><br><span class="line">                   <span class="string">&#x27;C&#x27;</span>: [randint(<span class="number">1</span>, <span class="number">9</span>)*<span class="number">100</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 조건문으로 Boolen Series 반환하기</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">&quot;B&quot;</span>] &gt; <span class="number">50</span></span><br><span class="line"></span><br><span class="line">(df[<span class="string">&quot;B&quot;</span>] &gt; <span class="number">50</span>) &amp; (df[<span class="string">&quot;C&quot;</span>] == <span class="number">900</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loc에 바로 조건문을 넣을 경우</span></span><br><span class="line"></span><br><span class="line">df.loc[(df[<span class="string">&quot;B&quot;</span>] &gt; <span class="number">50</span>) &amp; (df[<span class="string">&quot;C&quot;</span>] == <span class="number">900</span>), <span class="string">&quot;A&quot;</span>] <span class="comment"># 행적용 조건문</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="데이터-전처리-방법들-index"><a href="#데이터-전처리-방법들-index" class="headerlink" title="데이터 전처리 방법들(index)"></a>데이터 전처리 방법들(index)</h2><h3 id="Cleaning"><a href="#Cleaning" class="headerlink" title="Cleaning"></a>Cleaning</h3><blockquote><p><strong>noise가 있을 경우 제거, inconsistency 수정</strong></p></blockquote><h3 id="Integration"><a href="#Integration" class="headerlink" title="Integration"></a>Integration</h3><blockquote><p><strong>데이터 나누기, 합치기(필요에 따라)</strong></p></blockquote><h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><blockquote><p><strong>데이터형태변환 , 보통 datatype을 맞춰주거나 정규화를 하는 것을 말한다.</strong></p></blockquote><h3 id="Redution"><a href="#Redution" class="headerlink" title="Redution"></a>Redution</h3><blockquote><p><strong>차원축소, 요인분석등을 사용해 분석 변수들을 줄이는 것</strong></p></blockquote><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe">https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.repeat.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.repeat.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[pandas]pandas 함수와 기초용법들</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-pandas_tricks/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-pandas_tricks/</url>
      
        <content type="html"><![CDATA[<h2 id="pandas-tricks"><a href="#pandas-tricks" class="headerlink" title="pandas tricks"></a><strong>pandas tricks</strong></h2><blockquote><p>pandas관련 자주 사용할만한 코드 정리</p></blockquote><h3 id="pandas-version확인"><a href="#pandas-version확인" class="headerlink" title="pandas version확인"></a>pandas version확인</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.__version__ <span class="comment"># pandas version확인</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.show_versions() <span class="comment">#의존성 패키지 확인</span></span><br></pre></td></tr></table></figure><h3 id="DF-생성하기"><a href="#DF-생성하기" class="headerlink" title="DF 생성하기"></a>DF 생성하기</h3><blockquote><p>여러 방법이 있지만 보통 dictionary를 사용한다.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;col one&#x27;</span>:[<span class="number">100</span>, <span class="number">200</span>], <span class="string">&#x27;col two&#x27;</span>:[<span class="number">300</span>, <span class="number">400</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 난수생성을 통핸 DF생성</span></span><br><span class="line">pd.DataFrame(np.random.rand(<span class="number">4</span>, <span class="number">8</span>))</span><br></pre></td></tr></table></figure><h3 id="열이름-변경하기"><a href="#열이름-변경하기" class="headerlink" title="열이름 변경하기"></a>열이름 변경하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dictionary 형태로 변경하기</span></span><br><span class="line">df = df.rename(&#123;<span class="string">&#x27;col one&#x27;</span> : <span class="string">&#x27;col_one&#x27;</span>,<span class="string">&#x27;col two&#x27;</span>: <span class="string">&#x27;col_two&#x27;</span>&#125;, axis = <span class="string">&#x27;columns&#x27;</span> ) <span class="comment"># 적용할 axis지정 rename</span></span><br><span class="line"></span><br><span class="line">df.add_prefix(<span class="string">&#x27;X_&#x27;</span>) <span class="comment">#컬럼에 접두어 X 추가</span></span><br><span class="line">df.add_suffix(<span class="string">&#x27;_Y&#x27;</span>) <span class="comment">#컬럼에 접미어 Y 추가</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list를 매핑해 변경하기</span></span><br><span class="line">df.columns = [<span class="string">&#x27;col_one&#x27;</span>, <span class="string">&#x27;col_two&#x27;</span>]</span><br></pre></td></tr></table></figure><h3 id="행순서-뒤집기"><a href="#행순서-뒤집기" class="headerlink" title="행순서 뒤집기"></a>행순서 뒤집기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks.loc[::-<span class="number">1</span>].head()</span><br></pre></td></tr></table></figure><h3 id="reverse-column-order"><a href="#reverse-column-order" class="headerlink" title="reverse column order"></a>reverse column order</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">drinks.loc[:, ::-<span class="number">1</span>].head() <span class="comment"># [start:end:(step)]에 대한 이해 필요</span></span><br><span class="line"><span class="comment"># start, end가 비어있고 step이 -1이기에 순서가 역순으로 바뀜</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="datatype-기준으로-컬럼-선택하기"><a href="#datatype-기준으로-컬럼-선택하기" class="headerlink" title="datatype 기준으로 컬럼 선택하기"></a>datatype 기준으로 컬럼 선택하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drinks.dtypes <span class="comment"># 모든 열의 dtype 확인</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">drinks.select_dtypes(include=<span class="string">&#x27;number&#x27;</span>).head() <span class="comment"># dtype이 numeric인 데이터 추출</span></span><br><span class="line"></span><br><span class="line">drinks.select_dtypes(include=[<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;object&#x27;</span>, <span class="string">&#x27;category&#x27;</span>, <span class="string">&#x27;datetime&#x27;</span>]).head()</span><br></pre></td></tr></table></figure><h3 id="문자열-numeric으로-변환하기"><a href="#문자열-numeric으로-변환하기" class="headerlink" title="문자열 numeric으로 변환하기"></a>문자열 numeric으로 변환하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;col_one&#x27;</span>:[<span class="string">&#x27;1.1&#x27;</span>, <span class="string">&#x27;2.2&#x27;</span>, <span class="string">&#x27;3.3&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;col_two&#x27;</span>:[<span class="string">&#x27;4.4&#x27;</span>, <span class="string">&#x27;5.5&#x27;</span>, <span class="string">&#x27;6.6&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;col_three&#x27;</span>:[<span class="string">&#x27;7.7&#x27;</span>, <span class="string">&#x27;8.8&#x27;</span>, <span class="string">&#x27;-&#x27;</span>]&#125;)</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="comment"># astype()을 활용한 변환</span></span><br><span class="line">df.astype(&#123;<span class="string">&#x27;col_one&#x27;</span>:<span class="string">&#x27;float&#x27;</span>, <span class="string">&#x27;col_two&#x27;</span>:<span class="string">&#x27;float&#x27;</span>&#125;).dtypes</span><br><span class="line"></span><br><span class="line"><span class="comment"># to_numeric을 활용한 변환</span></span><br><span class="line">pd.to_numeric(df.col_three, errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># df 전체에 적용(numeric 변환 후 fillna)</span></span><br><span class="line">df = df.apply(pd.to_numeric, errors=<span class="string">&#x27;coerce&#x27;</span>).fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># , 이 포함된 숫자형태의 문자열의 경우 replace사용</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">toInt</span>(<span class="params">string</span>):</span><br><span class="line">    string = <span class="built_in">int</span>(string.replace(<span class="string">&#x27;,&#x27;</span>,<span class="string">&#x27;&#x27;</span>))</span><br><span class="line">    returen string</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="DF-사이즈-줄이기"><a href="#DF-사이즈-줄이기" class="headerlink" title="DF 사이즈 줄이기"></a>DF 사이즈 줄이기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 메모리 사용정도 확인</span></span><br><span class="line">drinks.info(memory_usage=<span class="string">&#x27;deep&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 컬럼지정을 활용한 데이터 줄이기</span></span><br><span class="line">dtypes = &#123;<span class="string">&#x27;continent&#x27;</span>:<span class="string">&#x27;category&#x27;</span>&#125;</span><br><span class="line">smaller_drinks = pd.read_csv(<span class="string">&#x27;http://bit.ly/drinksbycountry&#x27;</span>, usecols=cols, dtype=dtypes)</span><br><span class="line">smaller_drinks.info(memory_usage=<span class="string">&#x27;deep&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="Build-a-DataFrame-from-mulfiple-files-row-wise"><a href="#Build-a-DataFrame-from-mulfiple-files-row-wise" class="headerlink" title="Build a DataFrame from mulfiple files (row-wise)"></a>Build a DataFrame from mulfiple files (row-wise)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 정규식,와일드카드 관련문서 참고</span></span><br><span class="line"><span class="comment"># stocks로 시작하는 data폴더 내 모든 csv 파일 </span></span><br><span class="line">stock_files = <span class="built_in">sorted</span>(glob(<span class="string">&#x27;data/stocks*.csv&#x27;</span>))</span><br><span class="line">stock_files</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;data/stocks1.csv&#x27;</span>, <span class="string">&#x27;data/stocks2.csv&#x27;</span>, <span class="string">&#x27;data/stocks3.csv&#x27;</span>] <span class="comment"># 리스트 형태로 반환</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파일합치기</span></span><br><span class="line">pd.concat((pd.read_csv(file) <span class="keyword">for</span> file <span class="keyword">in</span> stock_files), ignore_index=<span class="literal">True</span>) <span class="comment"># ignore index는 각 파일의 index를 무시하고 초기화하는 옵션이다.</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Build-a-DataFrame-from-mulfiple-files-column-wise"><a href="#Build-a-DataFrame-from-mulfiple-files-column-wise" class="headerlink" title="Build a DataFrame from mulfiple files (column-wise)"></a>Build a DataFrame from mulfiple files (column-wise)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 축옵션만 넣어주면 된다</span></span><br><span class="line">pd.concat((pd.read_csv(file) <span class="keyword">for</span> file <span class="keyword">in</span> drink_files), axis=<span class="string">&#x27;columns&#x27;</span>).head()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="클립보드에서-df불러오기"><a href="#클립보드에서-df불러오기" class="headerlink" title="클립보드에서 df불러오기"></a>클립보드에서 df불러오기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_clipboard()</span><br><span class="line">df</span><br></pre></td></tr></table></figure><h3 id="DF-subsetting-하기"><a href="#DF-subsetting-하기" class="headerlink" title="DF subsetting 하기"></a>DF subsetting 하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># frac으로 원db의 75% 할당</span></span><br><span class="line">movies_1 = movies.sample(frac=<span class="number">0.75</span>, random_state=<span class="number">1234</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 나머지</span></span><br><span class="line">movies_2 = movies.drop(movies_1.index)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="isin을-활용한-DF필터링"><a href="#isin을-활용한-DF필터링" class="headerlink" title="isin을 활용한 DF필터링"></a>isin을 활용한 DF필터링</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inin을 사용해 특정열에 대해 값에 대한조건을 넣어줄 수 있다.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 포함하고 뽑기</span></span><br><span class="line">movies[movies.genre.isin([<span class="string">&#x27;Action&#x27;</span>,<span class="string">&#x27;Drama&#x27;</span>,<span class="string">&#x27;Western&#x27;</span>])].head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 제외하고 뽑기</span></span><br><span class="line">movies[~movies.genre.isin([<span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;Western&#x27;</span>])].head()</span><br></pre></td></tr></table></figure><h3 id="value-counts-를-관측값-구하기"><a href="#value-counts-를-관측값-구하기" class="headerlink" title="value_counts()를 관측값 구하기"></a>value_counts()를 관측값 구하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 우선 카테고리(장르)별 관측값를 구한다</span></span><br><span class="line">counts = movies.genre.value_counts()</span><br><span class="line">counts</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># count에서 상위3개를 구한다.</span></span><br><span class="line">counts.nlargest(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="결측값-처리하기"><a href="#결측값-처리하기" class="headerlink" title="결측값 처리하기"></a>결측값 처리하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 결측값 조건걸기</span></span><br><span class="line">ufo = dropna(thresh = <span class="built_in">len</span>(ufo)*<span class="number">0.9</span>, axis = <span class="string">&#x27;columns&#x27;</span>) <span class="comment"># 90% 이상 값이 있는 컬럼만 유지</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 열별로 결측값의 수 세기</span></span><br><span class="line">ufo.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NA가 하나라도 있는 열 삭제</span></span><br><span class="line">ufo.dropna(axis=<span class="string">&#x27;columns&#x27;</span>).head()</span><br></pre></td></tr></table></figure><h3 id="split를-활용한-문자열-나누기"><a href="#split를-활용한-문자열-나누기" class="headerlink" title=".split를 활용한 문자열 나누기"></a>.split를 활용한 문자열 나누기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;name&#x27;</span>:[<span class="string">&#x27;John Arthur Doe&#x27;</span>, <span class="string">&#x27;Jane Ann Smith&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;location&#x27;</span>:[<span class="string">&#x27;Los Angeles, CA&#x27;</span>, <span class="string">&#x27;Washington, DC&#x27;</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;middle&#x27;</span>, <span class="string">&#x27;last&#x27;</span>]] = df.name.<span class="built_in">str</span>.split(<span class="string">&#x27; &#x27;</span>, expand=<span class="literal">True</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="/image/output.png"></p><h3 id="list를-DF로-변환하기"><a href="#list를-DF로-변환하기" class="headerlink" title="list를 DF로 변환하기"></a>list를 DF로 변환하기</h3><p>이건 자주 쓴다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;col_one&#x27;</span>:[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], <span class="string">&#x27;col_two&#x27;</span>:[[<span class="number">10</span>, <span class="number">40</span>], [<span class="number">20</span>, <span class="number">50</span>], [<span class="number">30</span>, <span class="number">60</span>]]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="/image/output2.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_new = df.col_two.apply(pd.Series) <span class="comment"># apply를 활용한 df 생성</span></span><br><span class="line">df_new</span><br></pre></td></tr></table></figure><h3 id="Aggregate-by-multiple-funtions"><a href="#Aggregate-by-multiple-funtions" class="headerlink" title="Aggregate by multiple funtions"></a>Aggregate by multiple funtions</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># aggregate를 활용한 요약통계량 산출하기</span></span><br><span class="line">orders.groupby(<span class="string">&#x27;order_id&#x27;</span>).item_price.agg([<span class="string">&#x27;sum&#x27;</span>, <span class="string">&#x27;count&#x27;</span>]).head()</span><br></pre></td></tr></table></figure><h3 id="Combine-the-output-of-an-aggregation-by-multiple-funtions"><a href="#Combine-the-output-of-an-aggregation-by-multiple-funtions" class="headerlink" title="Combine the output of an aggregation by multiple funtions"></a>Combine the output of an aggregation by multiple funtions</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transform()은 입력된 개체와 동일하게 인덱스된 객체를 반환하며 다중연산에 쓰인다.</span></span><br><span class="line">total_price = orders.groupby(<span class="string">&#x27;order_id&#x27;</span>).item_price.transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform() 관련레퍼런스</span></span><br><span class="line"><span class="comment"># https://kongdols-room.tistory.com/169 </span></span><br></pre></td></tr></table></figure><h3 id="loc를-활용한-행열-슬라이싱"><a href="#loc를-활용한-행열-슬라이싱" class="headerlink" title=".loc를 활용한 행열 슬라이싱"></a>.loc를 활용한 행열 슬라이싱</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">titanic.describe().loc[<span class="string">&#x27;min&#x27;</span>:<span class="string">&#x27;max&#x27;</span>]</span><br><span class="line"></span><br><span class="line">titanic.describe().loc[<span class="string">&#x27;min&#x27;</span>:<span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>:<span class="string">&#x27;Parch&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="계층적-index를-가지는-Series-DF로-변환하기"><a href="#계층적-index를-가지는-Series-DF로-변환하기" class="headerlink" title="계층적 index를 가지는 Series DF로 변환하기"></a>계층적 index를 가지는 Series DF로 변환하기</h3><ul><li>부모자식 노드처럼 계층이 있는 인덱스를 가지는 DF를 만들 수있다</li><li>잘 쓰진 않는 것 같다<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 계층적</span></span><br><span class="line"><span class="comment"># https://nittaku.tistory.com/122</span></span><br><span class="line"></span><br><span class="line">titanic.groupby([<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>]).Survived.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># changing multiple Series into a DF</span></span><br><span class="line">titanic.groupby([<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>]).Survived.mean().unstack()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="피벗테이블-만들기"><a href="#피벗테이블-만들기" class="headerlink" title="피벗테이블 만들기"></a>피벗테이블 만들기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">titanic.pivot_table(index=<span class="string">&#x27;Sex&#x27;</span>, columns=<span class="string">&#x27;Pclass&#x27;</span>, values=<span class="string">&#x27;Survived&#x27;</span>, aggfunc=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"><span class="comment"># pivot_table에서 aggfunc 파라미터를 &#x27;count&#x27; 으로 바꿀 경우 단순 crosstable을 반환한다</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># margins = True option으로 행열합을 DF에 추가한다</span></span><br><span class="line">titanic.pivot_table(index=<span class="string">&#x27;Sex&#x27;</span>, columns=<span class="string">&#x27;Pclass&#x27;</span>, values=<span class="string">&#x27;Survived&#x27;</span>, aggfunc=<span class="string">&#x27;mean&#x27;</span>,</span><br><span class="line">                    margins=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="bin과-labels를-활용해-수치형-변수-범주형-변수로-바꾸기"><a href="#bin과-labels를-활용해-수치형-변수-범주형-변수로-바꾸기" class="headerlink" title="bin과 labels를 활용해 수치형 변수 범주형 변수로 바꾸기"></a>bin과 labels를 활용해 수치형 변수 범주형 변수로 바꾸기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use bin with the labels</span></span><br><span class="line">pd.cut(titanic.Age, bins=[<span class="number">0</span>, <span class="number">18</span>, <span class="number">25</span>, <span class="number">99</span>], labels=[<span class="string">&#x27;child&#x27;</span>, <span class="string">&#x27;young adult&#x27;</span>, <span class="string">&#x27;adult&#x27;</span>]).head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="DF-표시형식-바꾸기"><a href="#DF-표시형식-바꾸기" class="headerlink" title="DF 표시형식 바꾸기"></a>DF 표시형식 바꾸기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set_option을 통해 표시형식 바꾸기</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.float_format&#x27;</span>, <span class="string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>)</span><br></pre></td></tr></table></figure><h3 id="DF-꾸미기-Style-a-DataFrame"><a href="#DF-꾸미기-Style-a-DataFrame" class="headerlink" title="DF 꾸미기 (Style a DataFrame)"></a>DF 꾸미기 (Style a DataFrame)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">format_dict = &#123;<span class="string">&#x27;Date&#x27;</span>:<span class="string">&#x27;&#123;:%m/%d/%y&#125;&#x27;</span>, <span class="string">&#x27;Close&#x27;</span>:<span class="string">&#x27;$&#123;:.2f&#125;&#x27;</span>, <span class="string">&#x27;Volume&#x27;</span>:<span class="string">&#x27;&#123;:,&#125;&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">df.style.<span class="built_in">format</span>(format_dict) <span class="comment"># 스타일 바꾸기</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="ProfileReport를-통해-DF-구조-통계량-한번에-확인하기"><a href="#ProfileReport를-통해-DF-구조-통계량-한번에-확인하기" class="headerlink" title="ProfileReport를 통해 DF 구조, 통계량 한번에 확인하기"></a>ProfileReport를 통해 DF 구조, 통계량 한번에 확인하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">i</span><br><span class="line">mport pandas_profiling</span><br><span class="line">pandas_profiliing.PrifileReport(titanic)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="glob을-사용해-여러-csv파일을-하나의-df로-합치기"><a href="#glob을-사용해-여러-csv파일을-하나의-df로-합치기" class="headerlink" title="glob을 사용해 여러 csv파일을 하나의 df로 합치기"></a>glob을 사용해 여러 csv파일을 하나의 df로 합치기</h3><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line">path = <span class="string">r&#x27;C:\DRO\DCL_rawdata_files&#x27;</span> <span class="comment"># use your path</span></span><br><span class="line">all_files = glob.glob(path + <span class="string">&quot;/*.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">li = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> all_files:</span><br><span class="line">    df = pd.read_csv(filename, index_col=<span class="literal">None</span>, header=<span class="number">0</span>)</span><br><span class="line">    li.append(df)</span><br><span class="line"></span><br><span class="line">frame = pd.concat(li, axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="DF에-컬럼-추가하기"><a href="#DF에-컬럼-추가하기" class="headerlink" title="DF에 컬럼 추가하기"></a>DF에 컬럼 추가하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dic = &#123;<span class="string">&#x27;Name&#x27;</span>: [<span class="string">&#x27;Jai&#x27;</span>, <span class="string">&#x27;Princi&#x27;</span>, <span class="string">&#x27;Gaurav&#x27;</span>, <span class="string">&#x27;Anuj&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;Height&#x27;</span>: [<span class="number">5.1</span>, <span class="number">6.2</span>, <span class="number">5.1</span>, <span class="number">5.2</span>],</span><br><span class="line">        <span class="string">&#x27;Qualification&#x27;</span>: [<span class="string">&#x27;Msc&#x27;</span>, <span class="string">&#x27;MA&#x27;</span>, <span class="string">&#x27;Msc&#x27;</span>, <span class="string">&#x27;Msc&#x27;</span>]&#125;</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Convert the dictionary into DataFrame</span></span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Declare a list that is to be converted into a column</span></span><br><span class="line">address = [<span class="string">&#x27;Delhi&#x27;</span>, <span class="string">&#x27;Bangalore&#x27;</span>, <span class="string">&#x27;Chennai&#x27;</span>, <span class="string">&#x27;Patna&#x27;</span>]</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Using &#x27;Address&#x27; as the column name</span></span><br><span class="line"><span class="comment"># and equating it to the list</span></span><br><span class="line">df[<span class="string">&#x27;Address&#x27;</span>] = address</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="apply-등을-활용한-파생변수-생성하기"><a href="#apply-등을-활용한-파생변수-생성하기" class="headerlink" title="apply 등을 활용한 파생변수 생성하기"></a>apply 등을 활용한 파생변수 생성하기</h3><p>-DF전체에 적용하거나 DF일부에 적용할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="lambda를-활용한-함수-적용"><a href="#lambda를-활용한-함수-적용" class="headerlink" title="lambda를 활용한 함수 적용"></a>lambda를 활용한 함수 적용</h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p><a href="http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/">http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/</a></p><p><a href="https://wikidocs.net/46758">https://wikidocs.net/46758</a></p><p><a href="https://data-make.tistory.com/123">https://data-make.tistory.com/123</a></p><h2 id="3-References"><a href="#3-References" class="headerlink" title="3. References"></a>3. References</h2><ul><li><a href="https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/">https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/</a></li><li><a href="https://www.youtube.com/watch?v=RlIiVeig3hc">https://www.youtube.com/watch?v=RlIiVeig3hc</a></li><li><a href="https://kongdols-room.tistory.com/169">https://kongdols-room.tistory.com/169</a> </li><li><a href="https://www.delftstack.com/ko/howto/python-pandas/how-to-create-dataframe-column-based-on-given-condition-in-pandas/">https://www.delftstack.com/ko/howto/python-pandas/how-to-create-dataframe-column-based-on-given-condition-in-pandas/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Sampling]Class Imbalance 다루기</title>
      <link href="/2023/10/28/preprocessing/Preprocessing-sampling-imbalance-data/"/>
      <url>/2023/10/28/preprocessing/Preprocessing-sampling-imbalance-data/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html오버 샘플링 렉카https://wyatt37.tistory.com/10--><h1 id="Dealing-with-Class-Imbalance-클래스-불균형-다루기"><a href="#Dealing-with-Class-Imbalance-클래스-불균형-다루기" class="headerlink" title="Dealing with Class Imbalance(클래스 불균형 다루기)"></a>Dealing with Class Imbalance(클래스 불균형 다루기)</h1><hr><!--오버 샘플링 렉카https://wyatt37.tistory.com/10--><p><strong>여기서 해결하는 문제</strong></p><ul><li>Biased predictions</li><li>Misleading accuracy</li></ul><p><strong>보통 고려하는 해결방법</strong></p><ul><li>데이터 합성(Synthesisis of new minority class instances)</li><li>Over-sampling </li><li>Under-sampling </li><li>class weight 조정하기(상향&#x2F;하향가중치 적용)</li><li>cost function 조정</li></ul><h2 id="Random-Under-Sampling"><a href="#Random-Under-Sampling" class="headerlink" title="Random Under-Sampling"></a>Random Under-Sampling</h2><hr><ul><li><p><strong>Advantages</strong></p><ul><li>It can help improve run time and storage problems by reducing the number of training data samples when the training data set is huge.</li></ul></li><li><p><strong>Disadvantages</strong></p><ul><li>It can discard potentially useful information which could be important for building rule classifiers.</li><li>The sample chosen by random under-sampling may be a biased sample. And it will not be an accurate representation of the population. Thereby, resulting in inaccurate results with the actual test data set.</li></ul></li></ul><h3 id="Tomeck-Links"><a href="#Tomeck-Links" class="headerlink" title="Tomeck Links"></a>Tomeck Links</h3><p>Tomek Links란 두 샘플 사이에 다른 관측치가 없는 경우를 말한다.</p><p><img src="https://blog.dominodatalab.com/hubfs/Imported_Blog_Media/machine-learning-challenges-for-automated-prompting-in-smart-homes-23-638-2.jpg"></p><p>Tomek Links 방법은 Tomeck links 중에 major에 속하는 데이터포인트를 제거하는 undersampling 기법의 일종이다. 이 경우 데이터 불균형을 해결하면서 클래스 간 거리가 확보 되지만 여전히 정보 자체를 잃어버린다는 단점은 남는다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> TomekLinks</span><br><span class="line"></span><br><span class="line">tomek = TomekLinks(random_state = <span class="number">123</span>)</span><br><span class="line"></span><br><span class="line">X_tm, y_tm = tomek.fit_sample(X, y)</span><br></pre></td></tr></table></figure><h2 id="Random-Over-Sampling"><a href="#Random-Over-Sampling" class="headerlink" title="Random Over-Sampling"></a>Random Over-Sampling</h2><hr><p>minor class의 데이터를 반복적으로 replace하는 것</p><p>단순히 부트스트래핑을 통한 업샘플링의 변형이다.</p><ul><li><strong>Advantages</strong><ul><li>no information loss</li></ul></li><li><strong>Disadvantages</strong><ul><li>prone to overfitting due to copying same information</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X_samp, y_samp = RandomOverSampler(random_state=<span class="number">0</span>).fit_sample(X_imb, y_imb)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">classification_result2(X_imb, y_imb)</span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">model_samp = classification_result2(X_samp, y_samp)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>부트스트래핑을 직접 구현할 경우</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bootstrap</span>(<span class="params">X, n = <span class="literal">None</span>, iterations = <span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">if</span> n == <span class="literal">None</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(X)</span><br><span class="line">        X_resampled = np.random.choice(X, size = (iterations, n), replace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X_resampled</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="SMOTE-Synthetic-Minority-Oversample-Technique"><a href="#SMOTE-Synthetic-Minority-Oversample-Technique" class="headerlink" title="SMOTE(Synthetic Minority Oversample Technique)"></a>SMOTE(Synthetic Minority Oversample Technique)</h3><p>임의의 마이너 클래스 데이터 포인트와 근접한 마이너 클래스 데이터 포인트 사이에 새로운 데이터 포인트를 생성하는 것</p><p><strong>반드시 training set에 대해서만 SMOTE 시행. 이는 data leakage 문제와 관련이 있다.</strong></p><p>$$syntetic &#x3D; x_{minor} + u * (x_{nn}-x_{minor})$$</p><p>synthetic 합성 값은 minor class의 데이터 포인트와 근접한 minor class의 데이터포인트의 차이에 uniform distribution을 곱한 뒤 minor class의 데이터포인트를 더해준 값이다.</p><!--- Process  + Identify the feature vectore and its nearest neighbor  + take the the difference between the two  + multiply the difference with a random number between 0 and 1  + identify a new point on the line segment by adding the randomg number to feature vector  + repeat the process of identified feature vectors- 절차--><ul><li>numpy로 SMOTE 구현하기</li></ul><p>알고리즘을 구현하는 것 자체는 어렵지 않지만 실제로 작업을 할때는 <code>imblearn</code> 모듈에서 제공하는 SMOTE함수를 사용하는 것이 훨씬 낫다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># SMOTE</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_dist</span>(<span class="params">x1,x2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(<span class="built_in">sum</span>((x1-x2)**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_neighbors</span>(<span class="params">X, x, k</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  minor 클레스 데이터에 대해서 k개의 nearest neighbor를 구한다</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">    X_len = <span class="built_in">len</span>(X)</span><br><span class="line">    euclidean_dist = [euclidean_dist(X[i],x) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X_len)]</span><br><span class="line">    euclidean_dist = np.sort(euclidean_dist)</span><br><span class="line">    neighbors = euclidean_dist[:k]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> neighbors</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">SMOTE</span>(<span class="params">X,k</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  smote algorithm 적용한 합성 데이터 생성</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">    X_len = <span class="built_in">len</span>(X)</span><br><span class="line">    synthetic = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,X_len):</span><br><span class="line">        w = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> w == <span class="number">0</span>:</span><br><span class="line">            w = np.random.uniform(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        add = get_neighbors(X,X[i],k)</span><br><span class="line">        rand_idx = random.randint(<span class="number">0</span>,k-<span class="number">1</span>)</span><br><span class="line">        add = add[rand_idx]</span><br><span class="line">        </span><br><span class="line">        diff = X[i] - add</span><br><span class="line">        </span><br><span class="line">        synthetic.append(X[i] + w*diff)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(synthetic)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>imblearn을 활용한 target resampling</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"></span><br><span class="line">rs = SMOTE(random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line">X_new, y_new = rs.fit_sample(X, y)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Borderline-SMOTE"><a href="#Borderline-SMOTE" class="headerlink" title="Borderline-SMOTE"></a>Borderline-SMOTE</h3><p>: major와 minor를 구분하는 경계선에 있는 Borderline에 속하는 데이터데 대해 SMOTE을 적용하는 것</p><p>Minor class data X와 근접한 K개의 데이터포인트의 클래스의 수에 따라 SMOTE 적용 여부를 결정</p><ul><li><p>0 &lt;&#x3D; K’ &lt;&#x3D; K&#x2F;2 : Safe</p></li><li><p>K &#x3D; K’ : Noise</p></li><li><p>K&#x2F;2 &lt; K’ &lt; K : Danger : 이 경우에 SMOTE을 적용한다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Borderline-SMOTE</span></span><br><span class="line"></span><br><span class="line">bsmote = BorderlineSMOTE(random_state = <span class="number">1234</span>, k_neighbors=<span class="number">3</span>, m_neighbors=<span class="number">10</span>)</span><br><span class="line">X, y_new = bsmote.fit_resample(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Original_y %s&#x27;</span> % Counter(y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;BorderlineSMOTE_y %s&#x27;</span> % Counter(y_new))</span><br></pre></td></tr></table></figure><h3 id="ADASYN"><a href="#ADASYN" class="headerlink" title="ADASYN"></a>ADASYN</h3><p>: Adaptive Synthetic Sampling</p><ul><li>가중치를 적용해 SMOTE을 다르게 진행</li><li>인접한 major class의 비율에 따라 SMOTE을 다르게 적용하는 것</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_samp, y_samp = ADASYN(random_state=<span class="number">0</span>).fit_sample(X_imb, y_imb)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="모델링과-평가-단계에서-Class-Imbalance-다루기"><a href="#모델링과-평가-단계에서-Class-Imbalance-다루기" class="headerlink" title="모델링과 평가 단계에서 Class Imbalance 다루기"></a>모델링과 평가 단계에서 Class Imbalance 다루기</h2><hr><p>샘플링 단계가 아니라 모델링과 평가단계에서 Class Imbalance 문제를 처리한다.</p><h3 id="Change-the-performance-metric"><a href="#Change-the-performance-metric" class="headerlink" title="Change the performance metric"></a>Change the performance metric</h3><p>class weight에 영향을 덜 받게끔 평가지표 자체를 바꿀 수 있다.</p><p>다른 방법보다 품이 덜 들어서 의외로 괜찮은 방법이다.</p><ul><li><p><strong>Confusion Matrix</strong>: a table showing correct predictions and types of incorrect predictions.</p></li><li><p><strong>Precision</strong>: the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier’s exactness. Low precision indicates a high number of false positives.</p></li><li><p><strong>Recall</strong>: the number of true positives divided by the number of positive values in the test data. The recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier’s completeness. Low recall indicates a high number of false negatives.</p></li><li><p><strong>F1</strong>: Score: the weighted average of precision and recall.</p></li><li><p><strong>Area Under ROC Curve (AUROC)</strong>: AUROC represents the likelihood of your model distinguishing observations from two classes.<br>In other words, if you randomly select one observation from each class, what’s the probability that your model will be able to “rank” them correctly?</p></li></ul><h3 id="Penalize-Algorithms-class-weight"><a href="#Penalize-Algorithms-class-weight" class="headerlink" title="Penalize Algorithms(class_weight)"></a>Penalize Algorithms(class_weight)</h3><ul><li>Cost-Sensitive Training</li><li>minority class로의 오분류에 대한 패널티를 크게 만듦</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load library</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># class weight </span></span><br><span class="line">svc_model = SVC(class_weight=<span class="string">&#x27;balanced&#x27;</span>, probability=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">svc_model.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">svc_predict = svc_model.predict(x_test)<span class="comment"># check performance</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;ROCAUC score:&#x27;</span>,roc_auc_score(y_test, svc_predict))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy score:&#x27;</span>,accuracy_score(y_test, svc_predict))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 score:&#x27;</span>,f1_score(y_test, svc_predict))</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>sklearn를 활용한 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Classweight  계산 </span></span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_class_weight</span><br><span class="line">classes = np.unique(y_train)</span><br><span class="line">weights = compute_class_weight(class_weight=<span class="string">&#x27;balanced&#x27;</span>, classes=classes, y=y_train)</span><br><span class="line">class_weights = <span class="built_in">dict</span>(<span class="built_in">zip</span>(classes, weights)) <span class="comment"># 모델의 인수로 들어간다.</span></span><br></pre></td></tr></table></figure><ul><li>R 을 활용한 구현</li></ul><p>대출연체가 minor이기에 연제에 대한 가중치를 1&#x2F;p로 적용.<br>p는 연체의 확률값</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wt 가중치 벡터 만들기</span></span><br><span class="line">wt <span class="operator">&lt;-</span> ifelse<span class="punctuation">(</span>loan_all_data<span class="operator">$</span>outcome <span class="operator">==</span> <span class="string">&#x27;default&#x27;</span><span class="punctuation">,</span></span><br><span class="line">             <span class="number">1</span><span class="operator">/</span>mean<span class="punctuation">(</span>loan_all_data<span class="operator">$</span>outcome <span class="operator">==</span> <span class="string">&#x27;default&#x27;</span><span class="punctuation">)</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">clf <span class="operator">&lt;-</span> glm<span class="punctuation">(</span>outcome <span class="operator">~</span> payment_inc_ratio<span class="operator">+</span>purpose_<span class="operator">+</span>home_<span class="operator">+</span>emp_len<span class="punctuation">,</span></span><br><span class="line">           data<span class="operator">=</span> loan_all_data<span class="punctuation">,</span></span><br><span class="line">           weight <span class="operator">=</span>wt<span class="punctuation">,</span> family<span class="operator">=</span><span class="string">&quot;binomial&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Novelty-Detection-단일클래스-분류기법"><a href="#Novelty-Detection-단일클래스-분류기법" class="headerlink" title="Novelty Detection(단일클래스 분류기법)"></a>Novelty Detection(단일클래스 분류기법)</h3><ul><li>단일클래스 분류기법</li><li>Minor를 무시하고 Major class 에 속하는 데이터를 결정하는 일종의 바운더리를 생성하고 그 바운더리에 들어가냐 들어가지 않냐의 boolen으로 클래스를 결정한다.</li><li>outlier 를 판별하는 알고리즘</li></ul><h2 id="Reference-amp-annotation"><a href="#Reference-amp-annotation" class="headerlink" title="Reference &amp; annotation"></a><strong>Reference &amp; annotation</strong></h2><ul><li><a href="https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18">https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18</a></li><li><strong>Class weight를 적용하는 방식이 minor를 oversampling하거나 major를 undersampling하는 방법을 대체할 수 있다.(Practical Statistics for Data Scientist)</strong></li><li><a href="https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/">https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Preprocessing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sampling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Algorithms]Decision Tree의 이해</title>
      <link href="/2023/10/28/machine-learning/ML-SP-Decision_Tree/"/>
      <url>/2023/10/28/machine-learning/ML-SP-Decision_Tree/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Decision-Tree의-이해"><a href="#Decision-Tree의-이해" class="headerlink" title="Decision Tree의 이해"></a>Decision Tree의 이해</h2><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>Decision Tree(결정트리)</strong>: 질문을 던지고 답을 하는 과정을 연쇄적으로 반복해 집단을 분류하거나 예측하는 분석방법.</li><li><strong>threshold</strong> : 결정트리에서의 학습대상. 정확히는 데이터를 나누는 best feature의 best threshold를 찾는 것이 학습의 목적이다,</li><li><strong>full tree</strong> : 모든 학습데이터에 대해 분기한 상태.</li><li><strong>Entropy</strong> : Entropy 는 데이터셋의 불순도와 무질서한 정도를 나타내는 측정치</li><li><strong>지니 불순도</strong> : 데이터 집합에서 클래스 분포에 따라 무작위로 라벨이 지정된 경우 무작위로 선택한 요소들을 잘못 분류할 확률이다.(Chance of being incorrect if you randomly assign a label to an example in the same set)</li><li><strong>정보 이득</strong> : 정보 이득은 단순히 부모 노드의 불순도와 자식 노드의 불순도 합의 차이.</li><li><strong>Root Node</strong> : 초기노드. 데이터셋 혹은 샘플 전체. </li><li><strong>Leaf Node(Terminal Node)</strong> : 자식이 없는 노드.하위노드가 없다.</li><li><strong>Pure Node</strong> : 노드의 모든 데이터포인트가 하나의 클래스에 할당되어 있을 경우. 타깃 한개로만 이루어진 Leaf Node.</li><li><strong>Branch</strong> : sub-section of an entire tree.</li><li><strong>Splitting</strong> : 특정 노드를 나눠 하위노드를 생성하는 것.</li><li><strong>Pruning</strong> : 특정 노드의 하위노드를 날리는 것(삭제).</li><li><strong>Pre-prune</strong>: When you stop growing DT branches when information becomes unreliable.</li><li><strong>Post-prune</strong>: When you take a fully grown DT and then remove leaf nodes only if it results in a better model performance. This way, you stop removing nodes when no further improvements can be made.</li></ul><p><img src="https://miro.medium.com/max/888/1*FYEZGG-gEijSb87KuxSE_Q.png"></p><hr><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><hr><ul><li>SVM처럼 <strong>분기점(threshold)을 학습한다.</strong></li><li>기본적으로 정보이득량이 가장 커지는 방식으로 반복적으로 분할을 진행(recursive partitioning)한다.</li><li><strong>분기의 기준이 정보이득이라는 것이 핵심이다.</strong></li><li>과적합을 방지하기 위해 pruning이 필요하다.</li><li>선형모델과 달리 비선형(non-linear), 비단조(non-monotonic), 특성상호작용(feature interactions) 특징을 가지고 있는 데이터 분석에 용이하다.</li><li>특성을 해석하기 좋아 많이 쓰임</li><li><strong>샘플에 민감해 트리 고저가 자주 바뀐다.</strong></li><li>앙상블 방법의 기초가 된다.</li><li><strong>결정트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예&#x2F;아니오 질문 목록을 학습한다는 것이다. 이러한 질문들을 test라고 한다.</strong></li><li>학습 데이터셋에 과대적합되는 경향이 있다.</li><li>결정트리의 트리를 제어하지 않으면 트리는 무한정 깁어지고 복잡해진다.(일반화 성능이 낮아진다.)</li><li>따라서 사전&#x2F;사후 가지치기를 통해 과대적합을 방지한다.</li><li>알고리즘 특성상 feature scaling이 필요하지 않지만 주로 다른 알고리즘과의 비교(시각화)를 위해 scaling을 해주는 경우도 있다.</li></ul><h3 id="불순도-지표"><a href="#불순도-지표" class="headerlink" title="불순도 지표"></a>불순도 지표</h3><hr><h4 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h4><hr><p><a href="https://www.analyticsvidhya.com/blog/2020/11/[]entropy-a-key-concept-for-all-data-science-beginners/">엔트로피 중요개념</a></p><p><a href="https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8">매우중요</a></p><ul><li>Entropy 는 데이터셋의 불순도와 무질서한 정도를 나타내는 측정치이다.(measure disorder)</li><li>0~1의 값을 가진다.<ul><li>클래스가 완전히 균일하게 분포되어있을 경우(0.5) Entropy가 최대인 1이된다. </li><li>데이터셋의 요소의 분포가 특정 클래스에 치우쳐있을수록 Entropy가 0에 가까워진다.</li></ul></li><li>트리를 만들때 알고리즘은 가능한 모든 테스트에서 타깃값에 대해 가장 많은 정보를 가진 것을 고른다. -&gt; 엔트로피가 최소화되는 방향으로 학습을 진행한다.</li></ul><p align="center"><img src="https://miro.medium.com/max/750/1*M15RZMSk8nGEyOnD8haF-A.png" alt="drawing" width="400"/></p><ul><li><strong>정보이득은 엔트로피의 변화량으로 계산된다.(1-엔트로피)</strong></li><li>N은 범주의 개수</li><li>$p_{i}$ 는 p 영역에 속한 데이터 중 i 범주에 속하는 데이터의 비율.</li></ul><p>$$\text { Entropy }(p)&#x3D;-\sum_{i&#x3D;1}^{N} p_{i} \log <em>{2} p</em>{i}$$</p><h4 id="지니불순도"><a href="#지니불순도" class="headerlink" title="지니불순도"></a>지니불순도</h4><hr><ul><li><strong>잘못 분류될 확률을 최소화하기 위한 기준이다.</strong><ul><li>정확히는 <code>데이터 집합에서 클래스 분포에 따라 무작위로 라벨이 지정된 경우 무작위로 선택한 요소들을 잘못 분류할 확률이다.(Chance of being incorrect if you randomly assign a label to an example in the same set)</code></li><li>기본적으로 Single Node에 대해 계산한 값이다,</li></ul></li><li>클래스의 비율이 완벽히 균등할 때 최대가 된다.</li><li>기본적으로 노드가 중요할수록 불순도가 크게 감소한다.</li><li>범주형데이터가 라벨이라면 카디널리티가 적을 수록 불순도는 낮아진다.</li><li><strong>Entropy와 지니불순도의 차이는 불순도의 max가 Entopy가 보다 높다는 것이다.</strong></li><li><strong>지니불순도가 가장 낮은 Feature statement를 의사결정 트리의 가장 위에 놓는다.</strong>(지니인덱스가 낮으면 불순도가 낮기 때문에 루트노드에 올 가능성이 높아진다.)<ul><li>불순도가 낮다는 것은 해당 Feature statement로 인한 정보이득이 높다는 것이다.</li></ul></li><li>최초 노드의 impurity(unsertainty)에서 마지막 노드의 uncertainty를 뺀 값이 information Gain 이다.</li><li>Entropy와 달리 식에 log가 없어 계산시 약간 유리하다.</li><li>Gain이 가장 큰쪽으로 가지치기를 반복하는 것이 기본적인 의사결정 트리 알고리즘이다.</li></ul><p>$$\text{Gini Impurity}&#x3D;\sum_{i&#x3D;1}^{N} p(i) *(1-p(i))$$</p><h4 id="information-Gain"><a href="#information-Gain" class="headerlink" title="information Gain"></a>information Gain</h4><hr><ul><li>leaf의 결과는 기본적으로 majority 를 반환한다.</li><li><strong>정보 이득은 단순히 부모 노드의 불순도와 자식 노드의 불순도 합의 차이이다.</strong><ul><li>이진트리의 경우 자식트리인 왼쪽,오른쪽 트리의 불순도의 합을 부모노드에서 뺀다.</li></ul></li><li>Information Gain is calculated for a split by subtracting the weighted entropies of each branch from the original entropy. When training a Decision Tree using these metrics, the best split is chosen by maximizing Information Gain.</li></ul><p>$$IG(Parent,Children) &#x3D; E(Parent) - E(Parent | Children)$$</p><ul><li><strong>자식 노드의 불순도가 낮을수록 정보 이득이 커진다.</strong> </li><li>보통 모듈에서 이진 결정 트리를 사용하므로 부모노드는 두 개의 자식 노드로 나눠진다.</li></ul><p>$$\text {E(parent)} - [\text {weighted average}] * E(children)$$</p><p><img src="https://tensorflowkorea.files.wordpress.com/2018/03/overview-plot.png"></p><ul><li>엔트로피보다 지니 불순도 방식이 불순도 값을 줄이기 위해 더 클래스 확률을 낮추어야 한다.</li><li>엔트로피를 불순도 지표로 사용할 경우 지니불순도를 사용하는 것보다 더 균형잡힌 트리를 만들 가능성이 높다.</li></ul><h3 id="결정트리의-최적화-문제"><a href="#결정트리의-최적화-문제" class="headerlink" title="결정트리의 최적화 문제"></a>결정트리의 최적화 문제</h3><hr><ul><li><a href="https://data-notes.co/decision-trees-how-to-optimize-my-decision-making-process-e1f327999c7a">최적화 원리와 코드</a></li></ul><p><strong>Training algorithm</strong></p><ul><li><p><strong>기본적으로 Best Threshold를 찾는 문제이다</strong></p></li><li><p>Start at the top node and at each node select the best split based o the best information gain</p></li><li><p>Greedy Search : Loop over all features and over all thresholds (<strong>all possible feature values</strong>)</p></li><li><p>Save the best split features and split threshold at each node</p></li><li><p>Build the tree recursively</p></li><li><p>Apply some stopping criteria to stop growing</p><ul><li>maximum depth</li><li>minimum samples</li><li>etc..</li></ul></li><li><p>When we have a leaf node, store the most common class label of this node</p></li></ul><p><strong>Predict :&#x3D; Traverse tree</strong></p><ul><li>Traverse the tree recursively.</li><li>At each node look at the best split feature of the test feature vector x and go left or right <strong>depending on x[feature idx] &lt;&#x3D; threshold</strong></li><li>When we reach the leaf node we return the stored most common class label</li></ul><h3 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h3><hr><p><strong>Put limits in How trees grow</strong></p><h4 id="PrePruning"><a href="#PrePruning" class="headerlink" title="PrePruning"></a>PrePruning</h4><hr><ul><li><p>트리의 최대 깊이 제한하기(max_depth)</p></li><li><p>리프의 최대 개수 제한하기</p></li><li><p>노드가 분할하기 위한 데이터 포인트의 최소 개수 지정</p></li><li><p>sklearn에서 제공하는 관련 Hyperparameter</p><ul><li>max_depth : 일반화 성능관련. 트리의 최대깊이<ul><li>min_sample_splite</li><li>max_feature : 최대 피처 사용수</li><li>random_state : random state</li><li>class_weight : 가중치 balance 맟추기</li></ul></li></ul></li></ul><h4 id="PostPruning"><a href="#PostPruning" class="headerlink" title="PostPruning"></a>PostPruning</h4><hr><p>Post-pruning is also known as backward pruning. In this, first generate the decision tree and then remove non-significant branches. Post-pruning a decision tree implies that we begin by generating the (complete) tree and then adjust it with the aim of improving the accuracy on unseen instances. There are two principal methods of doing this. One method that is widely used begins by converting the tree to an equivalent set of rules. Another commonly used approach aims to retain the decision tree but to replace some of its subtrees by leaf nodes, thus converting a complete tree to a smaller pruned one which predicts the classification of unseen instances at least as accurately. There are various methods for the post pruning.</p><h3 id="Feature-Importance-in-Decision-Tree"><a href="#Feature-Importance-in-Decision-Tree" class="headerlink" title="Feature Importance in Decision Tree"></a>Feature Importance in Decision Tree</h3><hr><h3 id="More-to-learn"><a href="#More-to-learn" class="headerlink" title="More to learn"></a>More to learn</h3><hr><ul><li>Pruning</li><li>Handling missing data</li><li>Building Trees for regression</li><li>Using trees to explore datasets</li></ul><p><strong>more</strong></p><ul><li>Gini-Index is providing us with the highest accuracy with max depth &#x3D; 6.</li><li>Entropy and Gini-index can behave similarly with appropriately selected min_weight_fraction_leaf.</li><li>With min_samples_split as 7, Entropy is outperforming Gini for a rudimentary assumption that More samples will provide more information gain and tend to skew the Gini index as the impurity increases.</li></ul><p>Therefore with taking the criteria as Gini and max_depth &#x3D; 6, we obtained the accuracy as 32% which is an 18% increase from without using parametric optimization. Hence, Optimizing the parameter rightfully, will increase the model accuracy and provide better results.</p><p><strong>결정트리의 장점</strong></p><ul><li>설명가능성</li></ul><p><strong>결정트리의 단점</strong></p><ul><li>과적합</li></ul><h3 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h3><hr><ul><li>numpy로 구현</li><li><strong>기본적으로 Best Split Threshold를 찾는 것이 목적이다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropy</span>(<span class="params">y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the entropy of a label vector</span></span><br><span class="line"><span class="string">    :param y: label vector</span></span><br><span class="line"><span class="string">    :return: entropy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    hist = np.bincount(y) <span class="comment"># class distribution # 0부터 max까지 class label의 빈도</span></span><br><span class="line">    ps = hist / <span class="built_in">len</span>(y) <span class="comment"># probability of each class</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> -np.<span class="built_in">sum</span>([p * np.log2(p) <span class="keyword">for</span> p <span class="keyword">in</span> ps <span class="keyword">if</span> p != <span class="number">0</span>]) <span class="comment"># 음수에 대해서는 정의하지 않음</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,feature=<span class="literal">None</span>,threshold=<span class="literal">None</span>,left=<span class="literal">None</span>,right=<span class="literal">None</span>,*,value=<span class="literal">None</span></span>):</span><br><span class="line">        self.feature = feature</span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line">        self.value = value</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_leaf</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="comment"># leaf node의 경우 value가 있다.</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecisionTree</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, min_samples_split=<span class="number">2</span>, max_depth=<span class="number">100</span>, n_feats = <span class="literal">None</span></span>):</span><br><span class="line">        self.min_samples_split = min_samples_split</span><br><span class="line">        self.max_depth = max_depth</span><br><span class="line">        self.n_feats = n_feats</span><br><span class="line">        self.root = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># grow tree</span></span><br><span class="line">        <span class="comment"># X.shape[1] : feature의 개수</span></span><br><span class="line">        </span><br><span class="line">        self.n_feats = X.shape[<span class="number">1</span>] <span class="keyword">if</span> <span class="keyword">not</span> self.n_feats <span class="keyword">else</span> <span class="built_in">min</span>(self.n_feats, X.shape[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># if not self.n_feats -&gt; n.feats가 정의되있지 않을 경우  min(self.n_feats,X.shape[1]) </span></span><br><span class="line">        <span class="comment"># input의 feature 수보다 n_feats기 커지지 않게끔하는 </span></span><br><span class="line">        self.root = self._grow_tree(X, y)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_grow_tree</span>(<span class="params">self, X, y, depth=<span class="number">0</span></span>):</span><br><span class="line">        n_sample, n_feats = X.shape</span><br><span class="line">        n_labels = <span class="built_in">len</span>(np.unique(y))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># stopping criteria # 더 이상 분류할 수 없는 경우 혹은 pruning 기준에 도달한 경우</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (</span><br><span class="line">            depth &gt;= self.max_depth </span><br><span class="line">            <span class="keyword">or</span> n_labels == <span class="number">1</span> </span><br><span class="line">            <span class="keyword">or</span> n_sample &lt; self.min_samples_split</span><br><span class="line">        ):</span><br><span class="line">            leaf_value = self._most_common_label(y)</span><br><span class="line">            <span class="keyword">return</span> Node(value=leaf_value)</span><br><span class="line">        </span><br><span class="line">        feat_idxs = np.random.choice(n_feats, self.n_feats, replace=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># calculate information gain</span></span><br><span class="line">        best_feat, best_threshold = self._best_criteria(X, y, feat_idxs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># grow the children that result from splitting on the best feature</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 정보이득을 계산한 best_feature와 best threshold 기준으로 분할</span></span><br><span class="line">        left_idxs , right_idxs = self._split(X[:,best_feat], best_threshold)</span><br><span class="line">        left = self._grow_tree(X[left_idxs,:], y[left_idxs], depth+<span class="number">1</span>) <span class="comment"># depth+1</span></span><br><span class="line">        right = self._grow_tree(X[right_idxs,:], y[right_idxs], depth+<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> Node(best_feat, best_threshold, left, right) </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_best_criteria</span>(<span class="params">self,X,y,feat_idxs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Find the best criteria to split the data</span></span><br><span class="line"><span class="string">        :param X: input data</span></span><br><span class="line"><span class="string">        :param y: label</span></span><br><span class="line"><span class="string">        :param feat_idxs: indices of features to consider</span></span><br><span class="line"><span class="string">        :return: best feature index, best threshold</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        best_gain = -<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        split_idx, split_threshold = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> feat_idx <span class="keyword">in</span> feat_idxs:</span><br><span class="line">            X_col = X[:,feat_idx] <span class="comment"># X의 각 feature</span></span><br><span class="line">            thresholds = np.unique(X_col) <span class="comment"># 각 feature의 cardianlity</span></span><br><span class="line">            <span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">                gain = self._information_gain(y,X_col,threshold) <span class="comment"># 각 feuture의 모든 threshold에 대해서 gain을 계산</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> gain &gt; best_gain:</span><br><span class="line">                    best_gain = gain</span><br><span class="line">                    split_idx = feat_idx</span><br><span class="line">                    split_threshold = threshold</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> split_idx, split_threshold</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_information_gain</span>(<span class="params">self,y,X_column,split_threshold</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Calculate information gain</span></span><br><span class="line"><span class="string">        E(parent) - [weight average] * E(Children)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># parent entropy</span></span><br><span class="line">        </span><br><span class="line">        parent_entropy = entropy(y)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># generate split</span></span><br><span class="line">        left_idxs, right_idxs = self._split(X_column, split_threshold)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 더이상 분할이 안될 경우 정보이득이 0</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(left_idxs) == <span class="number">0</span>) <span class="keyword">or</span> (<span class="built_in">len</span>(right_idxs)) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the weighted avg. of the loss for the children</span></span><br><span class="line">        n = <span class="built_in">len</span>(y)</span><br><span class="line">        n_l, n_r = <span class="built_in">len</span>(left_idxs), <span class="built_in">len</span>(right_idxs)</span><br><span class="line">        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])</span><br><span class="line">        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r</span><br><span class="line"></span><br><span class="line">        <span class="comment"># information gain is difference in loss before vs. after split</span></span><br><span class="line">        ig = parent_entropy - child_entropy</span><br><span class="line">        <span class="keyword">return</span> ig</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_split</span>(<span class="params">self, X_column, split_threshold</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Split data according to the threshold</span></span><br><span class="line"><span class="string">        :param X_column: input data</span></span><br><span class="line"><span class="string">        :param split_threshold: threshold to split</span></span><br><span class="line"><span class="string">        :return: left and right indices</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># np.argwhere을 사용 조건에 해당하는 인덱스 반환.</span></span><br><span class="line">        left_idxs = np.argwhere(X_column &lt;= split_threshold).flatten()</span><br><span class="line">        right_idxs = np.argwhere(X_column &gt; split_threshold).flatten()</span><br><span class="line">        <span class="keyword">return</span> left_idxs, right_idxs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_most_common_label</span>(<span class="params">self, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Find the most common label in the dataset</span></span><br><span class="line"><span class="string">        :param y: labels</span></span><br><span class="line"><span class="string">        :return: most common label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        counter = Counter(y)</span><br><span class="line">        <span class="comment"># counter.most_common(1) -&gt; [(label, count)] # 리스트 안에 튜플</span></span><br><span class="line">        most_common = counter.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> most_common <span class="comment"># Counter(y) : Counter(&#123;0: 2, 1: 2&#125;) #value과 count중 value만 반환 </span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># traverse the tree</span></span><br><span class="line">        <span class="keyword">return</span> np.array([self._traverse_tree(x,self.root) <span class="keyword">for</span> x <span class="keyword">in</span> X]) <span class="comment"># X의 각 데이터포인트에 대해서 트리를 순회하며 각 데이터포인트에 대한 결과를 반환</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_traverse_tree</span>(<span class="params">self, x, node</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Traverse the tree from the root</span></span><br><span class="line"><span class="string">        :param x: input data</span></span><br><span class="line"><span class="string">        :param node: root node</span></span><br><span class="line"><span class="string">        :return: label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> node.is_leaf(): <span class="comment"># check if leaf node</span></span><br><span class="line">            <span class="keyword">return</span> node.value</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> x[node.feature] &lt;= node.threshold:</span><br><span class="line">            <span class="keyword">return</span> self._traverse_tree(x, node.left)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self._traverse_tree(x, node.right)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y,y_pred</span>):</span><br><span class="line">        acc = np.<span class="built_in">sum</span>(y == y_pred) / <span class="built_in">len</span>(y)</span><br><span class="line">        <span class="keyword">return</span> acc</span><br><span class="line">    </span><br><span class="line">    data = datasets.load_breast_cancer()</span><br><span class="line">    X, y = data.data, data.target</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    </span><br><span class="line">    clf = DecisionTree(max_depth=<span class="number">10</span>)</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    y_pred = clf.predict(X_test)</span><br><span class="line">    acc = accuracy(y_test, y_pred)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Accuracy : <span class="subst">&#123;acc&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html">결정트리의 최적화 문제</a></li><li><a href="https://machinelearningmastery.com/information-gain-and-mutual-information/">정보이득</a></li><li><a href="https://victorzhou.com/blog/gini-impurity/">지니불순도</a></li><li><a href="https://tensorflow.blog/tag/%EC%A7%80%EB%8B%88-%EB%B6%88%EC%88%9C%EB%8F%84/">불순도 지표들</a></li><li><a href="-https://xzz201920.medium.com/post-pruning-techniques-in-decision-tree-4be56636172b">Post_Pruning</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Supervised Learning </tag>
            
            <tag> Decision Tree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[SVM]서포트벡터머신의 이해</title>
      <link href="/2023/10/28/machine-learning/ML-SP-SVM/"/>
      <url>/2023/10/28/machine-learning/ML-SP-SVM/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><!--진짜 refhttps://excelsior-cjh.tistory.com/165진짜 가장중요한 refhttps://www.baeldung.com/cs/svm-hard-margin-vs-soft-margin--><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>결정 경계</strong>: 서로 다른 두 데이터를 구분하는 기준선(threshold). 선형 SVM의 결정 경계는 데이터 feature의 n차원의 초평면(hyperplane)이다.</li><li><strong>초평면(hyperplane)</strong> : flat affine subspace of p-1 (p는 데이터의 차원) </li><li><strong>Support Vector</strong> : 결정 경계와 가장 가까운 데이터 포인트. Soft Margin의 끝에 있는 데이터포인트</li><li><strong>Margin</strong> : 결정경계와 Support Vector사이의 거리(threshold와 데이터포인트 사이의 최소거리)</li><li><strong>Support Vector Machine</strong> : 마진을 최대화 하는 결정 경계를 찾는 알고리즘.<ul><li><strong>Soft Margin</strong> : <strong>Allow misclassification</strong>. outlier의 오분류를 허용함으로써 과적합으로 인한 문제(low bias, high variance) 를 완화시키려고 하는 것. Soft Margin은 오분류를 허용한 경우의 Margin을 뜻한다.</li><li><strong>Hard Margin</strong>: 결정경계면이 선형이며 오분류를 허용하지 않는 Margin. 오차항이 없는 경우의 soft margin 을 hard margin이라 한다.</li></ul></li></ul><hr><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><hr><ul><li>데이터가 p차원일 경우 분류기(Support Vector Classifier)는 p-1차원의 subspace에 존재한다. 이를 hyperplane이라 한다.</li><li>기본적인 컨셉은 margin을 최대화 하는 결정경계를 찾는 것이다.</li><li>margin을 크게 할 수록 일반화 성능이 좋아진다.(과적합이 덜 된다.)</li><li>마진이 커질경우 일반화 성능이 좋아지지만 bias가 상승한다,</li><li>패널티 항을 추가해서 생각하면 SVM에서의 최적화는 결국 마진을 크게 하는 것과 에러에 대한 페널티를 크게 하는 것의 균형으로 볼 수 있다.<ul><li>maximizing the margin and minimizing the loss</li></ul></li></ul><p><img src="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/svm-all.png"></p><p>margin이 최대화 하려면 결정경계에 해당하는 wx+b&#x3D;0이 되게끔 하는 w를 찾아야 한다.<br>이는 <code>wx+b=0</code>에 수직인 벡터(법선벡터)인 $\frac{2}{|\boldsymbol{w}|}$ 최대화 하는 것이다.(w의 유클리드 norm에 대해 2를 곱해준 것)<br>따라서 $\frac{2}{|\boldsymbol{w}|}$ 를 최대화 하는 것이 SVM의 기본적인 목적이 된다.<br>Graidient 계산을 보다 용이하게 하기 위해 $\frac{2}{|\boldsymbol{w}|}$을 최대화하는 문제를 아래와 같이 치환할 수 있다.</p><p>$$\min _{\boldsymbol{w}, b} \frac{1}{2}|\boldsymbol{w}|^{2} \equiv \min _{\boldsymbol{w}, b} \frac{1}{2} \boldsymbol{w}^{T} \boldsymbol{w}$$</p><p>class label을 각각 1,-1로 가정할 때 데이터포인트를 정하게 분류하기 위해 다음과 같은 제약조건이 필요하다.</p><ul><li><strong>양성 plane 보다 위에 있는 관측치는 1보다 커야하고 음성 plane 보다 아래 있는 관측치들은 -1 보다 작아야 한다.</strong></li></ul><p>이를 모두 만족하는 제약식은 아래와 같다.</p><p>$\quad y_{i}\left(\boldsymbol{w}^{T} \boldsymbol{x}_{i}+b\right) \geq 1$</p><p>따라서 최적화 문제를 최종적으로 아래와 같이 정리 할 수 있다.</p><p>$$\min _{\boldsymbol{w}, b} \frac{1}{2} \boldsymbol{w}^{T} \boldsymbol{w}$$</p><p>$$\text { s.t. } \quad y_{i}\left(\boldsymbol{w}^{T} \boldsymbol{x}_{i}+b\right) \geq 1$$</p><h3 id="Soft-Margin"><a href="#Soft-Margin" class="headerlink" title="Soft Margin"></a>Soft Margin</h3><hr><p>소프트마진은 분류기에 오차를 나타내는 slack variable $\zeta$ 를 목적함수에 추가한다. </p><p>hyperparameter C를 통해 loss에 대한 비용을 조정할 수 있다. C가 클 수록 분류오차에 민감해진다. 즉 C값이 커질 경우 마진이 커진다.</p><p>반대로 C값을 줄일 경우 bias가 늘어나는 대신 variance가 줄어든다.</p><p>소프트 마진 SVM의 최적화 함수는 다음과 같다.</p><p>아래의 제약조건을 포함해 생각하면 slack vairable $\zeta$가 0&gt;인 경우를 최소화하고 margin을 최대화 하는 hyperplane을 찾는 것이  Soft Margin SVM의 목적이 된다.</p><p>$$\min \frac{1}{2}|\mathbf{w}|^{2}+C \sum_{i&#x3D;1}^{m} \zeta_{i}$$</p>$$\quad y_{i}\left(\mathbf{w}^{T} \mathbf{x}_{i}+b\right) \geq 1-\zeta_{i} \quad i=1, \ldots, n, \quad \zeta_{i} \geq 0$$<h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><hr><p>max(0, 1−yi(wTxi − b)) 는 SVM의 loss function으로 기능한다.</p><p>SVM의 loss function은 <code>hinge loss</code> 라고 불리는 데 yi(wTxi − b)이 safety margin인 1보다 크면 loss를 0으로 두고 1보다 작을수록 loss가 크도록 유도한 것이다.</p><p>SVM의 hyperparmeter C 는 단순히 hinge loss에 대한 계수이다.</p><p>결정경계로 부터의 거리가 0보다 작을 경우 hinge loss가 커지고 이는 데이터포인트가 결정경계의 잘못된 부분에 있는 것을 의미한다.</p><p>결정경계로 부터의 거리가 0 과 1 사이에 있는 경우에도 기본적인 loss가 존재하지만 기본적으로 결정경계로부터의 거리가 0보다 커질 경우  loss는 0으로 수렴한다.</p><p><img src="https://miro.medium.com/max/1150/1*PGqpYm7o5GCbDXxXErr2JA.png"></p><h3 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h3><ul><li>iris data set에 대해 soft margin 구현</li></ul><p>사실 직접 구현보다는 그냥 잘 만들어진 프레임워크를 쓰는 것이 훨씬 낫다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> svc</span><br><span class="line">linear_svm = SVC(kernel=<span class="string">&#x27;linear&#x27;</span>,C=<span class="number">1.0</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">linear_svm.fit(X_train,y_train)</span><br></pre></td></tr></table></figure><ul><li>numpy로 직접구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy로 svm구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SVM</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,learning_rate=<span class="number">0.0001</span>,lambda_param =<span class="number">0.01</span>,n_iter =<span class="number">1000</span></span>):</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.lambda_param = lambda_param</span><br><span class="line">        self.n_iters = n_iters</span><br><span class="line">        self.w = <span class="literal">None</span></span><br><span class="line">        self.b = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y</span>):</span><br><span class="line">        y_ = np.where(y&lt;=<span class="number">0</span> ,-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        n_samples = X.shape</span><br><span class="line"></span><br><span class="line">        self.w = np.zeros(n_features) <span class="comment"># 가중치 초기화</span></span><br><span class="line">        self.b = <span class="number">0</span> <span class="comment"># 편향 초기화</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iters):</span><br><span class="line">            <span class="keyword">for</span> idx, x_i <span class="keyword">in</span> <span class="built_in">enumerate</span>(X):</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                current index, data point</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                condition = y_[idx] * (np.dot(x_i,self.w)) &gt;= <span class="number">1</span> <span class="comment"># 제약조건 구현</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 가중치 업데이트(hinge loss의 gradient update)</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> condition:</span><br><span class="line">                    self.w -= self.lr * (<span class="number">2</span> * self.lambda_param * self.w)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.w -= self.lr * (<span class="number">2</span> * self.lambda_param * self.w - np.dot(x_i,y_[idx]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">        linear_output = np.dot(X,self.w) - self.b</span><br><span class="line">        <span class="keyword">return</span> np.sign(linear_output) <span class="comment"># numpy 부호 판별 함수 부호에 따라 -1,1,0 중 하나를 반환</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># weight가 주어졌을 경우 SVM을 시각화하는 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_svm</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_hyperplane_value</span>(<span class="params">x, w, b, offset</span>):</span><br><span class="line">        <span class="keyword">return</span> (-w[<span class="number">0</span>] * x + b + offset) / w[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">&quot;o&quot;</span>, c=y)</span><br><span class="line"></span><br><span class="line">    x0_1 = np.amin(X[:, <span class="number">0</span>])</span><br><span class="line">    x0_2 = np.amax(X[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    x1_1 = get_hyperplane_value(x0_1, clf.w, clf.b, <span class="number">0</span>)</span><br><span class="line">    x1_2 = get_hyperplane_value(x0_2, clf.w, clf.b, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    x1_1_m = get_hyperplane_value(x0_1, clf.w, clf.b, -<span class="number">1</span>)</span><br><span class="line">    x1_2_m = get_hyperplane_value(x0_2, clf.w, clf.b, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x1_1_p = get_hyperplane_value(x0_1, clf.w, clf.b, <span class="number">1</span>)</span><br><span class="line">    x1_2_p = get_hyperplane_value(x0_2, clf.w, clf.b, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    ax.plot([x0_1, x0_2], [x1_1, x1_2], <span class="string">&quot;y--&quot;</span>)</span><br><span class="line">    ax.plot([x0_1, x0_2], [x1_1_m, x1_2_m], <span class="string">&quot;k&quot;</span>)</span><br><span class="line">    ax.plot([x0_1, x0_2], [x1_1_p, x1_2_p], <span class="string">&quot;k&quot;</span>)</span><br><span class="line"></span><br><span class="line">    x1_min = np.amin(X[:, <span class="number">1</span>])</span><br><span class="line">    x1_max = np.amax(X[:, <span class="number">1</span>])</span><br><span class="line">    ax.set_ylim([x1_min - <span class="number">3</span>, x1_max + <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>Reference &amp; Annotaion</strong></p><ul><li><a href="https://youtu.be/efR1C6CvhmE">https://youtu.be/efR1C6CvhmE</a></li><li><a href="https://en.wikipedia.org/wiki/Support-vector_machine">https://en.wikipedia.org/wiki/Support-vector_machine</a></li><li><a href="https://towardsdatascience.com/a-definitive-explanation-to-hinge-loss-for-support-vector-machines-ab6d8d3178f1">https://towardsdatascience.com/a-definitive-explanation-to-hinge-loss-for-support-vector-machines-ab6d8d3178f1</a></li><li>데이터가 비선형일 경우 커널 트릭을 활용한 고차원 매핑을 시행한다.</li><li>법선벡터를 최대화 하는 문제를 최적화 문제로 바꾸는 변환에 주의할 것.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
          <category> Supervised Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVM </tag>
            
            <tag> hyperplane </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Unsupervised Learning]KNN을 활용한 분류</title>
      <link href="/2023/10/28/machine-learning/ML-US-knn/"/>
      <url>/2023/10/28/machine-learning/ML-US-knn/</url>
      
        <content type="html"><![CDATA[<!--- ML- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><hr><h2 id="간단한-컨셉"><a href="#간단한-컨셉" class="headerlink" title="간단한 컨셉"></a>간단한 컨셉</h2><p><strong>KNN</strong></p><ul><li><p>새로운 데이터에 대해 기존 데이터 가운데 가장 가까운 K개 이웃의 정보로 새로운 데이터를 예측하는 방법론.</p></li><li><p>회귀문제와 분류문제 해결에 모두 사용되는 지도학습</p></li><li><p>하이퍼파라미터는 기본적으로 거리측정방법과 탐색할 이웃 수 2가지 이다.</p></li><li><p><strong>K(이웃)을 적게 사용하면 모델 복잡도가 높아지고 많이 사용하면 복잡도가 낮아진다(K의 수를 늘릴수록 결정경계가 부드러워진다.).</strong></p></li><li><p>KNN은 회귀분석에도 쓰이며 여러개의 K를 사용할 경우 이웃들의 종속변수의 평균이 예측된다.</p></li><li><p>거리측정방법</p><ul><li>유클리디안 거리 : 데이터포인트 사이 직선 최단거리</li><li>마할라노비스 거리 : 공분산을 고려해 거리를 계산한다. 변수간 상관관계를 고려한 거리지표.</li><li>맨해튼 거리 : 각 좌표축 방향으로만 이동할 경우 계산된다. 격자모양의 길을 따라간다.</li></ul></li><li><p>주의점</p><ul><li>기본적으로 거리기반이기 때문에 KNN을 돌리기 전 반드시 변수를 정규화 해야 한다.</li><li>불균형 데이터의 분류문제를 풀 경우 학습데이터 범주의 사전확률(Prior Probability)를 고려해야핟다.</li></ul></li><li><p>장단점</p><ul><li>장점 : 학습 데이터 내 노이즈의 영향들 덜받음. 학습데이터가 많으면 효과적 </li><li>단점 : 어떤 거리척도가 분석에 적랍한지 불분명. 계산시간이 오래 걸림</li></ul></li></ul><h2 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h2><ul><li>유클라디안 거리를 활용한 KNN 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">x1,x2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>((x1-x2)**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KNN</span>:</span><br><span class="line"></span><br><span class="line">    self __init__(self, k=<span class="number">3</span>):</span><br><span class="line">        self.k = k </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>): <span class="comment"># triain sample and label</span></span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        predicted_labels = [self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">        <span class="keyword">return</span> np.array</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        1. 거리 계산하기</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        2. k nearest sample</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        3. majority vote, get most common class</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        distances = [euclidean_distance(x,x_train) <span class="keyword">for</span> x_train <span class="keyword">in</span> X_train]</span><br><span class="line"></span><br><span class="line">        k_indices = np.argsort(distances)[:self.k]</span><br><span class="line">        k_nearest_labels = [self.y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> k_indices]</span><br><span class="line"></span><br><span class="line">        most_common = Counter(k_nearest_labels).most_common(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> most_common[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="분류문제-풀이"><a href="#분류문제-풀이" class="headerlink" title="분류문제 풀이"></a>분류문제 풀이</h2><ul><li>iris 데이터를 바탕으로 분류문제 풀이</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">cmap = ListedColormap([<span class="string">&quot;#FF0000&quot;</span>, <span class="string">&quot;#00FF00&quot;</span>, <span class="string">&quot;#0000FF&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    accuracy = np.<span class="built_in">sum</span>(y_true == y_pred) / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">        X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1234</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">clf = KNN(k=k)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">predictions = clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KNN classification 정확도&quot;</span>, accuracy(y_test, predictions))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$KNN</span> classification accuracy 1.0</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>sklearn에서도 knn 분류기가 구현되어 있다.<ul><li>irsis data load까지는 동일하게 진행된다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeiborsClassifier</span><br><span class="line"></span><br><span class="line">clf = KNeiborsClassifier(n_neighbors =<span class="number">3</span>)</span><br><span class="line">clf.fit()</span><br><span class="line"></span><br><span class="line">pred = clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KNN classification 정확도&quot;</span>, clf.score(X_test,y_test))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="K값과-모델-복잡도의-관계"><a href="#K값과-모델-복잡도의-관계" class="headerlink" title="K값과 모델 복잡도의 관계"></a>K값과 모델 복잡도의 관계</h2><ul><li>위스콘신 유방암데이터로 구현한다.</li><li>k의 수가 1개일 때는(적을 때는) train 데이터에 대해서만 예측력이 높고 test에서는 낮은 과적합된 모습을 보인다.</li><li>k의 수가 많을 수록 모델이 단순해지고 train 데이터의 정확도는 줄어든다.</li><li>k의 수가 10개일 때는 모델이 너무 단순해 train과 test모두에서 예측력이 낮은 모습을 보인다.</li><li>중간정도의 범위에서 k의 수를 선정할 필요가 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X_train , X_test , y_train , y_test = train_test_split(cancer.data,</span><br><span class="line">                                                       cancer.target,</span><br><span class="line">                                                       stratify = cancer.target, <span class="comment"># stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해준다. (한 쪽에 쏠려서 분배되는 것을 방지)</span></span><br><span class="line">                                                       random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">train_acc = []</span><br><span class="line">test_acc = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">k_indices = <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_indices:</span><br><span class="line">    clf = KNeiborsClassifier(n_neighbors=k)</span><br><span class="line">    clf.fit()</span><br><span class="line">    train_acc.append(clf.score(X_train,y_train))</span><br><span class="line">    test_acc.append(clf.score(X_test,y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(neighbors_settings, training_accuracy, label=<span class="string">&quot;훈련 정확도&quot;</span>)</span><br><span class="line">plt.plot(neighbors_settings, test_accuracy, label=<span class="string">&quot;테스트 정확도&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;정확도&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;n_neighbors&quot;</span>)</span><br><span class="line">plt.legend(</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://tensorflowkorea.files.wordpress.com/2017/06/2-7.png?w=1024"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.python.org/3/library/collections.html">https://docs.python.org/3/library/collections.html</a></li><li><a href="https://tensorflow.blog/%EA%B0%9C%EC%A0%95%ED%8C%90-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/">파이싼 라이브러리를 활용한 머신러닝</a></li><li><a href="https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/">https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[XAI]PDP Plot의 이해와 구현</title>
      <link href="/2023/10/28/machine-learning/ML-XAI-PDP/"/>
      <url>/2023/10/28/machine-learning/ML-XAI-PDP/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="PDP-plot"><a href="#PDP-plot" class="headerlink" title="PDP plot"></a>PDP plot</h2><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>ICE(Indivisual Conditional Expectation)</strong> :하나의 관측치에 대해 특정 feature의 값을 변화시킬 때 모델의 예측.</li><li><strong>marginal effect</strong> :독립변수의 변화예 따른 종속변수의 변화</li><li><strong>Partial Dependence Plot</strong> : 1개나 2개의 특성의 변화(상호작용)에 따른 모델 예측의 변화를 그린 것.</li></ul><hr><blockquote><p>The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model (J. H. Friedman 200130). A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. </p></blockquote><ul><li>feature가 모델에 미치는 긍정적&#x2F;부정적 영향 확인</li><li>특정 feture에 대해 여유분(buffer)을 함께 표시 -&gt; feature간 독립을 보장하지 못하는 환경에서 모델에 어느정도 있을 수 있는 지를 확인할 수 있게끔 함</li></ul><h3 id="기본적인-컨셉에-대한-이해"><a href="#기본적인-컨셉에-대한-이해" class="headerlink" title="기본적인 컨셉에 대한 이해"></a>기본적인 컨셉에 대한 이해</h3><p>$$\hat{f}<em>S(x_S)&#x3D;E</em>{X_C}\left[\hat{f}(x_S,X_C)\right]&#x3D;\int\hat{f}(x_S,X_C)d\mathbb{P}(X_C)$$</p><p>$$\hat{f}<em>S(x_S)&#x3D;\frac{1}{n}\sum</em>{i&#x3D;1}^n\hat{f}(x_S,x^{(i)}_{C})$$</p><ul><li>$X_S$는 분석하고자 하는 feature이다.</li><li>$X_C$는 분석하고자 하는 feauture 외의 모델의 feauture들이다.</li><li>여기서 $f(x_{S}, x_{C}^{(i)})$ 가 하나의 ICE 곡선을 나타낸다.</li><li>Partial Dependence는 단순히 $X_C$를 를 고정시킨 상태에서 $X_S$를 변화시키며 모델의 예측값을 계산 후 그 값을 평균한 것이다.</li><li><strong>target과 관련이 있는 특성에 대한 Global한 설명이 필요할 때 사용한다.</strong></li></ul><h3 id="ICE-Indivisual-Conditional-Expectation"><a href="#ICE-Indivisual-Conditional-Expectation" class="headerlink" title="ICE(Indivisual Conditional Expectation)"></a>ICE(Indivisual Conditional Expectation)</h3><ul><li><p>ICE 곡선은 하나의 관측치에 대해 관심 특성을 변화시킴에 따른 타겟값 변화 곡선. </p></li><li><p>PDP는 기본적으로 여러 ICE곡선의 평균이다.</p></li><li><p><code>frac_to_plot</code> : 라인 수 조정 파라미터. 라인 수 혹은 비율</p></li><li><p><strong>ICE와 PDF에 대한 직관적 이해</strong> : <a href="https://twitter.com/i/status/1066398522608635904">https://twitter.com/i/status/1066398522608635904</a></p></li><li><p>부분 의존성 계산 및 PDP plot 그리기</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ice = pdp.pdp_isolate(</span><br><span class="line">      model = clf,</span><br><span class="line">      dataset = df,</span><br><span class="line">      model_features=features</span><br><span class="line">      feature = <span class="string">&quot;feature_1&quot;</span> <span class="comment"># 분석하고자 하는 feature</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># PDP plot</span></span><br><span class="line"></span><br><span class="line">fig, axes = pdp.pdp_plot(</span><br><span class="line">            ice,</span><br><span class="line">            <span class="string">&quot;feature_1&quot;</span>,</span><br><span class="line">            plot_line = <span class="literal">False</span>,</span><br><span class="line">            frac_to_plot = <span class="number">0.5</span>,</span><br><span class="line">            plot_pts_dist = <span class="literal">True</span></span><br><span class="line">                         )</span><br></pre></td></tr></table></figure><h3 id="PDP-interaction"><a href="#PDP-interaction" class="headerlink" title="PDP interaction"></a>PDP interaction</h3><ul><li><p>두 특성간 상호작용 확인</p></li><li><p>등고선 그래프를 그렸을 때 특정 축에 평행할 경우 다른 축의 값에 상관없이 </p><ul><li>X축에 평행할 경우 모델의 예측 X축의 변수에 보다 의존적.</li><li>Y축의 변수의 값에 상관없이 X축의 값에 따라 모델 예측이 결정됨</li></ul></li><li><p>해석하기에는 Grid로 그래프를 그리는 것이 더 나을 수 있다. </p></li><li><p>skearn으로 구현한 등고선 그래프<br><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_partial_dependence_003.png" alt="ICE"></p></li><li><p>pdp plot 패키지로 구현한 상호작용</p><ul><li>모델이 없이 두 feature의 상호작용에 따른 target의 값을 보여준다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pdpbox <span class="keyword">import</span> info_plots, get_dataset</span><br><span class="line"></span><br><span class="line">test_titanic = get_dataset.titanic()</span><br><span class="line">titanic_data = test_titanic[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">titanic_target = test_titanic[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig, axes, summary_df = info_plots.target_plot_interact(</span><br><span class="line">    df=titanic_data, features=[<span class="string">&#x27;Sex&#x27;</span>, [<span class="string">&#x27;Embarked_C&#x27;</span>, <span class="string">&#x27;Embarked_Q&#x27;</span>, <span class="string">&#x27;Embarked_S&#x27;</span>]],</span><br><span class="line">    feature_names=[<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>], target=titanic_target)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="PDP-plot에서-범주형-변수-Decoding하기"><a href="#PDP-plot에서-범주형-변수-Decoding하기" class="headerlink" title="PDP plot에서 범주형 변수 Decoding하기"></a>PDP plot에서 범주형 변수 Decoding하기</h3><ul><li>범주형 변수는 Ordinal Encoder나 target Encoder로 인코딩 한 후 사용된다.</li><li>인코딩을 하게되면 학습 후 PDP 를 그릴 때 인코딩된 값이 나오게 되어 카테고리특성의 실제 값을 확인하기 어려운 문제가 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line">df[<span class="string">&#x27;age&#x27;</span>] = df[<span class="string">&#x27;age&#x27;</span>].fillna(df[<span class="string">&#x27;age&#x27;</span>].median())</span><br><span class="line">df = df.drop(columns=<span class="string">&#x27;deck&#x27;</span>) <span class="comment"># NaN 77%</span></span><br><span class="line">df = df.dropna()</span><br><span class="line"></span><br><span class="line">target = <span class="string">&#x27;survived&#x27;</span></span><br><span class="line">features = df.columns.drop([<span class="string">&#x27;survived&#x27;</span>, <span class="string">&#x27;alive&#x27;</span>])</span><br><span class="line"></span><br><span class="line">X = df[features]</span><br><span class="line">y = df[target]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이프라인 생성 및 학습</span></span><br><span class="line">pipe = make_pipeline(</span><br><span class="line">    OrdinalEncoder(), </span><br><span class="line">    RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line">pipe.fit(X, y);</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">encoder = pipe.named_steps[<span class="string">&#x27;ordinalencoder&#x27;</span>]</span><br><span class="line">X_encoded = encoder.fit_transform(X)</span><br><span class="line">rf = pipe.named_steps[<span class="string">&#x27;randomforestclassifier&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>범주형 변수에 대한 ice plot</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pdpbox <span class="keyword">import</span> pdp</span><br><span class="line">feature = <span class="string">&#x27;sex&#x27;</span></span><br><span class="line">pdp_dist = pdp.pdp_isolate(model=rf, dataset=X_encoded, model_features=features, feature=feature)</span><br><span class="line">pdp.pdp_plot(pdp_dist, feature); <span class="comment"># 인코딩된 sex 값을 확인할 수 있습니다</span></span><br></pre></td></tr></table></figure><ul><li>자동으로 PDP 카테고리 매핑</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이번에는 PDP 카테고리값 맵핑을 자동으로 해보겠습니다</span></span><br><span class="line"></span><br><span class="line">feature = <span class="string">&#x27;sex&#x27;</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> encoder.mapping:</span><br><span class="line">    <span class="keyword">if</span> item[<span class="string">&#x27;col&#x27;</span>] == feature:</span><br><span class="line">        feature_mapping = item[<span class="string">&#x27;mapping&#x27;</span>] <span class="comment"># Series</span></span><br><span class="line">        </span><br><span class="line">feature_mapping = feature_mapping[feature_mapping.index.dropna()]</span><br><span class="line">category_names = feature_mapping.index.tolist()</span><br><span class="line">category_codes = feature_mapping.values.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pdp.pdp_plot(pdp_dist, feature)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xticks labels 설정을 위한 리스트를 직접 넣지 않아도 됩니다 </span></span><br><span class="line">plt.xticks(category_codes, category_names);</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>PDP 상호작용</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2D PDP 를 Seaborn Heatmap으로 그리기 위해 데이터프레임으로 만듭니다</span></span><br><span class="line">pdp = interaction.pdp.pivot_table(</span><br><span class="line">    values=<span class="string">&#x27;preds&#x27;</span>, </span><br><span class="line">    columns=features[<span class="number">0</span>], </span><br><span class="line">    index=features[<span class="number">1</span>]</span><br><span class="line">)[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">pdp = pdp.rename(columns=<span class="built_in">dict</span>(<span class="built_in">zip</span>(category_codes, category_names)))</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">5</span>))</span><br><span class="line">sns.heatmap(pdp, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;.2f&#x27;</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;PDP decoded categorical&#x27;</span>);</span><br></pre></td></tr></table></figure><p><strong>References &amp; annotation</strong></p><ul><li><a href="https://pdpbox.readthedocs.io/en/latest/index.html">https://pdpbox.readthedocs.io/en/latest/index.html</a></li><li><a href="https://christophm.github.io/interpretable-ml-book/pdp.html">https://christophm.github.io/interpretable-ml-book/pdp.html</a></li><li><a href="https://scikit-learn.org/stable/modules/partial_dependence.html">https://scikit-learn.org/stable/modules/partial_dependence.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XAI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Metrics]회귀모델의 평가지표</title>
      <link href="/2023/10/28/machine-learning/ML-Metrics-Regression/"/>
      <url>/2023/10/28/machine-learning/ML-Metrics-Regression/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>회귀모델의 평가지표 정리</strong></p><h3 id="회귀모델의-평가지표"><a href="#회귀모델의-평가지표" class="headerlink" title="회귀모델의 평가지표"></a>회귀모델의 평가지표</h3><ul><li>$R^2$ 외에, MAE는 단위 유닛이 같으므로 보다 해석에 용이함.</li><li>MSE는 제곱을 하기 때문에 특이값에 보다 민감. </li><li>RMSE는 MSE를 실제값과 유사한 단위로 변화시켜줌.</li><li>회귀문제에서 RMSE가 일반적으로 선호되는 방법이지만, 상황에 맞는 다른 방식을 사용. 특이값이 많은 경우에는 MAE를 사용.</li></ul><hr><p><strong><em>Concept</em></strong></p><ul><li><p>MSE (Mean Squared Error) &#x3D;<br>$\frac{1}{n}\sum_{i&#x3D;1}^{n}(y_{i} - \hat{y_{i}})^{2}$</p></li><li><p>MAE (Mean absolute error) &#x3D; $\frac{1}{n}\sum_{i&#x3D;1}^{n}\left | y_{i} - \hat{y_{i}} \right |$</p></li><li><p>RMSE (Root Mean Squared Error) &#x3D;<br>$\sqrt{MSE}$</p></li><li><p>R-squared (Coefficient of determination) &#x3D;<br>$1 - \frac{\sum_{i&#x3D;1}^{n}(y_{i} - \hat{y_{i}})^{2}}{\sum_{i&#x3D;1}^{n}(y_{i} - \bar{y_{i}})^{2}} &#x3D; 1 - \frac{SSE}{SST} &#x3D; \frac {SSR}{SST}$</p></li><li><p>MAPE &#x3D; $\frac { \sum \vert \frac { y - \hat y}{y} \vert }{n}*100%$</p></li></ul><ul><li>참고<ul><li>SSE(Sum of Squares <code>Error</code>, 관측치와 예측치 차이): $\sum_{i&#x3D;1}^{n}(y_{i} - \hat{y_{i}})^{2}$</li><li>SSR(Sum of Squares due to <code>Regression</code>, 예측치와 평균 차이): $\sum_{i&#x3D;1}^{n}(\hat{y_{i}} - \bar{y_{i}})^{2}$</li><li>SST(Sum of Squares <code>Total</code>, 관측치와 평균 차이): $\sum_{i&#x3D;1}^{n}(y_{i} - \bar{y_{i}})^{2}$ , SSE + SSR</li></ul></li></ul><hr><h4 id="MSE"><a href="#MSE" class="headerlink" title="MSE"></a>MSE</h4><ul><li>모델의 예측값과 실제값 차이의 면적의 합.</li><li>특이값이 존재할 경우 수치가 많이 늘어남</li></ul><h4 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h4><ul><li>MSE 보다 특이치에 robust</li><li>절대값을 취하기 때문에 매우 직관적</li></ul><h4 id="RMSE"><a href="#RMSE" class="headerlink" title="RMSE"></a>RMSE</h4><ul><li>MSE의 제곱근. </li><li>큰 오류값에 대해 패널티를 주기 때문에 보통 이걸 사용</li></ul><h4 id="R-squared"><a href="#R-squared" class="headerlink" title="R-squared"></a>R-squared</h4><ul><li>설명량</li><li>$R^2$ 값이 1에 가까울 수록 데이터를 잘 설명하는 모델이 됨</li></ul><h4 id="MAPE"><a href="#MAPE" class="headerlink" title="MAPE"></a>MAPE</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">MAPE</span>(<span class="params">y_true, y_pred</span>): </span><br><span class="line">    <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>((y_true - y_pred) / y_true)) * <span class="number">100</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>MAE를 퍼센트 변환한 것.</li><li>MAE와 마찬가지로 MSE보다 특이치에 robust하다.</li><li>모델에 대한 편향이 존재.</li><li>0 근처의 값에서는 사용하기 어렵습니다.</li></ul><h4 id="MPE"><a href="#MPE" class="headerlink" title="MPE"></a>MPE</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">MAPE</span>(<span class="params">y_true, y_pred</span>): </span><br><span class="line">    <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>((y_true - y_pred) / y_true)) * <span class="number">100</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>MAPE를 퍼센트 변환한 것.</li><li>절대값을 제외했기 때문에 overperformance인지 underperformance인지 쉽게 알 수 있다.</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.dataquest.io/blog/understanding-regression-error-metrics/">https://www.dataquest.io/blog/understanding-regression-error-metrics/</a></li><li><a href="https://machinelearningmastery.com/regression-metrics-for-machine-learning/">https://machinelearningmastery.com/regression-metrics-for-machine-learning/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Regression </tag>
            
            <tag> Metrics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Tree]주요 Decision Tree 알고리즘</title>
      <link href="/2023/10/28/machine-learning/ML-SP-Main-Decision-Tree-Algorithms/"/>
      <url>/2023/10/28/machine-learning/ML-SP-Main-Decision-Tree-Algorithms/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p>주요 의사결정트리 알고리즘 4개에 대해 간단히 살펴보자.</p><hr><h2 id="Main-Decision-Tree-Algorithms"><a href="#Main-Decision-Tree-Algorithms" class="headerlink" title="Main Decision Tree Algorithms"></a>Main Decision Tree Algorithms</h2><h3 id="CHAID"><a href="#CHAID" class="headerlink" title="CHAID"></a><strong>CHAID</strong></h3><p>The Chi-squared Automatic Interaction Detection (CHAID) is one of the oldest DT algorithms methods that produces multiway DTs (splits can have more than two branches) suitable for classification and regression tasks. When building Classification Trees (where the dependent variable is categorical in nature), CHAID relies on the Chi-square independence tests to determine the best split at each step. Chi-square tests check if there is a relationship between two variables, and are applied at each stage of the DT to ensure that each branch is significantly associated with a statistically significant predictor of the response variable.<br><strong>In other words, it chooses the independent variable that has the strongest interaction with the dependent variable.</strong></p><h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a><strong>CART</strong></h3><p>CART is a DT algorithm that produces binary Classification or Regression Trees, depending on whether the dependent (or target) variable is categorical or numeric, respectively. It handles data in its raw form (no preprocessing needed), and can use the same variables more than once in different parts of the same DT, which may uncover complex interdependencies between sets of variables.</p><p><strong>Prepare Data for CART</strong></p><ul><li><p>The <strong>splitting of numerical features</strong> can be performed by sorting the features in the ascending order and trying each value as the threshold point and calculating the information gain for each value as the threshold. Finally, if that value obtained is equal to the threshold which gives the maximum I.G value then hurray..!!</p></li><li><p>Feature scaling(column standardization) not necessary to perform in decision trees. However, it helps with data visualization&#x2F;manipulation and might be useful if you intend to compare performance with other data or other methods like SVM.</p></li><li><p>In order to handle categorical features in Decision trees, we must never perform one hot encoding on a categorical variable even if the categorical variables are nominal since most of the libraries can handle categorical variables automatically. we can still assign a number for each variable if desired.</p></li><li><p>If height or depth of the tree is exactly one then such a tree is called as a decision stump.</p></li><li><p>Imbalanced class does have a detrimental impact on the tree’s structure so it can be avoided by either using upsampling or by using downsampling depending upon the dataset.</p></li><li><p>Apart from skewed classes, high dimensionality can also have an adverse effect on the structure of the tree if dimensionality is very high that means we have a lot of features which means that to find the splitting criterion on each node it will consume a lot of time.</p></li><li><p>Outliers also impact the tree’s structure as the depth increases the chance of outliers in the tree increases.</p></li><li><p>Feature importance can be determined by calculating the normalized sum at every level as we have t reduce the entropy and we then select the feature that helps to reduce the entropy by the large margin. so for whichever feature the normalized sum is highest, we can then think of it as the most important feature. similarly, feature which has the second highest normalized sum can be thought of as a second important feature.</p></li></ul><h3 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a><strong>ID3</strong></h3><p>The Iterative Dichotomiser 3 (ID3) is a DT algorithm that is mainly used to produce Classification Trees. Since it hasn’t proved to be so effective building Regression Trees in its raw data, ID3 is mostly used for classification tasks (although some techniques such as building numerical intervals can improve its performance on Regression Trees).</p><h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a><strong>C4.5</strong></h3><p>C4.5 is the successor of ID3 and represents an improvement in several aspects. C4.5 can handle both continuous and categorical data, making it suitable to generate Regression and Classification Trees. Additionally, it can deal with missing values by ignoring instances that include non-existing data.</p><p>Unlike ID3 (which uses Information Gain as splitting criteria), C4.5 uses Gain Ratio for its splitting process. Gain Ratio is a modification of the Information Gain concept that reduces the bias on DTs with huge amount of branches, by taking into account the number and size of the branches when choosing an attribute. Since Information Gain shows an unfair favoritism towards attributes with many outcomes, Gain Ratio corrects this trend by considering the intrinsic information of each split (it basically “normalizes” the Information Gain by using a split information value). This way, the attribute with the maximum Gain Ratio is selected as the splitting attribute.<br>Additionally, C4.5 includes a technique called windowing, which was originally developed to overcome the memory limitations of earlier computers. Windowing means that the algorithm randomly selects a subset of the training data (called a “window”) and builds a DT from that selection. This DT is then used to classify the remaining training data, and if it performs a correct classification, the DT is finished. Otherwise, all the misclassified data points are added to the windows, and the cycle repeats until every instance in the training set is correctly classified by the current DT. This technique generally results in DTs that are more accurate than those produced by the standard process due to the use of randomization, since it captures all the “rare” instances together with sufficient “ordinary” cases.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14">https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Supervised Learning </tag>
            
            <tag> Decision Tree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Tree]Random Forest의 이해</title>
      <link href="/2023/10/28/machine-learning/ML-SP-Random_Forest/"/>
      <url>/2023/10/28/machine-learning/ML-SP-Random_Forest/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>Bagging</strong> : 랜덤 복원추출을 통해 샘플링한 데이터를 바탕으로 피팅한 모델들의 예측결과를 다수결이나 평균을 내어 예측하는 것. </li><li><strong>weak learner</strong> : 서로 독립적으로 만들어지며 <strong>상관이 낮은</strong> 약한 분류기.</li><li><strong>Random Subspace Method</strong> : Bagging과 유사하지만 Bagging에 추가로 feature를 일부 선택해서 분할하는 것. Random Forest에서 사용</li><li><strong>Random Forest</strong> : 여러 <code>week learner</code>들을 합쳐서 하나의 트리를 만드는 것. boosting에 비해 과적합이 덜되는 경향이 있다.</li><li><strong>Bootstrap</strong> : datapoint가 n개일 때 n의 크기를 가지는 표본을 복원추출하는 것. 기본적으로 데이터가 편중되지 않게끔 한다.</li><li><strong>OOB</strong> : Out of Bag. 부트스트랩에서 추출되지 않는 36.8% 의 샘플.</li></ul><hr><blockquote><p>A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.</p></blockquote><p><strong>랜덤포레스트의 핵심적인 컨셉은 위의 인용처럼 서로 상관이 낮은 약한 분류기들을을 합쳐서 강력한 하나의 모델을 만드는 것이다.</strong></p><h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><img src="https://www.researchgate.net/profile/Xiaogang_He2/publication/309031320/figure/fig1/AS:422331542708224@1477703094069/Schematic-of-the-RF-algorithm-based-on-the-Bagging-Bootstrap-Aggregating-method.png" width="700" /><p>배깅의 핵심적인 목표는 <strong>의사결정 트리 사이의 분산을 줄이는 것이다.</strong> . Bagging은 기본적으로 모델의 bias를 상승시키지 않으면서 variance를 줄이는 방법이다.이를 위해 배깅에서는 <code>부트스트래핑</code>을 통한 데이터의 서브셋을 각각 학습시켜 독립적이고 서로 상관이 낮은 여러 기본모델들을 만든다. 이렇게 만든 여러 기본모델들의 앙상블이 <code>랜덤 포레스트</code>이다. <code>랜덤포레스트</code>는 한 트리의 오류가 전파되지 않아서 노이즈(이상치)에 강하며 따라서 일반적인 의사결정나무의 약점인 과적합에 강한 모습을 보인다.</p><h3 id="Random-Subspace-method"><a href="#Random-Subspace-method" class="headerlink" title="Random Subspace method"></a>Random Subspace method</h3><ul><li><p>Bagging과 유사하지만 Bagging에 추가로 feature를 일부 선택해서 분할하는 것. Random Forest에서 사용.</p></li><li><p>train dataset의 feature가 1개만 있다면 랜덤포레스트와 배깅의 알고리즘이 동일해진다.</p></li><li><p><strong>feature를 일부 선택해서 분할하는 이유는 설명력이 높은 feature가 모든 <code>weak learner</code>에서 선택되어 모델 간의 예측값의 상관이 높아지는 것을 방지하기 위함이다.</strong></p></li><li><p>기본모델 생성시 <strong>특성 m개 중 일부분 k개의 특성을 선택(sampling)한다</strong> </p></li><li><p>k개에서 최적의(information gain이 가장 높은) 특성을 찾아내어 분할함. k개는 일반적으로 $log_2 m$ 를 사용.</p></li><li><p>$\sqrt{m}$을 k로 활용할 수도 있다.</p></li><li><p>k가 작아질 수록 각 트리들이 모두 다르게 구성되어 예측력이 향상.</p></li><li><p>k가 너무 작아지면 가중치가 적은 feature가 상위노드에 들어가 불순도가 높아진다.</p></li><li><p>k가 너무 커지면 각 트리간 상관이 높아짐(트리들이 비슷해짐).예측력이 하락한다 </p></li><li><p>서로 상관이 높은 feature가 많은 경우 k를 적게 하는 것이 유리하다.**</p></li><li><p>트리의 수가 증가해도 과적합되지 않는다. 일정 수준이상으로 많아지면 error rate는 안정되는 경향을 보인다.<br><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/caLvgA/btraSXTXHT3/T0aBmdkrhHd3FCKGsSWN9k/img.png"></p></li></ul><p><strong>배깅과 Random subspave method의 비교</strong></p><ul><li>bagging: it is better when the training samples are sparse(결측값이 많은 경우)</li><li>Random subspace method: it is better when the classes are compact and the boundaries are smooth.</li></ul><h3 id="Random-Forest-알고리즘"><a href="#Random-Forest-알고리즘" class="headerlink" title="Random Forest 알고리즘"></a>Random Forest 알고리즘</h3><ul><li>m개의 feature와 n개의 데이터포인트가 있는 학습데이터에서 부트스트래핑을 통해 서브셋을 추출한다.</li><li>m개의 feature에서 각각 k개의 feature를 추출한 서브셋을 가지고 학습해 약한 분류기를 여러개 만든다. </li><li>각각의 약한 분류기로 결과를 예측한다.</li><li>각 분류기의 예측결과를 모아 최종결과를 도출한다.<ul><li>분류 문제일 경우 다수결을 통해 최종 결과를 도출한다</li><li>회귀 문제일 경우 평균을 통해 최종결과를 도출한다.</li></ul></li></ul><h3 id="Random-Forest-주요-hyperparameter"><a href="#Random-Forest-주요-hyperparameter" class="headerlink" title="Random Forest 주요 hyperparameter"></a>Random Forest 주요 hyperparameter</h3><p><a href="https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/">Randomforest Hyperparameter</a><br>sklearn에서 제공하는 하이퍼파라미터 기준으로 정리</p><ul><li>max_featuers : 기본트리에 사용되는 feature의 수. default는 전부 사요하는 것.</li><li>n_estimators : 기본트리 수. 커질수록 퍼포먼스가 좋아지지만 학습시간이 오래걸린다.</li><li>min_sample_leaf : 리프노드 샘플의 최소값. 작을 수록 학습데이터의 이상치를 잡기 어려워진다. 보통 50이상으로 놓는다.</li><li>oob_score : boolen 값. cross validation이랑 비슷. oob sample을 바탕으로 평가를 수행하는 것.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 보통 고려하는 것들</span></span><br><span class="line">&#123;<span class="string">&#x27;bootstrap&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line"> <span class="string">&#x27;criterion&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">3</span>, <span class="comment"># depth가 3일때까지만 split</span></span><br><span class="line"> <span class="string">&#x27;max_features&#x27;</span>: <span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;max_leaf_nodes&#x27;</span>: <span class="number">4</span>, <span class="comment"># leaf node가 4개일때까지만 split</span></span><br><span class="line"> <span class="string">&#x27;min_impurity_decrease&#x27;</span>: <span class="number">0.0</span>,</span><br><span class="line"> <span class="string">&#x27;min_impurity_split&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;min_samples_leaf&#x27;</span>: <span class="number">3</span>, <span class="comment"># 생성될 노드들의 샘플 수가 3개 이상이여만 split </span></span><br><span class="line"> <span class="string">&#x27;min_samples_split&#x27;</span>: <span class="number">5</span>, <span class="comment"># 5개 이상의 샘플만 split</span></span><br><span class="line"> <span class="string">&#x27;min_weight_fraction_leaf&#x27;</span>: <span class="number">0.0</span>,</span><br><span class="line"> <span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">&#x27;n_jobs&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">&#x27;oob_score&#x27;</span>: <span class="literal">False</span>,</span><br><span class="line"> <span class="string">&#x27;random_state&#x27;</span>: <span class="number">42</span>,</span><br><span class="line"> <span class="string">&#x27;verbose&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">&#x27;warm_start&#x27;</span>: <span class="literal">False</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="Random-Forest-장단점"><a href="#Random-Forest-장단점" class="headerlink" title="Random Forest 장단점"></a>Random Forest 장단점</h3><p><strong>장점</strong></p><ul><li>과적합에 강하다.</li><li>이상치에 크게 영향받지 않는다.</li><li>Scaling이 필요가 없다.</li><li>결측값에 크게 영향받지 않는다.</li></ul><p><strong>단점</strong></p><ul><li>고차원의 희소한 데이터에 대해 성능이 저하된다.</li><li>training 속도 느림(메모리 소모)</li><li>개별 트리 분석이 어럽다.</li></ul><h3 id="Random-Forest-구현"><a href="#Random-Forest-구현" class="headerlink" title="Random Forest 구현"></a>Random Forest 구현</h3><ul><li>sklearn을 활용한 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_features=<span class="number">4</span>,</span><br><span class="line">                            n_informative=<span class="number">2</span>, n_redundant=<span class="number">0</span>,</span><br><span class="line">                            random_state=<span class="number">0</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">clf = RandomForestClassifier(max_depth=<span class="number">2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line">RandomForestClassifier(...)</span><br><span class="line"><span class="built_in">print</span>(clf.predict([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>numpy를 활용한 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .decision_tree <span class="keyword">import</span> DecisionTree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bootstrap_sample</span>(<span class="params">X, y</span>):</span><br><span class="line">    n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line">    idxs = np.random.choice(n_samples, n_samples, replace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X[idxs], y[idxs]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">most_common_label</span>(<span class="params">y</span>):</span><br><span class="line">    counter = Counter(y)</span><br><span class="line">    most_common = counter.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> most_common</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomForest</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_trees=<span class="number">10</span>, min_samples_split=<span class="number">2</span>, max_depth=<span class="number">100</span>, n_feats=<span class="literal">None</span></span>):</span><br><span class="line">        self.n_trees = n_trees</span><br><span class="line">        self.min_samples_split = min_samples_split</span><br><span class="line">        self.max_depth = max_depth</span><br><span class="line">        self.n_feats = n_feats</span><br><span class="line">        self.trees = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        self.trees = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_trees):</span><br><span class="line">            tree = DecisionTree(</span><br><span class="line">                min_samples_split=self.min_samples_split,</span><br><span class="line">                max_depth=self.max_depth,</span><br><span class="line">                n_feats=self.n_feats,</span><br><span class="line">            )</span><br><span class="line">            X_samp, y_samp = bootstrap_sample(X, y)</span><br><span class="line">            tree.fit(X_samp, y_samp)</span><br><span class="line">            self.trees.append(tree)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        tree_preds = np.array([tree.predict(X) <span class="keyword">for</span> tree <span class="keyword">in</span> self.trees])</span><br><span class="line">        tree_preds = np.swapaxes(tree_preds, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        y_pred = [most_common_label(tree_pred) <span class="keyword">for</span> tree_pred <span class="keyword">in</span> tree_preds]</span><br><span class="line">        <span class="keyword">return</span> np.array(y_pred)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2">https://towardsdatascience.com/understanding-random-forest-58381e0602d2</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Supervised Learning </tag>
            
            <tag> Random Forest </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Regression]머신러닝 관정에서의 회귀</title>
      <link href="/2023/10/28/machine-learning/ML-SP-optimization/"/>
      <url>/2023/10/28/machine-learning/ML-SP-optimization/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h3 id="머신러닝-관점에서의-회귀"><a href="#머신러닝-관점에서의-회귀" class="headerlink" title="머신러닝 관점에서의 회귀"></a>머신러닝 관점에서의 회귀</h3><p>회귀분석에서 MSE은 비용함수이다.<br>비용함수를 최소화 하는 최적화 관점에서 머신러닝을 볼 수 있다.<br>기울기 업데이트를 통해 비용함수(MSE)의 최소값을 찾는다.</p><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>Gradient Descent</strong> : 함수의 기울기(즉, gradient)를 이용해 x의 값을 어디로 옮겼을 때 함수가 최소값을 찾는지 알아보는 방법. 함수값을 최소화 하는 독립변수를 찾는 방법</li><li><strong>learning rate</strong> : 학습을 한 내용을 다음 학습에 얼마나 반영할지의 문제. 정확히는 Loss 값을 각각의 가중치로 편미분하여 얻어낸 값에 얼마나 수정을 해야 할 지를 결정하는 하이퍼파라미터.<ul><li>learning rate가 너무 크다면 최적점에 도달하지 못하고 모델이 발산할 수 있다.</li><li>learning rate가 너무 작다면 최적점에 도달하지 못하고 학습이 끝날 수 있다.</li></ul></li><li><strong>iteration</strong> : 학습(가중치 업데이트)의 반복 횟수</li><li><strong>weight</strong> : 경사하강법을 통해 업데이트 되는 feature의 가중치</li><li><strong>bias</strong> : 활성함수에서 활성화가 잘 될지 안될지를 조절하는 hypterparameter의 일종.기본적으로 function curve 자체를 조정한다.(선형 비선형 상관없이)</li></ul><hr><h4 id="Cost-function-of-Linear-Regression"><a href="#Cost-function-of-Linear-Regression" class="headerlink" title="Cost function of Linear Regression"></a>Cost function of Linear Regression</h4><ul><li>이는 가설함수-실제 target 인 오차 제곱합에 대해 평균을 취한 것이다.</li><li>비용을 최소화 하는 w와 b를 찾는 것이 머신러닝에서의 학습의 목적이 된다.</li><li>이를 아래와 같이 일반화 할 수 있다.</li></ul><p>$$<br>cost(w, b) &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} \left[y^{(i)} - H(x^{(i)})\right]^2<br>$$</p><ul><li>단순선형회귀의 경우 아래와 같다</li></ul><p>$$<br>f(m,b) &#x3D;  \frac{1}{N} \sum_{i&#x3D;1}^{n} (y_i - (mx_i + b))^2<br>$$</p><h4 id="Gradiant-Descent"><a href="#Gradiant-Descent" class="headerlink" title="Gradiant Descent"></a>Gradiant Descent</h4><ul><li>경사하강법은 비용함수를 최소화하는 최적화 알고리즘의 일종이다.</li><li>오차가 낮아지는 방향으로 이동할 목적으로 현재 위치를 미분한다.</li><li><strong>경사하강법의 원리는 반복적인 미분을 통한 w값의 업데이트를 통해 w, cost 지점의 경사(기울기)가 0이 되도록 만드는 것이다.</strong></li></ul><p><strong>경사하강법의 원리</strong><br><img src="https://i.ytimg.com/vi/b4Vyma9wPHo/maxresdefault.jpg"></p><p>일단 비용함수인 MSE부터 시작한다.</p><p>$$<br>f(m,b) &#x3D;  \frac{1}{N} \sum_{i&#x3D;1}^{n} (y_i - (mx_i + b))^2<br>$$</p><p>미분할 경우 아래와 같이 변하며</p><p>$$<br>(y_i - (mx_i + b))^2 &#x3D; A(B(m,b))<br>$$</p><p>$$<br>A(x) &#x3D; x^2<br>$$</p><p>$$<br>\frac{df}{dx} &#x3D; A’(x) &#x3D; 2x<br>$$</p><p>따라서 다음와 같이 미분할 수 있다.</p><p>$$<br>B(m,b) &#x3D; y_i - (mx_i + b) &#x3D; y_i - mx_i - b \~\<br>$$</p><p>$$<br>\frac{dx}{dm} &#x3D; B’(m) &#x3D; 0 - x_i - 0 &#x3D; -x_i \~\<br>$$</p><p>$$<br>\frac{dx}{db} &#x3D; B’(b) &#x3D; 0 - 0 - 1 &#x3D; -1<br>$$</p><p>미분의 <code>Chain Rule</code> 을 활용하여 가중치와 편향의 미분값을 구할 수 있다.</p><p>$$<br>\frac{df}{dm} &#x3D; \frac{df}{dx} \frac{dx}{dm} \~\<br>$$</p><p>$$<br>\frac{df}{db} &#x3D; \frac{df}{dx} \frac{dx}{db}<br>$$</p><p>가중치와 절편에 Chain Rule을 적용해 미분을 하면 다음과 같다.</p><p>$$<br>\frac{df}{dm} &#x3D; A’(B(m,f)) B’(m) &#x3D; 2(y_i - (mx_i + b)) \cdot -x_i \~\<br>$$</p><p>$$<br>\frac{df}{db} &#x3D; A’(B(m,f)) B’(b) &#x3D; 2(y_i - (mx_i + b)) \cdot -1<br>$$</p><p>따라서 비용함수(MSE)의 Gradiant를 아래과 같이 유도할 수 있다.</p><p>$$<br>  \begin{align}<br>  f’(m,b) &#x3D;<br>    \begin{bmatrix}<br>      \frac{df}{dm}\<br>      \frac{df}{db}\<br>    \end{bmatrix}<br>  &amp;&#x3D;<br>    \begin{bmatrix}<br>      \frac{1}{N} \sum -x_i \cdot 2(y_i - (mx_i + b)) \<br>      \frac{1}{N} \sum -1 \cdot 2(y_i - (mx_i + b)) \<br>    \end{bmatrix}\<br>  &amp;&#x3D;<br>    \begin{bmatrix}<br>       \frac{1}{N} \sum -2x_i(y_i - (mx_i + b)) \<br>       \frac{1}{N} \sum -2(y_i - (mx_i + b)) \<br>    \end{bmatrix}<br>  \end{align}<br>$$</p><p><strong>최적의 비용함수는 Learning Rate(학습률)와 기울기(Gradient)를 곱한 값을 기존 가중치에서 빼서 새로운 가중치로 설정하는 것을 반복하는 방식으로 구한다.</strong></p><p><strong>따라서 최적화하고자 하는 함수 f(x)에 대해 아래와 같이 정리할 수 있다.</strong></p><p>$$<br>x_{i+1} &#x3D; x_i - \alpha \frac{df}{dx}(x_i)<br>$$</p><p><strong>기본적으로 반복횟수가 많아질수록 오차가 줄어들어야 한다.</strong></p><p><img src="https://ml-cheatsheet.readthedocs.io/en/latest/_images/linear_regression_training_cost.png"></p><h4 id="Gradiant-Descent를-활용한-선형회귀-구현"><a href="#Gradiant-Descent를-활용한-선형회귀-구현" class="headerlink" title="Gradiant Descent를 활용한 선형회귀 구현"></a>Gradiant Descent를 활용한 선형회귀 구현</h4><ul><li>dw는 비용함수인 MSE를 가중치 W에 대하여 편미분한 것이다.</li><li>db는 비용함수인 MSE를 편향 b에 대하여 편미분한 것이다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">r2_score</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    corr_matrix = np.corrcoef(y_true, y_pred)</span><br><span class="line">    corr = corr_matrix[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> corr ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, lr = <span class="number">0.001</span>, n_iters = <span class="number">1000</span></span>):</span><br><span class="line">    self.lr = lr</span><br><span class="line">    self.n_iters = n_iters</span><br><span class="line">    self.weigts = <span class="literal">None</span></span><br><span class="line">    self.bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># init paremeters : 시작지점을 초기화 한다.</span></span><br><span class="line">    n_samples , n_features = X.shape</span><br><span class="line">    self.weigts = np.zeros(n_features)</span><br><span class="line">    self.bias = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iters):</span><br><span class="line">      y_pred = np.dot(X,self.weigts) + self.bias</span><br><span class="line"></span><br><span class="line">      dw = (<span class="number">1</span>/n_samples) * np.dot(X.T,(y_pred - y)) <span class="comment"># 가중치의 기울기(Gradiant)(미분값)</span></span><br><span class="line">      db = (<span class="number">1</span>/n_samples) * np.<span class="built_in">sum</span>(y_pred - y) <span class="comment"># 편향의 기울기</span></span><br><span class="line"></span><br><span class="line">      self.weigts -= self.lr * dw <span class="comment"># 기울기 업데이트</span></span><br><span class="line">      self.bias -= self.lr * db <span class="comment"># 편향 업데이트</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">    y_pred = np.dot(X,self.weigts) + self.bias</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://angeloyeo.github.io/2020/08/24/linear_regression.html">경사하강법과 회귀</a></li><li><a href="https://youtu.be/4swNt7PiamQ?list=PLqnslRFeH2Upcrywf-u2etjdxxkL8nl7E">ML from scratch</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Supervised Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[XAI]Shap을 활용한 모델해석</title>
      <link href="/2023/10/28/machine-learning/ML-XAI-shap/"/>
      <url>/2023/10/28/machine-learning/ML-XAI-shap/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>굵은 글씨로 뭔가 쓴다.</strong></p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XAI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[NLP]NLU &amp; QA task</title>
      <link href="/2023/10/28/machine-learning/NLP-NLU/"/>
      <url>/2023/10/28/machine-learning/NLP-NLU/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h1 id="NLU"><a href="#NLU" class="headerlink" title="NLU"></a>NLU</h1><blockquote><p>NLP의 하위 분야인 NLU를 소개하고 NLU 의 subtask 중 하나인 QA(Question Answering) 에 대해 정리</p></blockquote><p>: Natural Language Understanding<br>기계가 자연어에 대한 Synthetic과 Semantic Understanding을 보인다면 그 기계는 NLU를 수행하고 있다고 볼 수 있다.</p><h2 id="Question-Answering-task"><a href="#Question-Answering-task" class="headerlink" title="Question Answering(task)"></a>Question Answering(task)</h2><p>특정 자연어 텍스트를 기계가 올바르게 이해하고 답변하는지 평가하는 Reading Comprehension의 일종이다.</p><p>질문에 대해 기계가 답변하는 QA의 형태를 가지고 있다는 점에서 NLU task라고 볼 수 있다.</p><p>QA task의 경우 질문에 대한 답이 Input인 지문안에 분명히 존재하기 때문에 평가지표로 Accuracy와 F1 Score를 사용할 수 있다.</p><h4 id="대표적인-데이터셋"><a href="#대표적인-데이터셋" class="headerlink" title="대표적인 데이터셋"></a>대표적인 데이터셋</h4><h4 id="SQuAD"><a href="#SQuAD" class="headerlink" title="SQuAD"></a>SQuAD</h4><p>: Stanford Question Answering Dataset</p><p>QA와 같은 Reading Comprehension 문제의 해결을 위해 스탠포스에서 개발한 대표 Benchmark.</p><p>Input은 지문인 Context와 지문 내에서 답을 찾을 수 있는 Question으로 구성된다.</p><p>SQuAD 데이터 셋을 통해 QA task를 수행할 경우 기계는 출력값으로 지문(Context) 내에 포함된 질문의 답의 시작과 끝의 인덱스를 반환해야 한다,</p><ul><li>ex) SQuAD의 예시</li></ul><p><img src="https://www.researchgate.net/publication/326569892/figure/fig1/AS:651759777234944@1532403048781/An-example-from-SQuAD-dataset.png"></p><h3 id="SOTA-models-for-QA-task"><a href="#SOTA-models-for-QA-task" class="headerlink" title="SOTA models for QA task"></a>SOTA models for QA task</h3><h4 id="T5-Text-to-Text-Transfer"><a href="#T5-Text-to-Text-Transfer" class="headerlink" title="T5 (Text to Text Transfer)"></a>T5 (Text to Text Transfer)</h4><p>T5는 전이학습을 기반으로한 구글에서 개발한 Transformer 기반 Language Model이다.</p><p>현 시점에서 QA task에서 가장 높은 성능을 보이는 SOTA 모델의 하나이다.</p><p><img src="https://media.vlpt.us/images/yjinheon/post/2b661472-0508-4446-b808-95b7d2a5b4d2/Velog_1_12.png"></p><h4 id="전이학습-Transfer-Learning"><a href="#전이학습-Transfer-Learning" class="headerlink" title="전이학습(Transfer Learning)"></a>전이학습(Transfer Learning)</h4><ul><li>전이학습은 이미 학습된 큰 데이터셋의 가중치를 가지고 와서 해결하고자 하는 다른 과제에 맞게 튜닝해서 사용하는 방법론이다.</li><li>T5 paper에서는 하나의 언어모델을 비지도로 pre-train한 뒤 세부 task에 따라 지도학습으로 fine tuning하는 방식을 사용하였다.</li></ul><h4 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet: Generalized Autoregressive Pretraining for Language Understanding</h4><p>BERT의 Autoencoding method에 Autoregressive기법을 더해 성능을 개선시킨 언어모델.</p><h4 id="Autoregressive-Pretrained-method"><a href="#Autoregressive-Pretrained-method" class="headerlink" title="Autoregressive Pretrained method"></a>Autoregressive Pretrained method</h4><ul><li>AR(자기회귀) 방법론은 기존 BERT가 가지고 있는 masking을 보완하기 위해 사용되었다.</li><li>AR은 BERT가 가지고 있는 문제점을 보완할 수 있지만 알고리즘 특성상 단방향 만을 고려한다는 문제점이 있다.</li><li>BERT의 경우 AutoEncoding 과정에서 토큰이 독립적으로 예측되기 때문에 토큰 간 Dependency가 학습이 안되는 문제점이 있었다.</li><li>XLNet에서는 permutation을 이용해 모든 가능한 sequence를 고려해서 (Factorization Order) AR 방법론을 적용하여 AR과 AutoEncoding 방법론을 모두 보완해 성능을 개선시켰다.</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://rajpurkar.github.io/SQuAD-explorer/">https://rajpurkar.github.io/SQuAD-explorer/</a></li><li><a href="https://arxiv.org/pdf/1910.10683v3.pdf">Text to Text Transfer</a></li><li><a href="https://arxiv.org/pdf/1906.08237v2.pdf">XLNet: Generalized Autoregressive Pretraining<br>for Language Understanding</a></li><li><a href="https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#Metrics-for-QA">QA task의 평가지표</a></li><li><a href="https://yhdosu.github.io/2019/11/12/T5.html">T5 paper설명</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> NLU </tag>
            
            <tag> QA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[SQL]Postgresql 자주 사용하는 명령어</title>
      <link href="/2023/10/28/data-engineering/DE-SQL-psql-commands/"/>
      <url>/2023/10/28/data-engineering/DE-SQL-psql-commands/</url>
      
        <content type="html"><![CDATA[<!--<center>중앙정렬 예제</center>--><h2 id="터미널-접속"><a href="#터미널-접속" class="headerlink" title="터미널 접속"></a>터미널 접속</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pqsl -u </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="터미널-접속-후-사용"><a href="#터미널-접속-후-사용" class="headerlink" title="터미널 접속 후 사용"></a>터미널 접속 후 사용</h2><ul><li><p>\l  :   데이터베이스 리스트 조회</p></li><li><p>\c - 데이터베이스 연결 ex) \c mydb</p></li><li><p>\dn :  스키마 조회</p></li><li><p>\dt - public 스키마의 테이블 조회</p></li><li><p>\dt schema1.*  :  특정 스카마의 테이블 조회.</p></li><li><p>dt 명령어에서 스키마 검색 범위 확장하기</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET search_path TO my_schema, public;</span><br><span class="line">\d</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
            <tag> Postgresql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[R]make: gfortran: No such file or directory 해결하기</title>
      <link href="/2023/10/28/troubleshooting/TS-R-lib-1/"/>
      <url>/2023/10/28/troubleshooting/TS-R-lib-1/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p>시계열 분석을 할 일이 있어서 Rstudio server에다가 <code>forecast</code> package를 설치하려 하는데 dependancy package를 설치하는 도중</p><p>아래와 같은 오류가 떴다.</p><p><code>make: gfortran: No such file or directory</code></p><p>그리고 라이브러리 설치가 안된다..</p><p>찾아보니까 package가 소스 형태라 컴파일러가 필요한데 그 중 포트란 컴파일러가 서버에 설치되지 않아서 생긴 문제였다.</p><p>터미널에다 아래 명령어를 쳐서 해결하였다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S gcc-fortran</span><br></pre></td></tr></table></figure><p>우분투 사용자의 경우 아래와 같이 컴파일러를 설치해주면 된다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install gfortran</span><br></pre></td></tr></table></figure><p>윈도우 사용자의 경우 <a href="https://fortran-lang.org/learn/os_setup/install_gfortran">링크</a> 에서 설치법을 확인할 수 있다.</p><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://www.r-bloggers.com/2021/03/gfortran-support-for-r-on-macos-2/">https://www.r-bloggers.com/2021/03/gfortran-support-for-r-on-macos-2/</a></li><li><a href="https://fortran-lang.org/learn/os_setup/install_gfortran">https://fortran-lang.org/learn/os_setup/install_gfortran</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Troubleshooting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux]zsh: corrupt history file 해결</title>
      <link href="/2023/10/28/troubleshooting/TS-linux-ts-1/"/>
      <url>/2023/10/28/troubleshooting/TS-linux-ts-1/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><hr><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~                          </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">mv</span> .zsh_history .zsh_history.1217</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ strings .zsh_history.1217 .zsh_history</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">fc</span> -R .zsh_history</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.whatwant.com/entry/zsh-corrupt-history-file">https://www.whatwant.com/entry/zsh-corrupt-history-file</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Troubleshooting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>프론트엔드 기본개념들</title>
      <link href="/2023/10/28/frond-end/fe-concepts/"/>
      <url>/2023/10/28/frond-end/fe-concepts/</url>
      
        <content type="html"><![CDATA[<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><ul><li>리액트 관련 개념</li><li>프론트엔드 개념</li></ul><h2 id="개념"><a href="#개념" class="headerlink" title="개념"></a>개념</h2><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><blockquote><p>Runtime은 기본적으로 프로그램이 자원(램, 변수 등) 을 할당받고 특정한 처리를 하고있는 상태를 의미한다.</p></blockquote><ul><li>실행시간 : 런타임은 일반적으로 어플리케이션 실행시간(execution time)과 동일한 의미를 가진다. </li><li>어플리케이션 성능평가 : 런타임은 어플리케이션 성능평가를 위한 주요 지표이다. 런타임(실행시간)이 적을 수록 해당 어플리케이션이 보다 효율적이라 볼 수 있다.</li><li>런타임 최적화 : 메모리 사용을 늘리거나 보다 효율적인 알고리즘을 통해 런타임을 최적화(실행시간 줄임) 할 수 있다.</li><li>동시성과 병렬성 문제 : 실행할 작업을 여러 쓰레드나 프로세스로 나눠서 할당해 런타임을  최적화 할 수 있다.</li><li>트레이드 오프 : 런타임 최적화는 보통 더 많은 자원의 소모, 더 복잡한 코드의 작성을 수반하기 때문에 이에 따른 영향을 고려하면서 작업해야 한다.</li><li>Runtime Error : 실행 중인 프로그램에서 발생할 수 있는 에러를 Runtime Error라고 한다.<ul><li>Runtime Error의 종류<ul><li>Null 참조</li><li>메모리 부족</li><li>zero division</li></ul></li></ul></li></ul><h3 id="Runtime-Environment-RTE"><a href="#Runtime-Environment-RTE" class="headerlink" title="Runtime Environment (RTE)"></a>Runtime Environment (RTE)</h3><blockquote><p>컴파일한 코드를 실행하기 위한 자원(메모리, 프로세서) 을 제공하는 일종의 실행환경.</p></blockquote><p>기본적으로 Runtime이 일어나기 위해 어플리케이션이 OS의 시스템 자원에 접근할 수있도록 해주는 실행환경이다.</p><h3 id="Node-Js"><a href="#Node-Js" class="headerlink" title="Node Js"></a>Node Js</h3><blockquote><p>웹브라우저가 아닌 서버에서 자바스크립트를 실행할 수 있게끔 해주는 런타입 환경</p></blockquote><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Hello World&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="NPM-Node-Package-Manager"><a href="#NPM-Node-Package-Manager" class="headerlink" title="NPM(Node Package Manager)"></a>NPM(Node Package Manager)</h3><blockquote><p>자바스크립트 라이브러리를 설치하고 버전관리를 위한 프로그램</p></blockquote><h3 id="WebPack"><a href="#WebPack" class="headerlink" title="WebPack"></a>WebPack</h3><blockquote><p>프로젝트에 사용된 파일을 분석하여 브라우저에 호환되는 파일(js,css) 등으로 변환해주는 프로그램</p></blockquote><h3 id="NVM-Node-Version-Manager"><a href="#NVM-Node-Version-Manager" class="headerlink" title="NVM(Node Version Manager)"></a>NVM(Node Version Manager)</h3><blockquote><p>노드 버전관리를 위한 프로그램</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvm -v</span><br></pre></td></tr></table></figure><h3 id="Eventloop"><a href="#Eventloop" class="headerlink" title="Eventloop"></a>Eventloop</h3><h3 id="DOM"><a href="#DOM" class="headerlink" title="DOM"></a>DOM</h3><h3 id="Virtual-Dom"><a href="#Virtual-Dom" class="headerlink" title="Virtual Dom"></a>Virtual Dom</h3><h3 id="props"><a href="#props" class="headerlink" title="props"></a>props</h3><h3 id="component"><a href="#component" class="headerlink" title="component"></a>component</h3><h3 id="state"><a href="#state" class="headerlink" title="state"></a>state</h3><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><!--- https://joontae-kim.github.io/2020/10/26/interview-question-fe/--><ul><li><a href="https://joshua1988.github.io/web-development/interview/frontend-questions/">https://joshua1988.github.io/web-development/interview/frontend-questions/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> React,Concept </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>자바스크립트 코드스니펫</title>
      <link href="/2023/10/28/frond-end/fe-javascript-index/"/>
      <url>/2023/10/28/frond-end/fe-javascript-index/</url>
      
        <content type="html"><![CDATA[<h3 id="spread-operator-배열"><a href="#spread-operator-배열" class="headerlink" title="spread operator - 배열"></a>spread operator - 배열</h3><p><code>...</code> 을 사용하여 배열을 복사하거나 합칠 수 있다.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">let</span> arr1 =[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;two&#x27;</span>,<span class="string">&#x27;three&#x27;</span>];</span><br><span class="line"><span class="keyword">let</span> arr2 =[<span class="string">&#x27;four&#x27;</span>,<span class="string">&#x27;five&#x27;</span>,<span class="string">&#x27;six&#x27;</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> arr3 = [...arr1, ...arr2];</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(arr3); <span class="comment">// [&quot;one&quot;, &quot;twi&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;, &quot;six&quot;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> [a,b,c,...rest] = arr1;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// one</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// two</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(c); <span class="comment">// three</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(rest); <span class="comment">// 배열의 나머지 값이 없으면 빈 배열이 출력</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="spread-operator-객체"><a href="#spread-operator-객체" class="headerlink" title="spread operator - 객체"></a>spread operator - 객체</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">let</span> obj1 = &#123;<span class="attr">one</span>:<span class="number">1</span>, <span class="attr">two</span>:<span class="number">2</span>, <span class="attr">other</span>:<span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">let</span> obj2 = &#123;<span class="attr">four</span>:<span class="number">4</span>, <span class="attr">five</span>:<span class="number">5</span>, <span class="attr">other</span>:<span class="number">6</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> combined = &#123;</span><br><span class="line">  ...obj1,</span><br><span class="line">  ...obj2,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(combined); <span class="comment">// &#123;one: 1, two: 2, other: 6, four: 4, five: 5&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> &#123;other ...rest&#125; = combined;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(rest); <span class="comment">// &#123;one: 1, two: 2, four: 4, five: 5&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="destructuring"><a href="#destructuring" class="headerlink" title="destructuring"></a>destructuring</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 핵심은 배열을 나누는 것</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> userNameData = [<span class="string">&#x27;John&#x27;</span>, <span class="string">&#x27;Doe&#x27;</span>]</span><br><span class="line"><span class="keyword">const</span> [firstName, lastName] = userNameData; <span class="comment">// destructuring array</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(firstName)</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(lastName)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> string = <span class="string">&#x27;Hello&#x27;</span>;</span><br><span class="line"><span class="keyword">let</span> string2 = <span class="string">&#x27;Jinheon&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> greetings = <span class="string">`<span class="subst">$&#123;string&#125;</span> <span class="subst">$&#123;string2&#125;</span>`</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(greetings);</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> product = &#123;</span><br><span class="line">    name : <span class="string">&#x27;Milk&#x27;</span>,</span><br><span class="line">    price : <span class="number">1.99</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// templete string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> message = <span class="string">`The price of <span class="subst">$&#123;product.name&#125;</span> is <span class="subst">$&#123;product.price&#125;</span>`</span>;</span><br><span class="line"><span class="keyword">let</span> multiline = <span class="string">`This is</span></span><br><span class="line"><span class="string">a multiline</span></span><br><span class="line"><span class="string">string`</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(message);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(multiline);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Link,javascript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Probability]Python을 활용한 카이스퀘어 검정 구현</title>
      <link href="/2023/10/28/statistics/Statistics-Prob-chi-square-dist/"/>
      <url>/2023/10/28/statistics/Statistics-Prob-chi-square-dist/</url>
      
        <content type="html"><![CDATA[<h3 id="카이스퀘어-분포"><a href="#카이스퀘어-분포" class="headerlink" title="카이스퀘어 분포"></a>카이스퀘어 분포</h3><h4 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h4><ul><li>감마분포의 특수한 형태이다.</li><li>표준정규분포로부터 얻은 랜덤 변수들을 제곱해서 더한 것이다.</li><li>자유도 수 만큼 표준정규분포에서 변수를 뽑고 그 값들을 제곱해서 더한다.</li><li><strong>데이터의 분산이 퍼저있는 정도를 분포로 보여준다는 것이 핵심이다.</strong><ul><li>모분산을 추정할 수 있다 -&gt; goodness of fit</li><li>두 분포의 차이를 확인할 수 있다 -&gt; Chi-square test of independence</li></ul></li></ul><h4 id="공식"><a href="#공식" class="headerlink" title="공식"></a>공식</h4><ul><li>k개의 정규분포를 따르는 확률변수 X_1 ,…, X_k를 정의하면 아래와 같이 자유도 k의 카이스퀘어 분포를 나타낼 수 있다.</li></ul><p>$$Q &#x3D; \sum_{i&#x3D;1}^{k} X_i^2$$</p><ul><li>독립성 검정(independence test)과 적합성 검정(goodness of fit)을 위하 사용하는 피어슨 카이스퀘어 통계량<ul><li>$\frac{(O_i - E_i)^2}{E_i}$는 정규분포를 따르고 데이터가 충분히 많다면 이를 합한 피어슨 카이스퀘어 통계량은 카이스퀘어 분포를 따른다.</li></ul></li></ul><p>$$\sum_i \frac{(O_i - E_i)^2}{E_i}$$</p><h4 id="적합성-검정-goodness-of-fit-구현"><a href="#적합성-검정-goodness-of-fit-구현" class="headerlink" title="적합성 검정(goodness of fit) 구현"></a>적합성 검정(goodness of fit) 구현</h4><p>적합성 검정은 기본적으로 샘플 데이터가 특정 분포를 따르는지(정규분포) 확인할 때 사용한다.<br>이 검정이 중요한 이유는 회귀분석 모델링에서 요구하는 오차의 정규성 가정을 확인하는데 쓸 수 있기 때문이다.</p><p><strong>관측한 데이터(샘플)의 분포가 기대되는 어떤 분포(보통 정규분포)를 따르는지 확인한다는 것이 핵심이고 로직 자체는 아래의 독립성 검정과 유사하다.</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"></span><br><span class="line">obs = [<span class="number">20</span>, <span class="number">40</span>, <span class="number">30</span>, <span class="number">10</span>, <span class="number">50</span>]</span><br><span class="line">exp = [<span class="number">20</span>, <span class="number">20</span>, <span class="number">20</span>, <span class="number">20</span>, <span class="number">20</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Goodness of Fit Test</span></span><br><span class="line"><span class="comment"># f_exp 인자로 로 기대되는 데이터 value를 넣을 수 있다. </span></span><br><span class="line">stats.chisquare(f_obs=obs,f_exp=exp)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;Power_divergenceResult(statistic=<span class="number">33.333333333333336</span>, pvalue=<span class="number">1.020735571764047e-06</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="독립성-검정-Chi-square-test-of-independence"><a href="#독립성-검정-Chi-square-test-of-independence" class="headerlink" title="독립성 검정(Chi-square test of independence)"></a>독립성 검정(Chi-square test of independence)</h4><ul><li><strong>두 범주형 변수 사이의 관계를 파악한다.</strong></li><li>독립성 검정을 시행하려면 교차표의 각 셀의 기대빈도가 5 이상이여 한다는 조건이 붙는다.</li><li>각 셀의 기대빈도가 5 이상일 경우 $\chi^2$ 는 근사적으로 기대빈도가 n-1인 카이스퀘어 분포를 따른다.</li><li>보통 범주형 독립변수와 범주형 종속변수의 관계가 있는지 확인할 때 사용한다.</li></ul><p>귀무가설은 두 범주형 변수가 독립적이라는 것이다.<br>귀무가설이 성립하려면 교차표의 각 셀의 관측빈도와 기대빈도의 차이는 0에 가까워야 한다.<br>두 범주형 변수의 빈도의 범주간 차이가 기댓값에서 유의미하게 벗어나는지 검정한다.</p><p>카이스퀘어 통계량이 유의수준을 넘어서면 귀무가설을 기각한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> chi2_contingency</span><br><span class="line"></span><br><span class="line"><span class="comment"># 교차표 자체는 pandas에서 제공하는 crostab함수를 통해 df로 만들 수도 있다.</span></span><br><span class="line">table = [[<span class="number">20</span>, <span class="number">40</span>, <span class="number">30</span>, <span class="number">10</span>], [<span class="number">20</span>, <span class="number">42</span> ,<span class="number">15</span>,  <span class="number">30</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 카이 , p-value, 자유도, 기대빈도</span></span><br><span class="line">stat, p, dof, expected = chi2_contingency(table)</span><br><span class="line"><span class="comment"># 유의수준 설정</span></span><br><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="comment"># 가설수용/기각</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;significance=%.3f, p=%.3f&#x27;</span> % (alpha, p))</span><br><span class="line"><span class="keyword">if</span> p &lt;= alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Variables are associated (reject H0)&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Variables are not associated(fail to reject H0)&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://youtu.be/2QeDRsxSF9M">https://youtu.be/2QeDRsxSF9M</a></li><li><a href="https://towardsdatascience.com/chi-squared-test-for-feature-selection-with-implementation-in-python-65b4ae7696db">https://towardsdatascience.com/chi-squared-test-for-feature-selection-with-implementation-in-python-65b4ae7696db</a></li><li>기대빈도가 5미만일 경우 피셔의 적합검정을 고려한다.</li><li>제대로 쓰려면 헬퍼함수를 따로 만들긴 해야할 것 같다.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Statistics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Probability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]Closure에 대한 이해</title>
      <link href="/2023/10/28/programming/python/Python-Closure/"/>
      <url>/2023/10/28/programming/python/Python-Closure/</url>
      
        <content type="html"><![CDATA[<!--categories- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing>goal## 개요### 특정개념이란### 선행지식## 특정개념을 언제 쓰는가## 특정개념 종류(있을 경우) , 옵션들,## 이미 작성한 다른 개념과 차이점## 특정개념 선택 방법론, 할 수 잇는 것들## 구현--><p><strong>Iterator,Generator,yield에 대한 정리</strong></p><hr><h3 id="Iterator"><a href="#Iterator" class="headerlink" title="Iterator"></a>Iterator</h3><ul><li><strong>Iterators are objects that allow you to traverse through all the elements of a collection and return one element at a time.</strong></li><li>iterator는 iterable로 생성되는 값을 순서대로 꺼낼 수 있는 객체이다. </li><li>iter(collections) : returns unmodified iterator</li><li>iter(<function>, to_exclusive) : A sequence of return values until ‘to_exclusive’</li><li>next(<iter>,default) :Raises StopIteration or returns ‘default’ on end.</li><li><list> &#x3D; list(<iter>) : Return a list of iterator’s remaining elements</li></ul><p>이터레이터 구현</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Iterator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>():</span><br><span class="line">        self.</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">temp = (<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;cherry&quot;</span>)</span><br><span class="line">myit = <span class="built_in">iter</span>(temp)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">30</span>]: iv = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: io = <span class="built_in">iter</span>(iv)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ...:     <span class="keyword">try</span>:</span><br><span class="line">    ...:</span><br><span class="line">    ...:         item = <span class="built_in">next</span>(io)</span><br><span class="line">    ...:         <span class="built_in">print</span>(item)</span><br><span class="line">    ...:     <span class="keyword">except</span> StopIteration:</span><br><span class="line">    ...:         <span class="keyword">break</span></span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><h4 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> count, repeat, cycle, chain, islice</span><br></pre></td></tr></table></figure><ul><li><code>count</code> :  count(시작, [step]) 의 함수로 시작 숫자부터 step만큼(없으면 1) 씩 무한히 증가하는 generator 반환</li><li><code>islice</code> : islice(iterable객체, [시작], 정지[,step])의 함수로, iterable한 객체를 특정 범위로 슬라이싱하고 iterator로 반환.</li><li><code>chain</code> : chain(<strong>iterable</strong>)은 iterable한 객체들을 인수로 받아 하나의 iterator로 반환</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chain</span></span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> chain</span><br><span class="line">e1 = [<span class="string">&#x27;Happiness&#x27;</span>,<span class="string">&#x27;Caring&#x27;</span>,<span class="string">&#x27;Energy&#x27;</span>]</span><br><span class="line">e2 = [<span class="string">&#x27;Fear&#x27;</span>,<span class="string">&#x27;Hurt&#x27;</span>,<span class="string">&#x27;Tired&#x27;</span>]</span><br><span class="line">emotions = chain(e1, e2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Happiness&#x27;</span></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Caring&#x27;</span></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Energy&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><a href="https://www.geeksforgeeks.org/python-itertools/">itertools</a></li><li><a href="https://realpython.com/python-itertools/">https://realpython.com/python-itertools/</a></li><li><a href="https://hamait.tistory.com/803">https://hamait.tistory.com/803</a></li></ul><p><strong>itertools.product를 활용한 이중 반복문 변형</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기존 반복문</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> i_ex:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> j_ex:</span><br><span class="line">        <span class="built_in">print</span>(i,j)</span><br><span class="line"></span><br><span class="line"><span class="comment"># itertools활용</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(i_ex, j_ex):</span><br><span class="line">    <span class="built_in">print</span>(i, j)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><ul><li><p>Any function that contains a yield statement returns a generator.</p></li><li><p>Generators and iterators are interchangeable.</p></li><li><p><strong>Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly</strong></p></li><li><p>Lazy-evaluation : 값을 미리 생성하여 메모리에 저장하고 있는게 아니며, 요청이 있을 때마다  함수를 실행하고 값을 공급(yield)해 줌</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: my_gen = (x*x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="built_in">type</span>(my_gen)</span><br><span class="line">Out[<span class="number">2</span>]: generator</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> my_gen:</span><br><span class="line">   ...:     <span class="built_in">print</span>(i)</span><br><span class="line">   ...:</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>It is just the same except you used () instead of []. BUT, you cannot perform for i in generator a second time since <strong>generators can only be used once</strong>: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one</p><h4 id="yield-form"><a href="#yield-form" class="headerlink" title="yield form"></a>yield form</h4><ul><li><code>yield</code>는 <code>return</code>과 유사하지만 generator를 반환한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: <span class="keyword">def</span> <span class="title function_">gen_count</span>(<span class="params">start,step</span>):</span><br><span class="line">   ...:     <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">   ...:         <span class="keyword">yield</span> start</span><br><span class="line">   ...:         start += step</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: counter = gen_count(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">8</span>]: <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">9</span>]: <span class="number">12</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">10</span>]: <span class="number">14</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">11</span>]: <span class="number">16</span></span><br></pre></td></tr></table></figure><ul><li><code>yield from a</code>를 통해 <code>iterable</code>의 전체 요소들을 반환할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">three_generator</span>():</span><br><span class="line"><span class="meta">... </span>    a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="keyword">from</span> a</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen = three_generator()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(gen)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do">핵심 stackoverflow ref</a></li><li>Python Comprehensive Cheat Sheet</li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Closure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]Iterator,Generator,yield에 대한 정리</title>
      <link href="/2023/10/28/programming/python/Python-Generator/"/>
      <url>/2023/10/28/programming/python/Python-Generator/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>Iterator,Generator,yield에 대한 정리</strong></p><hr><h3 id="Iterator"><a href="#Iterator" class="headerlink" title="Iterator"></a>Iterator</h3><ul><li><strong>Iterators are objects that allow you to traverse through all the elements of a collection and return one element at a time.</strong></li><li>iterator는 iterable로 생성되는 값을 순서대로 꺼낼 수 있는 객체이다. </li><li>iter(collections) : returns unmodified iterator</li><li>iter(<function>, to_exclusive) : A sequence of return values until ‘to_exclusive’</li><li>next(<iter>,default) :Raises StopIteration or returns ‘default’ on end.</li><li><list> &#x3D; list(<iter>) : Return a list of iterator’s remaining elements</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">temp = (<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;cherry&quot;</span>)</span><br><span class="line">myit = <span class="built_in">iter</span>(temp)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myit))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">30</span>]: iv = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: io = <span class="built_in">iter</span>(iv)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ...:     <span class="keyword">try</span>:</span><br><span class="line">    ...:</span><br><span class="line">    ...:         item = <span class="built_in">next</span>(io)</span><br><span class="line">    ...:         <span class="built_in">print</span>(item)</span><br><span class="line">    ...:     <span class="keyword">except</span> StopIteration:</span><br><span class="line">    ...:         <span class="keyword">break</span></span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><h4 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> count, repeat, cycle, chain, islice</span><br></pre></td></tr></table></figure><ul><li><code>count</code> :  count(시작, [step]) 의 함수로 시작 숫자부터 step만큼(없으면 1) 씩 무한히 증가하는 generator 반환</li><li><code>islice</code> : islice(iterable객체, [시작], 정지[,step])의 함수로, iterable한 객체를 특정 범위로 슬라이싱하고 iterator로 반환.</li><li><code>chain</code> : chain(<strong>iterable</strong>)은 iterable한 객체들을 인수로 받아 하나의 iterator로 반환</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chain</span></span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> chain</span><br><span class="line">e1 = [<span class="string">&#x27;Happiness&#x27;</span>,<span class="string">&#x27;Caring&#x27;</span>,<span class="string">&#x27;Energy&#x27;</span>]</span><br><span class="line">e2 = [<span class="string">&#x27;Fear&#x27;</span>,<span class="string">&#x27;Hurt&#x27;</span>,<span class="string">&#x27;Tired&#x27;</span>]</span><br><span class="line">emotions = chain(e1, e2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Happiness&#x27;</span></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Caring&#x27;</span></span><br><span class="line"><span class="built_in">next</span>(emotions) &gt;&gt;&gt; <span class="string">&#x27;Energy&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><a href="https://www.geeksforgeeks.org/python-itertools/">itertools</a></li><li><a href="https://realpython.com/python-itertools/">https://realpython.com/python-itertools/</a></li><li><a href="https://hamait.tistory.com/803">https://hamait.tistory.com/803</a></li></ul><p><strong>itertools.product를 활용한 이중 반복문 변형</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기존 반복문</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> i_ex:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> j_ex:</span><br><span class="line">        <span class="built_in">print</span>(i,j)</span><br><span class="line"></span><br><span class="line"><span class="comment"># itertools활용</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(i_ex, j_ex):</span><br><span class="line">    <span class="built_in">print</span>(i, j)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><ul><li><p>Any function that contains a yield statement returns a generator.</p></li><li><p>Generators and iterators are interchangeable.</p></li><li><p><strong>Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly</strong></p></li><li><p>Lazy-evaluation : 값을 미리 생성하여 메모리에 저장하고 있는게 아니며, 요청이 있을 때마다  함수를 실행하고 값을 공급(yield)해 줌</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: my_gen = (x*x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="built_in">type</span>(my_gen)</span><br><span class="line">Out[<span class="number">2</span>]: generator</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> my_gen:</span><br><span class="line">   ...:     <span class="built_in">print</span>(i)</span><br><span class="line">   ...:</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>It is just the same except you used () instead of []. BUT, you cannot perform for i in generator a second time since <strong>generators can only be used once</strong>: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one</p><h4 id="yield-form"><a href="#yield-form" class="headerlink" title="yield form"></a>yield form</h4><ul><li><code>yield</code>는 <code>return</code>과 유사하지만 generator를 반환한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: <span class="keyword">def</span> <span class="title function_">gen_count</span>(<span class="params">start,step</span>):</span><br><span class="line">   ...:     <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">   ...:         <span class="keyword">yield</span> start</span><br><span class="line">   ...:         start += step</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: counter = gen_count(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">8</span>]: <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">9</span>]: <span class="number">12</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">10</span>]: <span class="number">14</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: <span class="built_in">next</span>(counter)</span><br><span class="line">Out[<span class="number">11</span>]: <span class="number">16</span></span><br></pre></td></tr></table></figure><ul><li><code>yield from a</code>를 통해 <code>iterable</code>의 전체 요소들을 반환할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">three_generator</span>():</span><br><span class="line"><span class="meta">... </span>    a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="keyword">from</span> a</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen = three_generator()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(gen)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do">핵심 stackoverflow ref</a></li><li>Python Comprehensive Cheat Sheet</li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]Graph와 Graph Representation의 이해</title>
      <link href="/2023/10/28/programming/python/Python-Graph-basic/"/>
      <url>/2023/10/28/programming/python/Python-Graph-basic/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="그래프"><a href="#그래프" class="headerlink" title="그래프"></a>그래프</h2><h3 id="Graph-Concept"><a href="#Graph-Concept" class="headerlink" title="Graph Concept"></a>Graph Concept</h3><hr><p><strong><em>Concept</em></strong></p><p>(용어정리)</p><ul><li><strong>그래프</strong> : node(점)와 edge(간선)으로 이루어진 자료구조 . 추상자료형에 해당한다.</li><li><strong>Directed Graph</strong> : edge가 방향성이 있을 경우. 기본적으로 엣지가 순서가 있는 쌍으로 표현된다. <ul><li>leaf : Directed Graph는 순서가 있으므로 마지막 노드가 있다. leaf는 마지막 노드를 뜻한다.</li></ul></li><li><strong>Undirected Graph</strong> : edge가 방향성이 없을 경우. <ul><li>관계의 목적이 <strong>상호교환</strong> 일 경우 <code>Undirected Graph</code>가 가장 적합하다.</li><li>항상 동일한 노드에 재방문 가능하기 때문에 순환 그래프에 속한다.</li><li>adjacency(인접) : 간선이 연결된 것</li><li>neighbor : 간선이 연결된 노드들을 이웃(neighbor) 이라고 한다.</li></ul></li><li><strong>Cyclic  Graph</strong> :그래프에 루프가 있을 경우<ul><li>loop : 방문한 노드에 재방문 가능할 경우</li></ul></li><li><strong>Weighted Graph</strong> : edge에 값(가중치)가 있을 경우. 최단거리 문제에 사용<ul><li>그래프에서 경로의 총 가중치가 높을 경우 비용이 늘어난다.</li></ul></li><li><strong>Directed Acyclic Graph</strong> : 그래프가 순환되지 않고 단방향일 경우. 선형정렬 가능</li><li>Adjacency List : 배열로 표현된 그래프 자료구조(연결리스트)</li><li>Adjacency Matrix : 2차원 배열로 표현된 그래프 자료구조</li></ul><hr><h3 id="Graph-Representation"><a href="#Graph-Representation" class="headerlink" title="Graph Representation"></a>Graph Representation</h3><ul><li>기본적으로 인접리스트와 인접행렬 두 가지 방법을 사용한다.</li></ul><h4 id="인접리스트-adjacency-list"><a href="#인접리스트-adjacency-list" class="headerlink" title="인접리스트(adjacency list)"></a>인접리스트(adjacency list)</h4><p><img src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/listadjacency.png"></p><ul><li>인접리스트는 그래프를 배열로 나타내는 방식이다.</li><li>인접리스트에서 그래프는 <code>전체 노드 목록</code>을 저장한다,<ul><li>배열의 크기는 노드의 수와 같다.</li><li>배열의 i 번째 엔트리는 i번째 노드와 인접노드의 값을 리스트로 저장한다.</li><li>Weighted Graph 일 경우 리스트에 값이 아닌 값과 가중치의 페어들이 저장된다.</li></ul></li></ul><p><img src="https://i.imgur.com/GiStmNh.jpg"></p><ul><li>Dictionarys로 인접리스트 구현하기<ul><li>vertices는 <strong>O(1)상수시간에 각 edge(간선)에 접근</strong>할 수 있다.</li><li>edge가 set에 포함되어 있기 때문에 O(1) 상수 시간에 edge가 있는지 확인할 수 있다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 위 그림에 대해 딕셔너리를 사용한 인접리스트 예시</span></span><br><span class="line"><span class="comment"># 노드가 키가 되고, 인접노드가 값이 되는 딕셔너리이다.</span></span><br><span class="line"><span class="comment"># 가장자리 노드들은 set으로 구현되어 있다.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.vertices = &#123;</span><br><span class="line">                            <span class="string">&quot;A&quot;</span>: &#123;<span class="string">&quot;B&quot;</span>&#125;,   <span class="comment"># 여기서 &#123;&quot;B&quot;&#125;가 set의 형태이다.</span></span><br><span class="line">                            <span class="string">&quot;B&quot;</span>: &#123;<span class="string">&quot;C&quot;</span>, <span class="string">&quot;D&quot;</span>&#125;, <span class="comment"># &#123;&quot;B&quot; : &#123;&#125;&#125;의 형태는 딕셔너리</span></span><br><span class="line">                            <span class="string">&quot;C&quot;</span>: &#123;<span class="string">&quot;E&quot;</span>&#125;,     <span class="comment"># 즉, 딕셔너리 안에 set이 있는 것이다.</span></span><br><span class="line">                            <span class="string">&quot;D&quot;</span>: &#123;<span class="string">&quot;F&quot;</span>, <span class="string">&quot;G&quot;</span>&#125;,</span><br><span class="line">                            <span class="string">&quot;E&quot;</span>: &#123;<span class="string">&quot;C&quot;</span>&#125;,</span><br><span class="line">                            <span class="string">&quot;F&quot;</span>: &#123;<span class="string">&quot;C&quot;</span>&#125;,</span><br><span class="line">                            <span class="string">&quot;G&quot;</span>: &#123;<span class="string">&quot;A&quot;</span>, <span class="string">&quot;F&quot;</span>&#125;</span><br><span class="line">                        &#125;</span><br></pre></td></tr></table></figure><ul><li>List로 인접리스트 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이웃노드를 반복적으로 접근해 탐색</span></span><br><span class="line"><span class="comment"># 시간복잡도(N)</span></span><br><span class="line"></span><br><span class="line">a,b,c,d,e,f = <span class="built_in">range</span>(<span class="number">6</span>) <span class="comment"># 6개노드</span></span><br><span class="line"></span><br><span class="line">N = [[b,c,d,f],[a,d,f],[a,b,c],[a,e],[b,c,d,e]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>class로 인접리스트 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 기본적으로 연결리스트처럼 초기화 클래스가 필요하다.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">adjnode</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,data</span>):</span><br><span class="line">    self.node = data</span><br><span class="line">    self.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vertices</span>):</span><br><span class="line">    self.V = vertices</span><br><span class="line">    self.gragh = [<span class="literal">None</span>] * self.V</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self,src,dest</span>):</span><br><span class="line">    <span class="comment"># 시작지점(src)에 노드 추가</span></span><br><span class="line">    <span class="comment"># 기본적으로 Undirected Graph를 만든다.</span></span><br><span class="line">    node = adjnode(dest)</span><br><span class="line">    <span class="comment"># 아래 코드로 두 노드를 연결시킨다.</span></span><br><span class="line">    node.<span class="built_in">next</span> = self.graph[src]</span><br><span class="line">    self.graph[src] = node</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">print_graph</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.V):</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">f&quot;노드 <span class="subst">&#123;i&#125;</span>의 인접리스트 \n&quot;</span>)</span><br><span class="line">      temp = self.graph[i]</span><br><span class="line">      <span class="keyword">while</span> temp:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;-&gt; <span class="subst">&#123;temp.node&#125;</span>&quot;</span>,end=<span class="string">&quot;&quot;</span> )</span><br><span class="line">        temp = temp.<span class="built_in">next</span></span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">graph.add_edge(<span class="number">0</span>,<span class="number">1</span>) <span class="comment"># </span></span><br><span class="line">graph.add_edge(<span class="number">0</span>,<span class="number">4</span>)</span><br><span class="line">graph.add_edge(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">graph.add_edge(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">graph.add_edge(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">graph.add_edge(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">graph.add_edge(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">graph.add_edge(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">노드 0의 인접리스트 </span><br><span class="line"></span><br><span class="line">-&gt; 4-&gt; 1</span><br><span class="line"></span><br><span class="line">노드 1의 인접리스트 </span><br><span class="line"></span><br><span class="line">-&gt; 4-&gt; 3-&gt; 2</span><br><span class="line"></span><br><span class="line">노드 2의 인접리스트 </span><br><span class="line"></span><br><span class="line">-&gt; 3</span><br><span class="line"></span><br><span class="line">노드 3의 인접리스트 </span><br><span class="line"></span><br><span class="line">-&gt; 4-&gt; 1</span><br><span class="line"></span><br><span class="line">노드 4의 인접리스트 </span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="인접행렬-adjacency-matrix"><a href="#인접행렬-adjacency-matrix" class="headerlink" title="인접행렬(adjacency matrix)"></a>인접행렬(adjacency matrix)</h4><ul><li><p>N * N 크기의 2차원 배열로 나타낸다.</p><ul><li>N 은 노드의 개수이다.</li></ul></li><li><p>인접행렬은 2차원 배열을 활용해 그래프를 표현한 것이다.</p><ul><li><code>adj[i][j] : 노드 i에서 노드 j로 가는 간선이 있으면 1, 아니면 0</code></li></ul></li><li><p>파이썬에서는 중첩리스트로 구현한다.</p></li><li><p>Undirected Graph의 인접행렬은 항상 대칭이다.</p></li><li><p>인접행령의 가중치를 추가할 경우 1과 0 값을 다른 숫자로 바꾼다.</p></li><li><p>인접행렬로 나타낸 그래프 구조들</p><img src="https://www.researchgate.net/publication/347300725/figure/fig1/AS:969208926044162@1608088823984/Different-types-of-graphs-and-their-corresponding-adjacency-matrix-representations-The.ppm" alt="700"/></li></ul><p><img src="https://i.imgur.com/GiStmNh.jpg" alt="https://i.imgur.com/GiStmNh.jpg"></p><ul><li>위 그래프를 인접행렬로 만들 경우 우선 아래와 같은 그림을 만들 수 있다.</li></ul><p><img src="https://github.com/Maiven/data-science/blob/main/%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%E1%84%92%E1%85%A2%E1%86%BC%E1%84%85%E1%85%A7%E1%86%AF.png?raw=true" alt="https://github.com/Maiven/data-science/blob/main/%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%E1%84%92%E1%85%A2%E1%86%BC%E1%84%85%E1%85%A7%E1%86%AF.png?raw=true"></p><ul><li><p>List로 구현한 인접행렬</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 리스트로 구현한 인접행렬</span></span><br><span class="line"><span class="comment"># 아래 코드처럼 위의 간선 가중치는 1이다.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.edges = [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>위에서 행렬은 리스트 안에 리스트가 있는 2차원 배열로 표현된다.</p><ul><li>구현을 통해 기본 제공되는 행렬 간에 **edge weights(간선 가중치)**를 알 수 있다.</li><li><strong>0은 관계가 없음</strong>을 나타내지만 다른 값은 <strong>edge label 또는 edge weight</strong>를 나타낸다.</li><li>인접행렬의 단점은 <strong>노드 값과 해당 인덱스 사이에 연관성이 없다</strong>는 것이다.</li></ul></li><li><p>실제로 인접리스트와 인접행렬을 모두 구현하면 Vertex(정점) 및 Edge(간선) 클래스를 포함하여 더 많은 정보를 파악할 수 있다.</p></li></ul><h4 id="Weighted-Graph-구현하기"><a href="#Weighted-Graph-구현하기" class="headerlink" title="Weighted Graph 구현하기"></a>Weighted Graph 구현하기</h4><ul><li>리스트로 그래프 가중치를 표현하는 것 보다 행렬로 구현하는 것이 쉽다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 인접리스트 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.vertices = &#123;</span><br><span class="line">                            <span class="string">&quot;A&quot;</span>: &#123;<span class="string">&quot;B&quot;</span>: <span class="number">1</span>&#125;,  <span class="comment"># 가중치 부여</span></span><br><span class="line">                            <span class="string">&quot;B&quot;</span>: &#123;<span class="string">&quot;C&quot;</span>: <span class="number">3</span>, <span class="string">&quot;D&quot;</span>: <span class="number">2</span>&#125;,  <span class="comment"># 가중치 부여</span></span><br><span class="line">                            <span class="string">&quot;C&quot;</span>: &#123;&#125;,</span><br><span class="line">                            <span class="string">&quot;D&quot;</span>: &#123;&#125;,</span><br><span class="line">                            <span class="string">&quot;E&quot;</span>: &#123;<span class="string">&quot;D&quot;</span>: <span class="number">1</span>&#125;   <span class="comment"># 가중치 부여</span></span><br><span class="line">                        &#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 인접행렬 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.edges = [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure><h3 id="그래프에서의-복잡도-계산"><a href="#그래프에서의-복잡도-계산" class="headerlink" title="그래프에서의 복잡도 계산"></a>그래프에서의 복잡도 계산</h3><ul><li>인접행렬은 특징은 <strong>구현이 쉽다</strong>는 것이다.<ul><li>때문에 인접행렬의 가장 큰 단점은 <strong>특정노드에 방문한 노드들을 알기 위해서는 모든 노드를 확인</strong>해야 한다는 것이다. (시간복잡도 O(N))</li><li>이러한 단점을 위해 인접리스트로 표현방식이 생겼다.</li></ul></li><li>인접리스트는 실제 연결된 관계만을 저장해주기 때문에 실행시간에 영향을 적게 준다.<ul><li>인접리스트의 단점은 <strong>특정 노드간의 연결관계를 확인하기 위해서는 반복문이 활용되어야 하며 따라서 O(N) 이상의 시간복잡도</strong> 가 발생한다는 것이다.</li></ul></li></ul><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://youtu.be/ofykE5elSfI">Graph Concept</a></li><li><a href="https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/">Graph Data Structure</a></li><li><a href="https://www.geeksforgeeks.org/graph-and-its-representations/">Graph Representaion</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Algorithm </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Algorithm]Hash Table과 Hash에 대한 이해</title>
      <link href="/2023/10/28/programming/python/Python-hash-table/"/>
      <url>/2023/10/28/programming/python/Python-hash-table/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h3 id="Hash-table"><a href="#Hash-table" class="headerlink" title="Hash table"></a>Hash table</h3><hr><p><strong><em>Concept</em></strong></p><ul><li>hash function : 데이터의 효율적 관리를 목적으로 임의의 길의의 데이터를 고정된 길이의 데이터로 매핑하는 함수.<ul><li>key : 매핑 전 원래 데이터의 값</li><li>hashing value : 매핑 후 데이터의 값</li></ul></li><li>hash table : 해시함수를 이용해 키를 해시값으로 매핑하고 이 해시값을 index로 해서 데이터의 값을 키와 함께 빠르게 저장 및 검색할 수 있는 <strong>테이블 형태의 자료구조</strong></li><li>hashing : 매핑하는 과정 자체를 뜻한다.해싱은 기본적으로 다 흩뜨려놓고, 키와 매칭되는 값을 검색하는 과정이다.</li><li>hash collision(해시충돌) : 서로 다른 두개의 키에 대해 동일한 해시값을 내는 것</li><li>Load Factor : 해시테이블에 저장된 항목 수(테이블에 입력된 키 갯수)를 슬롯 수 (해시테이블 전체 인덱스 갯수)로 나눈 값</li></ul><hr><p>:hash table은 기본적으로 <strong>키를 활용하여 값에 직접 접근이 가능한 구조</strong> 이다.</p><ul><li><p>key : value system을 활용해 자료를 정리함</p><ul><li>-&gt; 데이터 양에 영향을 덜 받으며 성능이 빠르다.</li></ul></li><li><p>해싱의 목적은 기본적으로 <strong>검색</strong>이다. -&gt; 해시 테이블은 검색알고리즘의 역할도 한다.</p></li><li><p>Python Dictionary는 내부적으로 해시테이블 구조로 구현되어 있다.</p><ul><li>hash table은 검색을 위한 역할도 하고 딕셔너리를 위한 자료구조의 역할도 한다.</li></ul></li><li><p><strong>hash table 사용이유</strong></p><ul><li>기본적으로 적은 리소르로 많은 데이터를 효율적으로 관리할 수 있다<ul><li>하드디스크나 클라우드에 존재하는 데이터(키) 들을 유한한 개수의 해시값으로 매핑함으로써 작은 크기의 캐쉬메모리로도 프로세스를 관리할 수 있게 된다.</li><li><strong>index에 해시값을 사용함으로서 모든 데이터를 살피지 않아도 검색과 삽입&#x2F;삭제를 빠르게 수행할 수 있습니다.</strong></li><li>해시함수는 언제나 동일한 해시값을 리턴하고 해당 index만 알면 해시테이블 크기에 상관 없이 데이터에 빠르게 접근할 수 있다.<ul><li>index는 계산이 간단한 함수로 작동하기 때무에 매우 효율적이다.</li></ul></li></ul></li></ul></li><li><p>hash table in python</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># case 1 - 딕셔너리로 활용되는 hash table</span></span><br><span class="line"></span><br><span class="line">test_code = &#123;<span class="number">2.5</span>: <span class="string">&#x27;A&#x27;</span> ,<span class="string">&#x27;2.0&#x27;</span>: <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;1.0&#x27;</span>: <span class="string">&#x27;C&#x27;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(test_code[<span class="number">2.5</span>]) </span><br><span class="line"><span class="built_in">print</span>(test_code[<span class="string">&#x27;1.0&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(test_code[<span class="string">&#x27;2.0&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># case 2 - 리스트와 튜플을 활욯한 hash table</span></span><br><span class="line"><span class="comment"># 데이터는 튜플로 저장</span></span><br><span class="line"></span><br><span class="line">test_code = [(<span class="number">2.5</span>, <span class="string">&#x27;A&#x27;</span>), (<span class="string">&#x27;2.0&#x27;</span>, <span class="string">&#x27;B&#x27;</span>), (<span class="string">&#x27;1.0&#x27;</span>, <span class="string">&#x27;C&#x27;</span>)]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insert</span>(<span class="params">item_list, key, value</span>):</span><br><span class="line">    item_list.append((key, value))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">item_list, key</span>):</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_list:    </span><br><span class="line">        <span class="keyword">if</span> item[<span class="number">0</span>] == key:</span><br><span class="line">            <span class="keyword">return</span> item[<span class="number">1</span>]      </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;not matching&#x27;</span>)       </span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(search(test_code, <span class="string">&#x27;2.0&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(search(test_code, <span class="number">2.5</span>))</span><br><span class="line">search(test_code, <span class="number">2.5</span>)    </span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>딕셔너리를 활용한  hash table의 이해</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 테이블에 값 할당</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">dict</span> = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">dict</span>[<span class="string">&#x27;a&#x27;</span>] = <span class="number">1</span></span><br><span class="line"><span class="built_in">dict</span>[<span class="string">&#x27;b&#x27;</span>] = <span class="number">2</span></span><br><span class="line"><span class="built_in">dict</span>[<span class="string">&#x27;c&#x27;</span>] = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">dict</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># hash table에 반복문 적용</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> <span class="built_in">dict</span>.keys():</span><br><span class="line">  <span class="built_in">print</span>(<span class="built_in">dict</span>[key])</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;키, 쌍&#125; 출력</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">dict</span>.items():</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;key : <span class="subst">&#123;k&#125;</span> , value : <span class="subst">&#123;v&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="hash-function"><a href="#hash-function" class="headerlink" title="hash function"></a>hash function</h4><ul><li>해시함수는 보통 문자열 입력값에 정수형 출력값을 반환한다.</li><li>정수형에서 문자열로 변환하기 위해 해시함수는 문자열에 해당하는 개별 단어들을 활용한</li><li>삽입, 검색, 삭제 무엇을 하든지 해시함수는 키를 통해 저장된 값에 연관된 인덱스를 반환한다.(키와 인덱스가 매칭되어야 한다.)<ul><li>-&gt; 만약 해시테이블이 하나의 요소를 갖고 잇다면, 해시테이블 인덱스 갯수에 관계 겂이 프로그래밍 수행시간이 비슷하다</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 굳이 리스트로 hash를 구현할 경우</span></span><br><span class="line"><span class="comment"># 파이썬의 hash table 은 Dictionary이다.</span></span><br><span class="line"><span class="comment"># Dictionary method로 삽입, 삭제, 검색을 수행할 수 있다.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hash_func</span>(<span class="params"><span class="built_in">str</span>,list_size</span>):</span><br><span class="line">    bytes_repr = <span class="built_in">str</span>.encode()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#print(f&quot;str : &#123;str&#125;&quot;)</span></span><br><span class="line">    <span class="comment">#print(f&quot;str_encode : &#123;str.encode()&#125;&quot;)</span></span><br><span class="line">    <span class="comment">#print(f&quot;byte_repr : &#123;bytes_repr&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> byte <span class="keyword">in</span> bytes_repr:</span><br><span class="line">        <span class="built_in">sum</span> += byte</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span> % list_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_list = [<span class="literal">None</span>] * <span class="number">5</span> <span class="comment"># 리스트 초기화: 중요 테크닉</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_list[hash_func(<span class="string">&quot;aqua&quot;</span>,<span class="built_in">len</span>(my_list))] = <span class="string">&quot;#00FFFF&quot;</span> <span class="comment"># 삽입</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#print(my_list[hash_func(&quot;aqua&quot;,len(my_list))]) # 리스트 값 출력</span></span><br><span class="line"><span class="built_in">print</span>(my_list[hash_func(<span class="string">&quot;aqua&quot;</span>,<span class="built_in">len</span>(my_list))])</span><br><span class="line"><span class="built_in">print</span>(my_list)</span><br><span class="line"><span class="comment"># print(hash_func(&quot;aqua&quot;,len(my_list)))</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>Python Hash table 구현하기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python hash table 구현</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">hash_table</span>:</span><br><span class="line">    <span class="comment"># 키에 따른 값 초기화</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.table = [<span class="literal">None</span>] * <span class="number">5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 기능3) name에 따라 특정값을 반환해주는 해시함수</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_function</span>(<span class="params">self, name</span>):</span><br><span class="line">        table_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        encoded = name.encode() <span class="comment"># 문자열을 </span></span><br><span class="line">        <span class="keyword">for</span> byte <span class="keyword">in</span> encoded:</span><br><span class="line">            table_sum += byte</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> table_sum % <span class="built_in">len</span>(self.table) <span class="comment"># 반환된 정수 값이 리스틔 인덱스(키) 가 된다</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># name에 따라 num이 매칭되게끔 삽입</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_insert</span>(<span class="params">self, name, num</span>):</span><br><span class="line">        hash_key = self.hash_function(name) <span class="comment">#</span></span><br><span class="line">        self.table[hash_key] = num <span class="comment"># </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># name에 따라 매칭되는 num 검색</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_search</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="keyword">return</span> self.table[self.hash_function(name)]</span><br><span class="line"></span><br><span class="line">ht = hash_table()</span><br><span class="line"></span><br><span class="line">ht.hash_insert(<span class="string">&#x27;Kim&#x27;</span>, <span class="number">1234</span>)</span><br><span class="line">ht.hash_insert(<span class="string">&#x27;Johne&#x27;</span>, <span class="number">5678</span>)</span><br><span class="line">ht.hash_insert(<span class="string">&#x27;Smith&#x27;</span>, <span class="number">1526</span>)</span><br><span class="line">ht.hash_insert(<span class="string">&#x27;Michael&#x27;</span>, <span class="number">3748</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ht.hash_search(<span class="string">&#x27;Johne&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="hash-충돌"><a href="#hash-충돌" class="headerlink" title="hash 충돌"></a>hash 충돌</h4><ul><li><p>해시함수가 서로 다른 두 개의 키에 대해 동일한 해시값을 내는 것을 해시 충돌이라고 한다.</p></li><li><p>해시충돌은 보통 해쉬값의 개수보다 많은 키값을 해쉬값으로 변환하는 일대다 대응 때문에 발생한다.</p><ul><li>키가 들어갈 자리(버킷)이 없는 경우에 발생한다.</li></ul></li><li><p>아래 그림의 경우 Sandra와 Jonn의 키가 같아 버킷 152에서 충돌이 발생한다.</p></li></ul><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Hash_table_5_0_1_1_1_1_1_LL.svg/675px-Hash_table_5_0_1_1_1_1_1_LL.svg.png" alt="700"/><h4 id="hash-충돌-방지-chaining-활용"><a href="#hash-충돌-방지-chaining-활용" class="headerlink" title="hash 충돌 방지 - chaining 활용"></a>hash 충돌 방지 - chaining 활용</h4><ul><li>chaining은 충돌이 발생한 위 그림처럼 해시테이블에서 동일한 해시 값에 대해 충돌이 일어나면, 해당 위치에 있던 버킷에 키값을 뒤이어 연결하는 것이다.</li><li>이때 데이터는 <strong>해시값이 같은 노드를 연결하는</strong> 연결리스트의 형태를 가진다.<ul><li>따라서 특정 해시값에 대해 충돌이 발생하여도, 체이닝을 통해 값을 찾을 수 있다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># python hashtable chaining 구현</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chain_hash_table = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chain_hash_func</span>():</span><br><span class="line">  <span class="keyword">return</span> key % <span class="built_in">len</span>(chain_hash_table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 키 값 쌍을 해시테이블에 삽입</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chain_insert_func</span>(<span class="params">chain_hash_table, key, value</span>):</span><br><span class="line">  hash_key = chain_hash_func(key)</span><br><span class="line">  chain_hash_table[hash_key].extend(value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chain_insert_func(chain_hash_table,<span class="number">20</span>,<span class="string">&quot;C&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(chain_hash_table)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="hash-충돌-방지-open-addressing"><a href="#hash-충돌-방지-open-addressing" class="headerlink" title="hash 충돌 방지 - open addressing"></a>hash 충돌 방지 - open addressing</h4><ul><li><p>하나의 버켓에 하나의 entry만 들어갈 수 있는 형태이다.(저장공간이 정해져있다.)</p></li><li><p>기본적인 로직은 비어있는 배열 슬롯이 발견될 때까지 배열의 위치를 검색하는 것이다.</p></li><li><p>Chaining은 연결문제를 해결하여 충돌을 해결하고 Open Addressing은 내부적으로 공간이 정해진 배열을 활용하여 빈공간을 찾는 식으로 충돌을 해결한다.</p></li><li><p>close hashing이라고도 불린다.</p></li><li><p>파이썬 자료형으로 구현된 hash table이 Dictionary이다.</p></li><li><p>Dictioanary는 내부적으로 open addressing 방식을 활용한다.</p></li><li><p><strong>로드 팩터</strong> : (Number of items in hash table) &#x2F; (Total Number of Slots)</p><ul><li>해시테이블에 저장된 항목 수(테이블에 입력된 키 갯수)를 슬롯 수 (해시테이블 전체 인덱스 갯수)로 나눈 값</li><li>open addressing을 사용하면 최대 로드 팩터는 1정도 나온다.</li><li>체이닝을 사용할 경우 로드 팩터는 open addressing보다 좋은 성능을 보인다.</li><li>로드 팩터를 낮추면 해시에 대한 성능이 올라간다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파이썬으로 구현한 open addressing</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">open_address</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, table_size</span>):</span><br><span class="line">        self.size = table_size</span><br><span class="line">        self.hash_table = [<span class="number">0</span> <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(self.size)]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getKey</span>(<span class="params">self, data</span>):</span><br><span class="line">        self.key = <span class="built_in">ord</span>(data[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> self.key</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hashFunction</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">return</span> key % self.size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getAddress</span>(<span class="params">self, key</span>):</span><br><span class="line">        myKey = self.getKey(key)</span><br><span class="line">        hash_address = self.hashFunction(myKey)</span><br><span class="line">        <span class="keyword">return</span> hash_address</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        hash_address = self.getAddress(key)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.hash_table[hash_address] != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(hash_address, <span class="built_in">len</span>(self.hash_table)):</span><br><span class="line">                <span class="keyword">if</span> self.hash_table[a] == <span class="number">0</span>:</span><br><span class="line">                    self.hash_table[a] = [key, value]</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                <span class="keyword">elif</span> self.hash_table[a][<span class="number">0</span>] == key:</span><br><span class="line">                    self.hash_table[a] = [key, value]</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.hash_table[hash_address] = [key, value]</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">self, key</span>):</span><br><span class="line">        hash_address = self.getAddress(key)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(hash_address, <span class="built_in">len</span>(self.hash_table)):</span><br><span class="line">            <span class="keyword">if</span> self.hash_table[a][<span class="number">0</span>] == key:</span><br><span class="line">                <span class="keyword">return</span> self.hash_table[a][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">self, key</span>):</span><br><span class="line">        hash_address = self.getAddress(key)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(hash_address, <span class="built_in">len</span>(self.hash_table)):</span><br><span class="line">            <span class="keyword">if</span> self.hash_table[a] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> self.hash_table[a][<span class="number">0</span>] == key:</span><br><span class="line">                self.hash_table[a] = <span class="number">0</span></span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment">#Test Code</span></span><br><span class="line"><span class="comment">#h_table = CloseHash(8)</span></span><br><span class="line"></span><br><span class="line">h_table = open_address(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">data1 = <span class="string">&#x27;aa&#x27;</span></span><br><span class="line">data2 = <span class="string">&#x27;ad&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">ord</span>(data1[<span class="number">0</span>]), <span class="built_in">ord</span>(data2[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">h_table.save(<span class="string">&#x27;aa&#x27;</span>, <span class="string">&#x27;3333&#x27;</span>)</span><br><span class="line">h_table.save(<span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;9999&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(h_table.hash_table)</span><br><span class="line"></span><br><span class="line">h_table.read(<span class="string">&#x27;ad&#x27;</span>)</span><br><span class="line"></span><br><span class="line">h_table.delete(<span class="string">&#x27;aa&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(h_table.hash_table)</span><br><span class="line"></span><br><span class="line">h_table.delete(<span class="string">&#x27;ad&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(h_table.hash_table)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://en.wikipedia.org/wiki/Hash_table">hash table wikipedia</a></li><li><a href="https://ratsgo.github.io/data%20structure&algorithm/2017/10/25/hash/">참조 블로그</a></li><li><a href="http://wiki.hash.kr/index.php/%ED%95%B4%EC%8B%9C_%ED%85%8C%EC%9D%B4%EB%B8%94">hashnet hash</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Algorithm </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]자주쓰는 High Order 함수 정리(lambda,map,filter,apply..)</title>
      <link href="/2023/10/28/programming/python/Python-lambda-highorder/"/>
      <url>/2023/10/28/programming/python/Python-lambda-highorder/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p>for loop과 조건문 만으로도 동일한 결과를 낼 수 있지만 <strong>가독성, 속도, 재사용성</strong> 때문애 고차함수를 사용해 프로그래밍을 하는 경우가 많다.<br>특히 lambda는 데이터 전처리시 자주 사용한다.</p><hr><h3 id="High-order-function"><a href="#High-order-function" class="headerlink" title="High order function"></a>High order function</h3><p>Higher-order Function(고차 함수)</p><p><strong>함수의 매개변수의 인수로 전달이 될수 있고 함수로 결과를 반환할 수 있는 함수를 말한다.</strong></p><p>(First-class Function이 성립되는 3조건 중 2개만 만족한다.)</p><p>대표적인 함수로는 map, filter, reduce, lambda 등이 있다.</p><h4 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h4><ul><li><code>lambda 인자 : 표현식</code> 형태로 사용한다.</li><li>lambda 함수 자체가 파이썬에서 정의된 함수처럼 기능한다고 생각하면 편하다.</li><li>간단한 기능의 함수가 컨테이너의 요소로 들어가거나 다른 함수(high order function)의 인자로 함수를 넘길때 주로 사용한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lambda 예시</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">1</span>]: double = <span class="keyword">lambda</span> x : x+x</span><br><span class="line">   ...: <span class="built_in">print</span>(double(<span class="number">2</span>))</span><br><span class="line">   ...:</span><br><span class="line"><span class="number">4</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>단일 값에 lambda 적용하기</p></li><li><p>lambda 자체를 변수에 바인딩하여 사용 가능하다.</p><ul><li><code>PEP8</code>에 어긋나기 때문에 별로 권장하지 않는다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: temp = <span class="keyword">lambda</span> x,y : x*y</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: temp(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">9</span>]: <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: temp(<span class="number">10</span>,<span class="number">50</span>)</span><br><span class="line">Out[<span class="number">10</span>]: <span class="number">500</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>lamda로 필터링한 파생변수 만들기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Conditional Lambda statement</span></span><br><span class="line">df[<span class="string">&#x27;Gender&#x27;</span>] = df[<span class="string">&#x27;Status&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="string">&#x27;Male&#x27;</span> <span class="keyword">if</span> x==<span class="string">&#x27;father&#x27;</span> <span class="keyword">or</span> x==<span class="string">&#x27;son&#x27;</span> <span class="keyword">else</span> <span class="string">&#x27;Female&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h4><ul><li><code>filter(조건함수,iterable</code>)</li><li>특정 조건에 따라 필터된 요소들로 <code>iterator</code> 객체를 만들어 반환한다.<ul><li><code>map</code>과 마찬가지로 list형태로 만들어 결과를 볼 수 있다.</li></ul></li><li>조건에 따라 iterable에서 일부를 뽑을 때 사용한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lamdas in filter</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: even = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x : x%<span class="number">2</span> == <span class="number">0</span> ,<span class="built_in">range</span>(<span class="number">10</span>)))</span><br><span class="line">   ...: <span class="built_in">print</span>(even)</span><br><span class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># lamdas in filter2 </span></span><br><span class="line">sequences = [<span class="number">10</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">11</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">filtered_result = <span class="built_in">filter</span> (<span class="keyword">lambda</span> x: x &gt; <span class="number">4</span>, sequences) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(filtered_result))</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>보통은 filter 대신 <code>list comprehension</code> 같은 보다 pythonic한 방법을 사용해 iterable에서 일부를 필터링 한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># list comprehension을 활용한 filter</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: even = [x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>) <span class="keyword">if</span> x %<span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line">   ...: <span class="built_in">print</span>(even)</span><br><span class="line">   ...:</span><br><span class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>dataframe</code>에서 파생변수를 만들때 쓰기 좋다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x&gt;<span class="number">18</span>, df[<span class="string">&#x27;age&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="map"><a href="#map" class="headerlink" title="map"></a>map</h4><ul><li><code>map(func,list)</code> 형태로 사욯한다.</li><li><code>iterable</code>의 각 원소에 대해 함수를 적용시킨다.</li><li>map함수 자체는 <code>map</code> 타입으로 결과를 리턴하기에 함수가 적용된 결과를 리스트로 받으려면 내장함수 <code>list()</code>를 사용해야 한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x+x, <span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line">Out[<span class="number">2</span>]: &lt;<span class="built_in">map</span> at <span class="number">0x2446499e640</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x+x,<span class="built_in">range</span>(<span class="number">5</span>)))</span><br><span class="line">Out[<span class="number">3</span>]: [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>map with lambda</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: sequences = [<span class="number">10</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">11</span>,<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">   ...: filtered_result = <span class="built_in">map</span> (<span class="keyword">lambda</span> x: x*x, sequences)</span><br><span class="line">   ...: <span class="built_in">print</span>(<span class="built_in">list</span>(filtered_result))</span><br><span class="line">   ...:</span><br><span class="line">[<span class="number">100</span>, <span class="number">4</span>, <span class="number">64</span>, <span class="number">49</span>, <span class="number">25</span>, <span class="number">16</span>, <span class="number">9</span>, <span class="number">121</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>dataframe</code>의 <code>series</code> 객체에 적용해 파생변수를 생성힐때 유용하다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#Double the age </span></span><br><span class="line">df[<span class="string">&#x27;double_age&#x27;</span>] = df[<span class="string">&#x27;age&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x*<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h4><ul><li><code>reduce(func,sequence)</code> 형태로 사용한다.</li><li>iterable의 요소들을 함수에 누적해서 적용 후 반환한다.</li><li><strong><code>iterable</code>의 순회가 끝날때까지 재귀적으로 함수를 적용한다고 생각하면 이해가 쉽다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">9</span>]:  <span class="keyword">def</span> <span class="title function_">my_add</span>(<span class="params">a, b</span>):</span><br><span class="line">   ...:      result = a + b</span><br><span class="line">   ...:      <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;a&#125;</span> + <span class="subst">&#123;b&#125;</span> = <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">   ...:      <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: <span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: numbers = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>,<span class="number">11</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: reduce(my_add,numbers)</span><br><span class="line"><span class="number">0</span> + <span class="number">1</span> = <span class="number">1</span></span><br><span class="line"><span class="number">1</span> + <span class="number">2</span> = <span class="number">3</span></span><br><span class="line"><span class="number">3</span> + <span class="number">3</span> = <span class="number">6</span></span><br><span class="line"><span class="number">6</span> + <span class="number">4</span> = <span class="number">10</span></span><br><span class="line"><span class="number">10</span> + <span class="number">5</span> = <span class="number">15</span></span><br><span class="line"><span class="number">15</span> + <span class="number">6</span> = <span class="number">21</span></span><br><span class="line"><span class="number">21</span> + <span class="number">7</span> = <span class="number">28</span></span><br><span class="line"><span class="number">28</span> + <span class="number">8</span> = <span class="number">36</span></span><br><span class="line"><span class="number">36</span> + <span class="number">9</span> = <span class="number">45</span></span><br><span class="line"><span class="number">45</span> + <span class="number">10</span> = <span class="number">55</span></span><br><span class="line">Out[<span class="number">12</span>]: <span class="number">55</span></span><br></pre></td></tr></table></figure><ul><li><p>초기값(함수를 적용하기 시직할 지점)을 추가 인자로 넣어줄 수 있다.</p></li><li><p><strong>reduce에 lambda 적용</strong></p><ul><li>코드 가독성을 해치기 때문에 그다지 권장되지 않는다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">13</span>]: numbers = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: reduce(<span class="keyword">lambda</span> x,y :x*y,numbers)</span><br><span class="line">Out[<span class="number">14</span>]: <span class="number">120</span></span><br></pre></td></tr></table></figure><h4 id="apply"><a href="#apply" class="headerlink" title="apply"></a>apply</h4><ul><li>pandas의 dataframe의 행이나 열 단위로 함수를 적용하는 함수이다. <code>map</code> 과 유사하지만 df의 메소드로 보다 쉽게 쓸 수 있다.</li><li><code>df.apply(func, axis = 0 or 1 )</code> 형태로 사용한다<ul><li>axis &#x3D; 0 . 열단위로 함수 적용. default 옵션</li><li>axis &#x3D; 1 . 행단위로 함수적용</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">3</span>]: df</span><br><span class="line">Out[<span class="number">3</span>]:</span><br><span class="line">    A   B</span><br><span class="line"><span class="number">0</span>  <span class="number">16</span>  <span class="number">81</span></span><br><span class="line"><span class="number">1</span>  <span class="number">16</span>  <span class="number">81</span></span><br><span class="line"><span class="number">2</span>  <span class="number">16</span>  <span class="number">81</span></span><br><span class="line"><span class="number">3</span>  <span class="number">16</span>  <span class="number">81</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 열단위 함수적용</span></span><br><span class="line">In [<span class="number">6</span>]: df.apply(np.<span class="built_in">sum</span>,axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">A     <span class="number">64</span></span><br><span class="line">B    <span class="number">324</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 행단위 함수적용</span></span><br><span class="line">In [<span class="number">7</span>]: df.apply(np.<span class="built_in">sum</span>,axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">7</span>]:</span><br><span class="line"><span class="number">0</span>    <span class="number">97</span></span><br><span class="line"><span class="number">1</span>    <span class="number">97</span></span><br><span class="line"><span class="number">2</span>    <span class="number">97</span></span><br><span class="line"><span class="number">3</span>    <span class="number">97</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>lambda with apply 예시</strong><ul><li>df의 파생변수 생성에 유용하다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df[<span class="string">&#x27;age&#x27;</span>] = df[<span class="string">&#x27;Birthyear&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">2021</span>-x)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="applymap"><a href="#applymap" class="headerlink" title="applymap"></a>applymap</h4><ul><li><code>df.applymap(func)</code> 형태로 사용항다.</li><li><strong>df의 모든 요소에 인자로 주어진 함수를 적용한다.</strong></li><li>na_action&#x3D;’ignore’ 옵션을 적용할 경우 null값에 대해서는 함수를 적용하지 않는다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">   ...:</span><br><span class="line">   ...: df = pd.DataFrame(&#123;</span><br><span class="line">   ...:     <span class="string">&#x27;Col 1&#x27;</span>: [<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>],</span><br><span class="line">   ...:     <span class="string">&#x27;Col 2&#x27;</span>: [<span class="number">23</span>,<span class="number">35</span>,<span class="number">65</span>,<span class="number">45</span>],</span><br><span class="line">   ...:     <span class="string">&#x27;Col 3&#x27;</span>: [<span class="number">85</span>,<span class="number">87</span>,<span class="number">90</span>,<span class="number">89</span>],</span><br><span class="line">   ...:</span><br><span class="line">   ...: &#125;,index=[<span class="string">&quot;A&quot;</span>,<span class="string">&quot;B&quot;</span>,<span class="string">&quot;C&quot;</span>,<span class="string">&quot;D&quot;</span>])</span><br><span class="line">   ...:</span><br><span class="line">   ...: <span class="built_in">print</span>(<span class="string">&quot;Initial DF:&quot;</span>)</span><br><span class="line">   ...: <span class="built_in">print</span>(df,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: scaled_df=df.applymap(<span class="keyword">lambda</span> a: a*<span class="number">10</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: <span class="built_in">print</span>(<span class="string">&quot;Scaled DF:&quot;</span>)</span><br><span class="line">   ...: <span class="built_in">print</span>(scaled_df,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">Initial DF:</span><br><span class="line">   Col <span class="number">1</span>  Col <span class="number">2</span>  Col <span class="number">3</span></span><br><span class="line">A     <span class="number">30</span>     <span class="number">23</span>     <span class="number">85</span></span><br><span class="line">B     <span class="number">40</span>     <span class="number">35</span>     <span class="number">87</span></span><br><span class="line">C     <span class="number">50</span>     <span class="number">65</span>     <span class="number">90</span></span><br><span class="line">D     <span class="number">60</span>     <span class="number">45</span>     <span class="number">89</span></span><br><span class="line"></span><br><span class="line">Scaled DF:</span><br><span class="line">   Col <span class="number">1</span>  Col <span class="number">2</span>  Col <span class="number">3</span></span><br><span class="line">A    <span class="number">300</span>    <span class="number">230</span>    <span class="number">850</span></span><br><span class="line">B    <span class="number">400</span>    <span class="number">350</span>    <span class="number">870</span></span><br><span class="line">C    <span class="number">500</span>    <span class="number">650</span>    <span class="number">900</span></span><br><span class="line">D    <span class="number">600</span>    <span class="number">450</span>    <span class="number">890</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap">pandas 공식문서</a></li><li><a href="https://towardsdatascience.com/lambda-functions-with-practical-examples-in-python-45934f3653a8">lambda</a></li><li><a href="https://realpython.com/python-reduce-function/">reduce</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]Regex 정리</title>
      <link href="/2023/10/28/programming/python/Python-regex/"/>
      <url>/2023/10/28/programming/python/Python-regex/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>굵은 글씨로 뭔가 쓴다.</strong></p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> regex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python] asterisk를 활용한 unpacking</title>
      <link href="/2023/10/28/programming/python/Python-unpacking/"/>
      <url>/2023/10/28/programming/python/Python-unpacking/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wranglingience-interview-questions.html--><p><strong>asterisk를 활용한 Unpacking을 간단히 정리</strong></p><p>Python에서 <code>*</code>(asterisk)를 쓰는 방법은 크게 3가지이다.</p><ul><li><p><strong>function call 할때 인자를 unpacking 하기</strong> </p><ul><li><code>*</code> 연산자는 리스트 또는 튜플과 같은 iterable을 unpack한다</li><li><code>**</code> 연산자는 dictionary를 펑션에 필요한 인수로 unpack한다.</li></ul></li><li><p><strong>Variadic Parameters(가변인자) 사용하기</strong></p><ul><li>positional arguments 나 keyword arguments(dictionary 형태)를 여러개 받고 싶을 때 사용한다</li></ul></li><li><p><strong>곱셈, 거듭제곱의 연산자로 사용</strong></p></li></ul><p>여기서는 일단 iterable에 unpacking을 적용하는 것 중심으로 작성한다.</p><hr><h2 id="unpacking-parameters"><a href="#unpacking-parameters" class="headerlink" title="unpacking parameters"></a>unpacking parameters</h2><ul><li>5개의 positional argument를 받는 함수가 있을 때 unpacking을 활용해 보다 간소화해서 실행할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">num_sum</span>(<span class="params">num1,num2,num3,num4,num5</span>):</span><br><span class="line">    <span class="keyword">return</span> num1 + num2 + num3 + num4 + num5</span><br><span class="line"></span><br><span class="line">num_list = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">num_sum(*num_list) <span class="comment"># 1+2+3+4+5</span></span><br></pre></td></tr></table></figure><h2 id="iterable의-데이터를-unpacking하기"><a href="#iterable의-데이터를-unpacking하기" class="headerlink" title="iterable의 데이터를 unpacking하기"></a>iterable의 데이터를 unpacking하기</h2><ul><li><p>list unpacking</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(*test) <span class="comment"># 1 2 3 4</span></span><br></pre></td></tr></table></figure></li><li><p>tuple unpacking</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = (<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line"><span class="built_in">print</span>(*test) <span class="comment"># 5 6 7 8</span></span><br></pre></td></tr></table></figure><ul><li>unpacking 을 활용해 iterable을 여러 부분으로 나눌 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">n = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span> ,<span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># unpacking의 좌변은 iterable의 형태를 가져야 한다,</span></span><br><span class="line"></span><br><span class="line">*a, = num</span><br><span class="line"><span class="comment"># a = [2, 3, 4, 5, 6 ,7]</span></span><br><span class="line"></span><br><span class="line">*a, b = num</span><br><span class="line"><span class="comment"># a = [2, 3, 4, 5, 6]</span></span><br><span class="line"><span class="comment"># b = 7</span></span><br><span class="line"></span><br><span class="line">a, *b, = num</span><br><span class="line"><span class="comment"># a = 2</span></span><br><span class="line"><span class="comment"># b = [3, 4, 5, 6, 7]</span></span><br><span class="line"></span><br><span class="line">a, *b, c = num</span><br><span class="line"><span class="comment"># a = 2</span></span><br><span class="line"><span class="comment"># b = [3, 4, 5, 6]</span></span><br><span class="line"><span class="comment"># c = 7</span></span><br></pre></td></tr></table></figure><ul><li>dictionary unpacking 예시</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dct = &#123;<span class="string">&#x27;a&#x27;</span>:<span class="number">3</span>, <span class="string">&#x27;b&#x27;</span>:<span class="number">3</span>,<span class="string">&#x27;c&#x27;</span>:<span class="number">5</span>,<span class="string">&#x27;d&#x27;</span>:<span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">lst = [<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]</span><br><span class="line"></span><br><span class="line">res = [*<span class="built_in">map</span>(dct.get,lst)] <span class="comment"># unpacking</span></span><br><span class="line"></span><br><span class="line">res2 = <span class="built_in">map</span>(dct.get,lst)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 각 인자를 unpacking해서 출력</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> res2:</span><br><span class="line">      <span class="built_in">print</span>(i) <span class="comment"># 3, 3, 5 ,3 </span></span><br></pre></td></tr></table></figure><h2 id="multiple-list를-합치기"><a href="#multiple-list를-합치기" class="headerlink" title="multiple list를 합치기"></a>multiple list를 합치기</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_list = [1,2,3,4,5]</span><br><span class="line">num_list2 = [6,7,8,9,10]</span><br><span class="line"></span><br><span class="line">new_list = [*num_list, *num_list_2]</span><br><span class="line"># [1,2,3,4,5,6,7,8,9,10]</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://treyhunner.com/2018/10/asterisks-in-python-what-they-are-and-how-to-use-them/">https://treyhunner.com/2018/10/asterisks-in-python-what-they-are-and-how-to-use-them/</a></li><li><a href="https://mingrammer.com/understanding-the-asterisk-of-python/">https://mingrammer.com/understanding-the-asterisk-of-python/</a></li><li><a href="https://towardsdatascience.com/unpacking-operators-in-python-306ae44cd480">https://towardsdatascience.com/unpacking-operators-in-python-306ae44cd480</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python]for-loop관련 함수들</title>
      <link href="/2023/10/28/programming/python/Python-zip-enumerate/"/>
      <url>/2023/10/28/programming/python/Python-zip-enumerate/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><ul><li>대부분의 문제는 반복문과 제어문을 잘 쓰면 어떻게든 해결이 된다.</li><li>for loop에 자주쓰이는 유용한 내장함수로 zip과 enumerate가 있다.</li><li>itertools를 활욯해 반복문의 코드 가독성을 높일 수 있다.</li></ul><hr><h2 id="for-loop"><a href="#for-loop" class="headerlink" title="for-loop"></a>for-loop</h2><h4 id="zip"><a href="#zip" class="headerlink" title="zip"></a>zip</h4><ul><li>같은 크기의 여러 <code>iterable</code>를 한 쌍으로 묶은 뒤 tuple의 형태로 접근할 수 있는 <code>iterator</code>를 반환한다.</li><li>2개 이상의 인자를 넘겨서 병렬처리가 가능하다(가변인자를 받는다.)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">num = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">name = [<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">zip</span>(num, name):</span><br><span class="line">   <span class="built_in">print</span>(i)</span><br><span class="line"></span><br><span class="line">(<span class="number">1</span>, <span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="string">&#x27;B&#x27;</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>zip으로 쉽게 dictionary를 만들 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">food = [<span class="string">&#x27;beef&#x27;</span>, <span class="string">&#x27;chicken&#x27;</span>]</span><br><span class="line">count = [<span class="number">5</span>, <span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">stock = <span class="built_in">dict</span>(<span class="built_in">zip</span>(food, count))</span><br><span class="line"></span><br><span class="line"><span class="comment"># dictionary comprehension을 사욯할 경우</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">stock2 = &#123;k:v*<span class="number">2</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(food, count)&#125; <span class="comment"># stock이 2배 늘어남</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(stock)</span><br><span class="line"><span class="built_in">print</span>(stock2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>*</code> 연산자를 사용해 unzip이 가능하다</li><li><code>*</code> 은 iterable의 각 요소를 분리하는 역할을 한다.<ul><li><ul><li>(a, b, c, d) 는 a,b,c,d 각각을 분리한 것과 같다.</li></ul></li></ul></li><li>zip(* zipped) 는 배열의 각 요소들을 분리한 다음 페어로 다시 묶은 것이다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a = [(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b,c,d=<span class="built_in">zip</span>(*a) <span class="comment"># 배열을 페어링</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: b</span><br><span class="line">Out[<span class="number">12</span>]: (<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: c</span><br><span class="line">Out[<span class="number">13</span>]: (<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: d</span><br><span class="line">Out[<span class="number">14</span>]: (<span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="enumerate"><a href="#enumerate" class="headerlink" title="enumerate"></a>enumerate</h4><ul><li><strong>Get the element and index from a list</strong></li><li><code>iterable</code>에 사용한다. <code>iterable</code>의 인덱스와 원소를 튜플형태로 반환한다.</li><li><code>zip</code>과 다른 것은 배열을 묶는게 아니라 배열의 인덱스를 원소와 함께 묶은 <code>iterator</code>를 반환한다는 것.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lst = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">enumerate</span>(lst):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"></span><br><span class="line">(<span class="number">0</span>,<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line">(<span class="number">3</span>,<span class="string">&#x27;d&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>zip()과 enumerate() 활용</strong></p><ul><li>인덱스와 배열을 묶은 값을 모두 반환해야 할경우 zip과 enumerate를 같이 사용한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">names = [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Chris&#x27;</span>]</span><br><span class="line">ages = [<span class="number">18</span>, <span class="number">20</span>, <span class="number">24</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (name, age) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(names, ages)):</span><br><span class="line">    <span class="built_in">print</span>(i, name, age)</span><br><span class="line"><span class="comment"># 0 Alice 18</span></span><br><span class="line"><span class="comment"># 1 Bob 20</span></span><br><span class="line"><span class="comment"># 2 Chris 14</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="itertools를-활용한-반복문-응용"><a href="#itertools를-활용한-반복문-응용" class="headerlink" title="itertools를 활용한 반복문 응용"></a>itertools를 활용한 반복문 응용</h3><p><strong>itertools.product를 활용한 이중 반복문 변형</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기존 반복문</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> i_ex:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> j_ex:</span><br><span class="line">        <span class="built_in">print</span>(i,j)</span><br><span class="line"></span><br><span class="line"><span class="comment"># itertools활용</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(i_ex, j_ex):</span><br><span class="line">    <span class="built_in">print</span>(i, j)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>References &amp; annotation</strong></p><ul><li><a href="https://stackoverflow.com/questions/5917522/unzipping-and-the-operator">unzipping 연산자</a></li><li><a href="https://www.geeksforgeeks.org/python-itertools/">itertools</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/assets/References/"/>
      <url>/2023/10/28/machine-learning/notebook/assets/References/</url>
      
        <content type="html"><![CDATA[<h2 id="회귀모델의-종류와-특징"><a href="#회귀모델의-종류와-특징" class="headerlink" title="회귀모델의 종류와 특징"></a>회귀모델의 종류와 특징</h2><p><a href="https://danbi-ncsoft.github.io/study/2018/05/04/study-regression_model_summary.html">https://danbi-ncsoft.github.io/study/2018/05/04/study-regression_model_summary.html</a></p><p><img src="https://danbi-ncsoft.github.io/assets/study/regression_model_summary/regression_tree.png" alt="regression_tree"></p><p>특징에 따른 회귀모델 분류</p><p><img src="https://danbi-ncsoft.github.io/assets/study/regression_model_summary/regression_summary.png" alt="regression_summary"></p><h3 id="시계열-데이터의-회귀분석에서-고려할-점들"><a href="#시계열-데이터의-회귀분석에서-고려할-점들" class="headerlink" title="시계열 데이터의 회귀분석에서 고려할 점들"></a>시계열 데이터의 회귀분석에서 고려할 점들</h3><p><a href="https://otexts.com/fpp2/regression.html">https://otexts.com/fpp2/regression.html</a></p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> assets </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/ref-links/"/>
      <url>/2023/10/28/machine-learning/notebook/ref-links/</url>
      
        <content type="html"><![CDATA[<ul><li>kaggle</li><li>medium</li><li>kdnuggets 렉카 링크</li></ul>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/template/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/template/</url>
      
        <content type="html"><![CDATA[<ul><li>Introduction: Provide a brief overview of the machine learning concept you are summarizing, and why it is important in the field of artificial intelligence and data science.</li><li>Definition: Define the concept in simple terms, and explain what it is used for in machine learning. Include any relevant mathematical formulas or notation, if applicable.</li><li>Examples: Provide some concrete examples of how the concept is used in practice, including any real-world applications and datasets that are commonly used to illustrate the concept.</li><li>Advantages: Explain why the concept is useful in machine learning, and how it can help to solve complex problems or improve the accuracy of predictive models.- </li><li>Limitations: Discuss any limitations or drawbacks of the concept, and describe situations where it may not be appropriate to use it in practice.</li><li>Conclusion: Summarize the main points of the concept, and provide some insights into how it fits into the broader landscape of machine learning and data science. Highlight any key takeaways or future research directions that may be relevant to the concept.</li></ul>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/unsorted/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/unsorted/</url>
      
        <content type="html"><![CDATA[<h1 id="어딘가-집어넣을-것들"><a href="#어딘가-집어넣을-것들" class="headerlink" title="어딘가 집어넣을 것들"></a>어딘가 집어넣을 것들</h1><h2 id="n211"><a href="#n211" class="headerlink" title="n211"></a>n211</h2><h4 id="기준모델"><a href="#기준모델" class="headerlink" title="기준모델"></a>기준모델</h4><ul><li><a href="https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa">Always start with a stupid model, no exceptions</a></li></ul><h4 id="Scikit-Learn"><a href="#Scikit-Learn" class="headerlink" title="Scikit-Learn"></a>Scikit-Learn</h4><ul><li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Basics-of-the-API">Python Data Science Handbook, Chapter 5.2: Introducing Scikit-Learn</a></li><li><a href="https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/text_analytics/general_concepts.html#supervised-learning-model-fit-x-y">2.4.2.2. Supervised Learning</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">sklearn.linear_model.LinearRegression</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html">sklearn.metrics.mean_absolute_error</a></li></ul><h4 id="읽어보세요"><a href="#읽어보세요" class="headerlink" title="읽어보세요"></a>읽어보세요</h4><ul><li><a href="https://towardsdatascience.com/art-of-choosing-metrics-in-supervised-models-part-1-f960ae46902e">Art of Choosing Metrics in Supervised Models</a></li><li><a href="https://priceonomics.com/the-discovery-of-statistical-regression/">The Discovery of Statistical Regression</a></li></ul><h4 id="최소제곱법"><a href="#최소제곱법" class="headerlink" title="최소제곱법"></a>최소제곱법</h4><ul><li><a href="https://terms.naver.com/entry.nhn?cid=58944&docId=3569970&categoryId=58970">수학산책-최소제곱법</a></li></ul><h4 id="참고-더-세련된-시각화툴-Plotly"><a href="#참고-더-세련된-시각화툴-Plotly" class="headerlink" title="(참고) 더 세련된 시각화툴: Plotly"></a>(참고) 더 세련된 시각화툴: Plotly</h4><ul><li><a href="https://plot.ly/python/plotly-express/">Plotly Express</a></li><li><a href="https://www.plotly.express/plotly_express/#plotly_express.scatter">plotly_express.scatter</a></li></ul><h4 id="ipywidgets-interact"><a href="#ipywidgets-interact" class="headerlink" title="ipywidgets interact"></a>ipywidgets interact</h4><ul><li><a href="https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html#Using-Interact">Using Interact</a></li></ul><h3 id="210624"><a href="#210624" class="headerlink" title="210624"></a>210624</h3><p><a href="https://velog.io/@tobigs_xai/1%EC%A3%BC%EC%B0%A8-XAI-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90-xgboost">https://velog.io/@tobigs_xai/1%EC%A3%BC%EC%B0%A8-XAI-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90-xgboost</a> # 오늘 건진것중 가장 중요(아마)</p><h4 id="ADABoost"><a href="#ADABoost" class="headerlink" title="ADABoost"></a>ADABoost</h4><ul><li><a href="https://ko.wikipedia.org/wiki/%EC%97%90%EC%9D%B4%EB%8B%A4%EB%B6%80%EC%8A%A4%ED%8A%B8">https://ko.wikipedia.org/wiki/%EC%97%90%EC%9D%B4%EB%8B%A4%EB%B6%80%EC%8A%A4%ED%8A%B8</a></li><li><a href="https://jungsooyun.github.io/statistics/Adaboost_weight/">https://jungsooyun.github.io/statistics/Adaboost_weight/</a></li><li><a href="https://assaeunji.github.io/ml/2020-08-14-adaboost/">https://assaeunji.github.io/ml/2020-08-14-adaboost/</a></li></ul><h4 id="shell-scipt"><a href="#shell-scipt" class="headerlink" title="shell scipt"></a>shell scipt</h4><ul><li><a href="https://vaert.tistory.com/103">https://vaert.tistory.com/103</a></li><li><a href="https://devhints.io/bash">https://devhints.io/bash</a></li><li><a href="https://www.educative.io/blog/bash-shell-command-cheat-sheet">https://www.educative.io/blog/bash-shell-command-cheat-sheet</a></li></ul><h3 id="210622"><a href="#210622" class="headerlink" title="210622"></a>210622</h3><h4 id="misc"><a href="#misc" class="headerlink" title="misc"></a>misc</h4><ul><li><a href="https://m.blog.naver.com/onevibe12/222003789290">https://m.blog.naver.com/onevibe12/222003789290</a> [[파이썬]] vim 설정</li></ul><h4 id="프로젝트-관련데이터사이트"><a href="#프로젝트-관련데이터사이트" class="headerlink" title="프로젝트 관련데이터사이트"></a>프로젝트 관련데이터사이트</h4><ul><li><a href="https://data.world/">https://data.world/</a></li><li><a href="https://researchguide.cau.ac.kr/c.php?g=549836&p=3774670">https://researchguide.cau.ac.kr/c.php?g=549836&amp;p=3774670</a></li><li><a href="https://bigdata.seoul.go.kr/main.do">https://bigdata.seoul.go.kr/main.do</a></li><li><a href="https://rstudio-pubs-static.s3.amazonaws.com/594440_b5a14885d559413ab6e57087eddd68e6.html">https://rstudio-pubs-static.s3.amazonaws.com/594440_b5a14885d559413ab6e57087eddd68e6.html</a></li></ul><h4 id="웜업"><a href="#웜업" class="headerlink" title="웜업"></a>웜업</h4><ul><li><dl><dt>클래스 불균형시의 분류문제</dt><dd>과학저술의 99.99는 노벨상이 되지 않는다. 라고 할때 정확한 분류기를 얻을 수 있다.</dd></dl></li><li><p>Relative cost of false positive&#x2F;false negative</p><ul><li>이 경우 상대적인 Cost는 False postive(false alarm)이 더 크다.</li><li>Hyper Plane(Decision Boundary)를 그릴때 threshold를 크게 하는것이 중요하다.</li><li>상대적인 Cost가 FP가 더 크기때문에 Precision이 아닌 Recall에 더 가중치를 준다</li><li>따라서 F-beta score에서 beta의 가중치는 줄인다</li></ul></li><li><p>고전적인 비교</p><ul><li>Medical diagnosis &amp; investment opportunities</li></ul></li></ul><h5 id="Choos-ML-Problems"><a href="#Choos-ML-Problems" class="headerlink" title="Choos ML Problems"></a>Choos ML Problems</h5><ul><li>예측문제 정의 : 예측타겟 선택</li><li>정보의 누수(Data Leakage) : 두 가지 경우 :<ul><li>타겟변수 외에 예측시점에 사용할 수 없는 데이터가 포함되어 학습이 이뤄질 경우</li><li>훈련데이터와 검증데이터를 완전히 분리하지 못했을 경우 -&gt; 답안이 유출된것, 어쩔 수 없이 과적합이 일어난다.<ul><li>정보의 누수가 과적합을 일으키고 실제성능을 떨어트린다.</li><li>불균형클래스 : 타겟특성의 클래스 비율이 차이가 많이 날 경우가 존재<ul><li>대부분의 scikit-learn 분류기들은 class_weight와 같은 클래스의 밸런스를 맞추는 파라미터를 가지고 있음<ol><li>데이터가 적은 범주 데이터의 손실을 계산할 때 가중치를 더 곱하여 데이터의 균형을 맞추기</li><li>적은 범주 데이터를 추가샘플링 하거나 반대로 많은 범주 데이터를 적게 샘플링 하는 방법이 있다.</li></ol></li></ul></li><li>오버샘플링, 언더샘플링</li></ul></li></ul></li></ul><h5 id="테크블로그"><a href="#테크블로그" class="headerlink" title="테크블로그"></a>테크블로그</h5><ul><li><a href="https://tech.kakao.com/2020/04/29/kakaoarena-3rd-part2/">https://tech.kakao.com/2020/04/29/kakaoarena-3rd-part2/</a> # 카카오</li><li><a href="https://woowabros.github.io/study/2018/08/01/linear_regression_qr.html">https://woowabros.github.io/study/2018/08/01/linear_regression_qr.html</a> # 우아한 형제들</li></ul><h5 id="Information-Leakage"><a href="#Information-Leakage" class="headerlink" title="Information Leakage"></a>Information Leakage</h5><ul><li><a href="https://machinelearningmastery.com/data-leakage-machine-learning/">https://machinelearningmastery.com/data-leakage-machine-learning/</a></li><li><a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba">https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba</a></li></ul><h5 id="왜도-관련"><a href="#왜도-관련" class="headerlink" title="왜도 관련"></a>왜도 관련</h5><ul><li><a href="https://ko.wikipedia.org/wiki/%EB%B9%84%EB%8C%80%EC%B9%AD%EB%8F%84">https://ko.wikipedia.org/wiki/%EB%B9%84%EB%8C%80%EC%B9%AD%EB%8F%84</a> # 왜도 위키피디아</li><li><a href="https://cceeddcc.tistory.com/14">https://cceeddcc.tistory.com/14</a></li><li><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=istech7&logNo=50154573592">https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=istech7&amp;logNo=50154573592</a></li><li><a href="https://medium.com/@ODSC/transforming-skewed-data-for-machine-learning-90e6cc364b0">https://medium.com/@ODSC/transforming-skewed-data-for-machine-learning-90e6cc364b0</a></li></ul><h4 id="210621-스프린트-정리"><a href="#210621-스프린트-정리" class="headerlink" title="210621 스프린트 정리"></a>210621 스프린트 정리</h4><ul><li><p>결정트리</p><ul><li>파이프라인</li><li>사이킷런 결정트리</li><li>특성 중요도</li><li>결정트리 모델의 장점을 이해하고 선형회귀모델과 비교</li></ul></li><li><p>Random Foreset</p><ul><li>ensemble : 성능을 높이기 위해 여러 모델을 합친다</li><li>랜덤포레스트 :  </li><li>배깅 : 단순히 부트스트래핑(복원추출)하고 합친것</li><li>파라미터<ul><li>n_estimators : 기준모델의 수</li><li>max_depth : 나무 깊이</li></ul></li></ul></li><li><p>Confusion Matrix</p><ul><li>Recall : 초기암진단 : 민감도 : 기본적으로 Type2 error(Miss), False Negative를 피하는 것이 중</li><li>Precision : 스팸메일 : 정밀도: 모델이 예측한 True 중 실제 True의 비율,Type1 error(False Alarm), False Positive를 피하는 것이 중요</li></ul></li><li><p>Model Selection</p><ul><li>CV는 기본적으로는 데이터 양이 적어서 학습세트를 늘리려고 만든것이다.</li><li>Train-valid-test로 나누는 홀드아웃 검정의 경우 하이퍼파라미터 튜닝할 때 데이터의 일부에 튜닝할 수 있는 단점이 있다.예컨대<br>valid set에 관한 검증 결과 확인 후 모델 파라미터 튜닝을 하는 작업을 반복하게 되면 모델이 valid set에 대해 overfit 될 가능성이 높다는 것이 단점이다</li><li>Taget encoder : 성능향상에 도움이되는 인코더, 사용시 정보의 누수가 일어나지 않도록 주의</li></ul></li><li><p>하이퍼파라미터 튜닝</p><ul><li>기본적으로 트리가 커질수록 과적합 가능성이 높아진다.</li><li>Max depth를 어느지점에서 결정할 지 validation cureve를 활용해야한</li><li>fold는 보통 5-fold이상</li></ul></li></ul><h5 id="CrossValidation-사용이유와-용법"><a href="#CrossValidation-사용이유와-용법" class="headerlink" title="CrossValidation 사용이유와 용법"></a>CrossValidation 사용이유와 용법</h5><ul><li><a href="https://modern-manual.tistory.com/20?category=902149">https://modern-manual.tistory.com/20?category=902149</a></li><li><a href="https://m.blog.naver.com/ckdgus1433/221599517834">https://m.blog.naver.com/ckdgus1433/221599517834</a></li></ul><h5 id="Git-bash-Conda-사용하기"><a href="#Git-bash-Conda-사용하기" class="headerlink" title="Git bash Conda 사용하기"></a>Git bash Conda 사용하기</h5><p><a href="https://azanewta.tistory.com/29">https://azanewta.tistory.com/29</a></p><h5 id="Fit과-교차검증의-관계"><a href="#Fit과-교차검증의-관계" class="headerlink" title="Fit과 교차검증의 관계"></a>Fit과 교차검증의 관계</h5><h5 id="교차검증의-전단계에서-Fit은-끝나있다"><a href="#교차검증의-전단계에서-Fit은-끝나있다" class="headerlink" title="교차검증의 전단계에서 Fit은 끝나있다."></a>교차검증의 전단계에서 Fit은 끝나있다.</h5><ul><li>교차검증은 기본적으로 검증만 하는것</li><li>모든 fold에 대해 valid set이 될 기회를 끝나있다.</li></ul><h5 id="관련있는-피처-gt-통합-유의미한-피처"><a href="#관련있는-피처-gt-통합-유의미한-피처" class="headerlink" title="관련있는 피처 -&gt;통합 유의미한 피처"></a>관련있는 피처 -&gt;통합 유의미한 피처</h5><ul><li>설명력 강화와 차원축소를 위해 합친다</li></ul><h5 id="random-forest"><a href="#random-forest" class="headerlink" title="random forest"></a>random forest</h5><ul><li>oob score는 보통 거의 쓰지 않는다.</li></ul><h5 id="Crossvalidation"><a href="#Crossvalidation" class="headerlink" title="Crossvalidation"></a>Crossvalidation</h5><ul><li><a href="https://teddylee777.github.io/scikit-learn/grid-search-%EB%A1%9C-hyperparameter%EC%B5%9C%EC%A0%81%ED%99%94">https://teddylee777.github.io/scikit-learn/grid-search-%EB%A1%9C-hyperparameter%EC%B5%9C%EC%A0%81%ED%99%94</a></li><li><a href="https://learnaday.kr/open-course/tfcert">https://learnaday.kr/open-course/tfcert</a></li><li><a href="https://github.com/koni114/TIL/blob/master/Machine-Learning/contents/ML%EC%83%81%EC%8B%9D%EC%A0%95%EB%A6%AC.md">https://github.com/koni114/TIL/blob/master/Machine-Learning/contents/ML%EC%83%81%EC%8B%9D%EC%A0%95%EB%A6%AC.md</a></li></ul><h4 id="210617"><a href="#210617" class="headerlink" title="210617"></a>210617</h4><ul><li>중요 : 민감도 특이도 정밀도</li><li><a href="https://sumniya.tistory.com/26">https://sumniya.tistory.com/26</a> # 개념암기용 우선</li><li><a href="https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa">https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa</a> # 이해용 </li><li><a href="https://towardsdatascience.com/machine-learning-an-error-by-any-other-name-a7760a702c4d#">https://towardsdatascience.com/machine-learning-an-error-by-any-other-name-a7760a702c4d#</a> # 헷갈리는 명칭들</li><li><a href="https://towardsdatascience.com/classification-metrics-thresholds-explained-caff18ad2747">https://towardsdatascience.com/classification-metrics-thresholds-explained-caff18ad2747</a></li><li><a href="https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa">https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa</a></li><li><a href="http://seb.kr/w/F1_%EC%8A%A4%EC%BD%94%EC%96%B4">http://seb.kr/w/F1_%EC%8A%A4%EC%BD%94%EC%96%B4</a></li><li><a href="https://en.wikipedia.org/wiki/F-score">https://en.wikipedia.org/wiki/F-score</a></li><li><a href="https://youtu.be/j-EB6RqqjGI">https://youtu.be/j-EB6RqqjGI</a></li><li><a href="https://www.youtube.com/watch?v=4jRBRDbJemM">https://www.youtube.com/watch?v=4jRBRDbJemM</a></li><li><a href="https://newsight.tistory.com/53">https://newsight.tistory.com/53</a> # ROC, AUC, 민감도, 특이도</li><li><a href="https://www.kaggle.com/nappon/animation-confusion-matrix-and-roc-interplay">https://www.kaggle.com/nappon/animation-confusion-matrix-and-roc-interplay</a></li><li><a href="https://darkpgmr.tistory.com/162">https://darkpgmr.tistory.com/162</a></li><li><a href="https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/">https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/</a> # 블로그 참고</li><li><a href="https://en.wikipedia.org/wiki/F-score">https://en.wikipedia.org/wiki/F-score</a></li><li><a href="https://stats.stackexchange.com/questions/221997/why-f-beta-score-define-beta-like-that">https://stats.stackexchange.com/questions/221997/why-f-beta-score-define-beta-like-that</a></li></ul><h5 id="multilabel-classification-problem"><a href="#multilabel-classification-problem" class="headerlink" title="multilabel classification problem"></a>multilabel classification problem</h5><h5 id="Visualize"><a href="#Visualize" class="headerlink" title="Visualize"></a>Visualize</h5><ul><li>Recall(Sensitivity)</li><li><a href="https://rafalab.github.io/dsbook/inference.html">https://rafalab.github.io/dsbook/inference.html</a></li><li><a href="https://github.com/reiinakano/scikit-plot">https://github.com/reiinakano/scikit-plot</a></li><li><a href="https://morioh.com/p/2298e2750226">https://morioh.com/p/2298e2750226</a> # 개쩌는 레퍼런스</li></ul><h4 id="210616"><a href="#210616" class="headerlink" title="210616"></a>210616</h4><ul><li>articles<ul><li><a href="https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/?utm_source=blog&utm_medium=4-ways-split-decision-tree">https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/?utm_source=blog&amp;utm_medium=4-ways-split-decision-tree</a></li></ul></li></ul><p>중요</p><ul><li><p>노드와 피처는 다르다!!</p></li><li><p>노드는 기본적으로 TF로 나누어질 수있는 Statement이다.</p></li><li><p>랜덤포레스트</p></li><li><p>배깅 : 부트스트랩을 통해 모델을 학습을 하고 합치는 과정</p><ul><li>원본 데이터의 개수만큼 복원추출을 하는 것을 부트스트탭 샘플링이라 한다</li><li>부트스트랩에서 추출되지 않는 36.8% 의 샘플을 OOB 샘플이라고 하며 이를 통해 모델을 검증한다.</li></ul></li><li><p>Ordinal encoding 하는 이유</p><ul><li>범주형 자료를 모델에서 사용하고자 할때 Ordinal </li><li>트리모델에서는 구조상 중요한 특성들이 상위노드에서 선택됨</li><li>중요한 범주형 특성이 원핫인코딩을 하게되면 제대로 쓰일 수없다</li><li>원핫인코딩에서는 한 피처가 여러 특성으로 나눠지기 때문에..</li></ul></li><li><p>기본적으로 노드가 중요할수록 불순도가 크게 감소한다.</p></li><li><p>지니인덱스가 낮으면 불순도가 낮기 때문에 루트노드에 올 가능성이 높아진다.</p></li><li><p>잘 나누는 기준은 나눴을 때 덜 섞이는 것</p></li><li><p>만들어진 결정트리를 보니 어떤 특성이 중요하다 로 이해하면 된다.</p></li></ul><h4 id="210615"><a href="#210615" class="headerlink" title="210615"></a>210615</h4><ul><li><a href="https://wikidocs.net/744">https://wikidocs.net/744</a></li><li><a href="https://soohee410.github.io/iml_tree_importance">https://soohee410.github.io/iml_tree_importance</a></li><li><a href="https://www.math.snu.ac.kr/~hichoi/machinelearning/lecturenotes/CART.pdf">https://www.math.snu.ac.kr/~hichoi/machinelearning/lecturenotes/CART.pdf</a></li></ul><h4 id="Post-Pruning-해볼-것"><a href="#Post-Pruning-해볼-것" class="headerlink" title="Post-Pruning : 해볼 것"></a>Post-Pruning : 해볼 것</h4><p><a href="https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html">https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html</a></p><p><a href="https://christophm.github.io/interpretable-ml-book/tree.html">https://christophm.github.io/interpretable-ml-book/tree.html</a></p><p><a href="https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95">https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95</a></p><ul><li><p>파이프라인 : Python,ML</p><ul><li>기타 레퍼런스</li><li><a href="https://spark.rstudio.com/guides/pipelines/">https://spark.rstudio.com/guides/pipelines/</a></li></ul></li><li><p>의사결정트리</p><ul><li><p>전반적으로 확인 <a href="https://blog.naver.com/ehdrndd/221158124011">https://blog.naver.com/ehdrndd/221158124011</a></p></li><li><p>목적</p></li><li><p>수식</p><ul><li>IG</li><li>df</li></ul></li><li><p>terminology</p><ul><li>root node</li><li>leaf node</li><li>pure node</li></ul></li><li><p>목적함수</p></li><li><p>하이퍼파라미터</p><ul><li>max_depth : 일반화 성능관련, 끝까지 학습환런</li><li>min_sample_splite</li><li>max_feature : 최대 피처 사용수</li><li>random_state : random state</li><li>class_weight : 가중치 balance 맟추기</li></ul></li><li><p>특징</p><ul><li>Scale의 영향을 받지 않는다.</li></ul></li></ul></li><li><p>결정트리구현-python</p><ul><li>시각화 : graphviz 확인</li><li>혼동행렬</li><li>Post-Pruning<br>수식<br><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">https://en.wikipedia.org/wiki/Decision_tree_learning</a><br><a href="https://zephyrus1111.tistory.com/124?category=858748">https://zephyrus1111.tistory.com/124?category=858748</a><br><a href="https://towardsdatascience.com/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3">https://towardsdatascience.com/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3</a><br><a href="https://youtu.be/yLh-UiqMC04?list=PLJN246lAkhQiEc-QvvGzUneCWuRnCNKgU">https://youtu.be/yLh-UiqMC04?list=PLJN246lAkhQiEc-QvvGzUneCWuRnCNKgU</a></li></ul></li></ul><h4 id="input이-continuous-한-경우의-의사결정-트리"><a href="#input이-continuous-한-경우의-의사결정-트리" class="headerlink" title="input이 continuous 한 경우의 의사결정 트리"></a>input이 continuous 한 경우의 의사결정 트리</h4><ul><li>매우 매우 매우 매우 매우 매우 매우 중요</li><li><a href="https://www.youtube.com/watch?v=v26lXTcAicw&t=13s">https://www.youtube.com/watch?v=v26lXTcAicw&amp;t=13s</a></li><li><a href="https://www.youtube.com/watch?v=OD8aO4ovIBo">https://www.youtube.com/watch?v=OD8aO4ovIBo</a> # input이 continuous 고</li></ul><h4 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h4><h4 id="재귀적인-이진분리의-수행"><a href="#재귀적인-이진분리의-수행" class="headerlink" title="재귀적인 이진분리의 수행"></a>재귀적인 이진분리의 수행</h4><h4 id="크로스-엔트로피"><a href="#크로스-엔트로피" class="headerlink" title="크로스 엔트로피"></a>크로스 엔트로피</h4><ul><li><a href="https://3months.tistory.com/436">https://3months.tistory.com/436</a></li><li><a href="http://melonicedlatte.com/machinelearning/2019/12/20/204900.html">http://melonicedlatte.com/machinelearning/2019/12/20/204900.html</a></li></ul><p>OLS회귀 랑 sklearn의 결과다른 이유 : dk</p><h4 id="graphviz-그래프-시각화"><a href="#graphviz-그래프-시각화" class="headerlink" title="graphviz 그래프 시각화"></a>graphviz 그래프 시각화</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line">export_graphviz(model, out_file=<span class="string">&#x27;cancer_tree_self.dot&#x27;</span>, class_names=cancer.target_names,</span><br><span class="line">                feature_names=cancer.feature_names,</span><br><span class="line">                filled=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&#x27;cancer_tree_self.dot&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    dot_graph = f.read()</span><br><span class="line">display(graphviz.Source(dot_graph))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/preprocessing/Preprocessing/"/>
      <url>/2023/10/28/machine-learning/notebook/preprocessing/Preprocessing/</url>
      
        <content type="html"><![CDATA[<!-- MarkdownTOC --><ul><li><a href="#file-processingreading-writing-file">File Processing(Reading, Writing File)</a><ul><li><a href="#file-and-dictionary-access">File and Dictionary Access</a></li><li><a href="#file-reading">File Reading</a><ul><li><a href="#json">json</a></li></ul></li><li><a href="#numpy">numpy</a><ul><li><a href="#numpy-basics">numpy basics</a><ul><li><a href="#boolen-indexing">boolen indexing</a></li><li><a href="#fancy-indexing">fancy indexing</a></li></ul></li><li><a href="#numpy-%EB%B0%B0%EC%97%B4-%EB%B3%80%ED%98%95%ED%95%98%EA%B8%B0array-transformation">numpy 배열 변형하기(array transformation)</a><ul><li><a href="#transpose">Transpose</a></li><li><a href="#changing-array-shape">Changing Array Shape</a></li><li><a href="#npreshape">np.reshape</a></li><li><a href="#addingremoving-elements">Adding&#x2F;Removing Elements</a></li><li><a href="#combine-array">Combine array</a></li></ul></li><li><a href="#split-array">Split array</a></li><li><a href="#numpy-method">numpy method</a><ul><li><a href="#npwhere">np.where</a></li><li><a href="#npselect">np.select</a></li><li><a href="#nplog">np.log</a></li><li><a href="#npsort%EB%B0%B0%EC%97%B4-%EC%A0%95%EB%A0%AC%ED%95%98%EA%B8%B0">np.sort(배열 정렬하기)</a></li><li><a href="#nppad">np.pad</a></li><li><a href="#npargwhere">np.argwhere</a></li></ul></li><li><a href="#numpy-broadcasting">numpy broadcasting</a><ul><li><a href="#numpy-%ED%86%B5%EA%B3%84">numpy 통계</a></li><li><a href="#numpy-boolen">numpy boolen</a></li><li><a href="#numpy-%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98">numpy 선형대수</a></li><li><a href="#numpy-%EC%A7%91%ED%95%A9-%ED%95%A8%EC%88%98%EB%93%A4">numpy 집합 함수들</a></li><li><a href="#numpy-sampling">numpy sampling</a></li></ul></li></ul></li><li><a href="#pandas">pandas</a><ul><li><a href="#creating-pandas-object">Creating Pandas Object</a><ul><li><a href="#series">Series</a></li><li><a href="#dataframe">DataFrame</a><ul><li><a href="#df-methods">DF methods</a></li><li><a href="#df-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0">DF 생성하기</a></li></ul></li></ul></li><li><a href="#viewing-data">Viewing Data</a><ul><li><a href="#type-casting">type casting</a></li></ul></li><li><a href="#sampling-data">Sampling Data</a></li><li><a href="#data-selection">Data Selection</a></li><li><a href="#reshaping">Reshaping</a></li><li><a href="#operations">Operations</a><ul><li><a href="#apply">apply</a></li><li><a href="#applymap">applymap</a></li><li><a href="#agg">agg</a></li><li><a href="#aggregate">aggregate</a></li></ul></li><li><a href="#maipulation">Maipulation</a><ul><li><a href="#renaming-colunm">Renaming Colunm</a></li><li><a href="#removing-column">Removing Column</a></li></ul></li><li><a href="#grouping-data">Grouping Data</a></li></ul></li><li><a href="#%EC%9D%91%EC%9A%A9-%ED%95%98%EA%B8%B0">응용 하기</a><ul><li><a href="#mergingjoining-and-concatenating">Merging,Joining and Concatenating</a></li><li><a href="#exporting-data">Exporting data</a></li><li><a href="#%EC%98%AE%EA%B8%B8-%EA%B2%83%EB%93%A4">옮길 것들</a></li><li><a href="#textdata">Textdata</a><ul><li><a href="#regex">regex</a></li><li><a href="#replace">replace</a></li><li><a href="#match">match</a></li></ul></li><li><a href="#date-and-time">Date and Time</a></li><li><a href="#miscellaneous">Miscellaneous</a><ul><li><a href="#vlookup">vlookup</a></li></ul></li></ul></li><li><a href="#%EA%B2%B0%EC%B8%A1%EA%B0%92-%EC%B2%98%EB%A6%ACmissing-value">결측값 처리(Missing value)</a><ul><li><a href="#%EA%B2%B0%EC%B8%A1%EC%B9%98-%EA%B4%80%EB%A0%A8-%ED%95%A8%EC%88%98">결측치 관련 함수</a></li><li><a href="#%EA%B2%B0%EC%B8%A1%EC%B9%98-%EC%B2%98%EB%A6%AC">결측치 처리</a></li></ul></li></ul></li><li><a href="#%EA%B2%B0%EC%B8%A1%EC%B9%98-%EA%B0%9C%EC%88%98-%ED%8C%8C%EC%95%85">결측치 개수 파악</a></li><li><a href="#%EA%B2%B0%EC%B8%A1%EC%B9%98-%EB%B9%84%EC%9C%A8-%ED%8C%8C%EC%95%85">결측치 비율 파악</a><ul><li><a href="#imputer">imputer</a></li><li><a href="#readwrite-file">Read&#x2F;Write File</a></li></ul></li><li><a href="#eda">EDA</a><ul><li><a href="#dlookr">dlookr</a></li><li><a href="#pingouin">pingouin</a></li><li><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EB%B0%9B%EC%95%98%EC%9D%84-%EB%95%8C-%ED%95%B4%EC%95%BC%ED%95%98%EB%8A%94-%EA%B2%83">데이터를 받았을 때 해야하는 것</a><ul><li><a href="#df-%ED%99%95%EC%9D%B8">DF 확인</a></li></ul></li><li><a href="#descriptive-stataistics">Descriptive Stataistics</a><ul><li><a href="#iqr">IQR</a></li><li><a href="#%EB%8B%A8%EC%9D%BC%EB%B3%80%EC%88%98-%EB%B6%84%EC%84%9D">단일변수 분석</a></li><li><a href="#%EC%83%81%EA%B4%80%EA%B4%80%EA%B3%84-%EB%B6%84%EC%84%9D">상관관계 분석</a></li></ul></li><li><a href="#type-checking--casting-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%83%80%EC%9E%85%EB%B3%80%ED%99%98">Type Checking &amp; Casting (데이터 타입변환)</a><ul><li><a href="#type-checeking">Type Checeking</a></li></ul></li><li><a href="#reshaping%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9E%AC%EA%B5%AC%EC%A1%B0%ED%99%94">Reshaping(데이터 재구조화)</a></li><li><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%B4%EB%A6%AC%EB%8B%9Dmissign">데이터 클리닝(missign)</a></li><li><a href="#%ED%85%8D%EC%8A%A4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC">텍스트 데이터 전처리</a></li><li><a href="#%EC%8B%9C%EA%B3%84%EC%97%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC">시계열 데이터 전처리</a></li><li><a href="#%EC%97%B0%EA%B4%80%EC%84%B1-%EA%B2%80%EC%A0%95">연관성 검정</a><ul><li><a href="#numerical-data--%EC%83%81%EA%B4%80%EB%B6%84%EC%84%9D-%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1-%EA%B2%B8%EC%A0%95">numerical data : 상관분석, 다중공선성 겸정</a></li><li><a href="#categorical-data--%EB%8F%85%EB%A6%BD%EC%84%B1-%EA%B2%80%EC%A0%95">categorical data : 독립성 검정</a></li></ul></li></ul></li></ul><!-- /MarkdownTOC --><h1 id="File-Processing-Reading-Writing-File"><a href="#File-Processing-Reading-Writing-File" class="headerlink" title="File Processing(Reading, Writing File)"></a>File Processing(Reading, Writing File)</h1><ul><li>python doc  libraries</li></ul><h2 id="File-and-Dictionary-Access"><a href="#File-and-Dictionary-Access" class="headerlink" title="File and Dictionary Access"></a>File and Dictionary Access</h2><ul><li><a href=""></a></li></ul><h2 id="File-Reading"><a href="#File-Reading" class="headerlink" title="File Reading"></a>File Reading</h2><h3 id="json"><a href="#json" class="headerlink" title="json"></a>json</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_train_json</span>(<span class="params">path</span>):</span><br><span class="line">    f = pd.read_json(path ,typ = <span class="string">&#x27;frame&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    df = pd.DataFrame(f)</span><br><span class="line">    df = df.sort_values(by=[<span class="string">&#x27;like_cnt&#x27;</span>],ascending=<span class="literal">False</span>)</span><br><span class="line">    df = df[df[<span class="string">&#x27;like_cnt&#x27;</span>]&gt;<span class="number">10</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;load_train_json&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_val_json</span>(<span class="params">path</span>):</span><br><span class="line">    f = pd.read_json(path ,typ = <span class="string">&#x27;frame&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    df = pd.DataFrame(f)</span><br><span class="line">    df = df.sort_values(by=[<span class="string">&#x27;like_cnt&#x27;</span>],ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;load_test_json&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_meta_json</span>(<span class="params">path</span>):</span><br><span class="line">    f = pd.read_json(path ,typ = <span class="string">&#x27;frame&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    df = pd.DataFrame(f)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;load_meta_json&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><h2 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h2><p><strong>numpy 기능들</strong></p><ul><li>벡터 배열상에서 데이터 가공, 정제, 부분집합 필터링, 변형 및 기타연산</li><li>정렬, unique 탐색, 집합연산같은 일반적인 배열처리 알고리즘</li></ul><p>numpy의 중요한 특징은 <strong>파이썬 반복문을 사용하지 않고</strong> 대용량 배열에 대한 복잡한 연산이 가능하다는 것.</p><h3 id="numpy-basics"><a href="#numpy-basics" class="headerlink" title="numpy basics"></a>numpy basics</h3><ul><li>배열 생성</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">5</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">   ...: arr = np.arange(<span class="number">0</span>,<span class="number">10</span>) <span class="comment"># 0에서 9까지 의 </span></span><br><span class="line">   ...:</span><br><span class="line">   ...: arr.reshape(<span class="number">2</span>,<span class="number">5</span>) <span class="comment"># 배열 형태 변환</span></span><br><span class="line">Out[<span class="number">5</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">   ...: arr = np.arange(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: arr=arr.reshape(<span class="number">2</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure><ul><li>배열 형태 확인(ndim,shape,len)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">7</span>]: arr.ndim <span class="comment"># 차원 수</span></span><br><span class="line">Out[<span class="number">7</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: arr.shape <span class="comment"># 모양</span></span><br><span class="line">Out[<span class="number">8</span>]: (<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: <span class="built_in">len</span>(arr)</span><br><span class="line">Out[<span class="number">9</span>]: <span class="number">10</span></span><br></pre></td></tr></table></figure><ul><li>배열 데이터 타입 확인(dtype)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">15</span>]: arr_2 = np.random.rand(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: arr_2</span><br><span class="line">Out[<span class="number">16</span>]: array([<span class="number">0.55155657</span>, <span class="number">0.32745746</span>, <span class="number">0.92681611</span>, <span class="number">0.04614794</span>, <span class="number">0.17832697</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: arr_2.dtype</span><br><span class="line">Out[<span class="number">17</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: arr_3 = np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype = np.float64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: arr_3.dtype</span><br><span class="line">Out[<span class="number">19</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>배열 데이터 타입 변환(astype)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">24</span>]: arr_2=arr_2.astype(np.int64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: arr_2.dtype</span><br><span class="line">Out[<span class="number">25</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: arr_3=arr_3.astype(np.int64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: arr_3.dtype</span><br><span class="line">Out[<span class="number">27</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>배열 생성함수들</strong></p><ul><li><code>array</code> : 입력데이터를 다차원 배열로 변환.</li><li><code>arange</code> : <code>range</code>와 동일하지만 다차원 배열을 반환.</li><li><code>np.empty(a)</code> ,<code>np.empty_like(M)</code> : 0 이나 1로 값을 초기화하지 않은 배열을 반환.</li><li><code>np.ones(a)</code> : a 크기의 1으로 채워진 배열을 반환 </li><li><code>np.ones_like(M)</code> M 배열의 사이즈와 같은 1으로 채워진 배열을 반환</li><li><code>np.zeros(a)</code> : a 크기의 0으로 채워진 배열을 반환 </li><li><code>np.zeros_like(M)</code> M 배열의 사이즈와 같은 0으로 채워진 배열을 반환</li><li><strong><code>np.full</code> :인자로 값과 형태를 받고. 인자로 받은 형태에 값을 채운다. (자주 쓴다.)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np full 용법</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">- `np.full_like` : 인자로 값과 형태를 받고. 인자로 받은 형태에 값을 채운다.</span><br><span class="line">- `eye` , `identity`: N * N 크기의 단위행렬생성</span><br><span class="line">- `np.random.rand(n)` : n 크기 난수 배열 생성</span><br><span class="line"></span><br><span class="line">### numpy indexing</span><br><span class="line"></span><br><span class="line">- 기본 파이썬 list indexing과 유사하지만 차원이 복잡해지면 어려워진다.</span><br><span class="line"></span><br><span class="line">#### 기초 슬라이싱과 인덱싱</span><br><span class="line"></span><br><span class="line">- 기본적으로 list의 그것과 다를 건 없다.</span><br><span class="line">- `i:j:k` 형태로 인덱싱한다.</span><br><span class="line">    + i는 starting index </span><br><span class="line">    + j는 stopping index(j-1 까지 슬라이싱된다.)</span><br><span class="line">    + k는 step</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">In [1]: import numpy as np</span><br><span class="line"></span><br><span class="line">In [2]: x = np.array(range(10))</span><br><span class="line"></span><br><span class="line">In [3]: x[1:7:2]</span><br><span class="line">Out[3]: array([1, 3, 5])</span><br><span class="line"></span><br><span class="line">In [4]: x[-2:10]</span><br><span class="line">Out[4]: array([8, 9])</span><br><span class="line"></span><br><span class="line">In [5]: x[-3:3:-1]</span><br><span class="line">Out[5]: array([7, 6, 5, 4])</span><br><span class="line"></span><br><span class="line">In [6]: x[5:]</span><br><span class="line">Out[6]: array([5, 6, 7, 8, 9])</span><br></pre></td></tr></table></figure><ul><li>인덱스 리스트를 통해 쉽게 배열의 값에 접근할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">50</span>]: arr_2d = np.arange(<span class="number">1</span>,<span class="number">10</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: arr_2d</span><br><span class="line">Out[<span class="number">51</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: arr_2d[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">52</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 보통 두 번째 방법을 많이 사용한다.</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: arr_2d[<span class="number">0</span>,<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">53</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure><ul><li>다차원 슬라이싱하기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">54</span>]: arr_2d[:<span class="number">2</span>,<span class="number">1</span>:]</span><br><span class="line">Out[<span class="number">54</span>]:</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure><ul><li>좀 복잡한 형태의 다차원 슬라이싱</li></ul><p><img src="https://media.geeksforgeeks.org/wp-content/uploads/Numpy1.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 다차원 배열 인덱싱 예시</span></span><br><span class="line"> [[<span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>] </span><br><span class="line">  [<span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span>]</span><br><span class="line">  [<span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> <span class="number">16</span> <span class="number">17</span>]</span><br><span class="line">  [<span class="number">18</span> <span class="number">19</span> <span class="number">20</span> <span class="number">21</span> <span class="number">22</span> <span class="number">23</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">25</span> <span class="number">26</span> <span class="number">27</span> <span class="number">28</span> <span class="number">29</span>]</span><br><span class="line">  [<span class="number">30</span> <span class="number">31</span> <span class="number">32</span> <span class="number">33</span> <span class="number">34</span> <span class="number">35</span>]]</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>, <span class="number">3</span>:<span class="number">5</span>]  =  [<span class="number">3</span> <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">a[<span class="number">4</span>:, <span class="number">4</span>:] = [[<span class="number">28</span> <span class="number">29</span>],</span><br><span class="line">             [<span class="number">34</span> <span class="number">35</span>]]</span><br><span class="line"></span><br><span class="line">a[:, <span class="number">2</span>] =  [<span class="number">2</span> <span class="number">8</span> <span class="number">14</span> <span class="number">20</span> <span class="number">26</span> <span class="number">32</span>]</span><br><span class="line"></span><br><span class="line">a[<span class="number">2</span>:;<span class="number">2</span>, ::<span class="number">2</span>] = [[<span class="number">12</span> <span class="number">14</span> <span class="number">16</span>],</span><br><span class="line">                [<span class="number">24</span> <span class="number">26</span> <span class="number">28</span>]]</span><br></pre></td></tr></table></figure><ul><li><code>:</code> 연산자를 통해  <code>:</code> 가 위치하는 축의 모든 값에 접근할 수 있다.</li><li>배열 자체에 <code>[:]</code> 를 사용할 경우 배열의 모든 값이 할당된다.<ul><li><strong>기본적으로 데이터가 복사되지 않는다.</strong></li><li>데이터를 복사해야 할 경우 <code>copy</code> 함수를 따로 사용한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">44</span>]: arr</span><br><span class="line">Out[<span class="number">44</span>]:</span><br><span class="line">array([[<span class="number">0.23061655</span>, <span class="number">0.86734388</span>, <span class="number">0.27967631</span>],</span><br><span class="line">       [<span class="number">0.63734555</span>, <span class="number">0.47048728</span>, <span class="number">0.04833744</span>],</span><br><span class="line">       [<span class="number">0.99362969</span>, <span class="number">0.87636748</span>, <span class="number">0.59988875</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: arr[:,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">45</span>]: array([<span class="number">0.86734388</span>, <span class="number">0.47048728</span>, <span class="number">0.87636748</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: arr[:,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">46</span>]: array([<span class="number">0.86734388</span>, <span class="number">0.47048728</span>, <span class="number">0.87636748</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: arr[:]</span><br><span class="line">Out[<span class="number">47</span>]:</span><br><span class="line">array([[<span class="number">0.23061655</span>, <span class="number">0.86734388</span>, <span class="number">0.27967631</span>],</span><br><span class="line">       [<span class="number">0.63734555</span>, <span class="number">0.47048728</span>, <span class="number">0.04833744</span>],</span><br><span class="line">       [<span class="number">0.99362969</span>, <span class="number">0.87636748</span>, <span class="number">0.59988875</span>]])</span><br></pre></td></tr></table></figure><ul><li><strong>배열의 일부(subset)는 원본배열의 View 이기 때문에 파이썬 <code>list</code> 와 달리 배열의 일부에 대한 변경은 그대로 원본배열에 반영된다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">28</span>]: arr_new = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: arr_new[<span class="number">4</span>:<span class="number">7</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: arr_new</span><br><span class="line">Out[<span class="number">30</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br></pre></td></tr></table></figure><h4 id="boolen-indexing"><a href="#boolen-indexing" class="headerlink" title="boolen indexing"></a>boolen indexing</h4><ul><li>실질적으로 가장 자주쓰는 인덱싱이다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">62</span>]: temp=np.random.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: temp[temp&gt;<span class="number">0.5</span>]</span><br><span class="line">Out[<span class="number">63</span>]:</span><br><span class="line">array([<span class="number">0.77402793</span>, <span class="number">0.59064775</span>, <span class="number">0.67170741</span>, <span class="number">0.51967736</span>, <span class="number">0.75161734</span>,</span><br><span class="line">       <span class="number">0.98559447</span>])</span><br></pre></td></tr></table></figure><h4 id="fancy-indexing"><a href="#fancy-indexing" class="headerlink" title="fancy indexing"></a>fancy indexing</h4><ul><li>인덱싱과 슬라이싱의 차이는 입력된 범위의 값을 가져오느냐 연속된 값들을 가져오느냐의 차이밖에 없다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">56</span>]: array = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">    ...:</span><br><span class="line">    ...: </span><br><span class="line">    ...: array[[<span class="number">0</span>, <span class="number">2</span>], :<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">56</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><h3 id="numpy-배열-변형하기-array-transformation"><a href="#numpy-배열-변형하기-array-transformation" class="headerlink" title="numpy 배열 변형하기(array transformation)"></a>numpy 배열 변형하기(array transformation)</h3><h4 id="Transpose"><a href="#Transpose" class="headerlink" title="Transpose"></a>Transpose</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i = np.transpose(b) Permute array dimensions</span><br><span class="line">i.T Permute array dimensions</span><br></pre></td></tr></table></figure><h4 id="Changing-Array-Shape"><a href="#Changing-Array-Shape" class="headerlink" title="Changing Array Shape"></a>Changing Array Shape</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b.ravel() [[Flatten]] the array</span><br><span class="line">g.reshape(<span class="number">3</span>,-<span class="number">2</span>) [[Reshape]], but don’t change data</span><br><span class="line">b.flatten() <span class="comment"># rabel() 과 같지만 배열의 copy를 생성</span></span><br></pre></td></tr></table></figure><h4 id="np-reshape"><a href="#np-reshape" class="headerlink" title="np.reshape"></a>np.reshape</h4><ul><li><p>n차원 배열 flatten관련해서 특히 중요하다.</p></li><li><p>reshape()의 ‘-1’이 의미는, 변경된 배열의 ‘-1’ 위치의 차원은 “원래 배열의 길이와 남은 차원으로 부터 추정”이 된다는 것이다.</p></li><li><p>-1외의 나머지 차원에 의해서 -1에 해당하는 차원이 결정된다고 생각하면 편하다.</p></li><li><p><code>np.reshape(-1)</code> 인 경우 단순히 1차원 배열을 반환한다.</p></li><li><p>행자리에 -1이 있을 경우(-1,)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure></li></ul><p>In [2]: arr &#x3D; np.arange(1,13)</p><p>In [3]: arr<br>Out[3]: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])</p><p>In [4]: arr.reshape(-1,2)<br>Out[4]:<br>array([[ 1,  2],<br>       [ 3,  4],<br>       [ 5,  6],<br>       [ 7,  8],<br>       [ 9, 10],<br>       [11, 12]])</p><p>In [5]: arr.reshape(-1,3)<br>Out[5]:<br>array([[ 1,  2,  3],<br>       [ 4,  5,  6],<br>       [ 7,  8,  9],<br>       [10, 11, 12]])</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">- 열자리에 -1이 있을 경우</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">In [1]: import numpy as np</span><br><span class="line"></span><br><span class="line">In [2]: arr = np.arange(1,13)</span><br><span class="line"></span><br><span class="line">In [3]: arr.reshape(2,-1)</span><br><span class="line">Out[3]:</span><br><span class="line">array([[ 1,  2,  3,  4,  5,  6],</span><br><span class="line">       [ 7,  8,  9, 10, 11, 12]])</span><br><span class="line"></span><br><span class="line">In [4]: arr.reshape(3,-1)</span><br><span class="line">Out[4]:</span><br><span class="line">array([[ 1,  2,  3,  4],</span><br><span class="line">       [ 5,  6,  7,  8],</span><br><span class="line">       [ 9, 10, 11, 12]])</span><br></pre></td></tr></table></figure><h4 id="Adding-x2F-Removing-Elements"><a href="#Adding-x2F-Removing-Elements" class="headerlink" title="Adding&#x2F;Removing Elements"></a>Adding&#x2F;Removing Elements</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">h.resize((<span class="number">2</span>,<span class="number">6</span>)) Return a new array <span class="keyword">with</span> shape (<span class="number">2</span>,<span class="number">6</span>)</span><br><span class="line">np.append(h,g) Append items to an array</span><br><span class="line">np.insert(a, <span class="number">1</span>, <span class="number">5</span>) Insert items <span class="keyword">in</span> an array</span><br><span class="line">np.delete(a,[<span class="number">1</span>]) Delete items <span class="keyword">from</span> an array</span><br></pre></td></tr></table></figure><h4 id="Combine-array"><a href="#Combine-array" class="headerlink" title="Combine array"></a>Combine array</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">11</span>]: arr_1 = np.arange(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: arr_2 = np.arange(<span class="number">6</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: np.concatenate((arr_1,arr_2),axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">13</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: np.vstack((arr_1,arr_2))</span><br><span class="line">Out[<span class="number">14</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: np.r_[arr_1,arr_2]</span><br><span class="line">Out[<span class="number">15</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: np.hstack((arr_1,arr_2))</span><br><span class="line">Out[<span class="number">16</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: np.c_[arr_1,arr_2]</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><h3 id="Split-array"><a href="#Split-array" class="headerlink" title="Split array"></a>Split array</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">19</span>]: np.hsplit(arr_1,<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">19</span>]: [array([<span class="number">1</span>, <span class="number">2</span>]), array([<span class="number">3</span>, <span class="number">4</span>])]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: arr_3 = np.arange(<span class="number">1</span>,<span class="number">10</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 행 단위 split</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: np.vsplit(arr_3,<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">25</span>]: [array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]), array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]), array([[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])]</span><br></pre></td></tr></table></figure><h3 id="numpy-method"><a href="#numpy-method" class="headerlink" title="numpy method"></a>numpy method</h3><ul><li>위의 3개가 중요하고 그 아래는 그다지 쓸 일이 없다.</li></ul><h4 id="np-where"><a href="#np-where" class="headerlink" title="np.where"></a>np.where</h4><ul><li><code>np.where(조건,if true 값,else 값)</code> 방식으로 사용한다.</li><li>기본적으로 조건에 기반해 새로운 배열을 생성한다.</li><li><strong>logical statement를 vectorize한다.</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Out[<span class="number">63</span>]: df</span><br><span class="line">   A   B   C     D</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: df[<span class="string">&quot;E&quot;</span>] = np.where((df[<span class="string">&quot;B&quot;</span>] &gt; <span class="number">10</span>) &amp; (df[<span class="string">&quot;C&quot;</span>] &gt; <span class="number">10</span>), <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    ...: df</span><br><span class="line">Out[<span class="number">64</span>]:</span><br><span class="line">   A   B   C     D  E</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span>  <span class="number">1</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span>  <span class="number">0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span>  <span class="number">0</span></span><br></pre></td></tr></table></figure><h4 id="np-select"><a href="#np-select" class="headerlink" title="np.select"></a>np.select</h4><ul><li><code>np.where</code>의 multiple condition 버전이다.</li><li>2개 이상의 조건을 한번에 처리해야 할경우 pandas를 사용하는 것 보다 <code>np.select</code>를 활용해 한번에 처리하는 것이 낫다.</li></ul><p><img src="https://i.imgur.com/Z3XHteT.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np select 예시</span></span><br><span class="line">In [<span class="number">65</span>]: conditions = [</span><br><span class="line">    ...:   (df[<span class="string">&quot;B&quot;</span>] &gt;= <span class="number">10</span>) &amp; (df[<span class="string">&quot;A&quot;</span>] == <span class="number">0</span>),</span><br><span class="line">    ...:   (df[<span class="string">&quot;B&quot;</span>] &gt;= <span class="number">10</span>) &amp; (df[<span class="string">&quot;A&quot;</span>] == <span class="number">8</span>)</span><br><span class="line">    ...: ]</span><br><span class="line">    ...: values = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    ...: df[<span class="string">&quot;F&quot;</span>] = np.select(conditions, values, default=<span class="number">0</span>)</span><br><span class="line">    ...: df</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">65</span>]:</span><br><span class="line">   A   B   C     D  E  F</span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>  <span class="number">14</span>  <span class="number">10</span>  <span class="number">0.24</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">8</span>   <span class="number">2</span>  <span class="number">17</span>  <span class="number">0.56</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">18</span>  <span class="number">16</span>  <span class="number">0.12</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>   <span class="number">4</span>  <span class="number">16</span>  <span class="number">0.88</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">9</span>   <span class="number">8</span>  <span class="number">16</span>  <span class="number">0.61</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">7</span>   <span class="number">3</span>  <span class="number">17</span>  <span class="number">0.44</span>  <span class="number">0</span>  <span class="number">0</span></span><br></pre></td></tr></table></figure><h4 id="np-log"><a href="#np-log" class="headerlink" title="np.log"></a>np.log</h4><ul><li>자연로그를 리턴한다.<ul><li>np.log(np.e) 는 1을 리턴한다.</li></ul></li><li>데이터 정규화시 사용.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.log([<span class="number">1</span>, np.e, np.e**<span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">array([  <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">2.</span>, -Inf])</span><br></pre></td></tr></table></figure><h4 id="np-sort-배열-정렬하기"><a href="#np-sort-배열-정렬하기" class="headerlink" title="np.sort(배열 정렬하기)"></a>np.sort(배열 정렬하기)</h4><ul><li><code>np.sort(M)</code> 로 배열을 정렬한다.<ul><li>M.sort() 는 배열 자체를 정렬한 결과를 리턴하지만 <code>np.sort(M)</code>은 배열의 복사본을 정렬해 리턴한다,</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">39</span>]: arr_1d = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">    ...:</span><br><span class="line">    ...: arr_2d = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    ...:</span><br><span class="line">    ...: <span class="built_in">print</span>(arr_1d)</span><br><span class="line">    ...: <span class="built_in">print</span>(arr_2d)</span><br><span class="line">[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">8</span> <span class="number">5</span> <span class="number">2</span> <span class="number">8</span> <span class="number">0</span> <span class="number">3</span> <span class="number">9</span>]</span><br><span class="line">[[<span class="number">8</span> <span class="number">4</span> <span class="number">3</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: <span class="built_in">print</span>(np.sort(arr_1d))</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span> <span class="number">5</span> <span class="number">8</span> <span class="number">8</span> <span class="number">9</span>]</span><br></pre></td></tr></table></figure><ul><li><code>np.sort(M)[::-1]</code> : 역순 정렬</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">41</span>]: <span class="built_in">print</span>(np.sort(arr_1d)[::-<span class="number">1</span>])</span><br><span class="line">[<span class="number">9</span> <span class="number">8</span> <span class="number">8</span> <span class="number">5</span> <span class="number">3</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br></pre></td></tr></table></figure><ul><li>행과 열 기준으로 정렬이 가능하다.<ul><li><code>np.sort(x, axis=1)</code> : 열 기준</li><li><code>np.sort(x, axis=0)</code> : 행 기준</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: <span class="built_in">print</span>(np.sort(arr_2d, axis=<span class="number">0</span>))</span><br><span class="line">    ...: <span class="built_in">print</span>(np.sort(arr_2d, axis=<span class="number">1</span>))</span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">4</span> <span class="number">3</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">8</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]]</span><br><span class="line">[[<span class="number">1</span> <span class="number">3</span> <span class="number">4</span> <span class="number">8</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">4</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure><h4 id="np-pad"><a href="#np-pad" class="headerlink" title="np.pad"></a>np.pad</h4><ul><li>배열을 일정한 고정길이로 만들기 위해 특정한 값으로 채우는 함수.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Z = np.ones((<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">Z.pad(pad_width=<span class="number">1</span>, </span><br><span class="line">      mode=<span class="string">&#x27;constant&#x27;</span>, <span class="comment"># 특정한 값을 지정해서 패딩할 경우</span></span><br><span class="line">      constant_values=<span class="number">0</span>) <span class="comment"># 값 지정</span></span><br><span class="line"></span><br><span class="line">Z      </span><br><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure><ul><li>2차원 배열 패딩</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: m = np.arange(<span class="number">1</span>,<span class="number">9</span>).reshape(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: m</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 행과 열 모두 2개씩 0으로 패딩 </span></span><br><span class="line">In [<span class="number">20</span>]: np.pad(m,((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>)),<span class="string">&#x27;constant&#x27;</span>,constant_values =<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">20</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: np.pad(m,((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>)),<span class="string">&#x27;constant&#x27;</span>,constant_values =<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">21</span>]:</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure><h4 id="np-argwhere"><a href="#np-argwhere" class="headerlink" title="np.argwhere"></a>np.argwhere</h4><ul><li><code>np.argwhere(condition)</code>은 배열에서 조건에 해당하는 값의 인덱스를 리턴한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">&gt;&gt;&gt;x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line">&gt;&gt;&gt;np.argwhere(x&gt;<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure><h3 id="numpy-broadcasting"><a href="#numpy-broadcasting" class="headerlink" title="numpy broadcasting"></a>numpy broadcasting</h3><ul><li><p>numpy의 연산은 기본적으로 같은 크기의 배열간의 연산을 전제한다.</p></li><li><p>하지만 특정 조건을 만족했을 때 numpy는 자동적으로 크기가 다른 배열간의 연산을 수행하기도 하는데 이를 <code>broadcasting</code>이라 한다.</p></li><li><p><code>broadcasting</code> 연산이 성립되기 위한 다음의 3가지 규칙이 존재한다.</p><ul><li><strong>규칙 1: 두 배열의 차원 수가 다를 경우, 크기가 작은 배열의 모양은 맨 앞(왼쪽)에 패딩됨</strong></li><li><strong>규칙 2: 두 배열의 모양이 임의의 차원에서 일치하지 않으면 해당 차원에서 모양이 1인 배열은 다른 모양과 일치하도록 확장됨</strong></li><li><strong>규칙 3: 어떤 차원에서든 크기가 일치하지 않고 둘 다 1과 같지 않으면 오류가 발생.</strong></li></ul></li><li><p><strong>단순히 한쪽의 크기를 맞춰서 연산이 가능하게끔 만드는 것이라고 생각하면 이해하기 쉽다.</strong></p></li></ul><p><img src="https://jakevdp.github.io/PythonDataScienceHandbook/figures/02.05-broadcasting.png"></p><ul><li><code>a</code> 의 차원이 더 작기 때문에 규칙 1,2 에 따라 연산시 <code>a</code> 가 padding 되고 확장됨.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">5</span>]: M = np.ones((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">   ...: a = np.arange(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="built_in">print</span>(M.shape)</span><br><span class="line">(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: <span class="built_in">print</span>(a.shape)</span><br><span class="line">(<span class="number">3</span>,)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: M + a</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: a.shape</span><br><span class="line">Out[<span class="number">9</span>]: (<span class="number">3</span>,)</span><br></pre></td></tr></table></figure><p><strong>ref</strong></p><ul><li><a href="https://numpy.org/doc/stable/index.html">Numpy 공식문서</a></li><li><a href="https://www.datacamp.com/community/blog/python-numpy-cheat-sheet">numpy array transfrormation</a></li><li><a href="https://www.geeksforgeeks.org/numpy-indexing/">numpy indexing</a></li><li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html">numpy broadcasting</a></li><li><a href="https://sparrow.dev/numpy-pad/">numpy padding</a></li><li><a href="https://towardsdatascience.com/3-numpy-functions-to-facilitate-data-analysis-with-pandas-b1ad342a569">numpy select</a></li></ul><h4 id="numpy-통계"><a href="#numpy-통계" class="headerlink" title="numpy 통계"></a>numpy 통계</h4><p><strong>no blog</strong></p><ul><li><p>a.sum() : Array-wise sum</p></li><li><p>a.min() : Array-wise minimum value</p></li><li><p>b.max(axis&#x3D;0) :Maximum value of an array row</p></li><li><p>b.cumsum(axis&#x3D;1): Cumulative sum of the elements</p></li><li><p>a.mean() : Mean</p></li><li><p>b.median() : Median</p></li><li><p>a.corrcoef() :Correlation coefficient</p></li><li><p>np.std(b) : standarddeviation</p></li><li><p>np.histogram : 객체를 구간수로 구분하여 각 구간수에 속하는 빈도수 리턴. <code>np.histogram([1, 2, 1], bins=[0, 1, 2, 3])</code></p></li><li><p>np.bincount : 0부터 가장 큰 값까지 각각의 발생 빈도수를 체크</p></li></ul><h4 id="numpy-boolen"><a href="#numpy-boolen" class="headerlink" title="numpy boolen"></a>numpy boolen</h4><ul><li>no blog</li></ul><h4 id="numpy-선형대수"><a href="#numpy-선형대수" class="headerlink" title="numpy 선형대수"></a>numpy 선형대수</h4><h4 id="numpy-집합-함수들"><a href="#numpy-집합-함수들" class="headerlink" title="numpy 집합 함수들"></a>numpy 집합 함수들</h4><ul><li><code>np.unique</code> 함수 말고 다른 함수는 거의 쓸일이 없다.</li><li><code>np.unique(array)</code> : 고윳값</li><li><code>np.union1d(array,array)</code>: 합집합</li><li><code>np.intersect1d(array,array,assume_unique)</code> : 교집합</li><li><code>np.setdiff1d(arr1, arr2, assume_unique=True)</code> : 차집합</li><li><code>np.setxor1d(arr1, arr2, assume_unique=True)</code> : 대칭차집합(교집합의 여집합)</li></ul><h4 id="numpy-sampling"><a href="#numpy-sampling" class="headerlink" title="numpy sampling"></a>numpy sampling</h4><ul><li><code>np.random.seed</code> : 초기값설정. 재현성 확보</li><li>&#96;np.random.randint : 균일 분포의 정수 난수 1개</li><li><code>np.random.rand</code> : 0부터 1사이의 균일 분포에서 random 다차원 배열 반환</li><li><code>np.random.randn</code> : 가우시안 표준 정규 분포에서 random 다차원 배열 반환</li><li><code>np.random.shuffle</code>: 기존 배열의 순서 섞기</li><li><code>np.random.permutaion</code> : 기존 배열은 냅두고, 순서를 랜덤하게 섞은 배열 객체를 새로 생성</li><li><code>np.random.choice</code> : 1차원 배열로부터 랜덤 복원&#x2F;비복원 추출(replace)</li><li><code>np.bincount</code> : 0 부터 객체x의 최대값인 9까지 각 원소의 빈도수를 계산</li><li><code>binomial</code></li><li><code>normal</code></li><li><code>beta</code></li><li><code>chisqare</code></li><li><code>gamma</code></li></ul><h2 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h2><ul><li>sample df는 무조건 penguins에서 랜덤 샘플링 30개</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">penguins = sns.load_dataset(<span class="string">&quot;penguins&quot;</span>)</span><br><span class="line">df = penguins.sample(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><h3 id="Creating-Pandas-Object"><a href="#Creating-Pandas-Object" class="headerlink" title="Creating Pandas Object"></a>Creating Pandas Object</h3><h4 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h4><h4 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h4><h5 id="DF-methods"><a href="#DF-methods" class="headerlink" title="DF methods"></a>DF methods</h5><ul><li><code>df.values</code> : df의 값을 배열형태로 리턴한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex</span><br><span class="line"><span class="number">221</span>  Gentoo     Biscoe            <span class="number">50.0</span>           <span class="number">16.3</span>              <span class="number">230.0</span>       <span class="number">5700.0</span>    Male</span><br><span class="line"><span class="number">145</span>  Adelie      Dream            <span class="number">39.0</span>           <span class="number">18.7</span>              <span class="number">185.0</span>       <span class="number">3650.0</span>    Male</span><br><span class="line"><span class="number">128</span>  Adelie  Torgersen            <span class="number">39.0</span>           <span class="number">17.1</span>              <span class="number">191.0</span>       <span class="number">3050.0</span>  Female</span><br><span class="line"><span class="number">292</span>  Gentoo     Biscoe            <span class="number">48.2</span>           <span class="number">15.6</span>              <span class="number">221.0</span>       <span class="number">5100.0</span>    Male</span><br><span class="line"><span class="number">89</span>   Adelie      Dream            <span class="number">38.9</span>           <span class="number">18.8</span>              <span class="number">190.0</span>       <span class="number">3600.0</span>  Female</span><br><span class="line"><span class="number">295</span>  Gentoo     Biscoe            <span class="number">48.6</span>           <span class="number">16.0</span>              <span class="number">230.0</span>       <span class="number">5800.0</span>    Male</span><br><span class="line"><span class="number">119</span>  Adelie  Torgersen            <span class="number">41.1</span>           <span class="number">18.6</span>              <span class="number">189.0</span>       <span class="number">3325.0</span>    Male</span><br><span class="line"><span class="number">88</span>   Adelie      Dream            <span class="number">38.3</span>           <span class="number">19.2</span>              <span class="number">189.0</span>       <span class="number">3950.0</span>    Male</span><br><span class="line"><span class="number">338</span>  Gentoo     Biscoe            <span class="number">47.2</span>           <span class="number">13.7</span>              <span class="number">214.0</span>       <span class="number">4925.0</span>  Female</span><br><span class="line"><span class="number">136</span>  Adelie      Dream            <span class="number">35.6</span>           <span class="number">17.5</span>              <span class="number">191.0</span>       <span class="number">3175.0</span>  Female</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: df.values</span><br><span class="line">Out[<span class="number">22</span>]:</span><br><span class="line">array([[<span class="string">&#x27;Gentoo&#x27;</span>, <span class="string">&#x27;Biscoe&#x27;</span>, <span class="number">50.0</span>, <span class="number">16.3</span>, <span class="number">230.0</span>, <span class="number">5700.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Dream&#x27;</span>, <span class="number">39.0</span>, <span class="number">18.7</span>, <span class="number">185.0</span>, <span class="number">3650.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Torgersen&#x27;</span>, <span class="number">39.0</span>, <span class="number">17.1</span>, <span class="number">191.0</span>, <span class="number">3050.0</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Gentoo&#x27;</span>, <span class="string">&#x27;Biscoe&#x27;</span>, <span class="number">48.2</span>, <span class="number">15.6</span>, <span class="number">221.0</span>, <span class="number">5100.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Dream&#x27;</span>, <span class="number">38.9</span>, <span class="number">18.8</span>, <span class="number">190.0</span>, <span class="number">3600.0</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Gentoo&#x27;</span>, <span class="string">&#x27;Biscoe&#x27;</span>, <span class="number">48.6</span>, <span class="number">16.0</span>, <span class="number">230.0</span>, <span class="number">5800.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Torgersen&#x27;</span>, <span class="number">41.1</span>, <span class="number">18.6</span>, <span class="number">189.0</span>, <span class="number">3325.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Dream&#x27;</span>, <span class="number">38.3</span>, <span class="number">19.2</span>, <span class="number">189.0</span>, <span class="number">3950.0</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Gentoo&#x27;</span>, <span class="string">&#x27;Biscoe&#x27;</span>, <span class="number">47.2</span>, <span class="number">13.7</span>, <span class="number">214.0</span>, <span class="number">4925.0</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line">       [<span class="string">&#x27;Adelie&#x27;</span>, <span class="string">&#x27;Dream&#x27;</span>, <span class="number">35.6</span>, <span class="number">17.5</span>, <span class="number">191.0</span>, <span class="number">3175.0</span>, <span class="string">&#x27;Female&#x27;</span>]],</span><br><span class="line">      dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure><ul><li>df.columns : 컬럼 라벨을 반환한다.<ul><li>대개의 경우 list로 변환해서 사용한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">26</span>]: df.columns</span><br><span class="line">Out[<span class="number">26</span>]:</span><br><span class="line">Index([<span class="string">&#x27;species&#x27;</span>, <span class="string">&#x27;island&#x27;</span>, <span class="string">&#x27;bill_length_mm&#x27;</span>, <span class="string">&#x27;bill_depth_mm&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;flipper_length_mm&#x27;</span>, <span class="string">&#x27;body_mass_g&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>],</span><br><span class="line">      dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: df.columns.tolist()</span><br><span class="line">Out[<span class="number">27</span>]:</span><br><span class="line">[<span class="string">&#x27;species&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;island&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;bill_length_mm&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;bill_depth_mm&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;flipper_length_mm&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;body_mass_g&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sex&#x27;</span>]</span><br></pre></td></tr></table></figure><h5 id="DF-생성하기"><a href="#DF-생성하기" class="headerlink" title="DF 생성하기"></a>DF 생성하기</h5><table><thead><tr><th align="right">Age</th><th align="right">CustomerID</th><th align="left">Genre</th></tr></thead><tbody><tr><td align="right">19</td><td align="right">1</td><td align="left">Male</td></tr><tr><td align="right">21</td><td align="right">2</td><td align="left">Male</td></tr><tr><td align="right">20</td><td align="right">3</td><td align="left">Female</td></tr><tr><td align="right">23</td><td align="right">4</td><td align="left">Female</td></tr><tr><td align="right">31</td><td align="right">5</td><td align="left">Female</td></tr></tbody></table><p><strong>Collection to DataFrame</strong></p><ul><li>Dictionary to DataFrame</li></ul><p>기본적으로 하나의 row가 하나의 dictionary형태로 list에 들어간다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data=&#123;<span class="string">&#x27;Age&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">19</span>, <span class="number">1</span>: <span class="number">21</span>, <span class="number">2</span>: <span class="number">20</span>, <span class="number">3</span>: <span class="number">23</span>, <span class="number">4</span>: <span class="number">31</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;CustomerID&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">1</span>, <span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">3</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">5</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;Genre&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;Female&#x27;</span>&#125;&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br></pre></td></tr></table></figure><ul><li>Tuple to DataFrame</li></ul><p>Tuple은 분석단계에서보다는 DataBase와 연결해서 CRUD할 일이 있을 경우 자주 사용된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data=[(<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data, columns=[<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;ID&#x27;</span>, <span class="string">&#x27;Gender&#x27;</span>])</span><br></pre></td></tr></table></figure><ul><li>List to DataFrame</li></ul><p>list의 경우 <code>list(zip(lst, lst2, lst3))</code> 로 tuple 형태로 데이터를 변환해준 뒤 DF를 만든다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(<span class="built_in">list</span>(<span class="built_in">zip</span>(lst, lst2, lst3)),</span><br><span class="line">               columns=[<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;ID&#x27;</span>, <span class="string">&#x27;Gender&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><strong>DataFrame to Collection</strong></p><p>반대로 DataFrame에서 Python 기본 자료형을 받아야와 할 경우도 있다.</p><p>이 경우는 pandas library에서 제공하는 함수들을 통해 쉽게 해결할 수 있다.</p><ul><li>Dataframe to Ditonary</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.to_dict()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&#123;<span class="string">&#x27;Age&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">19</span>, <span class="number">1</span>: <span class="number">21</span>, <span class="number">2</span>: <span class="number">20</span>, <span class="number">3</span>: <span class="number">23</span>, <span class="number">4</span>: <span class="number">31</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;CustomerID&#x27;</span>: &#123;<span class="number">0</span>: <span class="number">1</span>, <span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">3</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">5</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;Genre&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;Male&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;Female&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;Female&#x27;</span>&#125;&#125;</span><br></pre></td></tr></table></figure><ul><li>Dataframe to Tuple</li></ul><p><code>itertuple()</code>을 사용할 시 name을 default로 넣으면 컬럼명도 같이 반환된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>(df.itertuples(index=<span class="literal">False</span>,name=<span class="literal">None</span>)) <span class="comment"># df to tuple</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;[(<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>),</span><br><span class="line"> (<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>),</span><br><span class="line"> (<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>)]</span><br></pre></td></tr></table></figure><ul><li>DataFrame to List</li></ul><p>컬럼을 list로 변환</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.columns.values.tolist()</span><br></pre></td></tr></table></figure><p>값을 list로 변환</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.values.tolist()</span><br><span class="line"></span><br><span class="line">&gt;&gt;[[<span class="number">19</span>, <span class="number">1</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line"> [<span class="number">21</span>, <span class="number">2</span>, <span class="string">&#x27;Male&#x27;</span>],</span><br><span class="line"> [<span class="number">20</span>, <span class="number">3</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line"> [<span class="number">23</span>, <span class="number">4</span>, <span class="string">&#x27;Female&#x27;</span>],</span><br><span class="line"> [<span class="number">31</span>, <span class="number">5</span>, <span class="string">&#x27;Female&#x27;</span>]]</span><br></pre></td></tr></table></figure><h3 id="Viewing-Data"><a href="#Viewing-Data" class="headerlink" title="Viewing Data"></a>Viewing Data</h3><ul><li>info</li><li>describe</li><li>shape</li><li>pydatalook</li><li>결측치 이상치 확인</li><li>히스토그램</li><li>pandas profiliing : 반드시 최신버전으로 업데이트 할 것</li><li>type 확인</li></ul><h4 id="type-casting"><a href="#type-casting" class="headerlink" title="type casting"></a>type casting</h4><p><a href="https://stackoverflow.com/questions/40095712/when-to-applypd-to-numeric-and-when-to-astypenp-float64-in-python">https://stackoverflow.com/questions/40095712/when-to-applypd-to-numeric-and-when-to-astypenp-float64-in-python</a></p><ul><li><a href="https://stackoverflow.com/questions/15891038/change-column-type-in-pandas">Type Casting 무지성 카피할 것</a></li></ul><h3 id="Sampling-Data"><a href="#Sampling-Data" class="headerlink" title="Sampling Data"></a>Sampling Data</h3><h3 id="Data-Selection"><a href="#Data-Selection" class="headerlink" title="Data Selection"></a>Data Selection</h3><ul><li><code>filter</code>를 통해 sql 처럼 열 선택</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select columns containing &#x27;a&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: df.<span class="built_in">filter</span>(like=<span class="string">&#x27;a&#x27;</span>,axis=<span class="number">1</span>).head()</span><br><span class="line">   ...:</span><br><span class="line">   ...:</span><br><span class="line">Out[<span class="number">3</span>]:</span><br><span class="line">     island  body_mass_g</span><br><span class="line"><span class="number">167</span>   Dream       <span class="number">4050.0</span></span><br><span class="line"><span class="number">207</span>   Dream       <span class="number">3450.0</span></span><br><span class="line"><span class="number">295</span>  Biscoe       <span class="number">5800.0</span></span><br><span class="line"><span class="number">139</span>   Dream       <span class="number">4250.0</span></span><br><span class="line"><span class="number">106</span>  Biscoe       <span class="number">3750.0</span></span><br></pre></td></tr></table></figure><ul><li>정규식를 활용한 열 필터링</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select columns using regex</span></span><br><span class="line">df.<span class="built_in">filter</span>(regex=<span class="string">&#x27;b$&#x27;</span>,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><code>axis=0</code> 인 경우 index를 기준으로 필터링하기 때문에 index가 문자열인 경우를 제외하면 굳이 쓸 일이 없다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">8</span>]: df</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">       Name  Age</span><br><span class="line"><span class="number">0</span>    Harris   <span class="number">20</span></span><br><span class="line"><span class="number">1</span>    Taylor   <span class="number">27</span></span><br><span class="line"><span class="number">2</span>      Lucy   <span class="number">29</span></span><br><span class="line"><span class="number">3</span>  Nicholas   <span class="number">20</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: df.<span class="built_in">filter</span>(regex=<span class="string">&#x27;1&#x27;</span>,axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">     Name  Age</span><br><span class="line"><span class="number">1</span>  Taylor   <span class="number">27</span></span><br></pre></td></tr></table></figure><h3 id="Reshaping"><a href="#Reshaping" class="headerlink" title="Reshaping"></a>Reshaping</h3><ul><li>테이블 형태 자체를 바꾸기</li></ul><h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><ul><li>파생변수 만들기</li><li>하나의 테이블에서 다른 파생테이블을 만들기 ex) 요약통계량 테이블</li></ul><h4 id="apply"><a href="#apply" class="headerlink" title="apply"></a>apply</h4><h4 id="applymap"><a href="#applymap" class="headerlink" title="applymap"></a>applymap</h4><h4 id="agg"><a href="#agg" class="headerlink" title="agg"></a>agg</h4><h4 id="aggregate"><a href="#aggregate" class="headerlink" title="aggregate"></a>aggregate</h4><h3 id="Maipulation"><a href="#Maipulation" class="headerlink" title="Maipulation"></a>Maipulation</h3><h4 id="Renaming-Colunm"><a href="#Renaming-Colunm" class="headerlink" title="Renaming Colunm"></a>Renaming Colunm</h4><ul><li>특정 칼럼을 대체하기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = df.rename(columns=&#123;<span class="string">&#x27;oldName1&#x27;</span>: <span class="string">&#x27;newName1&#x27;</span>, <span class="string">&#x27;oldName2&#x27;</span>: <span class="string">&#x27;newName2&#x27;</span>&#125;)</span><br><span class="line"><span class="comment"># Or rename the existing DataFrame (rather than creating a copy) </span></span><br><span class="line">df.rename(columns=&#123;<span class="string">&#x27;oldName1&#x27;</span>: <span class="string">&#x27;newName1&#x27;</span>, <span class="string">&#x27;oldName2&#x27;</span>: <span class="string">&#x27;newName2&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="Removing-Column"><a href="#Removing-Column" class="headerlink" title="Removing Column"></a>Removing Column</h4><p><strong>DataFrame의 특정 열 제외하기</strong></p><ul><li><strong>하나의 컬럼을 DF에서 제거할 결우</strong></li></ul><p>기본적으로 두 가지 방법이 있다.</p><p><strong>drop 활용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.drop(column_name, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><strong>.loc 활용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col = [<span class="string">&#x27;사용할&#x27;</span>,<span class="string">&#x27;컬럼&#x27;</span>]</span><br><span class="line"></span><br><span class="line">df.loc[:, df.columns != col]</span><br></pre></td></tr></table></figure><p>drop이 익숙하다보니 좀 더 많이 사용하게 된다.</p><ul><li><strong>여러 컬럼을 DF에서 제거할 경우</strong></li></ul><p><strong>indexing 사용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df.columns[~df.columns.isin([<span class="string">&#x27;지울&#x27;</span>,<span class="string">&#x27;컬럼&#x27;</span>])]]</span><br></pre></td></tr></table></figure><p><strong>difference 사용</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df.columns.difference([<span class="string">&#x27;지울&#x27;</span>, <span class="string">&#x27;칼럼&#x27;</span>])]</span><br></pre></td></tr></table></figure><p>difference가 있는걸 모르고 계속 isin을 써왔다.<br>difference에도 익숙해져야 겠다.</p><p><strong>ref</strong></p><ul><li><a href="https://datascience.stackexchange.com/questions/46434/dataframe-columns-difference-use">https://datascience.stackexchange.com/questions/46434/dataframe-columns-difference-use</a></li></ul><h3 id="Grouping-Data"><a href="#Grouping-Data" class="headerlink" title="Grouping Data"></a>Grouping Data</h3><p><strong>기본적인 용법들</strong></p><ul><li>데이터 불러오기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">   ...: drinks = pd.read_csv(<span class="string">&#x27;http://bit.ly/drinksbycountry&#x27;</span>)</span><br><span class="line">   ...: drinks.head()</span><br><span class="line">Out[<span class="number">1</span>]:</span><br><span class="line">       country  beer_servings  spirit_servings  wine_servings  total_litres_of_pure_alcohol continent</span><br><span class="line"><span class="number">0</span>  Afghanistan              <span class="number">0</span>                <span class="number">0</span>              <span class="number">0</span>                           <span class="number">0.0</span>      Asia</span><br><span class="line"><span class="number">1</span>      Albania             <span class="number">89</span>              <span class="number">132</span>             <span class="number">54</span>                           <span class="number">4.9</span>    Europe</span><br><span class="line"><span class="number">2</span>      Algeria             <span class="number">25</span>                <span class="number">0</span>             <span class="number">14</span>                           <span class="number">0.7</span>    Africa</span><br><span class="line"><span class="number">3</span>      Andorra            <span class="number">245</span>              <span class="number">138</span>            <span class="number">312</span>                          <span class="number">12.4</span>    Europe</span><br><span class="line"><span class="number">4</span>       Angola            <span class="number">217</span>               <span class="number">57</span>             <span class="number">45</span>                           <span class="number">5.9</span>    Africa</span><br></pre></td></tr></table></figure><ul><li>대륙별 beer_servings 평균</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).beer_servings.mean()</span><br><span class="line"></span><br><span class="line">Out[<span class="number">2</span>]:</span><br><span class="line">continent</span><br><span class="line">Africa            <span class="number">61.471698</span></span><br><span class="line">Asia              <span class="number">37.045455</span></span><br><span class="line">Europe           <span class="number">193.777778</span></span><br><span class="line">North America    <span class="number">145.434783</span></span><br><span class="line">Oceania           <span class="number">89.687500</span></span><br><span class="line">South America    <span class="number">175.083333</span></span><br><span class="line">Name: beer_servings, dtype: float64</span><br></pre></td></tr></table></figure><ul><li><code>.agg()</code>와 같은 집계함수를 사용해 한 변수의 여러 요약통계량을 구하는 것이 가능하다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">drinks[drinks.continent==<span class="string">&#x27;Asia&#x27;</span>].beer_servings.agg([<span class="string">&#x27;count&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>])</span><br><span class="line"></span><br><span class="line">Out[<span class="number">3</span>]:</span><br><span class="line">count     <span class="number">44.000000</span></span><br><span class="line">mean      <span class="number">37.045455</span></span><br><span class="line"><span class="built_in">max</span>      <span class="number">247.000000</span></span><br><span class="line"><span class="built_in">min</span>        <span class="number">0.000000</span></span><br><span class="line">Name: beer_servings, dtype: float64</span><br></pre></td></tr></table></figure><ul><li><code>groupby</code>를 통해 대륙별 요약통계량 구하기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).beer_servings.agg([<span class="string">&#x27;count&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>])</span><br><span class="line"></span><br><span class="line">               count        mean  <span class="built_in">max</span>  <span class="built_in">min</span></span><br><span class="line">continent</span><br><span class="line">Africa            <span class="number">53</span>   <span class="number">61.471698</span>  <span class="number">376</span>    <span class="number">0</span></span><br><span class="line">Asia              <span class="number">44</span>   <span class="number">37.045455</span>  <span class="number">247</span>    <span class="number">0</span></span><br><span class="line">Europe            <span class="number">45</span>  <span class="number">193.777778</span>  <span class="number">361</span>    <span class="number">0</span></span><br><span class="line">North America     <span class="number">23</span>  <span class="number">145.434783</span>  <span class="number">285</span>    <span class="number">1</span></span><br><span class="line">Oceania           <span class="number">16</span>   <span class="number">89.687500</span>  <span class="number">306</span>    <span class="number">0</span></span><br><span class="line">South America     <span class="number">12</span>  <span class="number">175.083333</span>  <span class="number">333</span>   <span class="number">93</span></span><br></pre></td></tr></table></figure><ul><li>분석할 칼럼을 지정해주지 않으면 모든 numeric의 평균을 그룹별로 반환한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line">               beer_servings  spirit_servings  wine_servings  total_litres_of_pure_alcohol</span><br><span class="line">continent</span><br><span class="line">Africa             <span class="number">61.471698</span>        <span class="number">16.339623</span>      <span class="number">16.264151</span>                      <span class="number">3.007547</span></span><br><span class="line">Asia               <span class="number">37.045455</span>        <span class="number">60.840909</span>       <span class="number">9.068182</span>                      <span class="number">2.170455</span></span><br><span class="line">Europe            <span class="number">193.777778</span>       <span class="number">132.555556</span>     <span class="number">142.222222</span>                      <span class="number">8.617778</span></span><br><span class="line">North America     <span class="number">145.434783</span>       <span class="number">165.739130</span>      <span class="number">24.521739</span>                      <span class="number">5.995652</span></span><br><span class="line">Oceania            <span class="number">89.687500</span>        <span class="number">58.437500</span>      <span class="number">35.625000</span>                      <span class="number">3.381250</span></span><br><span class="line">South America     <span class="number">175.083333</span>       <span class="number">114.750000</span>      <span class="number">62.416667</span>                      <span class="number">6.308333</span></span><br></pre></td></tr></table></figure><ul><li>group by 시각화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># m</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).mean().plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/KvoD6CS.png">    </p><ul><li>데이터를 long form으로 바꾸고 <code>seaborn</code>을 활용해 구현할수도 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">drinks_melt = pd.melt(drinks, id_vars=[<span class="string">&#x27;country&#x27;</span>, <span class="string">&#x27;continent&#x27;</span>], var_name=<span class="string">&#x27;beberage_type&#x27;</span>, value_name=<span class="string">&#x27;servings&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">4</span>)) <span class="comment"># avoid overlapping</span></span><br><span class="line">sns.barplot(x=<span class="string">&#x27;continent&#x27;</span>, y=<span class="string">&#x27;servings&#x27;</span>, hue=<span class="string">&#x27;beberage_type&#x27;</span>, data=drinks_melt, estimator=np.mean)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="응용-하기"><a href="#응용-하기" class="headerlink" title="응용 하기"></a>응용 하기</h2><ul><li><p>Groupby에서 특정 그룹에 접근하기</p></li><li><p>Groupby에서 특정 그룹에 접근 후 필터링 하기 (filter 사용)</p></li><li><p>pd.cut 을 사용한 파생변수 만들기</p></li><li><p><code>get_group</code>으로 아시아 그룹만 접근</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">drinks.groupby(<span class="string">&#x27;continent&#x27;</span>).get_group(<span class="string">&#x27;Asia&#x27;</span>).head()</span><br><span class="line"></span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">        country  beer_servings  spirit_servings  wine_servings  total_litres_of_pure_alcohol continent</span><br><span class="line"><span class="number">0</span>   Afghanistan              <span class="number">0</span>                <span class="number">0</span>              <span class="number">0</span>                           <span class="number">0.0</span>      Asia</span><br><span class="line"><span class="number">12</span>      Bahrain             <span class="number">42</span>               <span class="number">63</span>              <span class="number">7</span>                           <span class="number">2.0</span>      Asia</span><br><span class="line"><span class="number">13</span>   Bangladesh              <span class="number">0</span>                <span class="number">0</span>              <span class="number">0</span>                           <span class="number">0.0</span>      Asia</span><br><span class="line"><span class="number">19</span>       Bhutan             <span class="number">23</span>                <span class="number">0</span>              <span class="number">0</span>                           <span class="number">0.4</span>      Asia</span><br><span class="line"><span class="number">24</span>       Brunei             <span class="number">31</span>                <span class="number">2</span>              <span class="number">1</span>                           <span class="number">0.6</span>      Asia</span><br></pre></td></tr></table></figure><ul><li>여러 그룹의 통계량을 조건걸어서 구할 경우</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">10</span>]: drinks.groupby([<span class="string">&#x27;wine_servings&#x27;</span>, <span class="string">&#x27;continent&#x27;</span>]).get_group((<span class="number">0</span>, <span class="string">&#x27;Asia&#x27;</span>)).total_litres_of_pure_al</span><br><span class="line">    ...: cohol.<span class="built_in">sum</span>()</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">10</span>]: <span class="number">6.2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pd.cut을 활용한 연속형 변수의 구간화 변수생성</span></span><br><span class="line">drinks[<span class="string">&#x27;Range&#x27;</span>] = drinks.groupby(<span class="string">&#x27;country&#x27;</span>).beer_servings.apply(pd.cut, bins=<span class="number">2</span>)</span><br><span class="line">drinks.head()</span><br></pre></td></tr></table></figure><p>TF를 반환하는 lamba 함수를 작성할 경우 any()나 all()을 써서 값을 반환해줄 필요가 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## filter를 사용한 조건식. 위의 결과와 같은 값을 리턴한다.</span></span><br><span class="line">drinks.groupby([<span class="string">&#x27;wine_servings&#x27;</span>,<span class="string">&#x27;continent&#x27;</span>]).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x : ((x.wine_servings == <span class="number">0</span>) &amp; (x.continent==<span class="string">&#x27;Asia&#x27;</span>) ).<span class="built_in">any</span>()).total_litres_of_pure_alcohol.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><p><strong>ref</strong></p><ul><li><a href="https://www.youtube.com/watch?v=qy0fDqoMJx8">https://www.youtube.com/watch?v=qy0fDqoMJx8</a></li><li><a href="https://pandas.pydata.org/docs/reference/groupby.html">https://pandas.pydata.org/docs/reference/groupby.html</a></li></ul><h3 id="Merging-Joining-and-Concatenating"><a href="#Merging-Joining-and-Concatenating" class="headerlink" title="Merging,Joining and Concatenating"></a>Merging,Joining and Concatenating</h3><ul><li>여러 테이블 합치기</li></ul><h3 id="Exporting-data"><a href="#Exporting-data" class="headerlink" title="Exporting data"></a>Exporting data</h3><ul><li><a href="https://stackoverflow.com/questions/36977223/how-should-i-read-a-csv-file-without-the-unnamed-row-with-pandas">https://stackoverflow.com/questions/36977223/how-should-i-read-a-csv-file-without-the-unnamed-row-with-pandas</a></li></ul><p>두 가지 모두 알아야 함</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.to_csv(<span class="string">&#x27;file.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;file.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="옮길-것들"><a href="#옮길-것들" class="headerlink" title="옮길 것들"></a>옮길 것들</h3><p><strong>DF handling</strong></p><ul><li>index</li><li>values</li><li>columns</li><li>dtypes</li><li>info</li><li>select_dtypes</li><li>loc</li><li>iloc</li><li>insert</li><li>head</li><li>tail</li><li>apply</li><li>applymap</li><li>aggregate</li><li>drop</li><li>rename</li><li>replace</li><li>nsmallest</li><li>nlargest</li><li>sort_values</li><li>sort_index</li><li>value_counts</li><li>describe</li></ul><h3 id="Textdata"><a href="#Textdata" class="headerlink" title="Textdata"></a>Textdata</h3><h4 id="regex"><a href="#regex" class="headerlink" title="regex"></a>regex</h4><h4 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h4><h4 id="match"><a href="#match" class="headerlink" title="match"></a>match</h4><h3 id="Date-and-Time"><a href="#Date-and-Time" class="headerlink" title="Date and Time"></a>Date and Time</h3><h3 id="Miscellaneous"><a href="#Miscellaneous" class="headerlink" title="Miscellaneous"></a>Miscellaneous</h3><h4 id="vlookup"><a href="#vlookup" class="headerlink" title="vlookup"></a>vlookup</h4><ul><li>any()와 all() 관련 함수</li><li>filter</li><li>assign</li><li>pd.cut과 np.digitize를 활용한 연속형 변수의 구간화</li><li>pandas query as dplyr filter</li></ul><h2 id="결측값-처리-Missing-value"><a href="#결측값-처리-Missing-value" class="headerlink" title="결측값 처리(Missing value)"></a>결측값 처리(Missing value)</h2><h3 id="결측치-관련-함수"><a href="#결측치-관련-함수" class="headerlink" title="결측치 관련 함수"></a>결측치 관련 함수</h3><p><strong>Missing data</strong></p><ul><li>isna</li><li>isnull</li><li>notna</li><li>notnull</li><li>dropna</li><li>fillna</li></ul><h3 id="결측치-처리"><a href="#결측치-처리" class="headerlink" title="결측치 처리"></a>결측치 처리</h3><ul><li><p>결측치 파악</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure></li></ul><h1 id="결측치-개수-파악"><a href="#결측치-개수-파악" class="headerlink" title="결측치 개수 파악"></a>결측치 개수 파악</h1><p>df.isnull().sum().to_frame(‘count_nan’)</p><h1 id="결측치-비율-파악"><a href="#결측치-비율-파악" class="headerlink" title="결측치 비율 파악"></a>결측치 비율 파악</h1><p>pd.DataFrame(data&#x3D;df.isnull().sum()&#x2F;len(df),columns&#x3D;[‘nan_ratio’])</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 결측치 제거</span><br><span class="line"></span><br><span class="line">어지간히 데이터가 없는게 아닌 이상 결측데이터는 그냥 날리는 것이 속편하다.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- 결측치 채우기(filna)</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">df[&quot;A&quot;] = df[&quot;A&quot;].fillna(0) # 0으로 채워넣기</span><br><span class="line">df[&quot;WeeklyExercise&quot;] = df[&quot;WeeklyExercise&quot;].fillna(method=&quot;ffill&quot;) # NaN값이 나오기 전 값으로 뒤의 NaN값 채워넣기 (Forward Fill)</span><br><span class="line">df[&quot;Salary&quot;] = df[&quot;Salary&quot;].fillna(df[&quot;Salary&quot;].median()) # 중간값으로 채워넣기</span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure><ul><li>interpolate를 활용한 결측치 채우기</li></ul><h3 id="imputer"><a href="#imputer" class="headerlink" title="imputer"></a>imputer</h3><p>파이프라인 내부의 연산으로 사용</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imputer_numeric = Pipeline(steps=[</span><br><span class="line">    (&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;mean&#x27;)),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><ul><li>단독을 사용학ㄹ 경우</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line"><span class="comment">## default, imputing &#x27;mean&#x27; value</span></span><br><span class="line">imputer = SimpleImputer() </span><br><span class="line">X_train_imputed = imputer.fit_transform(X_train)</span><br><span class="line">X_val_imputed = imputer.transform(X_val)</span><br></pre></td></tr></table></figure><p>무지성 추가</p><p><a href="https://stackoverflow.com/questions/50529022/pandas-melt-unmelt-preserve-index">https://stackoverflow.com/questions/50529022/pandas-melt-unmelt-preserve-index</a><br><a href="https://wikidocs.net/46755">https://wikidocs.net/46755</a><br><a href="https://kongdols-room.tistory.com/170">https://kongdols-room.tistory.com/170</a><br><a href="https://www.tutorialspoint.com/r/r_data_reshaping.html">https://www.tutorialspoint.com/r/r_data_reshaping.html</a><br><a href="https://koreadatascientist.tistory.com/12">https://koreadatascientist.tistory.com/12</a><br><a href="https://j-ungry.tistory.com/118">https://j-ungry.tistory.com/118</a><br><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=yu_seon_kim&logNo=221556994880">https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=yu_seon_kim&amp;logNo=221556994880</a><br><a href="https://blog.naver.com/PostView.naver?blogId=kurtnim&logNo=222271823879">https://blog.naver.com/PostView.naver?blogId=kurtnim&amp;logNo=222271823879</a><br><a href="https://stackoverflow.com/questions/36267745/how-is-a-pandas-crosstab-different-from-a-pandas-pivot-table">https://stackoverflow.com/questions/36267745/how-is-a-pandas-crosstab-different-from-a-pandas-pivot-table</a><br><a href="https://3months.tistory.com/194">https://3months.tistory.com/194</a><br><a href="https://rfriend.tistory.com/280">https://rfriend.tistory.com/280</a><br><a href="https://dojang.io/mod/page/view.php?id=2360">https://dojang.io/mod/page/view.php?id=2360</a></p><h2 id="Read-x2F-Write-File"><a href="#Read-x2F-Write-File" class="headerlink" title="Read&#x2F;Write File"></a>Read&#x2F;Write File</h2><h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><ul><li>info</li><li>describe</li><li>shape</li><li>pydatalook</li><li>결측치 이상치 확인</li><li>히스토그램</li><li>pandas profiliing</li><li>type 확인</li><li>breeze eda</li><li>시각화를 통한 데이터 구조 파악</li><li>seaborn 기초 시각화</li></ul><h2 id="dlookr"><a href="#dlookr" class="headerlink" title="dlookr"></a>dlookr</h2><p>몇가지 함수만 파이썬 버전으로 가져와서 사용</p><h2 id="pingouin"><a href="#pingouin" class="headerlink" title="pingouin"></a>pingouin</h2><ul><li>pinguin을 활용한 정규성 검정</li></ul><p><a href="https://pingouin-stats.org/">https://pingouin-stats.org/</a></p><h2 id="데이터를-받았을-때-해야하는-것"><a href="#데이터를-받았을-때-해야하는-것" class="headerlink" title="데이터를 받았을 때 해야하는 것"></a>데이터를 받았을 때 해야하는 것</h2><ul><li><a href="https://medium.com/bondata/%EC%B4%88%EC%8B%AC%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-eda-%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8-%EC%8B%A4%EC%8A%B5-62d11f93e17e">EDA가이드라인</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"><span class="comment"># 커널을 구성하다보면 에러는 아니지만, 빨간색 네모 박스 warning이 뜨는 경우를 제거 </span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 라인</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># os 패키지를 통해 현재 디렉토리 위치를 변경하고, read_csv를 더 편리하게 함</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd() <span class="comment"># 현재 디렉토리 파악</span></span><br><span class="line">os.chdir(<span class="string">r&quot;______&quot;</span>) <span class="comment"># 불러오고 싶은 파일이 위치한 주소를 ___에 입력</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># intera</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cheat</span></span><br></pre></td></tr></table></figure><ul><li>한글폰트 시각화 관련</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 다른 노트북 작성할 때도 이 셀만 떼서 사용 가능하다.</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> platform                </span><br><span class="line"></span><br><span class="line"><span class="comment"># 웬만하면 해주는 것이 좋다.</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]= <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> platform.system() == <span class="string">&#x27;Darwin&#x27;</span>: <span class="comment"># 맥os 사용자의 경우에</span></span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-darkgrid&#x27;</span>) </span><br><span class="line">    rc(<span class="string">&#x27;font&#x27;</span>, family = <span class="string">&#x27;AppleGothic&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> platform.system() == <span class="string">&#x27;Windows&#x27;</span>:<span class="comment"># 윈도우 사용자의 경우에</span></span><br><span class="line">    path = <span class="string">&#x27;c:/Windows/Fonts/malgun.ttf&#x27;</span></span><br><span class="line">    font_name = font_manager.FontProperties(fname=path).get_name()</span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-darkgrid&#x27;</span>) <span class="comment"># https://python-graph-gallery.com/199-matplotlib-style-sheets/</span></span><br><span class="line">    rc(<span class="string">&#x27;font&#x27;</span>, family=font_name)</span><br></pre></td></tr></table></figure><ul><li>colab 한글폰트 시각화 관련</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">이후 런타임 재시작</span></span><br><span class="line">!sudo apt-get install -y fonts-nanum</span><br><span class="line">!sudo fc-cache -fv</span><br><span class="line">!rm ~/.cache/matplotlib -rf</span><br></pre></td></tr></table></figure><p>이후 폰트를 나눔폰트로 바꾼다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, family=<span class="string">&#x27;NanumBarunGothic&#x27;</span>) </span><br></pre></td></tr></table></figure><h3 id="DF-확인"><a href="#DF-확인" class="headerlink" title="DF 확인"></a>DF 확인</h3><ul><li><p>df.head()</p></li><li><p>df.shape</p></li><li><p>df.describe()</p></li><li><p>df.dtypes()</p></li><li><p>object type select</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure></li></ul><p>cat_cols &#x3D; df.select_dtypes(‘object’).columns </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- not object type select</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">cat_cols = df.select_dtypes(&#x27;object&#x27;).columns </span><br></pre></td></tr></table></figure><p><strong>데이터가 만약 wide로 되어 있다면 반드시 Long 형태로 바꾼다.</strong><br>시각화에 유용. 어차피 해야한다.</p><p>추가적으로 쓸 수 있는 util</p><h2 id="Descriptive-Stataistics"><a href="#Descriptive-Stataistics" class="headerlink" title="Descriptive Stataistics"></a>Descriptive Stataistics</h2><h3 id="IQR"><a href="#IQR" class="headerlink" title="IQR"></a>IQR</h3><p>IQR 구현</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">[[define]] array of data</span><br><span class="line">data = np.array([<span class="number">14</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">24</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">30</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">36</span>, <span class="number">38</span>, <span class="number">44</span>, <span class="number">47</span>])</span><br><span class="line"></span><br><span class="line">[[calculate]] interquartile <span class="built_in">range</span> </span><br><span class="line">q3, q1 = np.percentile(data, [<span class="number">75</span> ,<span class="number">25</span>])</span><br><span class="line">iqr = q3 - q1</span><br><span class="line"></span><br><span class="line">[[display]] interquartile <span class="built_in">range</span> </span><br><span class="line">iqr</span><br><span class="line"></span><br><span class="line"><span class="number">12.25</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">[[create]] data frame</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;rating&#x27;</span>: [<span class="number">90</span>, <span class="number">85</span>, <span class="number">82</span>, <span class="number">88</span>, <span class="number">94</span>, <span class="number">90</span>, <span class="number">76</span>, <span class="number">75</span>, <span class="number">87</span>, <span class="number">86</span>],</span><br><span class="line">                   <span class="string">&#x27;points&#x27;</span>: [<span class="number">25</span>, <span class="number">20</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">27</span>, <span class="number">20</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">14</span>, <span class="number">19</span>],</span><br><span class="line">                   <span class="string">&#x27;assists&#x27;</span>: [<span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">5</span>],</span><br><span class="line">                   <span class="string">&#x27;rebounds&#x27;</span>: [<span class="number">11</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">7</span>]&#125;)</span><br><span class="line"></span><br><span class="line">[[define]] function to calculate interquartile <span class="built_in">range</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_iqr</span>(<span class="params">x</span>):</span><br><span class="line">  <span class="keyword">return</span> np.subtract(*np.percentile(x, [<span class="number">75</span>, <span class="number">25</span>]))</span><br></pre></td></tr></table></figure><h3 id="단일변수-분석"><a href="#단일변수-분석" class="headerlink" title="단일변수 분석"></a>단일변수 분석</h3><ul><li>주요 feature나 target에 대해 분포 파악</li><li>단순히 시행을 하는데서 그치지 않고 해석 보태기</li><li>통계량 파악</li></ul><h3 id="상관관계-분석"><a href="#상관관계-분석" class="headerlink" title="상관관계 분석"></a>상관관계 분석</h3><h2 id="Type-Checking-amp-Casting-데이터-타입변환"><a href="#Type-Checking-amp-Casting-데이터-타입변환" class="headerlink" title="Type Checking &amp; Casting (데이터 타입변환)"></a>Type Checking &amp; Casting (데이터 타입변환)</h2><h3 id="Type-Checeking"><a href="#Type-Checeking" class="headerlink" title="Type Checeking"></a>Type Checeking</h3><p><a href="https://stackoverflow.com/questions/15891038/change-column-type-in-pandas">https://stackoverflow.com/questions/15891038/change-column-type-in-pandas</a></p><h2 id="Reshaping-데이터-재구조화"><a href="#Reshaping-데이터-재구조화" class="headerlink" title="Reshaping(데이터 재구조화)"></a>Reshaping(데이터 재구조화)</h2><ul><li><p>pivot : unmelt. long to wide</p></li><li><p>melt : wide to long</p></li><li><p>pivot_table</p></li><li><p>crosstab</p></li><li><p>stack</p></li><li><p>멀티 인덱싱 변환하기(Single 인덱스로 바꾸기)</p></li><li><p>컬럼에 있을 경우 hirerachical-index라고 한다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df.columns = df.columns.get_level_values(<span class="number">0</span>) <span class="comment"># 첫번째 컬럼으로 사용</span></span><br><span class="line"></span><br><span class="line">df.columns = [<span class="string">&#x27; &#x27;</span>.join(col).strip() <span class="keyword">for</span> col <span class="keyword">in</span> df.columns.values] <span class="comment"># flattening and renaming</span></span><br><span class="line"></span><br><span class="line">dat.columns = [<span class="string">&quot;_&quot;</span>.join(a) <span class="keyword">for</span> a <span class="keyword">in</span> dat.columns.to_flat_index()] <span class="comment"># flattening and renaming 최신버전</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/14507794/pandas-how-to-flatten-a-hierarchical-index-in-columns</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/26323926/pandas-groupby-agg-how-to-return-results-without-the-multi-index</span></span><br></pre></td></tr></table></figure><ul><li>멀티인덱싱 사용(쓸일 거의 없음)</li><li>dictionary to dataframe</li><li>list to dataframe</li><li><a href="https://stackoverflow.com/questions/18837262/convert-python-dict-into-a-dataframe">https://stackoverflow.com/questions/18837262/convert-python-dict-into-a-dataframe</a></li></ul><h2 id="데이터-클리닝-missign"><a href="#데이터-클리닝-missign" class="headerlink" title="데이터 클리닝(missign)"></a>데이터 클리닝(missign)</h2><ul><li>결측치 확인</li><li>결측치 삭제</li><li>결측치 대체</li></ul><h2 id="텍스트-데이터-전처리"><a href="#텍스트-데이터-전처리" class="headerlink" title="텍스트 데이터 전처리"></a>텍스트 데이터 전처리</h2><h2 id="시계열-데이터-전처리"><a href="#시계열-데이터-전처리" class="headerlink" title="시계열 데이터 전처리"></a>시계열 데이터 전처리</h2><h2 id="연관성-검정"><a href="#연관성-검정" class="headerlink" title="연관성 검정"></a>연관성 검정</h2><h3 id="numerical-data-상관분석-다중공선성-겸정"><a href="#numerical-data-상관분석-다중공선성-겸정" class="headerlink" title="numerical data : 상관분석, 다중공선성 겸정"></a>numerical data : 상관분석, 다중공선성 겸정</h3><h3 id="categorical-data-독립성-검정"><a href="#categorical-data-독립성-검정" class="headerlink" title="categorical data : 독립성 검정"></a>categorical data : 독립성 검정</h3>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> preprocessing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/preprocessing/deal/"/>
      <url>/2023/10/28/machine-learning/notebook/preprocessing/deal/</url>
      
        <content type="html"><![CDATA[<h3 id="Pad-zeroes-to-a-string"><a href="#Pad-zeroes-to-a-string" class="headerlink" title="Pad zeroes to a string"></a>Pad zeroes to a string</h3><ul><li><a href="https://stackoverflow.com/questions/339007/how-to-pad-zeroes-to-a-string">https://stackoverflow.com/questions/339007/how-to-pad-zeroes-to-a-string</a></li></ul><h3 id="pd-get-dummies"><a href="#pd-get-dummies" class="headerlink" title="pd.get_dummies"></a>pd.get_dummies</h3><ul><li><a href="https://mizykk.tistory.com/13">https://mizykk.tistory.com/13</a></li></ul><h3 id="drop-multiple-columns"><a href="#drop-multiple-columns" class="headerlink" title="drop multiple columns"></a>drop multiple columns</h3><ul><li><a href="https://www.geeksforgeeks.org/how-to-drop-one-or-multiple-columns-in-pandas-dataframe/">https://www.geeksforgeeks.org/how-to-drop-one-or-multiple-columns-in-pandas-dataframe/</a></li></ul><h3 id="filtering-out-nan"><a href="#filtering-out-nan" class="headerlink" title="filtering out nan"></a>filtering out nan</h3><ul><li><a href="https://stackoverflow.com/questions/22551403/python-pandas-filtering-out-nan-from-a-data-selection-of-a-column-of-strings">https://stackoverflow.com/questions/22551403/python-pandas-filtering-out-nan-from-a-data-selection-of-a-column-of-strings</a></li></ul><h3 id="Conditional-Creation-of-columns"><a href="#Conditional-Creation-of-columns" class="headerlink" title="Conditional Creation of columns"></a>Conditional Creation of columns</h3><ul><li><a href="https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column">https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column</a></li></ul><h3 id="Numpy-연습"><a href="#Numpy-연습" class="headerlink" title="Numpy 연습"></a>Numpy 연습</h3><ul><li><a href="https://github.com/rougier/numpy-100.git">https://github.com/rougier/numpy-100.git</a></li></ul><h3 id="remove-n-from-list-element"><a href="#remove-n-from-list-element" class="headerlink" title="remove n from list element"></a>remove n from list element</h3><p><a href="https://stackoverflow.com/questions/3849509/how-to-remove-n-from-a-list-element">https://stackoverflow.com/questions/3849509/how-to-remove-n-from-a-list-element</a></p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> preprocessing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/statitsics/1-probability/"/>
      <url>/2023/10/28/machine-learning/notebook/statitsics/1-probability/</url>
      
        <content type="html"><![CDATA[<h1 id="확률론-기초"><a href="#확률론-기초" class="headerlink" title="확률론 기초"></a>확률론 기초</h1><p>표본공간에서 어떤 사건이 발생할 가능성을 확률이라고 한다.<br>확률은 기본적으로 면적이다.</p><ul><li>프로그래머를 위한 확률과 통계</li></ul><h2 id="확률-Probability"><a href="#확률-Probability" class="headerlink" title="확률(Probability)"></a>확률(Probability)</h2><p>확률 P는 기본적으로 Event 사건과 그에 대응하는 수치에 대한 Mapping 이다.</p><h2 id="표본공간-Sample-Space"><a href="#표본공간-Sample-Space" class="headerlink" title="표본공간 (Sample Space)"></a>표본공간 (Sample Space)</h2><p>: <strong>기본적으로 실험으로부터 나온 모든 결과를 담고있는 집합을 표본공간이라고 한다.</strong></p><h2 id="확률변수-Random-Variable"><a href="#확률변수-Random-Variable" class="headerlink" title="확률변수(Random Variable)"></a>확률변수(Random Variable)</h2><p>: <strong>표본공간의 각 요소(사건)와 값을 매핑하는 함수. 정확히는 확률적으로 발생하는 사건을 실수에 매핑하는 함수이디.</strong></p><p><strong>확률 변수는 표본공간 안에서 특정한 확률을 가지고 발생하는 사건을 실수에 매핑한 함수이다.</strong></p><!---a function that associates values of a sample space to a real number.--><p>동전을 2번 던지는 시행에서 표본공간은 {HH,HT,TT,TH} 이다. 이때 변수 X를 동전의 위(Head)가 나올 수 있는 경우의 수로 생각할때 X는 {0,1,2} 의 3가지 값을 가질 수 있다 이때 변수 X를 확률변수라 한다.</p><p>사건에 실수값을 매핑하는 것이 중요한 이유는 이를 통해 불확실성을 가진 확률실험의 결과를 수학적으로 연산하고 모형화 하게끔 바꿔줄 수 있기 때문이다.</p><p>확률변수는 불확실성을 가진 어떤 현상이나 실험의 결과를 숫자로 바꾸는 역할</p><p><strong>보통 표본을 확률변수로 간주한다.</strong></p><h4 id="이산확률변수-descrete-random-variable"><a href="#이산확률변수-descrete-random-variable" class="headerlink" title="이산확률변수(descrete random variable)"></a>이산확률변수(descrete random variable)</h4><p>: 표본공간(Sample Space) 내에서 사건마나 매핑되는 실수 값들이 유한할 경우(Countable) 이산확률변수라고 한다.</p><ul><li>모든 값의 확률이 0과 1사이에 존재한다.</li><li>표기시 P(X&#x3D;x)와 같은 형태로 표기한다.</li></ul><h4 id="연속확률변수-continuous-random-variable"><a href="#연속확률변수-continuous-random-variable" class="headerlink" title="연속확률변수 (continuous random variable)"></a>연속확률변수 (continuous random variable)</h4><p>: <strong>구간 내의 모든 실수 값을 취하는 확률변수(random variable)이다.</strong></p><ul><li>이산확률변수와의 가장 큰 차이는 </li><li><strong>확률이 기본적으로 분포상의 특정구간의 면적에 할당된다.</strong></li></ul><h4 id="확률분포와-머신러닝"><a href="#확률분포와-머신러닝" class="headerlink" title="확률분포와 머신러닝"></a>확률분포와 머신러닝</h4><p>회귀분석 </p><h3 id="기댓값-Expected-Value"><a href="#기댓값-Expected-Value" class="headerlink" title="기댓값(Expected Value)"></a>기댓값(Expected Value)</h3><p>: <strong>확률적 사건에 대한 가중평균으로 각 확률변수와 그 확률변수에 대응하는 확률을 곱한 것을 합산한 값이다. 확률변수의 기대값은 E(X)로 표기한다.</strong></p><p><strong>이산확률분포의 기댓값</strong><br>:<br>이산확률변수의 기댓값은 Sample Space의 각 원소의 가중평균이다.</p><p>$$<br>\text{E}[X]&#x3D;\sum_i x_i P\left(X&#x3D;x_i\right)<br>$$</p><p><strong>연속확률분포의 기댓값</strong></p><p>이산확률변수의 기댓값은 적분을 통해 정의할 수 있다. </p><p>$$<br>\begin{align}<br>\text{E}[X] &#x3D; \int_{-\infty}^{\infty} x f(x) dx<br>\end{align}<br>$$</p><h3 id="분산-Variance"><a href="#분산-Variance" class="headerlink" title="분산(Variance)"></a>분산(Variance)</h3><p>: <strong>데이터가 평균으로부터 흩어진 정도</strong></p><p>분산은 모델의 신뢰도와 관련이 있다. </p><p>확률변수 X의 분산은 X의 기댓값 E[X] 로부터 확률변수가 얼마나 떨어져있는지 그 정도를 제곱한 것의 기댓값과 같다</p><h2 id="확률함수-Probability-funtion"><a href="#확률함수-Probability-funtion" class="headerlink" title="확률함수 (Probability funtion)"></a>확률함수 (Probability funtion)</h2><p>:<strong>확률 변수가 특정한 값을 가질 확률을 나타내는 함수이다</strong>. 아는 확률변수와 그 값이 나올 수 있는 확률을 대응시킨 것이다.(확률변수와 확률의 매핑)</p><p>기본적으로 input이 실수고 output이 그 실수에 대응하는 확률이다.</p><p>$$<br>p&#x3D;f(Real Number)<br>$$</p><ul><li>input이 되는 확률변수의 특징에 따라 **확률질량함수(PMF)**와 **확률밀도함수(PDF)**로 나뉜다.</li></ul><h3 id="PMF-Probability-Mass-Function"><a href="#PMF-Probability-Mass-Function" class="headerlink" title="PMF(Probability Mass Function)"></a>PMF(Probability Mass Function)</h3><p>: 확률함수의 input이 이산형일 때 <strong>확률질량함수</strong>라고 한다. 이산확률변수 X가 취할 수 있는 값들에 대해 각각 확률을 매핑해주는 함수이다.</p><p>$$<br>P(X&#x3D;x_{i})&#x3D;p_{i} (i&#x3D;1,2,3, … n)<br>$$</p><ul><li>확률이 가능성의 크기로 생각하여 일종의 질량으로 간주된다.</li><li>PMF에서 likelyhood와 probability는 개념상 같아진다. 이는</li></ul><p><strong>확률을 생성하는 함수</strong></p><h3 id="CDF-Cumulative-Distribution-Function"><a href="#CDF-Cumulative-Distribution-Function" class="headerlink" title="CDF(Cumulative Distribution Function)"></a>CDF(Cumulative Distribution Function)</h3><p>: </p><p>확률변수 X에 대한 확률을 p(x)라 할 경우 누적분포함수는 다음과 같이 나타난다.</p><p>$$<br>F_{X}(x)&#x3D; p_{X}(X \leq x)<br>$$</p><ul><li>확률변수가 이산형이던 연속형이던 상관없이 CDF로 나타낼 수 있다</li></ul><h3 id="PDF-Probability-Density-Function"><a href="#PDF-Probability-Density-Function" class="headerlink" title="PDF(Probability Density Function)"></a>PDF(Probability Density Function)</h3><p>: 확률함수의 input이 연속형일 경우 <strong>연속확률분포</strong>라 한다.</p><p>구체적으로는 확률 변수가 취하는 값들의 집합이 실수의 구간을 이루면 연속확률분포가 된다.</p><p>PDF에서의 확률은  f(x)dx를 구간내에서 정적분한 값이 PDF의 확률이 된다.<br>-&gt; <strong>PDF에서 확률은 어떤 구간 내의 면적으로 표현된다.</strong></p><p>$$<br>P(a\leq X \leq b) &#x3D; \int_{a}^{b}f(x)dx<br>$$</p><ul><li><p>CDF가 미분가능한 함수로 나타날 경우 연속확률변수이고 이를 미분한것이 PDF이다.</p></li><li><p>dx는 여기서 x의 변화량(기울기) 이므로 구간의 아주 작은 구간을 의미한다.</p></li><li><p>f(x)는 여기서 확률밀도(y축)을 의미한다.</p></li><li><p>따라서 확률이 f(x)가 아니라 f(x)dx가 된다.</p></li><li><p>PDF의 y축은 likelyhood로 특정 데이터 포인트가 고정 되어 있을 때 이 데이터가 어떤 분포로부터 나왔을 지에 대한 확률이다.</p><ul><li>$$<br>L(\theta | Data)<br>$$</li></ul></li></ul><p><img src="/home/jinheonyoon/workspace/ml/notebook/data/images/liklihood.png" alt="img"></p><h2 id="모수-parameter"><a href="#모수-parameter" class="headerlink" title="모수(parameter)"></a>모수(parameter)</h2><p>모수는 모집단(Poppulation)의 특성을 나타나는 값이다.<br>모수는 통계학에서 기본적으로 알 수 없는 값이며 상수이다.</p><h2 id="확률분포-Probability-dis"><a href="#확률분포-Probability-dis" class="headerlink" title="확률분포 (Probability dis)"></a>확률분포 (Probability dis)</h2><p>: <strong>확률분포는 확률변수를 확률에 매핑하는 함수로 확률함수로부터 생성되는 확률값들의 패턴을 의미한다. 기본적으로 일정한 범위에서 어떤 확률변수(random variable)이 가질 수 있는 모든 가능한 확률값을 나열한 것이다.</strong></p><h3 id="이산확률분포-Descrete-Probability-Distribution"><a href="#이산확률분포-Descrete-Probability-Distribution" class="headerlink" title="이산확률분포(Descrete Probability Distribution)"></a>이산확률분포(Descrete Probability Distribution)</h3><p>확률값들의 결과</p><p>이산확률분포의 기대값</p><p>이산확률분포의 분산</p><h4 id="베르누이분포"><a href="#베르누이분포" class="headerlink" title="베르누이분포"></a>베르누이분포</h4><h4 id="이항분포-Binary-Distribution"><a href="#이항분포-Binary-Distribution" class="headerlink" title="이항분포(Binary Distribution)"></a>이항분포(Binary Distribution)</h4><blockquote><p>n번의 독립시행에서 성공 확률이 p일 때의 이산확률분포</p></blockquote><ul><li><p>확률변수 K가 n과 p를 가지는 이항분포를 따른다면, K ~ B(n,p)로 나타낸다.</p></li><li><p>n번 시행 중에 k번 성공할 확률은 확률질량함수로 주어진다.</p></li><li><p>이항분포는 n이 일정수준 이상으로 커질 경우 정규분포에 근사한다.</p></li><li><p>보통 np &gt;&#x3D; 10일 경우 정규분포로 본다.</p></li><li><p><strong>n&#x3D;1일 경우 이항분포는 베르누이 시행이다.</strong></p></li><li><p>심플하게 생각하면 <strong>성공과 실패 두 가지 결과가 있는 확률적 사건을 n번 반복했을때 성공이 몇번 나타날지를 확률분포로 나타낸것이다.</strong></p><ul><li>ex) 성공확률이 주어졌을 때 특정 리뷰데이터가 나올 확률</li></ul></li></ul><p><strong>이항분포 공식</strong></p><ul><li>이항분포를 따르는 확률변수 K가 있을때 n번시행에서 k번 성공할 확률을 나타내는 PMF는 다음과 같다.<ul><li>$\binom{n}{k}$는 단순히 가능한 조합의 수를 나타낸다.</li></ul></li></ul><p>$$<br>P(X &#x3D; k) &#x3D; \binom{n}{k} p^k (1-p)^{n-k}<br>$$</p><ul><li>이항분포의 기댓값은 다음과 같다.</li></ul><p>$$<br>E(K) &#x3D; np<br>$$</p><ul><li>분산은 다음과 같다. 단순히 n번의 독립적인 베르누이 시행의 분산을 더한 것이다,</li></ul><p>$$<br>Var(K) &#x3D; np(1-p)<br>$$</p><p><strong>이항분포의 PMF</strong></p><p align="center"><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtoZzt%2FbtqVdebL4pt%2FmrdViwxudFPtOMDqVmyb2K%2Fimg.png" alt="drawing" width="500"/></p><p><strong>이항분포 구현</strong></p><p>R에서 제공하는 dbinom() 함수를 사용하여 이항분포를 구현할 수 있다.</p><ul><li>dbinom(k,n,p) : 이항분포의 확률값</li><li>pbinom(k,n,p) : 이항분포의 누적확률 값</li><li>qbinom(p,size,prob) : 이항분포의 백분위수. pbinom의 역수</li><li>rbinom(n,size,prob) : 이항분포를 따르는 난수생성</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 주사위를 10번 던져서 원하는 값이 2번 나올 확률 </span></span><br><span class="line">df <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>dice <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> prob <span class="operator">=</span> dbinom<span class="punctuation">(</span>x <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> size <span class="operator">=</span> <span class="number">10</span><span class="punctuation">,</span> prob <span class="operator">=</span> <span class="number">1</span><span class="operator">/</span><span class="number">6</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">df <span class="operator">%&gt;%</span> </span><br><span class="line">  mutate<span class="punctuation">(</span>Dice <span class="operator">=</span> ifelse<span class="punctuation">(</span>dice <span class="operator">==</span> <span class="number">2</span><span class="punctuation">,</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span> <span class="string">&quot;other&quot;</span><span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">%&gt;%</span></span><br><span class="line">  ggplot<span class="punctuation">(</span>aes<span class="punctuation">(</span>x <span class="operator">=</span> factor<span class="punctuation">(</span>dice<span class="punctuation">)</span><span class="punctuation">,</span> y <span class="operator">=</span> prob<span class="punctuation">,</span> fill <span class="operator">=</span> Dice<span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line">  geom_col<span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line">  geom_text<span class="punctuation">(</span></span><br><span class="line">    aes<span class="punctuation">(</span>label <span class="operator">=</span> <span class="built_in">round</span><span class="punctuation">(</span>prob<span class="punctuation">,</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span> y <span class="operator">=</span> prob <span class="operator">+</span> <span class="number">0.01</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">    position <span class="operator">=</span> position_dodge<span class="punctuation">(</span><span class="number">0.9</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">    size <span class="operator">=</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">    vjust <span class="operator">=</span> <span class="number">0</span></span><br><span class="line">  <span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line">  labs<span class="punctuation">(</span>title <span class="operator">=</span> <span class="string">&quot;Probability of X = 2 successes.&quot;</span><span class="punctuation">,</span></span><br><span class="line">       x <span class="operator">=</span> <span class="string">&quot;Successes&quot;</span><span class="punctuation">,</span></span><br><span class="line">       y <span class="operator">=</span> <span class="string">&quot;probability&quot;</span><span class="punctuation">)</span> </span><br></pre></td></tr></table></figure><p><img src="/../data/images/binary_distribution_r.png"></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이항분포가 B(10,0.5)를 따를 경우 P[X&gt;3] 계산 </span></span><br><span class="line">pbinom<span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span> <span class="number">10</span><span class="punctuation">,</span> <span class="number">0.5</span><span class="punctuation">,</span> lower.tail<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span> <span class="comment"># 1-pbinom(3, 10, 0.5) 과 같은 값이 나온다.</span></span><br></pre></td></tr></table></figure><h3 id="연속확률분포-Contiuous-Distribution"><a href="#연속확률분포-Contiuous-Distribution" class="headerlink" title="연속확률분포(Contiuous Distribution)"></a>연속확률분포(Contiuous Distribution)</h3><h4 id="Exponential-Distribution"><a href="#Exponential-Distribution" class="headerlink" title="Exponential Distribution"></a>Exponential Distribution</h4><h4 id="Uniform-Distribution"><a href="#Uniform-Distribution" class="headerlink" title="Uniform Distribution"></a>Uniform Distribution</h4><h4 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h4><p>: 정규분포</p><p>$$<br>N(x;|;\mu, \sigma^2)&#x3D;\dfrac{1}{(2\pi\sigma^2)^{1&#x2F;2}}\exp\left{-\dfrac{1}{2\sigma^2}(x-\mu)^2\right}<br>$$</p><p>다변량 가우시안 분포</p><p>$$<br>N({\bf x}|{\pmb \mu}, {\pmb \Sigma})&#x3D;\dfrac{1}{(2\pi)^{D&#x2F;2}|{\pmb \Sigma}|^{1&#x2F;2}}\exp\left{-\dfrac{1}{2}({\bf x}-{\pmb \mu})^T{\pmb \Sigma}^{-1}({\bf x}-{\pmb \mu})\right}<br>$$</p><p>$$<br>\hat{\theta} &#x3D;  (\textrm{x}^{T} \cdot \textrm{x})^{-1} \cdot \textrm{x}^{T} \cdot\textrm{y}<br>$$</p><p><strong>Z score</strong><br>:</p><ul><li><a href="https://www.researchgate.net/figure/Various-data-types-used-for-quantitative-morphological-phenotyping-Morphological_fig3_359634115">https://www.researchgate.net/figure/Various-data-types-used-for-quantitative-morphological-phenotyping-Morphological_fig3_359634115</a></li></ul><h4 id="Sample-Distribution"><a href="#Sample-Distribution" class="headerlink" title="Sample Distribution"></a>Sample Distribution</h4><p>정규분포가 중요한 이유는 많은 연속형 데이터가 정규분포를 따르기 때문만은 아니다. </p><p>샘플링을 통해 표봅평균을 구해보면 그것들이 따르는 분포가 정규분포인 것이 중요하다.</p><p>이를 표본분포(통계량의 확률분포)라고 한다.</p><p>모수의 확률분포가 정규분포를 따르지 않더라도 </p><h4 id="Exponential-Distribution-지수분포"><a href="#Exponential-Distribution-지수분포" class="headerlink" title="Exponential Distribution(지수분포)"></a>Exponential Distribution(지수분포)</h4><h4 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h4><h3 id="확률분포-사이의-관계"><a href="#확률분포-사이의-관계" class="headerlink" title="확률분포 사이의 관계"></a>확률분포 사이의 관계</h3><h3 id="확률분포의-결정-방법"><a href="#확률분포의-결정-방법" class="headerlink" title="확률분포의 결정 방법"></a>확률분포의 결정 방법</h3><ul><li>데이터는 0 또는 1 뿐이다. → 베르누이분포</li><li>데이터는 0과 1 사이의 실수 값이어야 한다. → 베타분포</li><li>데이터는 항상 0 또는 양수이어야 한다. → 로그정규분포, 감마분포, F분포, 카이제곱분포, 지수분포, 하프코시분포 등</li><li>데이터가 크기 제한이 없는 실수다. → 정규분포 또는 스튜던트 t분포, 코시분포, 라플라스분포 등</li></ul><h3 id="Marginal-Distripution"><a href="#Marginal-Distripution" class="headerlink" title="Marginal Distripution"></a>Marginal Distripution</h3><h3 id="Joint-Distribution"><a href="#Joint-Distribution" class="headerlink" title="Joint Distribution"></a>Joint Distribution</h3>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> statitsics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/statitsics/3-parameter-estimation/"/>
      <url>/2023/10/28/machine-learning/notebook/statitsics/3-parameter-estimation/</url>
      
        <content type="html"><![CDATA[<p><strong>일반선형모델 들어갈 내용</strong><br>generalized linear model의 파라메터는 convex optimization 기법으로 구한다. generalized linear model은 다음 두 가지 속성이 있다.</p><p>최적 generalized linear model의 예측 평균은 학습 데이터 정답의 평균과 같다.<br>최적 로지스틱 회귀 모델이 예측한 확률의 평균은 학습 데이터 정답의 평균과 같다.<br>generalized linear model의 예측력은 피처에 의해 제한된다. 딥러닝 모델과 달리 generalized linear model은 (학습데이터에 없는)새로운 피처를 학습할 수 없다.</p><p><a href="https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html">https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html</a></p><h1 id="Parameter-Estimation"><a href="#Parameter-Estimation" class="headerlink" title="Parameter Estimation"></a>Parameter Estimation</h1><h2 id="Method-of-Moment"><a href="#Method-of-Moment" class="headerlink" title="Method of Moment"></a>Method of Moment</h2><h2 id="Maximum-Likelyhood-Estimation"><a href="#Maximum-Likelyhood-Estimation" class="headerlink" title="Maximum Likelyhood Estimation"></a>Maximum Likelyhood Estimation</h2><p>: Maximum Likelyhood estimation</p><p>데이터 분석에 있어서 가장 핵심적인 컨셉 중의 하나는 우리가 관측한 데이터들이 기본적으로 특정한 확률분포를 따르는 표본(sample)이라는 것이다.<br>여기서 특정한 확률분포의 특성을 나타내는 값을 모수(Parameter)라고 부르고 보통 $\theta$ 라고 쓴다.</p><p>최대우도추정이란 </p><h3 id="합의-법칙"><a href="#합의-법칙" class="headerlink" title="합의 법칙"></a>합의 법칙</h3><p>합의 법칙 예시</p><h3 id="곱의-법칙"><a href="#곱의-법칙" class="headerlink" title="곱의 법칙"></a>곱의 법칙</h3><p>$P(O|\theta)$</p><p>가능도 값을</p><p>$L(\theta|O) &#x3D; P(O|\theta)$</p><p>$$<br>L(\theta ; ; y_1 ,y_2,\cdots ,y_n) &#x3D; \prod_{i&#x3D;1}^n f(\theta ; | ; y_1 ,y_2,\cdots ,y_n )<br>$$</p><h3 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h3><p>가능도를 최대화 한</p><p><strong>MLE는 기본적으로 확률분포의의 추론이다.</strong></p><p>MLE는 관측된 데이터가 나타날 확률을 최대화 하는 $\theta$(모수) 를 찾는 것이 목적이다.</p><p>어떤 데이터를 선택했을 때 그 데이터가 어떤 확률분포로 부터 추출되었을 지를 추정하는 것이다.</p><p>$$<br>\widehat{\theta}&#x3D;\operatorname{argmax}_{\theta} P(D \mid \theta)<br>$$</p><h3 id="MLE-Calculation"><a href="#MLE-Calculation" class="headerlink" title="MLE Calculation"></a>MLE Calculation</h3><p>$$<br>\theta&#x3D;\arg \max P(D \mid \theta)&#x3D;\operatorname{argm} a x_{\theta} \theta a_{n}(1-\theta)^{a_{T}}<br>$$</p><p>log함수는 단조증가(monotonic)하기 때문에 log를 취한 $\widehat{\theta}$ 의 P를 최대화 하는 $\theta$와 log를 취하지 않은 $\widehat{\theta}$의 P를 최대화하는 $\theta$는 결국 같게 된다.</p><p>따라서 수식을 아래와 같이 표현할 수 있다.</p><p>이후 최적화 문제를 풀기위해 미분을 통해 극점(0이되는 지점)을 찾는다.</p><p>$$<br>\frac{d}{d \theta}\left(a_{H} \ln \theta+a_{T} \ln (1-\theta)\right)&#x3D;0$$ $$ \frac{a_{H}}{\theta}-\frac{a_{T}}{1-\theta}&#x3D;0<br>$$</p><p>$$<br>\theta&#x3D;\frac{a_{H}}{a_{T}+a_{H}}<br>$$</p><ul><li>$\theta$는 최종적으로 앞면이 나온 횟수&#x2F;동전을 던진 횟수가 된다.</li></ul><p><strong>Simple Error Bound</strong></p><p>$$<br>P\left(\left|\hat{\theta}-\theta^{*}\right| \geq \varepsilon\right) \leq 2 e^{-2 N \varepsilon^{2}}<br>$$</p><h2 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h2><p>: # Maximum a posteriori estimation</p><p>주어진 관측결과와 사전지식(Prior)를 사용해서 </p><blockquote><p>MLE과 MAP의 차이는 기본적으로 사전확률(Prior)을 </p></blockquote><p><strong>references</strong></p><ul><li><p><a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation</a></p></li><li><p>edwith 문일철교수님 머신러닝 강의</p></li></ul><h1 id="Parameter-Estimation-Concept"><a href="#Parameter-Estimation-Concept" class="headerlink" title="Parameter Estimation Concept"></a>Parameter Estimation Concept</h1><dl><dt><strong>모수를 추정한다는 것의 의미</strong></dt><dd>통계학에서의 모수는 보통 알 수 없는 값이기 때문에 모집단의 일부인 표본(Sample)을 통해 모집단의 특성을 파악한다. 다시말하면 표본의 통계량을 이용해 모수의 추정치를 정의한다.</dd></dl><h2 id="Moment"><a href="#Moment" class="headerlink" title="Moment"></a>Moment</h2><p>적률과 적률생성함수</p><h3 id="적률"><a href="#적률" class="headerlink" title="적률"></a>적률</h3><h3 id="적률생성함수"><a href="#적률생성함수" class="headerlink" title="적률생성함수"></a>적률생성함수</h3><h2 id="Central-Limit-Theory"><a href="#Central-Limit-Theory" class="headerlink" title="Central Limit Theory"></a>Central Limit Theory</h2><p>sample size가 일정 수준 이상 커질 경우 표본평균의 분포는 정규분포에 근사한다.</p><p>표본평균의 적률생성함수가 n이 무한대일 때 생성되는 분포가 정규분포를 따름</p><p><a href="https://m.blog.naver.com/mykepzzang/220851280035">https://m.blog.naver.com/mykepzzang/220851280035</a></p><p align="center"><img src="https://datasciencebook.ca/img/population_vs_sample.png" alt="drawing" width="600"/></p><center><b>모비율 추정의 예시</b></center><p>통계학에서는 보통 $\theta$로 표현된다.<br>머신러닝에서의 모수는 보통 Weight라고 부른다.</p><h3 id="Parametric-Model"><a href="#Parametric-Model" class="headerlink" title="Parametric Model"></a>Parametric Model</h3><p>특정 확률분포를 가정하고 이를 바탕으로 모수를 추정할 경우 Parametric Model(모수적 모델) 이라 한다.<br>선형모델의 경우 모델링 과정에서 정규분포를 가정하기 때문에 Parmetric  Model에 속한다.</p><h3 id="Non-Parametric-Model"><a href="#Non-Parametric-Model" class="headerlink" title="Non-Parametric Model"></a>Non-Parametric Model</h3><p><strong>Unsupervised Parametric Model</strong></p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> statitsics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/statitsics/glm/"/>
      <url>/2023/10/28/machine-learning/notebook/statitsics/glm/</url>
      
        <content type="html"><![CDATA[<p><strong>일반선형모델 들어갈 내용</strong><br>generalized linear model의 파라메터는 convex optimization 기법으로 구한다. generalized linear model은 다음 두 가지 속성이 있다.</p><p>최적 generalized linear model의 예측 평균은 학습 데이터 정답의 평균과 같다.<br>최적 로지스틱 회귀 모델이 예측한 확률의 평균은 학습 데이터 정답의 평균과 같다.<br>generalized linear model의 예측력은 피처에 의해 제한된다. 딥러닝 모델과 달리 generalized linear model은 (학습데이터에 없는)새로운 피처를 학습할 수 없다.</p><p><a href="https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html">https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html</a></p><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> statitsics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/statitsics/survival-analisis/"/>
      <url>/2023/10/28/machine-learning/notebook/statitsics/survival-analisis/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> statitsics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/%EA%B4%80%EB%A0%A8%ED%95%B4%EC%84%9C%20%EC%95%8C%EC%95%84%EC%95%BC%20%ED%95%98%EB%8A%94%20%EA%B0%9C%EB%85%90%EB%93%A4/"/>
      <url>/2023/10/28/machine-learning/notebook/%EA%B4%80%EB%A0%A8%ED%95%B4%EC%84%9C%20%EC%95%8C%EC%95%84%EC%95%BC%20%ED%95%98%EB%8A%94%20%EA%B0%9C%EB%85%90%EB%93%A4/</url>
      
        <content type="html"><![CDATA[<p>관련해서 알아야 하는 개념들</p><p>sample</p><p>population</p><p>probability</p><p>random variable</p><p>이산확률 변수</p><p>probability distribtion</p><p>pmf</p><p>pdf</p><p>cdf</p><p>parameter</p><p>모수를 찾는다는 것의 의미</p><p>In a statistical model, a parameter is a numerical quantity that describes some aspect of the population or process being studied. Parameters are typically unknown and need to be estimated from sample data. </p><p>For example, in a simple linear regression model, the parameter is the slope of the line that best fits the data. In a normal distribution, the parameters are the mean and standard deviation of the distribution. In a logistic regression model, the parameters are the coefficients that describe the relationship between the predictor variables and the outcome variable.</p><p>The choice of parameters in a statistical model depends on the specific problem and the assumptions made about the data-generating process. In some cases, the parameters may be well-defined and have a clear interpretation in terms of the underlying process being studied. In other cases, the parameters may be more abstract and reflect a combination of multiple factors that are difficult to disentangle.</p><p>Estimating the parameters of a statistical model is a fundamental task in statistical inference. The goal is to find the values of the parameters that best explain the observed data and generalize well to new, unseen data. There are many different methods for estimating parameters, including maximum likelihood estimation, Bayesian estimation, and method of moments, among others. The choice of estimation method depends on the specific problem, the nature of the data, and the assumptions made about the underlying process.</p><p>우도의 의미</p><p>In statistics, likelihood refers to the probability of observing a set of data given a particular parameter value or set of parameter values in a statistical model. More specifically, the likelihood function is a function of the parameters of a statistical model that measures how well the model explains the observed data.</p><p>For example, consider a simple coin-flipping experiment. Suppose we have a coin and we want to estimate the probability of getting heads when we flip the coin. We can model this as a binomial distribution with a single parameter, p, representing the probability of getting heads. The likelihood function for this model would be the probability of observing the data we actually observed (i.e., the number of heads and tails) given a particular value of p.</p><p>The likelihood function is an important concept in statistical inference, as it is often used to estimate the parameters of a statistical model. Specifically, the maximum likelihood estimate (MLE) is the value of the parameter(s) that maximize(s) the likelihood function, meaning that it is the value(s) that make the observed data most likely to have been generated by the model.</p><p>It’s important to note that likelihood is not the same thing as probability. Probability refers to the chance of a future event happening, while likelihood refers to the degree of compatibility between the observed data and a particular model or set of parameter values.</p><p>베이즈 정리</p><p>odd </p><p>사전확률 </p><p>사후 확률</p><p>likelyhood</p><p>mle</p><p>map</p><p>gradient descent</p><p>statistical model</p><p>log-likelyhood</p><p>negative loglikeyhood</p><p><a href="https://paul-hyun.github.io/nlp-tutorial-02-04-negative-log-likelihood/">https://paul-hyun.github.io/nlp-tutorial-02-04-negative-log-likelihood/</a></p><p>cross entropy loss</p><p>activation funtion</p><p>softmax function</p><p>entropy</p><p>gini impurity</p><p>기울기 소실</p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/3_bias_variance/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/3_bias_variance/</url>
      
        <content type="html"><![CDATA[<p>lo</p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/3_distance_based_model/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/3_distance_based_model/</url>
      
        <content type="html"><![CDATA[<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><p><strong>KNN</strong></p><ul><li><p>새로운 데이터에 대해 기존 데이터 가운데 가장 가까운 K개 이웃의 정보로 새로운 데이터를 예측하는 방법론.</p></li><li><p>회귀문제와 분류문제 해결에 모두 사용되는 지도학습</p></li><li><p>하이퍼파라미터는 기본적으로 거리측정방법과 탐색할 이웃 수 2가지 이다.</p></li><li><p><strong>K(이웃)을 적게 사용하면 모델 복잡도가 높아지고 많이 사용하면 복잡도가 낮아진다(K의 수를 늘릴수록 결정경계가 부드러워진다.).</strong></p></li><li><p>KNN은 회귀분석에도 쓰이며 여러개의 K를 사용할 경우 이웃들의 종속변수의 평균이 예측된다.</p></li><li><p>거리측정방법</p><ul><li>유클리디안 거리 : 데이터포인트 사이 직선 최단거리</li><li>마할라노비스 거리 : 공분산을 고려해 거리를 계산한다. 변수간 상관관계를 고려한 거리지표.</li><li>맨해튼 거리 : 각 좌표축 방향으로만 이동할 경우 계산된다. 격자모양의 길을 따라간다.</li></ul></li><li><p>주의점</p><ul><li>기본적으로 거리기반이기 때문에 KNN을 돌리기 전 반드시 변수를 정규화 해야 한다.</li><li>불균형 데이터의 분류문제를 풀 경우 학습데이터 범주의 사전확률(Prior Probability)를 고려해야핟다.</li></ul></li><li><p>장단점</p><ul><li>장점 : 학습 데이터 내 노이즈의 영향들 덜받음. 학습데이터가 많으면 효과적 </li><li>단점 : 어떤 거리척도가 분석에 적랍한지 불분명. 계산시간이 오래 걸림</li></ul></li></ul><h3 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h3><ul><li>유클라디안 거리를 활용한 KNN 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">x1,x2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>((x1-x2)**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KNN</span>:</span><br><span class="line"></span><br><span class="line">    self __init__(self, k=<span class="number">3</span>):</span><br><span class="line">        self.k = k </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>): <span class="comment"># triain sample and label</span></span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        predicted_labels = [self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">        <span class="keyword">return</span> np.array</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        1. 거리 계산하기</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        2. k nearest sample</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        3. majority vote, get most common class</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        distances = [euclidean_distance(x,x_train) <span class="keyword">for</span> x_train <span class="keyword">in</span> X_train]</span><br><span class="line"></span><br><span class="line">        k_indices = np.argsort(distances)[:self.k]</span><br><span class="line">        k_nearest_labels = [self.y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> k_indices]</span><br><span class="line"></span><br><span class="line">        most_common = Counter(k_nearest_labels).most_common(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> most_common[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="분류문제-풀이"><a href="#분류문제-풀이" class="headerlink" title="분류문제 풀이"></a>분류문제 풀이</h3><ul><li>iris 데이터를 바탕으로 분류문제 풀이</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">cmap = ListedColormap([<span class="string">&quot;#FF0000&quot;</span>, <span class="string">&quot;#00FF00&quot;</span>, <span class="string">&quot;#0000FF&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    accuracy = np.<span class="built_in">sum</span>(y_true == y_pred) / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">        X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1234</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">clf = KNN(k=k)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">predictions = clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KNN classification 정확도&quot;</span>, accuracy(y_test, predictions))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$KNN</span> classification accuracy 1.0</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>sklearn에서도 knn 분류기가 구현되어 있다.<ul><li>irsis data load까지는 동일하게 진행된다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeiborsClassifier</span><br><span class="line"></span><br><span class="line">clf = KNeiborsClassifier(n_neighbors =<span class="number">3</span>)</span><br><span class="line">clf.fit()</span><br><span class="line"></span><br><span class="line">pred = clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KNN classification 정확도&quot;</span>, clf.score(X_test,y_test))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="K값과-모델-복잡도의-관계"><a href="#K값과-모델-복잡도의-관계" class="headerlink" title="K값과 모델 복잡도의 관계"></a>K값과 모델 복잡도의 관계</h3><ul><li>위스콘신 유방암데이터로 구현한다.</li><li>k의 수가 1개일 때는(적을 때는) train 데이터에 대해서만 예측력이 높고 test에서는 낮은 과적합된 모습을 보인다.</li><li>k의 수가 많을 수록 모델이 단순해지고 train 데이터의 정확도는 줄어든다.</li><li>k의 수가 10개일 때는 모델이 너무 단순해 train과 test모두에서 예측력이 낮은 모습을 보인다.</li><li>중간정도의 범위에서 k의 수를 선정할 필요가 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X_train , X_test , y_train , y_test = train_test_split(cancer.data,</span><br><span class="line">                                                       cancer.target,</span><br><span class="line">                                                       stratify = cancer.target, <span class="comment"># stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해준다. (한 쪽에 쏠려서 분배되는 것을 방지)</span></span><br><span class="line">                                                       random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">train_acc = []</span><br><span class="line">test_acc = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">k_indices = <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_indices:</span><br><span class="line">    clf = KNeiborsClassifier(n_neighbors=k)</span><br><span class="line">    clf.fit()</span><br><span class="line">    train_acc.append(clf.score(X_train,y_train))</span><br><span class="line">    test_acc.append(clf.score(X_test,y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(neighbors_settings, training_accuracy, label=<span class="string">&quot;훈련 정확도&quot;</span>)</span><br><span class="line">plt.plot(neighbors_settings, test_accuracy, label=<span class="string">&quot;테스트 정확도&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;정확도&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;n_neighbors&quot;</span>)</span><br><span class="line">plt.legend(</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://tensorflowkorea.files.wordpress.com/2017/06/2-7.png?w=1024"></p><p><strong>K값 선택하는 로직</strong></p><p>클러스터링이 잘 되었다고 하는 것은 어쨌든 클러스터내부의 유사성이 높다는 것이다.<br>따라서 중심점으로부터 데이터포인트 까지의 거리의 합이 더 이상 유의미하게 줄어들지 않을 때의 k값을 고르는 방식으로 언제 클러스터 세트가 데이터 분산을 가능한 많이 설명하는지 알 수 있다.</p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/7_model_pipeline/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/7_model_pipeline/</url>
      
        <content type="html"><![CDATA[<p>모델 파이프라인 구축 관련 내용 전부</p><p>파이토치 skorch 관련 내용 정리</p>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/tensorflow/</url>
      
        <content type="html"><![CDATA[<h2 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h2><h3 id="Tensor-연산"><a href="#Tensor-연산" class="headerlink" title="Tensor 연산"></a>Tensor 연산</h3><h4 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h4><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>tensor</strong> :</li><li><strong>rank</strong> :</li><li></li></ul><hr><h4 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h4><p>TensorFlow 시스템에서, tensor는 <em>rank</em>라는 차원 단위로 표현된다.<br>Tensor rank는 행렬의 rank와 다르다.<br>Tensor rank(<em>order</em>, <em>degree</em>, <em>-n_dimension</em> 으로도 언급됨)는 tensor의 차원수다.<br>예를 들어, 아래 tensor(Python 리스트로 정의)의 rank는 2다.</p><pre><code>t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]</code></pre><p>rank 2인 tensor는 행렬, rank 1인 tensor는 벡터로 생각할 수 있다.<br>rank 2인 tensor는 <code>t[i, j]</code> 형식으로 원소에 접근할 수 있다.<br>rank 3인 tensor는 <code>t[i, j, k]</code> 형식으로 원소를 지정할 수 있다.</p><h4 id="Shape"><a href="#Shape" class="headerlink" title="Shape"></a>Shape</h4><p>TensorFlow 문서는 tensor 차원을 표현할 때 세 가지 기호를 사용한다. rank, shape, Demension number.<br>아래 표는 그 세 가지의 관계를 보여준다:</p><table><thead><tr><th>Rank</th><th>Shape</th><th>Dimension number</th><th>Example</th></tr></thead><tbody><tr><td>0</td><td>[]</td><td>0-D</td><td>A 0-D tensor.  A scalar.</td></tr><tr><td>1</td><td>[D0]</td><td>1-D</td><td>A 1-D tensor with shape [5].</td></tr><tr><td>2</td><td>[D0, D1]</td><td>2-D</td><td>A 2-D tensor with shape [3, 4].</td></tr><tr><td>3</td><td>[D0, D1, D2]</td><td>3-D</td><td>A 3-D tensor with shape [1, 4, 3].</td></tr><tr><td>n</td><td>[D0, D1, … Dn-1]</td><td>n-D</td><td>A tensor with shape [D0, D1, … Dn-1].</td></tr></tbody></table><h3 id="Tensorflow-전처리-파이프라인-구현"><a href="#Tensorflow-전처리-파이프라인-구현" class="headerlink" title="Tensorflow 전처리 파이프라인 구현"></a>Tensorflow 전처리 파이프라인 구현</h3><p><strong>ref</strong></p><ul><li><a href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">Tensorflow 데이터 로딩 및 전처리 파이프라인 구현하기</a></li></ul><!--tensorflow를 사용하면서 가장 까다로운 부분이 입력데이터 파이프라인 처리해서 모델까지 데이터 흐르는 구간을 만드는게 아닌가 싶다. 데이터의 양이 많을때, 적을때, 그리고 형태에 따라 다양하게 구현을 해야하기 때문에 A라는 방법을 써서 구현하다 보면 모델에 데이터를 넣는 부분이 막힐때가 있다. 그래서 텐서플로우에서 입력데이터를 어떻게 처리해야 하는지에 대한 내용을 정리--><ul><li><strong>Dataset class 확인(tensorflow에서 데이터를 읽을 때 중심이 됨)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">dir</span>(tf.data.Dataset):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (m.startswith(<span class="string">&quot;_&quot;</span>) <span class="keyword">or</span> m.endswith(<span class="string">&quot;_&quot;</span>)):</span><br><span class="line">        func = <span class="built_in">getattr</span>(tf.data.Dataset, m)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(func, <span class="string">&quot;__doc__&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;● &#123;:21s&#125;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(m + <span class="string">&quot;()&quot;</span>, func.__doc__.split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><ul><li><strong>tfds 관련함수들</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">X = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices(X)</span><br><span class="line">dataset</span><br><span class="line"></span><br><span class="line">tf.data.Dataset.Range(<span class="number">10</span>) <span class="comment"># 위와 동일</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset: <span class="comment"># Tensor의 형태를 출력</span></span><br><span class="line">  <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># repeat(): 원본 데이터셋의 아이템을 N차례 반복하는 새로운 데이터셋을 반환 (복사하는 것은 아님)</span></span><br><span class="line"><span class="comment"># batch() : 아이템을 N개의 그룹으로 묶는다</span></span><br><span class="line"><span class="comment"># batch(drop_remainder=True): 마지막에 N보다 부족한 길이의 배치는 버림 (=모든 배치의 크기가 동일)</span></span><br><span class="line">dataset = dataset.repeat(<span class="number">3</span>).batch(<span class="number">7</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터에 원하는 전처리 작업에도 적용 (이미지 크기 변환, 회전계산)</span></span><br><span class="line"><span class="comment"># map(num_parallel_calls) 를 하면 여러개의 스레드로 나누어서 속도를 높여 처리 가능</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># map은 각 아이템에 변환을 적용하지만 apply는 데이터셋 전체에 변환을 적용</span></span><br><span class="line"><span class="comment"># dataset = dataset.apply(tf.data.experimental.unbatch()) # deprecated</span></span><br><span class="line">dataset = dataset.unbatch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter 할때</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(labmda x: x &lt;<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋에 있는 몇개의 아이템만 보고싶을때</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset.take(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure><h4 id="데이터-셔플하기"><a href="#데이터-셔플하기" class="headerlink" title="데이터 셔플하기"></a><strong>데이터 셔플하기</strong></h4><ul><li>경사 하강법은 훈련 세트에 있는 샘플이 독립적이고 동일한 분포일때 최고의 성능을 발휘 (&#x3D;shuffle이 필요한 이유)</li><li>동작순서<ul><li>원본 데이터셋의 처음 아이템을 buffer_size 개수만큼 추출하여 버퍼에 채운다.</li><li>새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내 반환</li><li>원본 데이터셋에서 새로운 아이템을 추출하여 비워진 버퍼를 채운다.</li><li>원본 데이터셋의 모든 아이템이 사용될 때까지 반복</li><li>버퍼가 비워질 때까지 계속하여 랜덤하게 아이템을 반환</li></ul></li><li>버퍼의 크기를 충분히 크게 하는 것이 중요하다. (&#x3D;셔플링 효과를 올리기 위해서), 메모리의 크기를 넘지 않도록, 데이터의 크기를 넘지 않도록</li><li>완벽한 셔플링을 위해서는 버퍼크기가 데이터셋의 크기와 동일</li><li>셔플링되는 순서를 동일하게 만들기 위해 랜덤 시드를 부여<ul><li><strong>반드시 suffle을 먼저 한뒤에 repeat를 해야함</strong></li><li><strong>일단 아래 순서로 할 것 : shuffle , repeat, map, batch</strong></li><li><a href="https://stackoverflow.com/questions/51485781/tf-dataset-api-is-the-following-sequence-correct-map-cache-shuffle-batch-repea">순서레퍼런스</a></li></ul></li></ul><p><strong>ref</strong></p><ul><li><a href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">Tensorflow 데이터 로딩 및 전처리 파이프라인 구현하기</a></li></ul><p>tensorflow를 사용하면서 가장 까다로운 부분이 입력데이터 파이프라인 처리해서 모델까지 데이터 흐르는 구간을 만드는게 아닌가 싶다. 데이터의 양이 많을때, 적을때, 그리고 형태에 따라 다양하게 구현을 해야하기 때문에 A라는 방법을 써서 구현하다 보면 모델에 데이터를 넣는 부분이 막힐때가 있다. 그래서 텐서플로우에서 입력데이터를 어떻게 처리해야 하는지에 대한 내용을 정리</p><ul><li><strong>Dataset class 확인(tensorflow에서 데이터를 읽을 때 중심이 됨)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">dir</span>(tf.data.Dataset):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (m.startswith(<span class="string">&quot;_&quot;</span>) <span class="keyword">or</span> m.endswith(<span class="string">&quot;_&quot;</span>)):</span><br><span class="line">        func = <span class="built_in">getattr</span>(tf.data.Dataset, m)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(func, <span class="string">&quot;__doc__&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;● &#123;:21s&#125;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(m + <span class="string">&quot;()&quot;</span>, func.__doc__.split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><ul><li><strong>tfds 관련함수들</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">X = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices(X)</span><br><span class="line">dataset</span><br><span class="line"></span><br><span class="line">tf.data.Dataset.Range(<span class="number">10</span>) <span class="comment"># 위와 동일</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset: <span class="comment"># Tensor의 형태를 출력</span></span><br><span class="line">  <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># repeat(): 원본 데이터셋의 아이템을 N차례 반복하는 새로운 데이터셋을 반환 (복사하는 것은 아님)</span></span><br><span class="line"><span class="comment"># batch() : 아이템을 N개의 그룹으로 묶는다</span></span><br><span class="line"><span class="comment"># batch(drop_remainder=True): 마지막에 N보다 부족한 길이의 배치는 버림 (=모든 배치의 크기가 동일)</span></span><br><span class="line">dataset = dataset.repeat(<span class="number">3</span>).batch(<span class="number">7</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터에 원하는 전처리 작업에도 적용 (이미지 크기 변환, 회전계산)</span></span><br><span class="line"><span class="comment"># map(num_parallel_calls) 를 하면 여러개의 스레드로 나누어서 속도를 높여 처리 가능</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># map은 각 아이템에 변환을 적용하지만 apply는 데이터셋 전체에 변환을 적용</span></span><br><span class="line"><span class="comment"># dataset = dataset.apply(tf.data.experimental.unbatch()) # deprecated</span></span><br><span class="line">dataset = dataset.unbatch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter 할때</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(labmda x: x &lt;<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋에 있는 몇개의 아이템만 보고싶을때</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset.take(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure><h4 id="데이터-셔플하기-1"><a href="#데이터-셔플하기-1" class="headerlink" title="데이터 셔플하기"></a><strong>데이터 셔플하기</strong></h4><ul><li>경사 하강법은 훈련 세트에 있는 샘플이 독립적이고 동일한 분포일때 최고의 성능을 발휘 (&#x3D;shuffle이 필요한 이유)</li><li>동작순서<ul><li>원본 데이터셋의 처음 아이템을 buffer_size 개수만큼 추출하여 버퍼에 채운다.</li><li>새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내 반환</li><li>원본 데이터셋에서 새로운 아이템을 추출하여 비워진 버퍼를 채운다.</li><li>원본 데이터셋의 모든 아이템이 사용될 때까지 반복</li><li>버퍼가 비워질 때까지 계속하여 랜덤하게 아이템을 반환</li></ul></li><li>버퍼의 크기를 충분히 크게 하는 것이 중요하다. (&#x3D;셔플링 효과를 올리기 위해서), 메모리의 크기를 넘지 않도록, 데이터의 크기를 넘지 않도록</li><li>완벽한 셔플링을 위해서는 버퍼크기가 데이터셋의 크기와 동일</li><li>셔플링되는 순서를 동일하게 만들기 위해 랜덤 시드를 부여<ul><li><strong>반드시 suffle을 먼저 한뒤에 repeat를 해야함</strong></li><li><strong>일단 아래 순서로 할 것 : shuffle , repeat, map, batch</strong></li><li><a href="https://stackoverflow.com/questions/51485781/tf-dataset-api-is-the-following-sequence-correct-map-cache-shuffle-batch-repea">순서레퍼런스</a></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.random.set_seed(<span class="number">42</span>) <span class="comment"># 셔플링 순서를 동일하게</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (2) shuffle하고 repeat</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">3</span>, seed=<span class="number">42</span>).repeat(<span class="number">3</span>).batch(<span class="number">7</span>) <span class="comment"># 반복마다 순서가 달라지도록</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure><h4 id="여러-파일에서-한줄씩-번갈아-읽기"><a href="#여러-파일에서-한줄씩-번갈아-읽기" class="headerlink" title="여러 파일에서 한줄씩 번갈아 읽기"></a>여러 파일에서 한줄씩 번갈아 읽기</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">[[여러]] 파일로 데이터 나누기</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">X_train_full, X_test, y_train_full, y_test = train_test_split(</span><br><span class="line">    housing.data, housing.target.reshape(-<span class="number">1</span>, <span class="number">1</span>), random_state=<span class="number">42</span>)</span><br><span class="line">X_train, X_valid, y_train, y_valid = train_test_split(</span><br><span class="line">    X_train_full, y_train_full, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X_train)</span><br><span class="line">X_mean = scaler.mean_</span><br><span class="line">X_std = scaler.scale_</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_to_multiple_csv_files</span>(<span class="params">data, name_prefix, header=<span class="literal">None</span>, n_parts=<span class="number">10</span></span>):</span><br><span class="line">    housing_dir = os.path.join(<span class="string">&quot;datasets&quot;</span>, <span class="string">&quot;housing&quot;</span>)</span><br><span class="line">    os.makedirs(housing_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    path_format = os.path.join(housing_dir, <span class="string">&quot;my_&#123;&#125;_&#123;:02d&#125;.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    filepaths = []</span><br><span class="line">    m = <span class="built_in">len</span>(data)</span><br><span class="line">    <span class="keyword">for</span> file_idx, row_indices <span class="keyword">in</span> <span class="built_in">enumerate</span>(np.array_split(np.arange(m), n_parts)):</span><br><span class="line">        part_csv = path_format.<span class="built_in">format</span>(name_prefix, file_idx)</span><br><span class="line">        filepaths.append(part_csv)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(part_csv, <span class="string">&quot;wt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">if</span> header <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                f.write(header)</span><br><span class="line">                f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> row_idx <span class="keyword">in</span> row_indices:</span><br><span class="line">                f.write(<span class="string">&quot;,&quot;</span>.join([<span class="built_in">repr</span>(col) <span class="keyword">for</span> col <span class="keyword">in</span> data[row_idx]]))</span><br><span class="line">                f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> filepaths</span><br><span class="line"></span><br><span class="line">train_data = np.c_[X_train, y_train]</span><br><span class="line">valid_data = np.c_[X_valid, y_valid]</span><br><span class="line">test_data = np.c_[X_test, y_test]</span><br><span class="line">header_cols = housing.feature_names + [<span class="string">&quot;MedianHouseValue&quot;</span>]</span><br><span class="line">header = <span class="string">&quot;,&quot;</span>.join(header_cols)</span><br><span class="line"></span><br><span class="line">train_filepaths = save_to_multiple_csv_files(train_data, <span class="string">&quot;train&quot;</span>, header, n_parts=<span class="number">20</span>)</span><br><span class="line">valid_filepaths = save_to_multiple_csv_files(valid_data, <span class="string">&quot;valid&quot;</span>, header, n_parts=<span class="number">10</span>)</span><br><span class="line">test_filepaths = save_to_multiple_csv_files(test_data, <span class="string">&quot;test&quot;</span>, header, n_parts=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">pd.read_csv(train_filepaths[<span class="number">0</span>]).head()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(train_filepaths[<span class="number">0</span>]) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(f.readline(), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">데이터 나눠서 읽기</span><br><span class="line"></span><br><span class="line">filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=<span class="number">42</span>) <span class="comment"># default: shuffle=True</span></span><br><span class="line">n_reader = <span class="number">5</span></span><br><span class="line"><span class="comment"># skip(1): header</span></span><br><span class="line"><span class="comment"># interleave(): filepath_dataset에 있는 다섯개의 파일 경로에서 데이터를 읽는 데이터셋을 생성,TextLineDataset 5개를 순회하면서 한줄씩 읽는다.</span></span><br><span class="line"><span class="comment"># 파일 길이가 동일할때 interleave를 사용하는게 좋음 (각파일에서 한줄씩 읽음)</span></span><br><span class="line"><span class="comment"># num_parallel_calls 매개변수에 원하는 스레드 개수를 지정</span></span><br><span class="line"><span class="comment"># tf.data.experimental.AUTOTUNE: 을 지정하면 텐서플로가 가용한 CPU를 기반으로 동적으로 적절한 스레드 개수를 선택할 수 있다.</span></span><br><span class="line"><span class="comment"># cycle_length: 동시에 처리할 입력 개수를 지정</span></span><br><span class="line">dataset = filepath_dataset.interleave(<span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).sip(<span class="number">1</span>), cycle_length=n_readers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 각 TextLineDataset의 순서가 랜덤으로 첫번째 해당하는 행을 읽음 (순서가 랜덤)</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> dataset.take(<span class="number">5</span>):</span><br><span class="line">  <span class="built_in">print</span>(line.numpy())</span><br></pre></td></tr></table></figure><ul><li>데이터 전처리</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 평균과 표준편차를 미리 계산했다고 가정함</span></span><br><span class="line">X_mean, X_std = [...]</span><br><span class="line">n_inputs = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.fuction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">line</span>):</span><br><span class="line">  defs = [<span class="number">0.</span>] * n_inputs + [tf.constant([], dtype=tf.float32)]</span><br><span class="line">  fields = tf.io.decode_csv(line, record_defaults=defs) <span class="comment"># csv의 한 라인을 받아 파싱</span></span><br><span class="line">  <span class="comment"># stack() 모든 텐서를 쌓아 1D 배열을 생성</span></span><br><span class="line">  x = tf.stack(fields[:-<span class="number">1</span>]) <span class="comment"># &lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)&gt;</span></span><br><span class="line">  y = tf.stack(fields[-<span class="number">1</span>:]) <span class="comment"># &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([7], dtype=int32)&gt;</span></span><br><span class="line">  <span class="keyword">return</span> (x - X_mean) / X_std, y</span><br><span class="line"></span><br><span class="line">preprocess(<span class="string">b&#x27;4.2083, 44.0, 5.332,....&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">record_defaults=[<span class="number">0</span>, np.nan, tf.constant(np.nan, dtype=tf.float64), <span class="string">&quot;Hello&quot;</span>, tf.constant([])]</span><br><span class="line">parsed_fields = tf.io.decode_csv(<span class="string">&#x27;1,2,3,4,5&#x27;</span>, record_defaults)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float64, numpy=3.0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#x27;4&#x27;&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">parsed_fields = tf.io.decode_csv(<span class="string">&#x27;,,,,5&#x27;</span>, record_defaults)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=nan&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float64, numpy=nan&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#x27;Hello&#x27;&gt;,</span></span><br><span class="line"><span class="string"> &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Exception</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    parsed_fields = tf.io.decode_csv(<span class="string">&#x27;,,,,&#x27;</span>, record_defaults) <span class="comment"># case 1</span></span><br><span class="line">    parsed_fields = tf.io.decode_csv(<span class="string">&#x27;1,2,3,4,5,6,7&#x27;</span>, record_defaults) <span class="comment"># case 2</span></span><br><span class="line"><span class="keyword">except</span> tf.errors.InvalidArgumentError <span class="keyword">as</span> ex:</span><br><span class="line">    <span class="built_in">print</span>(ex)</span><br><span class="line"></span><br><span class="line"><span class="comment"># case 1 : Field 4 is required but missing in record 0! [Op:DecodeCSV]</span></span><br><span class="line"><span class="comment"># case 2 : Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]</span></span><br></pre></td></tr></table></figure><h4 id="데이터-적재와-전처리-한번에"><a href="#데이터-적재와-전처리-한번에" class="headerlink" title="데이터 적재와 전처리 한번에"></a>데이터 적재와 전처리 한번에</h4><ul><li><p>위 코드를 재사용하기 위해서 하나의 함수로 생성</p></li><li><p>CSV파일에서 캘리포니아 주택 데이터셋을 효율적으로 적재하고 전처리, 셔플링, 반복, 배치를 적용한 데이터셋을 만들어 반환</p></li><li><p><code>prefetch()</code></p><ul><li>훈련 속도를 더 빠르게</li><li>prefetch(1)을 호출하면 데이터셋은 항상 한 배치가 미리 준비되도록 최선을 (&#x3D;알고리즘이 한 배치로 작업하는 동안 이 데이터셋이 동시에 다음 배치를 준비)</li><li>GPU에서 훈련하는 스텝을 수행하는 것보다 짧은 시간안에 한 배치 데이터를 준비할 수 있다. (&#x3D;GPU 100%활용하는 방법)</li><li>nterleave와 map에 num_parallel_calls을 함께 사용하면 데이터를 적재하고 전처리할때 CPU의 멀티코어를 사용해 더 빠르게 준비 가능</li><li>prefetch는 일반적으로 하나도 충분, tf.data.experimental.AUTOTUNE을 전달하면 텐서플로가 자동으로 결정</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">csv_reader_dataset</span>(<span class="params">filepaths, repeat=<span class="number">1</span>, n_readers=<span class="number">5</span>,</span></span><br><span class="line"><span class="params">                       n_read_threads=<span class="literal">None</span>, shuffle_buffer_size=<span class="number">10000</span>,</span></span><br><span class="line"><span class="params">                       n_parse_threads=<span class="number">5</span>, batch_size=<span class="number">32</span></span>):</span><br><span class="line">    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)</span><br><span class="line">    dataset = dataset.interleave(</span><br><span class="line">        <span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).skip(<span class="number">1</span>),</span><br><span class="line">        cycle_length=n_readers, num_parallel_calls=n_read_threads)</span><br><span class="line">    dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(preprocess, num_parallel_calls=n_parse_threads)</span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> dataset.prefetch(<span class="number">1</span>) <span class="comment"># 학습 성능에 아주 중요한 역할</span></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">train_set = csv_reader_dataset(train_filepaths, batch_size=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> train_set.take(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X =&quot;</span>, X_batch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y =&quot;</span>, y_batch)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><ul><li>csv_reader_dataset()함수로 훈련 세트로 사용할 데이터셋을 만들기</li><li><a href="https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/">https://doubly8f.netlify.app/%EA%B0%9C%EB%B0%9C/2020/08/19/tf-loading-preprocessing-data/</a></li></ul><h2 id="Modeling-with-Keras"><a href="#Modeling-with-Keras" class="headerlink" title="Modeling with Keras"></a>Modeling with Keras</h2><h3 id="Layers-Function"><a href="#Layers-Function" class="headerlink" title="Layers Function"></a>Layers Function</h3><ul><li><a href="https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc">Unit,Shape,Input Shape,Dimention에 대한 자세한 설명</a></li><li><a href="https://github.com/keras-team/keras-docs-ko/blob/master/sources/layers/core.md">Keras 한국어문서</a></li></ul><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>shape</strong> : 배열의 각 차원에 몇개의 요소가 있는지에 대한 정보를 담고있는 tuple<ul><li><code>(40,4,10)</code> 은 1차원에 40개, 2차원에 4개 , 3차원에 10개의 요소들을 담고있는 3차원 텐서를 의미한다.</li></ul></li><li><strong>input_shape</strong> : 기본적으로 첫번째 차원을 제외한 배열의 차원정보.</li><li><strong>unit</strong> : 출력층의 차원 수. output layer의 shape을 결정함.</li><li><strong>kernel</strong> : 층에서 만들어진 <code>가중치 행렬weight matrix</code></li><li><strong>Dense</strong> :<code>activation(dot(input, kernel) + bias)</code> 계산</li><li><strong>Input</strong> : 텐서 생성</li><li><strong>Activation</strong> : 출력값에 활성화함수 적용</li><li><strong>Dropout</strong> : 입력에 Dropout 적용.Dropout은 노드를 지정한 비율만큼 랜덤으로 드롭해서 너무 많은 노드들이 학습\되어 과적합 되는 것을 방지해 준다.노드를 랜덤으로끄고 나머지 노드를 학습을 더 시켜서 퍼포먼스를 향상시킨다.</li><li><strong>Reshape</strong> : 출력을 특정형태로 변환.</li><li><strong>Flatten</strong> : 입력을 1차원 텐서로 변환. batch size에는 영향을 주지 않음.</li><li><strong>Masking</strong> : 시퀀스를 마스킹. 따로 정리</li></ul><hr><h4 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h4><ul><li>케라스 텐서 생성</li><li>케라스 텐서는 백엔드(Theano, TensorFlow 혹은 CNTK)에서 사용되는 텐서에 몇가지 속성을 추가한 것으로, 이를 통해 모델의 입력과 출력을 아는 것만으로도 케라스 모델을 만들 수 있습니다.</li></ul><p>예를 들어 a, b와 c가 케라스 텐서라고 하면 model &#x3D; Model(input&#x3D;[a, b], output&#x3D;c)만으로도 모델을 생성할 수 있습니다.</p><p>케라스 텐서에 추가된 속성은 다음과 같습니다.<br><code>_keras_shape: 케라스의 형태 유추를 통해 전파되는 정수 튜플.</code><br><code>_keras_history: 텐서에 적용되는 마지막 층. 해당 층에서 전체 모델 전체의 그래프를 추출할 수 있습니다.</code></p><p><strong>인자</strong></p><ul><li><code>shape</code>: int로 이루어진 튜플. 배치 축을 포함하지 않습니다. 예를 들어 shape&#x3D;(32,)는 입력이 32차원 벡터의 배치라는 것을 나타냅니다.</li><li><code>batch_shape</code>: int로 이루어진 튜플. 배치 축을 포함합니다. 예를 들어 batch_shape&#x3D;(10, 32)는 입력이 10개의 32차원 벡터로 이루어진 배치라는 것을 나타냅니다. batch_shape&#x3D;(None, 32)는 임의의 수의 32차원 벡터로 이루어진 배치를 뜻합니다.</li><li><code>name</code>: str, 층의 문자열 이름. 모델 내에서 이름은 고유해야 하며 이미 사용한 이름은 다시 사용할 수 없습니다. 따로 지정하지 않을 경우, 자동으로 생성됩니다.</li><li><code>dtype</code>: str, 입력 데이터의 자료형(float32, float64, int32…) 입니다.</li><li><code>sparse</code>: bool, 생성할 플레이스홀더가 희소sparse한지 여부를 나타냅니다.</li><li><code>tensor</code>: 해당 인자가 주어진 경우 Input 층은 해당 텐서의 래퍼로 사용되며, 새로운 플레이스홀더 텐서를 만들지 않습니다.</li></ul><h4 id="Dense"><a href="#Dense" class="headerlink" title="Dense"></a>Dense</h4><ul><li><p><code>output = activation(dot(input, kernel) + bias)을 실행</code> </p><ul><li><code>activation</code>은 activation 인자로 전달되는 원소별element-wise 활성화 함수 </li><li><code>kernel</code>은 층에서 만들어진 <code>가중치 행렬weight matrix</code> </li><li><code>bias</code>는 층에서 만들어진 편향bias 벡터이며 ‘use_bias&#x3D;True’인 경우에만 적용 가능</li></ul></li><li><p>layer의 입력텐서의 rank가 2보다 클 경우 가중치 행렬과 내정을 하기 전에 1d 벡터로 형태를 변환해야함</p></li><li><p><strong>unit(출력층의 차원 수)과 <code>(*,입력층의 차원)</code> 형태의 배열을 인자로 받고 <code>(*,units)</code> 형태의 배열을 출력한다.</strong></p></li><li><p>input_shape 예시</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input_shape = (<span class="number">50</span>,<span class="number">50</span>,<span class="number">3</span>) <span class="comment"># regardless of how many images I have, each image has this shape  </span></span><br><span class="line">input_shape = (<span class="number">50</span>,<span class="number">50</span>,<span class="number">3</span>)</span><br><span class="line">  [[regardless]] of how many images I have, each image has this shape  </span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- Dense 예시</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">model = Sequential([</span><br><span class="line">                   Dense(32, input_shape = (16,))</span><br><span class="line">                   # (*,16)  형태의 배열을 받아서</span><br><span class="line">                   # (*,32) 형태의 배열을 출력한다.</span><br><span class="line">                   Dense(10)</span><br><span class="line">                   ]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dense(units,</span><br><span class="line"> activation=<span class="literal">None</span>,</span><br><span class="line"> use_bias=<span class="literal">True</span>,</span><br><span class="line"> kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line"> bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line"> kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line"> bias_regularizer=<span class="literal">None</span>, </span><br><span class="line"> activity_regularizer=<span class="literal">None</span>, </span><br><span class="line"> kernel_constraint=<span class="literal">None</span>, </span><br><span class="line"> bias_constraint=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p><strong>Dense Parameters</strong></p><ul><li><code>units</code>: 양의 int. 출력값의 차원 크기를 결정.</li><li><code>activation</code>: 사용할 활성화 함수. 기본값은 None이며, 이 경우 활성화 함수가 적용되지 않는다.(a(x) &#x3D; x).</li><li><code>use_bias</code>: bool. 층의 연산에 편향을 적용할지 여부를 결정.</li><li><code>kernel_initializer</code>: kernel 가중치 행렬의 초기화 함수를 결정. 이 가중치는 입력값에 곱해져서 선형변환하는 연산에 사용.</li><li><code>bias_initializer</code>: 편향 벡터의 초기화 함수를 결정.</li><li><code>kernel_regularizer</code>: kernel 가중치 행렬에 적용할 규제 함수regularizer를 결정.</li><li><code>bias_regularizer</code>: 편향 벡터에 적용할 규제 함수를 결정.</li><li><code>activity_regularizer</code>: 층의 출력값에 적용할 규제 함수를 결정.</li><li><code>kernel_constraint</code>: kernel 가중치 행렬에 적용할 제약constraints을 결정. </li><li><code>bias_constraint</code>: 편향 벡터에 적용할 제약을 결정.</li><li><code>units</code>: 양의 int. 출력값의 차원 크기를 결정.</li></ul><h4 id="Activation"><a href="#Activation" class="headerlink" title="Activation"></a>Activation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Activation(activation)</span><br></pre></td></tr></table></figure><ul><li>출력값에 활성화함수 적용</li><li>모델의 첫 번째 층으로 Activation층을 사용하려면 input_shape로 형태를 지정해야 한다.</li><li><code>input_shape</code>는 int로 이루어진 튜플로 <strong>배치 축을 포함하지 않는다.</strong></li></ul><h4 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h4><ul><li>input을 1차원으로 바꾼다.</li><li>layer의 입력텐서의 rank 가 2보다 클 경우 가중치와 내적을 하기 전에 1차원 배열로 형태를 변환할때 사용한다.</li></ul><h4 id="Conv2d"><a href="#Conv2d" class="headerlink" title="Conv2d"></a>Conv2d</h4><h3 id="Sequential-API"><a href="#Sequential-API" class="headerlink" title="Sequential API"></a>Sequential API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model1 = keras.Sequential(</span><br><span class="line">                          []</span><br><span class="line"></span><br><span class="line">                          )</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/unsupervised_learning/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/unsupervised_learning/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/machine-learning/xai/"/>
      <url>/2023/10/28/machine-learning/notebook/machine-learning/xai/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> machine-learning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/timeseries/TimeSeries/"/>
      <url>/2023/10/28/machine-learning/notebook/timeseries/TimeSeries/</url>
      
        <content type="html"><![CDATA[<!---블로그 글 구분용---><p>주요 개념</p><ul><li>시계열 분해<ul><li>추세</li><li>순환</li><li>계절성</li></ul></li><li>승법모형</li><li>가법모형</li></ul><h2 id="시계열-분해"><a href="#시계열-분해" class="headerlink" title="시계열 분해"></a>시계열 분해</h2><p>: 시계열 분해(Time Series Decompositon)</p><h3 id="추세-Trend"><a href="#추세-Trend" class="headerlink" title="추세 (Trend)"></a>추세 (Trend)</h3><h3 id="순환-Cycle"><a href="#순환-Cycle" class="headerlink" title="순환(Cycle)"></a>순환(Cycle)</h3><h3 id="계절성-Seasonality"><a href="#계절성-Seasonality" class="headerlink" title="계절성 (Seasonality)"></a>계절성 (Seasonality)</h3><h3 id="불규칙-변동-Irregular"><a href="#불규칙-변동-Irregular" class="headerlink" title="불규칙 변동(Irregular)"></a>불규칙 변동(Irregular)</h3><p>시계열</p><h2 id="시계열-모형"><a href="#시계열-모형" class="headerlink" title="시계열 모형"></a>시계열 모형</h2><h3 id="가법모형"><a href="#가법모형" class="headerlink" title="가법모형"></a>가법모형</h3><p>$y_t &#x3D; S_t+T_t+R_t + I_t$</p><h3 id="승법모형"><a href="#승법모형" class="headerlink" title="승법모형"></a>승법모형</h3><p>$y_t &#x3D; S_t * T_t*R_t * I_t$</p><h2 id="Refererences"><a href="#Refererences" class="headerlink" title="Refererences"></a>Refererences</h2><ul><li><a href="https://otexts.com/fppkr/index.html">https://otexts.com/fppkr/index.html</a></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> timeseries </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/visualization/Visualization/"/>
      <url>/2023/10/28/machine-learning/notebook/visualization/Visualization/</url>
      
        <content type="html"><![CDATA[<h1 id="문서-분리-기준"><a href="#문서-분리-기준" class="headerlink" title="문서 분리 기준"></a>문서 분리 기준</h1><ul><li>H1 기준으로 문서 분리</li><li>번호 붙일 것</li></ul><h1 id="이-문서에-넣을-것들"><a href="#이-문서에-넣을-것들" class="headerlink" title="이 문서에 넣을 것들"></a>이 문서에 넣을 것들</h1><ul><li>시각화 코드 전부</li><li><h2 id="toobox에-visualization에도-전부-넣기"><a href="#toobox에-visualization에도-전부-넣기" class="headerlink" title="toobox에 visualization에도 전부 넣기"></a>toobox에 visualization에도 전부 넣기</h2></li></ul><p>EDA는 기본적으로 데이터를 처음 받았을 때 하는 일들이다.<br>데이터 전처리랑 겹치는 부분이 있다.<br>EDA는 시각화와 관련이 있다.</p><p>시각화는 분석전후에도 쓰인다.</p><p>여기에는 시각화 관련 전반적인 내용과 시각화 중심의 EDA를 기록한다,</p><p><strong>무지성카피</strong></p><h1 id="데이터를-보고나서-해야할-것"><a href="#데이터를-보고나서-해야할-것" class="headerlink" title="데이터를 보고나서 해야할 것"></a>데이터를 보고나서 해야할 것</h1><p><strong>long 형태로 바꿀 수 있는 데이터라면 반드시 long 형태로 바꾼다.</strong></p><h1 id="분석과정중의-시각화"><a href="#분석과정중의-시각화" class="headerlink" title="분석과정중의 시각화"></a>분석과정중의 시각화</h1><h2 id="사전작업"><a href="#사전작업" class="headerlink" title="사전작업"></a>사전작업</h2><h2 id="pandas-함수들-pandas-utility"><a href="#pandas-함수들-pandas-utility" class="headerlink" title="pandas 함수들 (pandas utility)"></a><strong>pandas 함수들 (pandas utility)</strong></h2><blockquote><p>주요 pandas 함수 기능 정리</p></blockquote><ul><li>shape : DF 차원 파악</li></ul><h4 id="Visualization-나중에-옮길것"><a href="#Visualization-나중에-옮길것" class="headerlink" title="Visualization(나중에 옮길것)"></a>Visualization(나중에 옮길것)</h4><ul><li>plot</li><li>plot.area</li><li>plot.bar</li><li>plot.barh</li><li>plot.box</li><li>plot.density</li><li>plot.hexbin</li><li>plot.hist</li><li>plot.kde</li><li>plot.line</li><li>plot.pie</li><li>plot.scatter</li></ul><h3 id="한글폰트-설정하기"><a href="#한글폰트-설정하기" class="headerlink" title="한글폰트 설정하기"></a>한글폰트 설정하기</h3><ul><li>한글폰트 시각화 관련</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 다른 노트북 작성할 때도 이 셀만 떼서 사용 가능하다.</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> platform                </span><br><span class="line"></span><br><span class="line"><span class="comment"># 웬만하면 해주는 것이 좋다.</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]= <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> platform.system() == <span class="string">&#x27;Darwin&#x27;</span>: <span class="comment"># 맥os 사용자의 경우에</span></span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-darkgrid&#x27;</span>) </span><br><span class="line">    rc(<span class="string">&#x27;font&#x27;</span>, family = <span class="string">&#x27;AppleGothic&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> platform.system() == <span class="string">&#x27;Windows&#x27;</span>:<span class="comment"># 윈도우 사용자의 경우에</span></span><br><span class="line">    path = <span class="string">&#x27;c:/Windows/Fonts/malgun.ttf&#x27;</span></span><br><span class="line">    font_name = font_manager.FontProperties(fname=path).get_name()</span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn-darkgrid&#x27;</span>) <span class="comment"># https://python-graph-gallery.com/199-matplotlib-style-sheets/</span></span><br><span class="line">    rc(<span class="string">&#x27;font&#x27;</span>, family=font_name)</span><br></pre></td></tr></table></figure><ul><li>colab 한글폰트 시각화 관련</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">이후 런타임 재시작</span></span><br><span class="line">!sudo apt-get install -y fonts-nanum</span><br><span class="line">!sudo fc-cache -fv</span><br><span class="line">!rm ~/.cache/matplotlib -rf</span><br></pre></td></tr></table></figure><p>이후 폰트를 나눔폰트로 바꾼다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, family=<span class="string">&#x27;NanumBarunGothic&#x27;</span>) </span><br></pre></td></tr></table></figure><h2 id="plotting"><a href="#plotting" class="headerlink" title="plotting"></a>plotting</h2><h2 id="x범주형-y"><a href="#x범주형-y" class="headerlink" title="x범주형 y"></a>x범주형 y</h2><h3 id="bar-chart"><a href="#bar-chart" class="headerlink" title="bar chart"></a>bar chart</h3><h3 id="correlation-plot"><a href="#correlation-plot" class="headerlink" title="correlation plot"></a>correlation plot</h3><h3 id="raincloudplot"><a href="#raincloudplot" class="headerlink" title="raincloudplot"></a>raincloudplot</h3><ul><li><strong>기본적으로 분포를 보기위한 차트</strong></li></ul><p><strong>tools</strong></p><ul><li><p><a href="https://mjskay.github.io/ggdist/">https://mjskay.github.io/ggdist/</a></p></li><li><p><a href="https://github.com/pog87/PtitPrince">https://github.com/pog87/PtitPrince</a> # 파이썬 버전</p></li><li><p><a href="https://github.com/RainCloudPlots/RainCloudPlots">https://github.com/RainCloudPlots/RainCloudPlots</a></p></li><li><p>기본 베이스는 이거고 여기서 옵션 조절해가며 그릴 것</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>,font_scale=<span class="number">2</span>) <span class="comment"># 조절 가능</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.collections <span class="keyword">as</span> clt</span><br><span class="line"><span class="keyword">import</span> ptitprince <span class="keyword">as</span> pt <span class="comment"># raincloud function</span></span><br><span class="line"></span><br><span class="line">dx=<span class="string">&quot;group&quot;</span>; dy=<span class="string">&quot;score&quot;</span>; dhue = <span class="string">&quot;gr2&quot;</span>; ort=<span class="string">&quot;h&quot;</span>; pal = <span class="string">&quot;Set2&quot;</span>; sigma = <span class="number">.2</span></span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">5</span>)) <span class="comment"># 조절가능</span></span><br><span class="line"></span><br><span class="line">ax=pt.RainCloud(x = dx, y = dy, hue = dhue, data = df, palette = pal, bw = sigma, width_viol = <span class="number">.7</span>,</span><br><span class="line">                ax = ax, orient = ort , alpha = <span class="number">.65</span>, dodge = <span class="literal">True</span>, pointplot = <span class="literal">True</span>, move = <span class="number">.2</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Figure P18\n Shifting the Rain with the Move Parameter&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="분석-이후의-시각화"><a href="#분석-이후의-시각화" class="headerlink" title="분석 이후의 시각화"></a>분석 이후의 시각화</h1><h2 id="예측"><a href="#예측" class="headerlink" title="예측"></a>예측</h2><h3 id="회귀-시각화"><a href="#회귀-시각화" class="headerlink" title="회귀 시각화"></a>회귀 시각화</h3><ul><li>신뢰구간을 포함한 단순선형회귀</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.regplot(x=train[<span class="string">&#x27;GrLivArea&#x27;</span>], y=train[<span class="string">&#x27;SalePrice&#x27;</span>]).set_title(<span class="string">&#x27;Housing Prices&#x27;</span>);</span><br></pre></td></tr></table></figure><ul><li>2d 선형회귀직선과 제곱오차(squared errors)를 확인하기 위한 함수.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_metrics</span>(<span class="params">df, feature, target, slope, intercept</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    2d 선형회귀직선과 제곱오차(squared errors)를 확인하기 위한 함수</span></span><br><span class="line"><span class="string">    df : Pandas 데이터프레임</span></span><br><span class="line"><span class="string">    feature : 특징 열</span></span><br><span class="line"><span class="string">    target : 타겟 열</span></span><br><span class="line"><span class="string">    slope : 선형방정식의 기울기</span></span><br><span class="line"><span class="string">    intercept : 선형방정식의 y 절편</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    x = df[feature]</span><br><span class="line">    y = df[target]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot 데이터</span></span><br><span class="line">    ax = plt.axes()</span><br><span class="line">    df.plot.scatter(feature, target, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 예측</span></span><br><span class="line">    y_pred = slope * x + intercept</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot 예측</span></span><br><span class="line">    ax.plot(x, y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot 제곱오차(MSE)</span></span><br><span class="line">    x_left, x_right = ax.get_xlim() <span class="comment"># x-axis view limits</span></span><br><span class="line">    y_bottom, y_top = ax.get_ylim()</span><br><span class="line">    scale = (x_right - x_left) / (y_top - y_bottom)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> f, t, p <span class="keyword">in</span> <span class="built_in">zip</span>(x, y, y_pred):</span><br><span class="line">        xy = (f, <span class="built_in">min</span>(t, p))</span><br><span class="line">        h = <span class="built_in">abs</span>(t - p)</span><br><span class="line">        w_scaled = h * scale</span><br><span class="line">        ax.add_patch(Rectangle(xy=xy, width=w_scaled, height=h, alpha=<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 회귀방정식 평가지표</span></span><br><span class="line">    mse = mean_squared_error(y, y_pred)</span><br><span class="line">    mae = mean_absolute_error(y, y_pred)</span><br><span class="line">    rmse = mse ** <span class="number">0.5</span></span><br><span class="line">    r2 = r2_score(y, y_pred)</span><br><span class="line"></span><br><span class="line">    display(pd.DataFrame([[<span class="string">&#x27;MSE&#x27;</span>, mse],[<span class="string">&#x27;MAE&#x27;</span>, mae],[<span class="string">&#x27;RMSE&#x27;</span>, rmse],[<span class="string">&#x27;R2&#x27;</span>, r2]], columns=[<span class="string">&#x27;Metric&#x27;</span>, <span class="string">&#x27;Score&#x27;</span>]))</span><br></pre></td></tr></table></figure><h2 id="트리"><a href="#트리" class="headerlink" title="트리"></a>트리</h2><h3 id="dtreeviz를-활용한-tree시각화"><a href="#dtreeviz를-활용한-tree시각화" class="headerlink" title="dtreeviz를 활용한 tree시각화"></a>dtreeviz를 활용한 tree시각화</h3><p>-<a href="https://github.com/parrt/dtreeviz">깃허브 링크</a></p><p><strong>Code from TowardDS</strong></p><ul><li>setup</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris, load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># load the two data sets  </span></span><br><span class="line">iris = load_iris()</span><br><span class="line">boston = load_boston()</span><br></pre></td></tr></table></figure><ul><li>old way</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepare the data</span></span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the classifier</span></span><br><span class="line">clf = tree.DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tree.plot_tree(clf); <span class="comment"># this old way</span></span><br></pre></td></tr></table></figure><ul><li>Decision Tree의 Class Labeling (색칠하기)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tree.plot_tree(clf,</span><br><span class="line">               feature_names = iris.feature_names, </span><br><span class="line">               class_names=iris.target_names,</span><br><span class="line">               rounded=<span class="literal">True</span>, </span><br><span class="line">               filled = <span class="literal">True</span>);</span><br></pre></td></tr></table></figure><ul><li>dtreeviz in action</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">viz = dtreeviz(clf, </span><br><span class="line">               x_data=X_train,</span><br><span class="line">               y_data=y_train,</span><br><span class="line">               target_name=<span class="string">&#x27;class&#x27;</span>,</span><br><span class="line">               feature_names=iris.feature_names, </span><br><span class="line">               class_names=<span class="built_in">list</span>(iris.target_names), </span><br><span class="line">               title=<span class="string">&quot;Decision Tree - Iris data set&quot;</span>)</span><br><span class="line">viz</span><br></pre></td></tr></table></figure><p><img src="https://miro.medium.com/max/1050/1*iiYZWUlZyCvvNahmcVT1XA.png"></p><ul><li>highlight the path of first obervation of the test set</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">viz = dtreeviz(clf, </span><br><span class="line">               x_data=X_train,</span><br><span class="line">               y_data=y_train,</span><br><span class="line">               target_name=<span class="string">&#x27;class&#x27;</span>,</span><br><span class="line">               feature_names=iris.feature_names, </span><br><span class="line">               class_names=<span class="built_in">list</span>(iris.target_names),</span><br><span class="line">               title=<span class="string">&quot;Decision Tree - Iris data set&quot;</span>,</span><br><span class="line">               [[orientation]]=<span class="string">&quot;LR&quot;</span>, </span><br><span class="line">               X=X_test[<span class="number">0</span>])  </span><br><span class="line">viz</span><br></pre></td></tr></table></figure><ul><li>Regression example</li><li>회귀분석</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepare the data</span></span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fir the regressor</span></span><br><span class="line">reg = tree.DecisionTreeRegressor(max_depth=<span class="number">2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">reg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot the tree</span></span><br><span class="line">viz = dtreeviz(reg,</span><br><span class="line">               x_data=X_train,</span><br><span class="line">               y_data=y_train,</span><br><span class="line">               target_name=<span class="string">&#x27;price&#x27;</span>,</span><br><span class="line">               feature_names=boston.feature_names,</span><br><span class="line">               title=<span class="string">&quot;Decision Tree - Boston housing&quot;</span>,</span><br><span class="line">               show_node_labels = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://miro.medium.com/max/1050/1*XN54CVrnWqtn4GRs_ij2yQ.png"></p><h4 id="Regression-Tree"><a href="#Regression-Tree" class="headerlink" title="Regression_Tree"></a>Regression_Tree</h4><ul><li>Wine Dataset Regression Visualization</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">features = wine.drop(<span class="string">&#x27;quality&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">target = wine[<span class="string">&#x27;quality&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Regression tree on Wine data</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">25</span>,<span class="number">20</span>))</span><br><span class="line">regr= tree.DecisionTreeRegressor(max_depth=<span class="number">3</span>)  </span><br><span class="line">regr.fit(features, target)</span><br><span class="line">viz = dtreeviz(regr,</span><br><span class="line">               features,</span><br><span class="line">               target,</span><br><span class="line">               target_name=<span class="string">&#x27;wine quality&#x27;</span>,</span><br><span class="line">               feature_names=features.columns,</span><br><span class="line">               title=<span class="string">&quot;Wine data set regression&quot;</span>,</span><br><span class="line">               fontname=<span class="string">&quot;Arial&quot;</span>,</span><br><span class="line">               colors = &#123;<span class="string">&quot;title&quot;</span>:<span class="string">&quot;purple&quot;</span>&#125;,</span><br><span class="line">               scale=<span class="number">1.5</span>)</span><br><span class="line">viz</span><br></pre></td></tr></table></figure><p><img src="https://miro.medium.com/max/1050/1*qzLs2IBAYSEJwycZ0rc7mg.png"></p><h4 id="Classification-Tree"><a href="#Classification-Tree" class="headerlink" title="Classification_Tree"></a>Classification_Tree</h4><ul><li>Wine Dataset Classification Visualization</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">25</span>,<span class="number">20</span>))</span><br><span class="line">clf = tree.DecisionTreeClassifier(max_depth=<span class="number">3</span>)</span><br><span class="line">clf.fit(features, target)</span><br><span class="line"><span class="comment"># pick random X observation for demo</span></span><br><span class="line">X = features.iloc[np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(features)),:].values</span><br><span class="line">viz = dtreeviz(clf,</span><br><span class="line">               features,</span><br><span class="line">               target,</span><br><span class="line">               target_name=<span class="string">&#x27;wine quality&#x27;</span>,</span><br><span class="line">               feature_names=features.columns,</span><br><span class="line">               title=<span class="string">&quot;Wine data set classification&quot;</span>,</span><br><span class="line">               class_names=[<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;3&#x27;</span>],</span><br><span class="line">               scale=<span class="number">1.3</span>,</span><br><span class="line">               X=X)</span><br><span class="line">viz</span><br></pre></td></tr></table></figure><h4 id="Prediction-Path"><a href="#Prediction-Path" class="headerlink" title="Prediction Path"></a>Prediction Path</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">regr = tree.DecisionTreeRegressor(max_depth=<span class="number">2</span>)  <span class="comment"># limit depth of tree</span></span><br><span class="line">diabetes = load_diabetes()</span><br><span class="line">regr.fit(diabetes.data, diabetes.target)</span><br><span class="line">X = diabetes.data[np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(diabetes.data)),:]  <span class="comment"># random sample from training</span></span><br><span class="line"></span><br><span class="line">viz = dtreeviz(regr,</span><br><span class="line">               diabetes.data, </span><br><span class="line">               diabetes.target, </span><br><span class="line">               target_name=<span class="string">&#x27;value&#x27;</span>, </span><br><span class="line">               orientation =<span class="string">&#x27;LR&#x27;</span>,  <span class="comment"># left-right orientation</span></span><br><span class="line">               feature_names=diabetes.feature_names,</span><br><span class="line">               X=X)  <span class="comment"># need to give single observation for prediction</span></span><br><span class="line"></span><br><span class="line">viz.view()  </span><br></pre></td></tr></table></figure><p>If you want to visualize just the prediction path, you need to set parameter show_just_path&#x3D;True</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dtreeviz(regr,</span><br><span class="line">        diabetes.data, </span><br><span class="line">        diabetes.target, </span><br><span class="line">        target_name=<span class="string">&#x27;value&#x27;</span>, </span><br><span class="line">        orientation =<span class="string">&#x27;TD&#x27;</span>,  <span class="comment"># top-down orientation</span></span><br><span class="line">        feature_names=diabetes.feature_names,</span><br><span class="line">        X=X, <span class="comment"># need to give single observation for prediction</span></span><br><span class="line">        show_just_path=<span class="literal">True</span>     </span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p><strong>Explain Prediction Path</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">X = dataset[features].iloc[<span class="number">10</span>]</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line">Pclass              <span class="number">3.0</span></span><br><span class="line">Age                 <span class="number">4.0</span></span><br><span class="line">Fare               <span class="number">16.7</span></span><br><span class="line">Sex_label           <span class="number">0.0</span></span><br><span class="line">Cabin_label       <span class="number">145.0</span></span><br><span class="line">Embarked_label      <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(explain_prediction_path(tree_classifier, X, feature_names=features, explanation_type=<span class="string">&quot;plain_english&quot;</span>))</span><br><span class="line"><span class="number">2.5</span> &lt;= Pclass </span><br><span class="line">Age &lt; <span class="number">36.5</span></span><br><span class="line">Fare &lt; <span class="number">23.35</span></span><br><span class="line">Sex_label &lt; <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h4 id="Regression-with-univariate-feature-target-space"><a href="#Regression-with-univariate-feature-target-space" class="headerlink" title="Regression with univariate feature-target space"></a>Regression with univariate feature-target space</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X, y = df_cars[[<span class="string">&#x27;WGT&#x27;</span>]], df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.gca()</span><br><span class="line">rtreeviz_univar(dt, X, y, <span class="string">&#x27;WGT&#x27;</span>, <span class="string">&#x27;MPG&#x27;</span>, ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/178777/49105092-9b264d80-f234-11e8-9d67-cc58c47016ca.png"></p><h4 id="Regression-bivariate-feature-target-space"><a href="#Regression-bivariate-feature-target-space" class="headerlink" title="Regression bivariate feature-target space"></a>Regression bivariate feature-target space</h4><img src="https://user-images.githubusercontent.com/178777/49104999-4edb0d80-f234-11e8-9010-73b7c0ba5fb9.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X = df_cars[[<span class="string">&#x27;WGT&#x27;</span>,<span class="string">&#x27;ENG&#x27;</span>]]</span><br><span class="line">y = df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">figsize = (<span class="number">6</span>,<span class="number">5</span>)</span><br><span class="line">fig = plt.figure(figsize=figsize)</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">t = rtreeviz_bivar_3D(dt,</span><br><span class="line">                      X, y,</span><br><span class="line">                      feature_names=[<span class="string">&#x27;Vehicle Weight&#x27;</span>, <span class="string">&#x27;Horse Power&#x27;</span>],</span><br><span class="line">                      target_name=<span class="string">&#x27;MPG&#x27;</span>,</span><br><span class="line">                      fontsize=<span class="number">14</span>,</span><br><span class="line">                      elev=<span class="number">20</span>,</span><br><span class="line">                      azim=<span class="number">25</span>,</span><br><span class="line">                      dist=<span class="number">8.2</span>,</span><br><span class="line">                      show=&#123;<span class="string">&#x27;splits&#x27;</span>,<span class="string">&#x27;title&#x27;</span>&#125;,</span><br><span class="line">                      ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="Regression-bivariate-feature-target-space-heatmap"><a href="#Regression-bivariate-feature-target-space-heatmap" class="headerlink" title="Regression bivariate feature-target space heatmap"></a>Regression bivariate feature-target space heatmap</h4><img src="https://user-images.githubusercontent.com/178777/49107627-08d57800-f23b-11e8-85a2-ab5894055092.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X = df_cars[[<span class="string">&#x27;WGT&#x27;</span>,<span class="string">&#x27;ENG&#x27;</span>]]</span><br><span class="line">y = df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">t = rtreeviz_bivar_heatmap(dt,</span><br><span class="line">                           X, y,</span><br><span class="line">                           feature_names=[<span class="string">&#x27;Vehicle Weight&#x27;</span>, <span class="string">&#x27;Horse Power&#x27;</span>],</span><br><span class="line">                           fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p><p>Highlights the decision nodes in which the feature value of single observation passed in argument X falls. Gives feature values of the observation and highlights features which are used by tree to traverse path.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">regr = tree.DecisionTreeRegressor(max_depth=<span class="number">2</span>)  <span class="comment"># limit depth of tree</span></span><br><span class="line">diabetes = load_diabetes()</span><br><span class="line">regr.fit(diabetes.data, diabetes.target)</span><br><span class="line">X = diabetes.data[np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(diabetes.data)),:]  <span class="comment"># random sample from training</span></span><br><span class="line"></span><br><span class="line">viz = dtreeviz(regr,</span><br><span class="line">               diabetes.data, </span><br><span class="line">               diabetes.target, </span><br><span class="line">               target_name=<span class="string">&#x27;value&#x27;</span>, </span><br><span class="line">               orientation =<span class="string">&#x27;LR&#x27;</span>,  <span class="comment"># left-right orientation</span></span><br><span class="line">               feature_names=diabetes.feature_names,</span><br><span class="line">               X=X)  <span class="comment"># need to give single observation for prediction</span></span><br><span class="line"></span><br><span class="line">viz.view()  </span><br></pre></td></tr></table></figure><p>If you want to visualize just the prediction path, you need to set parameter show_just_path&#x3D;True</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dtreeviz(regr,</span><br><span class="line">        diabetes.data, </span><br><span class="line">        diabetes.target, </span><br><span class="line">        target_name=<span class="string">&#x27;value&#x27;</span>, </span><br><span class="line">        orientation =<span class="string">&#x27;TD&#x27;</span>,  <span class="comment"># top-down orientation</span></span><br><span class="line">        feature_names=diabetes.feature_names,</span><br><span class="line">        X=X, <span class="comment"># need to give single observation for prediction</span></span><br><span class="line">        show_just_path=<span class="literal">True</span>     </span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p><strong>Explain Prediction Path</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">X = dataset[features].iloc[<span class="number">10</span>]</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line">Pclass              <span class="number">3.0</span></span><br><span class="line">Age                 <span class="number">4.0</span></span><br><span class="line">Fare               <span class="number">16.7</span></span><br><span class="line">Sex_label           <span class="number">0.0</span></span><br><span class="line">Cabin_label       <span class="number">145.0</span></span><br><span class="line">Embarked_label      <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(explain_prediction_path(tree_classifier, X, feature_names=features, explanation_type=<span class="string">&quot;plain_english&quot;</span>))</span><br><span class="line"><span class="number">2.5</span> &lt;= Pclass </span><br><span class="line">Age &lt; <span class="number">36.5</span></span><br><span class="line">Fare &lt; <span class="number">23.35</span></span><br><span class="line">Sex_label &lt; <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h4 id="Regression-with-univariate-feature-target-space-1"><a href="#Regression-with-univariate-feature-target-space-1" class="headerlink" title="Regression with univariate feature-target space"></a>Regression with univariate feature-target space</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X, y = df_cars[[<span class="string">&#x27;WGT&#x27;</span>]], df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.gca()</span><br><span class="line">rtreeviz_univar(dt, X, y, <span class="string">&#x27;WGT&#x27;</span>, <span class="string">&#x27;MPG&#x27;</span>, ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/178777/49105092-9b264d80-f234-11e8-9d67-cc58c47016ca.png"></p><h4 id="Regression-bivariate-feature-target-space-1"><a href="#Regression-bivariate-feature-target-space-1" class="headerlink" title="Regression bivariate feature-target space"></a>Regression bivariate feature-target space</h4><img src="https://user-images.githubusercontent.com/178777/49104999-4edb0d80-f234-11e8-9010-73b7c0ba5fb9.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X = df_cars[[<span class="string">&#x27;WGT&#x27;</span>,<span class="string">&#x27;ENG&#x27;</span>]]</span><br><span class="line">y = df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">figsize = (<span class="number">6</span>,<span class="number">5</span>)</span><br><span class="line">fig = plt.figure(figsize=figsize)</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">t = rtreeviz_bivar_3D(dt,</span><br><span class="line">                      X, y,</span><br><span class="line">                      feature_names=[<span class="string">&#x27;Vehicle Weight&#x27;</span>, <span class="string">&#x27;Horse Power&#x27;</span>],</span><br><span class="line">                      target_name=<span class="string">&#x27;MPG&#x27;</span>,</span><br><span class="line">                      fontsize=<span class="number">14</span>,</span><br><span class="line">                      elev=<span class="number">20</span>,</span><br><span class="line">                      azim=<span class="number">25</span>,</span><br><span class="line">                      dist=<span class="number">8.2</span>,</span><br><span class="line">                      show=&#123;<span class="string">&#x27;splits&#x27;</span>,<span class="string">&#x27;title&#x27;</span>&#125;,</span><br><span class="line">                      ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="Regression-bivariate-feature-target-space-heatmap-1"><a href="#Regression-bivariate-feature-target-space-heatmap-1" class="headerlink" title="Regression bivariate feature-target space heatmap"></a>Regression bivariate feature-target space heatmap</h4><img src="https://user-images.githubusercontent.com/178777/49107627-08d57800-f23b-11e8-85a2-ab5894055092.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">df_cars = pd.read_csv(<span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">X = df_cars[[<span class="string">&#x27;WGT&#x27;</span>,<span class="string">&#x27;ENG&#x27;</span>]]</span><br><span class="line">y = df_cars[<span class="string">&#x27;MPG&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeRegressor(max_depth=<span class="number">3</span>, criterion=<span class="string">&quot;mae&quot;</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">t = rtreeviz_bivar_heatmap(dt,</span><br><span class="line">                           X, y,</span><br><span class="line">                           feature_names=[<span class="string">&#x27;Vehicle Weight&#x27;</span>, <span class="string">&#x27;Horse Power&#x27;</span>],</span><br><span class="line">                           fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>2392348623ab026ecc187a8b50d9619895c682ae</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><h4 id="Classification-univariate-feature-target-space"><a href="#Classification-univariate-feature-target-space" class="headerlink" title="Classification univariate feature-target space"></a>Classification univariate feature-target space</h4><img src="https://user-images.githubusercontent.com/178777/49105084-9497d600-f234-11e8-9097-56835558c1a6.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">know = pd.read_csv(<span class="string">&quot;knowledge.csv&quot;</span>)</span><br><span class="line">class_names = [<span class="string">&#x27;very_low&#x27;</span>, <span class="string">&#x27;Low&#x27;</span>, <span class="string">&#x27;Middle&#x27;</span>, <span class="string">&#x27;High&#x27;</span>]</span><br><span class="line">know[<span class="string">&#x27;UNS&#x27;</span>] = know[<span class="string">&#x27;UNS&#x27;</span>].<span class="built_in">map</span>(&#123;n: i <span class="keyword">for</span> i, n <span class="keyword">in</span> <span class="built_in">enumerate</span>(class_names)&#125;)</span><br><span class="line"></span><br><span class="line">X = know[[<span class="string">&#x27;PEG&#x27;</span>]]</span><br><span class="line">y = know[<span class="string">&#x27;UNS&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">3</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">ct = ctreeviz_univar(dt, X, y,</span><br><span class="line">                     feature_names = [<span class="string">&#x27;PEG&#x27;</span>],</span><br><span class="line">                     class_names=class_names,</span><br><span class="line">                     target_name=<span class="string">&#x27;Knowledge&#x27;</span>,</span><br><span class="line">                     nbins=<span class="number">40</span>, gtype=<span class="string">&#x27;strip&#x27;</span>,</span><br><span class="line">                     show=&#123;<span class="string">&#x27;splits&#x27;</span>,<span class="string">&#x27;title&#x27;</span>&#125;)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="Classification-bivariate-feature-target-space"><a href="#Classification-bivariate-feature-target-space" class="headerlink" title="Classification bivariate feature-target space"></a>Classification bivariate feature-target space</h4><img src="https://user-images.githubusercontent.com/178777/49105085-9792c680-f234-11e8-8af5-bc2fde950ab1.png" width="30%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> dtreeviz.trees <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">know = pd.read_csv(<span class="string">&quot;knowledge.csv&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(know)</span><br><span class="line">class_names = [<span class="string">&#x27;very_low&#x27;</span>, <span class="string">&#x27;Low&#x27;</span>, <span class="string">&#x27;Middle&#x27;</span>, <span class="string">&#x27;High&#x27;</span>]</span><br><span class="line">know[<span class="string">&#x27;UNS&#x27;</span>] = know[<span class="string">&#x27;UNS&#x27;</span>].<span class="built_in">map</span>(&#123;n: i <span class="keyword">for</span> i, n <span class="keyword">in</span> <span class="built_in">enumerate</span>(class_names)&#125;)</span><br><span class="line"></span><br><span class="line">X = know[[<span class="string">&#x27;PEG&#x27;</span>,<span class="string">&#x27;LPR&#x27;</span>]]</span><br><span class="line">y = know[<span class="string">&#x27;UNS&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">3</span>)</span><br><span class="line">dt.fit(X, y)</span><br><span class="line"></span><br><span class="line">ct = ctreeviz_bivar(dt, X, y,</span><br><span class="line">                    feature_names = [<span class="string">&#x27;PEG&#x27;</span>,<span class="string">&#x27;LPR&#x27;</span>],</span><br><span class="line">                    class_names=class_names,</span><br><span class="line">                    target_name=<span class="string">&#x27;Knowledge&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="Classification-boundaries-in-feature-space"><a href="#Classification-boundaries-in-feature-space" class="headerlink" title="Classification boundaries in feature space"></a>Classification boundaries in feature space</h4><ul><li><a href="https://github.com/parrt/dtreeviz/blob/master/README.md">https://github.com/parrt/dtreeviz/blob/master/README.md</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clfviz(rf, X, y, feature_names=[<span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;x2&#x27;</span>], markers=[<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;s&#x27;</span>,<span class="string">&#x27;D&#x27;</span>], target_name=<span class="string">&#x27;smiley&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/178777/113516349-a12c4780-952e-11eb-86f3-0ae457eb500f.png"></p><h2 id="XAI"><a href="#XAI" class="headerlink" title="XAI"></a>XAI</h2><h1 id="그래프-관련-이슈들"><a href="#그래프-관련-이슈들" class="headerlink" title="그래프 관련 이슈들"></a>그래프 관련 이슈들</h1><h2 id="컬러-팔레트"><a href="#컬러-팔레트" class="headerlink" title="컬러 팔레트"></a>컬러 팔레트</h2><ul><li><p><a href="https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/">https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/</a></p></li><li><p><a href="https://seaborn.pydata.org/tutorial/color_palettes.html">https://seaborn.pydata.org/tutorial/color_palettes.html</a></p></li><li><p><a href="https://www.omnisci.com/blog/12-color-palettes-for-telling-better-stories-with-your-data">https://www.omnisci.com/blog/12-color-palettes-for-telling-better-stories-with-your-data</a></p></li><li><p>차트에 컬러 팔렛 적용하기</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure></li></ul><p>import seaborn as sns<br>import matplotlib.pyplot as plt</p><p>five_thirty_eight &#x3D; [<br>    “#30a2da”,<br>    “#fc4f30”,<br>    “#e5ae38”,<br>    “#6d904f”,<br>    “#8b8b8b”,<br>]</p><p>sns.set_palette(five_thirty_eight)<br>sns.palplot(sns.color_palette())<br>plt.show(</p><h3 id="Categorical-Palettes"><a href="#Categorical-Palettes" class="headerlink" title="Categorical Palettes"></a>Categorical Palettes</h3><h3 id="Sequential-Palettes"><a href="#Sequential-Palettes" class="headerlink" title="Sequential Palettes"></a>Sequential Palettes</h3><h3 id="Diverging-Palettes"><a href="#Diverging-Palettes" class="headerlink" title="Diverging Palettes"></a>Diverging Palettes</h3><h2 id="축-이슈"><a href="#축-이슈" class="headerlink" title="축 이슈"></a>축 이슈</h2><h3 id="축에-있는-label-겹칠경우-overlapping-해결법-seaborn"><a href="#축에-있는-label-겹칠경우-overlapping-해결법-seaborn" class="headerlink" title="축에 있는 label 겹칠경우(overlapping) 해결법(seaborn)"></a>축에 있는 label 겹칠경우(overlapping) 해결법(seaborn)</h3><p><a href="https://stackoverflow.com/questions/42528921/how-to-prevent-overlapping-x-axis-labels-in-sns-countplot">https://stackoverflow.com/questions/42528921/how-to-prevent-overlapping-x-axis-labels-in-sns-countplot</a></p><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> visualization </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/10/28/machine-learning/notebook/visualization/mpl-seaborn/"/>
      <url>/2023/10/28/machine-learning/notebook/visualization/mpl-seaborn/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> machine-learning </category>
          
          <category> notebook </category>
          
          <category> visualization </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[NLP]Word Embedding과 Text Classification</title>
      <link href="/2022/03/02/machine-learning/NLP-wordembedding/"/>
      <url>/2022/03/02/machine-learning/NLP-wordembedding/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h1 id="NLP-subtask에-대한-정리"><a href="#NLP-subtask에-대한-정리" class="headerlink" title="NLP subtask에 대한 정리"></a>NLP subtask에 대한 정리</h1><p>: 주요 NLP task인 Word Embedding과 Text Classfication에 대해 간단히 정리</p><h2 id="1-Word-Embedding"><a href="#1-Word-Embedding" class="headerlink" title="1.Word Embedding"></a>1.Word Embedding</h2><h3 id="1-1-Word-Embedding에서-고려하는-task"><a href="#1-1-Word-Embedding에서-고려하는-task" class="headerlink" title="1.1 Word Embedding에서 고려하는 task"></a>1.1 Word Embedding에서 고려하는 task</h3><p>Word Embedding은 단어를 저차원의 실수벡터로 dense mapping하는 word representation 방식의 하나이다.</p><p>Embedding 자체는 토큰을 고정된 길이의 벡터로 표현하는 것을 뜻한다.</p><p><strong>단어의 구문(Syntax)와 의미(Semantics)를 실수벡터의 형태로 표현하는 것이 그 목적이다.</strong></p><p><img src="https://miro.medium.com/max/1050/1*lzjgo2KaWFRPkV3LCJDr7Q.png"></p><h4 id="1-1-1-차원의-저주"><a href="#1-1-1-차원의-저주" class="headerlink" title="1.1.1 차원의 저주"></a>1.1.1 차원의 저주</h4><p>단어를 실수벡터의 형태로 dense mapping하는 이유는 차원의 저주를 피하기 위함이다.</p><p>문서의 모든 단어를 One Hot encoding으로 표현할 경우 feature가 기하급수적으로 많아진 희소행렬이 생성되고 이 경우 연산비용이 증가하는 문제점이 발생한다.</p><p>이를 피하기 위해 Word Embedding을 통해 단어를 저차원 벡터에 고정시켜 나타내게 된다.</p><h4 id="1-1-2-Distribution-Hypothesis"><a href="#1-1-2-Distribution-Hypothesis" class="headerlink" title="1.1.2 Distribution Hypothesis"></a>1.1.2 Distribution Hypothesis</h4><p>Distribution Hypothesis는 비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다는 가설이다.</p><p>Word embedding은 이 분포 가설에 기반하여 주변 단어 분포를 기준으로 타겟이 되는 단어의 벡터 표현을 결정한다. </p><p>따라서 Word Embedding을 통해 생성된 두 단어 벡터의 거리가 가까울 수록 원문에서 두 단어가 유사한 의미와 용법을 가졌다고 볼 수 있다.</p><h4 id="1-1-3-Predictive-Method"><a href="#1-1-3-Predictive-Method" class="headerlink" title="1.1.3 Predictive Method"></a>1.1.3 Predictive Method</h4><p>Word Embedding은 기본적으로 단어의 예측을 학습하는 것으로 이루어진다.</p><h3 id="1-2-대표적인-데이터셋"><a href="#1-2-대표적인-데이터셋" class="headerlink" title="1.2 대표적인 데이터셋"></a>1.2 대표적인 데이터셋</h3><h4 id="Words-in-Context"><a href="#Words-in-Context" class="headerlink" title="Words in Context"></a>Words in Context</h4><p>Word in Context는 문맥에 따른 단어의 용법을 모아놓은 데이터 셋이다.</p><p>과거의 Word Embedding 기법들이 문맥에 따라 달라지는 단어의 의미를 구분하지 못한다는 문제점을 보완하기 위해 만들어졌다.</p><p>Word in Context을 통해 문맥정보를 학습한 임베딩을 생성할 수 있다.</p><p>데이터셋은 타겟단어 , 타겟이 되는 타겟단어의 Context 문장 2개와 해당 문장이 문맥상 같은 의미로 쓰여졌는지에 대한 label로 구성되어 있다.</p><p><img src="https://images.velog.io/images/yjinheon/post/b44f7201-b8ac-4c98-9646-510f7b2ef6a3/Velog_1_10.png"></p><h3 id="Contextual-Embedding-SOTA-Technique"><a href="#Contextual-Embedding-SOTA-Technique" class="headerlink" title="Contextual Embedding(SOTA Technique)"></a>Contextual Embedding(SOTA Technique)</h3><p>Word Embedding은 기본적으로 모델링이 아니라 NLP task의 input을 만드는 작업이기 때문에  BERT, ELMO, GPT-1와 같은 SOTA 모델에서 사용하는 Embedding 방식인 Contextual Embedding에 대해 기술하고자 한다.</p><p>과거의 Word Embedding 대표적인 문제점은 하나의 단어당 하나의 벡터 값 만이 매핑된다는 것이다. 따라서 단어의 문맥에 따라 달라지는 의미를 고려하기 어려워지고 성능에 부적인 영향을 주게 된다.</p><p>이러한 문제점을 보완하기 위해 Deep contextualized word representations(ELMO)에서 Contextual Embedding이 제시되었다.</p><h4 id="biLM-bidirectional-Language-Model-as-function"><a href="#biLM-bidirectional-Language-Model-as-function" class="headerlink" title="biLM(bidirectional Language Model) as function"></a>biLM(bidirectional Language Model) as function</h4><p>Contextual Embedding과 기존 임베딩의 차이점은 각 단어마다 고정된 크기의 벡터를 사용한 것이 아니라 pretrained model 자체를 일종의 함수으로 기능하게끔 하여 문맥정보를 학습에 반영한다는 것이다.</p><p>ELMo(Embedding from Language Model)는 여기서 단순한 Language Model이 아니라 일종의 함수이며 문장에 따라 같은 단어라도 다른 임베딩(단어 벡터)을 출력할 수 있다.</p><p>여기서 biLM은 단순히 forword LSTM(앞의 단어들로 뒤에 나올 단어를 예측)과 backword LSTM(뒤의 단어들로 앞의 단어를 예픅)을 합친 양방향 모델을 말하며 ELmo의 학습에 사용된다.</p><h2 id="Text-Classification"><a href="#Text-Classification" class="headerlink" title="Text Classification"></a>Text Classification</h2><h3 id="Text-Classification의-주요-task"><a href="#Text-Classification의-주요-task" class="headerlink" title="Text Classification의 주요 task"></a>Text Classification의 주요 task</h3><p>Text Classification은 문서의 내용을 바탕으로 특징을 추출해서 특정한 카테고리에 분류하는 것을 그 목적으로 한다.</p><h3 id="대표적인-데이터셋"><a href="#대표적인-데이터셋" class="headerlink" title="대표적인 데이터셋"></a>대표적인 데이터셋</h3><h4 id="IMDB-Movie-Review"><a href="#IMDB-Movie-Review" class="headerlink" title="IMDB Movie Review"></a>IMDB Movie Review</h4><p>IMDB에 게시된 영화 리뷰와 Positive&#x2F;Negative label로 구성된 데이터셋이며 주로 감성분석과 추천시스템 구현에 사용된다.</p><h3 id="BERT-SOTA-Technique"><a href="#BERT-SOTA-Technique" class="headerlink" title="BERT(SOTA Technique)"></a>BERT(SOTA Technique)</h3><p>BERT는 구글에서 개발한 신경망 구조이며 Text Classification 뿐 만 아니라 질의응답, 기계번역 , 문서요약과 같은 다양한 task에 적용할 수 있는 대표적인 SOTA Model이다.</p><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><ul><li>Transformer는 Encoder Decoder 구조를 가지는 딥러닝 모델이다.</li><li>기본적으로 여러개의 Encoder Decoder Layer가 존재하기 때문에 순차적으로 단어정보를 입력받지 않아 연산에서의 부담이 상대적으로 적은 편이다.</li><li>Encoder 내부에서는 self attention 기법으로 한 문장에서 한 단어가 다른 단어와 어떤 관계를 갖고 있는지 수치화한다.</li><li>문장의 Context를 학습하기 위해 Positional Encoding이라는 특수한 Input을 사용한다.<ul><li>Positional Encoding 을 통해 input으로 주어지는 단어의 vector안에 단어의 위치정보를 포함시킬 수 있다.</li></ul></li><li>BERT(Bidirectional Encoder Representations from Transformers)는 양방향 입력을 받는 Encoder를 여러개 쌓아올린 구조로 이루어져 있다.</li></ul><p>BERT에서는 일부 단어를 마스킹하고 해당 단어를 예측하거나(Masked L). 문장단위로 예측을 수행하는 기법(Next Sentence Prediction)</p><p>단어 토큰을 보다 세분화하는 WordPiece 기법을 사용한다.</p><h4 id="fine-tuning"><a href="#fine-tuning" class="headerlink" title="fine tuning"></a>fine tuning</h4><p>Transformer와 함께 BERT의 핵심 컨셉중 하나로 <em>기존의 학습된 모델을 기반으로 레이어를 새로운 task에 맞게 변형하고 이미 학습된 모델가중치를 업데이트하거나 모델의 파라미터를 재조정하는 것</em>을 뜻한다.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://machinelearningmastery.com/what-are-word-embeddings/">https://machinelearningmastery.com/what-are-word-embeddings/</a></li><li><a href="https://pilehvar.github.io/wic/">https://pilehvar.github.io/wic/</a></li><li><a href="https://arxiv.org/pdf/1808.09121v3.pdf">WiC: the Word-in-Context Dataset</a></li><li><a href="https://arxiv.org/pdf/1802.05365.pdf">Deep contextualized word representations</a></li><li><a href="https://paperswithcode.com/method/elmo">https://paperswithcode.com/method/elmo</a></li><li><a href="https://skyjwoo.tistory.com/entry/positional-encoding%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80">Positional Encoding의 이해</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> WordEmbedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Pyspark]하둡의 컨셉 이해하기</title>
      <link href="/2021/12/29/data-engineering/de-Pyspark-Hadoop.md/"/>
      <url>/2021/12/29/data-engineering/de-Pyspark-Hadoop.md/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Pyspark를 본격적으로 쓰기 전에 하둡의 컨셉을 간단히 정리하자.</p></blockquote><h2 id="하둡"><a href="#하둡" class="headerlink" title="하둡"></a>하둡</h2><p>: 하둡은 Data Locality에 바탕을 둔 분산컴퓨팅을 위한 소프트웨어 플랫폼 및 프레임워크이다. 기본적인 컨셉은 분산처리(큰 문제를 작은 문제의 집합으로 나누고 정리하는 것)이다.</p><p>하둡은 HDFS (Hadoop Distributed File System) 와 YARN(Yet Another Resource Navigator)로 구성된다.</p><ul><li>하둡은 데이터가 비공유 접근을 허용하는 클러스터의 노드에서 지역적으로 처리될 수 있게 한다</li><li>각 노드는 다른 노드들과 통신할 필요 없이 전체 데이터의 훨씬 작은 부분을 독립적으로 처리할 수 있다.</li><li>기본적으로 분산시스템이기에 네트워크 연결을 통해 여러 연산자원(노드들)의 사용을 조정한다.</li><li>선형적 확장성을 가진다. 이는 노드의 수 , 스토리지의 양 , 잡 루틴이 선형적 관계로 엮여있다는 것을 의미한다. (만약 노드의 수를 늘린다면 그만큼 처리시간이 줄어들 것이라고 예측할 수 있다.)</li></ul><p><strong>데이터가 기본적으로 분산되어있고 확장가능하며(노드의 수를 늘리는 방식으로) 오류에 대처할 수 있다.</strong></p><p>이는 분산파일시스템의 구현을 통해 가능해진다.</p><h3 id="Schima-on-Write"><a href="#Schima-on-Write" class="headerlink" title="Schima-on-Write"></a>Schima-on-Write</h3><p>: 데이터를 저장할때 스키마를 우선 정의하는 것</p><p>주로 RBDMS에 자주 쓰인다. 데이터에 대해 익숙하고 자주 쓴다고 가정할 경우 Schima-on-Write 방식이 보다 적합할 수 있다.</p><h3 id="Schima-On-Read"><a href="#Schima-On-Read" class="headerlink" title="Schima-On-Read"></a>Schima-On-Read</h3><p>: 분석을 위해 파일 시스템에서 데이터를 읽을 때 스키마가 정의되는 것.</p><p>반구조화를 포함한 광범위한 데이터를 저장하고 처리할 수 있다.이는 데이터를 원본 그대로 저장할 수있다는 것을 의미하며 빅데이터 처리 측면에서 강점을 가진다는 것을 의미한다.</p><img src="https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/hwyn_0105-2d2be3e87d610d5bece7f647d47d5fcc.png" alt="drawing" width="500"/><h3 id="Data-Locality"><a href="#Data-Locality" class="headerlink" title="Data Locality"></a>Data Locality</h3><p>: 데이터가 있는 곳으로 이동해서 계산하는 것. 데이터의 이동이 아닌 계산의 이동.</p><p><strong>데이터 지역성은 계산하기 위해 데이터를 이동하는 것이 아니라 데이터를 그대로 두고 계산을 이동시키는 것이다.</strong><br>빅 데이터를 계산하기 위해 데이터를 이동(move)를 최대한 줄여<br>시스템 쓰루풋(throughput)과 혼잡도를 늦추게 하는 것이다.<br>따라서 통신 대역폭이 당연히 줄어들고 성능은 늘어난다.</p><p>기본적으로 대용량데이터를 다룰경우 데이터를 옮기는 것보다 프로그램 자체를 이동시키는 것이 효율적이라는 아이디어에 기반한 개념이다.</p><h2 id="비공유-아키텍처"><a href="#비공유-아키텍처" class="headerlink" title="비공유 아키텍처"></a>비공유 아키텍처</h2><p>: Shared Nothing Architecture</p><p>분산 컴퓨팅에 사용되는 아키텍처로 RAM, Disk 등의 자원을 공유하지 않는 독립적인 노드들로 이루어진다.</p><p>각각의 노드는 독립적인 처리장치와 프로세스, 디스크를 가지고 있다.</p><img src="https://phoenixnap.com/kb/wp-content/uploads/2021/09/shared-nothing-architecture-diagram.png" alt="drawing" width="800"/><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><h3 id="Mater-x2F-Slave"><a href="#Mater-x2F-Slave" class="headerlink" title="Mater&#x2F;Slave"></a>Mater&#x2F;Slave</h3><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/Shared-nothing_architecture">https://en.wikipedia.org/wiki/Shared-nothing_architecture</a></li><li><a href="https://phoenixnap.com/kb/shared-nothing-architecture">https://phoenixnap.com/kb/shared-nothing-architecture</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pyspark </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[SQL]ERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides 해결하기</title>
      <link href="/2021/12/01/troubleshooting/TS-SQL-ts-1/"/>
      <url>/2021/12/01/troubleshooting/TS-SQL-ts-1/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p>안쓰던 노트북을 서버로 만들어서 작업중 다음 에러가 발생했다.</p><p>ERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides  </p><p>찾아보니 SQL 서버의 변수값을 변경해 해결할 수 있었다.</p><p>아래 명령을 통해 local_infile 상태가 ON 인지 OFF인지 확인 한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> variables <span class="keyword">like</span> <span class="string">&#x27;local_infile&#x27;</span>;</span><br></pre></td></tr></table></figure><p>값이 OFF일 경우 아래 명령 실행</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> local_infile <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://stackoverflow.com/questions/59993844/error-loading-local-data-is-disabled-this-must-be-enabled-on-both-the-client">https://stackoverflow.com/questions/59993844/error-loading-local-data-is-disabled-this-must-be-enabled-on-both-the-client</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Troubleshooting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[linux]기본 에디터 neovim으로 변경하기</title>
      <link href="/2021/11/08/data-engineering/linux/DE-linux-seteditor/"/>
      <url>/2021/11/08/data-engineering/linux/DE-linux-seteditor/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="유저-편집기-변경"><a href="#유저-편집기-변경" class="headerlink" title="유저 편집기 변경"></a>유저 편집기 변경</h2><blockquote><p>nano -&gt; nvim</p></blockquote><p>현재 편집기 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># check current editor</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$EDITOR</span></span><br></pre></td></tr></table></figure><p>현재 쉘의 편집기를 리눅스 환경변수로 등록</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nvim ~/.bashrc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> VISUAL=<span class="string">&quot;nvim&quot;</span></span><br><span class="line"><span class="built_in">export</span> EDITOR=<span class="variable">$VISUAL</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><h2 id="글로벌-설정"><a href="#글로벌-설정" class="headerlink" title="글로벌 설정"></a>글로벌 설정</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">sudo nvim /etc/profile</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commandline </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[linux]데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음</title>
      <link href="/2021/10/08/data-engineering/linux/DE-linux-commandline/"/>
      <url>/2021/10/08/data-engineering/linux/DE-linux-commandline/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="데이터-관련-프로젝트시-자주-사용하는-commandline-명령어-모음"><a href="#데이터-관련-프로젝트시-자주-사용하는-commandline-명령어-모음" class="headerlink" title="데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음"></a>데이터 관련 프로젝트시 자주 사용하는 commandline 명령어 모음</h2><h3 id="도움말"><a href="#도움말" class="headerlink" title="도움말"></a>도움말</h3><ul><li>man</li></ul><h3 id="파일관리"><a href="#파일관리" class="headerlink" title="파일관리"></a>파일관리</h3><ul><li>pwd</li><li>cd</li><li>ls</li><li>mkdir</li><li>rmdir</li><li>cp</li><li>mv</li><li>rm</li><li>ln</li><li>chmod</li></ul><h3 id="파일처리"><a href="#파일처리" class="headerlink" title="파일처리"></a>파일처리</h3><ul><li>cat</li><li>echo</li><li>head</li><li>tail</li><li>more&#x2F;less</li><li>grep</li><li>sed*</li><li>awk*</li><li>find*</li><li>which</li><li>sort</li><li>uniq</li><li>cut</li><li>tr</li><li>zip</li><li>unzip</li><li>gunzip</li><li>tar</li></ul><h3 id="프로세스-관리"><a href="#프로세스-관리" class="headerlink" title="프로세스 관리"></a>프로세스 관리</h3><ul><li>top</li><li>ps</li><li>kill</li><li>fg</li><li>bg</li></ul><h3 id="네트워크"><a href="#네트워크" class="headerlink" title="네트워크"></a>네트워크</h3><ul><li>ssh</li><li>scp</li><li>ping</li><li>traceroute</li><li>curl</li><li>finger</li><li>who</li></ul><h3 id="편집기"><a href="#편집기" class="headerlink" title="편집기"></a>편집기</h3><ul><li>vi</li><li>vim</li><li>nvim </li><li>nano</li></ul><h3 id="파이프와-리디렉션"><a href="#파이프와-리디렉션" class="headerlink" title="파이프와 리디렉션"></a>파이프와 리디렉션</h3><h3 id="셀-환경변"><a href="#셀-환경변" class="headerlink" title="셀 환경변"></a>셀 환경변</h3><ul><li>export</li><li>$path</li><li>$ps1</li></ul><h3 id="권한관리"><a href="#권한관리" class="headerlink" title="권한관리"></a>권한관리</h3><h4 id="파일권한체크"><a href="#파일권한체크" class="headerlink" title="파일권한체크"></a>파일권한체크</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">stat</span> -Lc <span class="string">&#x27;%a %A&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><code>stat</code> 메타데이터 정보 확인</li><li><code>-L</code>  symlink 파일 참조</li><li><code>-c</code> output 설정</li><li><code>%a</code> 8진법 권한</li><li><code>%A</code> Human readable한 권한</li></ul><h3 id="Unsorted"><a href="#Unsorted" class="headerlink" title="Unsorted"></a>Unsorted</h3><ul><li>cal</li><li>history</li></ul><p><strong>References &amp; annotation</strong></p><hr><ul><li>따라하며 배우는 데이터과학 (책)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commandline </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Neural Network]역전파 알고리즘(backpropagation)</title>
      <link href="/2021/09/28/machine-learning/DL-backpropagation/"/>
      <url>/2021/09/28/machine-learning/DL-backpropagation/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wranglinghttps://edgeaiguru.com/Feedforward-and-Backpropagationhttps://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>순전파가 입력층에서 신호를 받아 은닉층의 가중치(+bias)와 연산을 한 뒤 출력층에서 벡터를 출력하는 과정이라면<br>역전파는 예측값과 실제값의 차이(에러)를 줄이기 위해  손실함수가 최소가 되도록 출력층으로부터 순전파의 역방향으로 편미분을 통해 가중치를 업데이트 하는 것이다. 간단히 역전파의 컨셉을 알아보자.</strong></p><hr><h2 id="역전파-알고리즘"><a href="#역전파-알고리즘" class="headerlink" title="역전파 알고리즘"></a>역전파 알고리즘</h2><p><strong>순전파가 입력층에서 신호를 받아 은닉층의 가중치(+bias)와 연산을 한 뒤 출력층에서 벡터를 출력하는 과정이라면 역전파는 예측값과 실제값의 차이(에러)를 줄이기 위해  손실함수가 최소가 되도록 출력층으로부터 순전파의 역방향으로 편미분을 통해 가중치를 업데이트 하는 것이다.</strong></p><p>역전파 알고리즘에서 가중치를 업데이트 한다는 것은 가중치 매개변수의 기울기(Graidant)를 예측값을 바탕으로 다시 계산한다는 것이다.</p><p>기본적으로 <strong>타겟과 예측값의 차이를 줄이기 위해</strong> 가중치를 업데이트한다.</p><p>$$<br> y &#x3D; activiate(\sum(\theta_{1}x_{1} + \theta_{2}x_{2} + … + \theta_{n}x_{n}) + bias)<br>$$</p><p>타겟과 예측값의 차이는 <code>loss function(cost function)</code>이라고 볼 수 있다.</p><p>비용함수는 수식으로 나타내면 아래와 같다.</p><p>$$<br>J(\theta) &#x3D; y - h_\theta(x)<br>$$</p><p>여기서 $h_\theta(x)$ 는 가설함수(모형)이다.</p><p>역전파(backward Propagation)는 예측값의 국소적 미분값을 순전파(Forward Propagation)의 반대방향으로 곱한 후 다음노드로 전달하는 것이다.</p><p>비용함수의 편미분을 통해 기울기를 구하는 이유는 <strong>기울기가 비용함수의 값을 최소화 하는 방향을 제시하기 때문이다.</strong></p><p><img src="https://i.imgur.com/Olxv64J.png"></p><center><b>그림 1. Gradiant Boosting을 통한 global optimum 찾기</b></center><p>만약 모형의 loss function이 MSE(Mear Sqared Error)일 경우, 비용함수는 아래와 같이 나타낼 수 있다. (m은 sample의 수를 의미)</p><p>$$<br>J(\theta)&#x3D;\frac{1}{2 m} \sum_{i&#x3D;1}^{m}\left(y^{(i)}-\hat{y}^{(i)}\right)^{2}<br>$$</p><p>이를 미분할 경우 직접 계산하기 어렵거나 불가능하기 때문에 Chain Rule을 사용한 합성함수의 편미분을 통해 구한다.</p><p>아래와 같은 신경망이 있고 output node의 활성화함수는 sigmoid라고 할 경우</p><p><img src="https://i.imgur.com/bGCvYVJ.png"></p><center><b>그림 2. 신경망으로 나타낸 backpropagation</b></center><p>하나의 가중치에 대한 Gradiant를 아래와 같이 나타날 수 있다.</p><p>$$<br>Gradiant&#x3D;\frac{\partial J(\theta)}{\partial \theta_{i}}&#x3D;\frac{\frac{1}{2 m} \sum_{i&#x3D;1}^{m}\left(y^{(i)}-\hat{y}^{(i)}\right)} {\partial \theta_{i}}<br>$$</p><p>이 때 분자는 가중치 $\theta_i$에 대해 미분할 수 없기 때문에 아래와 같이 <code>Chain Rule</code> 을 사용해서 Gradiant를 도출한다.</p><p>$$<br>\frac{\partial J(\theta)}{\partial \theta_{i}} &#x3D;\frac{\partial J(\theta)}{\partial z_{2}} \times \frac{\partial z_{2}}{\partial s_{2}} \times \frac{\partial s_{2}}{\partial \theta_{i}}<br>$$</p><p><strong>chain rule(연쇄법칙)</strong><br>chain rule은 합성함수의 미분규칙이며 역전파과정에서 Gradiant를 도출할 때 사용된다.</p><p>기본적으로 바깥함수의 도함수에 안쪽함수를 인자로 넣어주고 안쪽함수의 도함수를 곱해주면 된다.</p><p><img src="https://i.imgur.com/4eSVZW0.png"></p><center><b>그림 3. Chain Rule 예시</b></center><p><strong>가중치 업데이트</strong></p><p>도출된 값을 learning rate와 곱해서 기존 가중치에서 빼주면 새로운 가중치는 다음과 같이 나타낼 수 있다.</p><p>$$<br>\theta_{j}&#x3D;\theta_{j}-\eta \frac{\partial}{\partial \theta_{j}} J(\theta)<br>$$</p><p><strong>결국 순전파와 역전파를 통해 가중치와 편향을 훈련데이터에 적응하도록 조정하는 과정이  기계학습에서의 <code>학습</code>이라는 것을 알 수 있다.</strong></p><h3 id="신경망-학습-알고리즘-절차-정리"><a href="#신경망-학습-알고리즘-절차-정리" class="headerlink" title="신경망 학습 알고리즘 절차 정리"></a>신경망 학습 알고리즘 절차 정리</h3><p>퍼셉트론과 역전파 알고리즘에 대한 이해를 바탕으로 지금까지의 절차를 아래와 같이 정리할 수 있다.</p><ol><li><p>학습할 신경망 구조를 선택</p><ul><li>입력층 유닛의 수 &#x3D; Feature 수 (input layer)</li><li>출력층 유닛의 수 &#x3D; target class 수 (output layer)</li><li>은닉층 수, 각 은닉층의 노드 수 (hidden layer)<ul><li>hyperparameter의 영역이다. </li><li>sqrt(input layer 수 * output layer 수 ) 로 구해줄 수 있지만 방식이 정해진 것은 아니다.</li></ul></li></ul></li><li><p>가중치 초기화</p></li><li><p>순방향 전파를 통해 $h_{\theta}(x^{(i)})$(출력층 y값) 을 모든 입력 $x^{(i)}$에 대해 계산</p><ul><li>입력벡터와 가중치벡터의 내적을 산출<br>비용함수 $J(\theta)$를 계산</li></ul></li><li><p>역방향 전파를 통해 편미분 값들 $\frac{\delta}{\delta\theta_{jk}^{l}}{J(\theta)}$ 을 계산</p></li><li><p>optimizer를 통해 loss function을 최소화</p></li><li><p>어떤 중지 기준을 충족하거나 비용함수를 최소화 할 때까지 단계 2-5를 반복한다.</p><ul><li>한번 학습할때의 sample의 size 를 <code>batch</code> 라고 한다.</li><li>전체 sample에 대해 2-5 의 과정을 반복한 것을 <code>epoch</code>라고 한다.</li><li><code>iteration</code>은 batch 기준으로 학습의 횟수를 카운팅 한 것이다. 100개의 sample의 batch가 50이고 epoch를 50으로 할 경우 전체 iteration의 수는 100이 된다.</li></ul></li></ol><h3 id="머신러닝에서의-학습"><a href="#머신러닝에서의-학습" class="headerlink" title="머신러닝에서의 학습"></a>머신러닝에서의 학습</h3><p>미분은 순간의 변화율을 구하는 것이다.<br><strong>역전파는 모형에서 계산한 예측값과 실제값의 차이를 바탕으로 미분을 통해 가중치를 보정하는 것을 최대한 반복해서 수행하는 것이다.</strong><br>구체적으로는 손실함수의 국소적 미분값(local deravitive)를 구해서 학습률과 곱한 값을 기존 파라미터에서 빼주는 것을 손실함수가 최소가 될 때까지 반복하는 것이다.<br><code>손실함수의 각 피처에 대한 편미분을 벡터로 묶은 것을 그래디언트(Gradient)라고 부른다.</code><br>결국 역전파는 gradient를 조정하는 것을 반복하는 것이라고 볼 수 있다.<br>결국 순전파와 역전파를 통해 가중치와 편향을 훈련데이터에 적응하도록 조정하는 과정이  기계학습에서의 <code>학습</code>이라는 것을 알 수 있다.</p><h2 id="신경망-학습-알고리즘-절차-정리-1"><a href="#신경망-학습-알고리즘-절차-정리-1" class="headerlink" title="신경망 학습 알고리즘 절차 정리"></a>신경망 학습 알고리즘 절차 정리</h2><p>퍼셉트론과 역전파 알고리즘에 대한 이해를 바탕으로 지금까지의 절차를 아래와 같이 정리할 수 있다.</p><ol start="0"><li><p>학습할 신경망 구조를 선택</p><ul><li>입력층 유닛의 수 &#x3D; Feature 수 (input layer)</li><li>출력층 유닛의 수 &#x3D; target class 수 (output layer)</li><li>은닉층 수, 각 은닉층의 노드 수 (hidden layer)<ul><li>hyperparameter의 영역이다. </li><li>sqrt(input layer 수 * output layer 수 ) 로 구해줄 수 있지만 방식이 정해진 것은 아니다.</li></ul></li></ul></li><li><p>가중치 초기화</p></li><li><p>순방향 전파를 통해 $h_{\theta}(x^{(i)})$(출력층 y값) 을 모든 입력 $x^{(i)}$에 대해 계산</p><ul><li>입력벡터와 가중치벡터의 내적을 산출<br>비용함수 $J(\theta)$를 계산</li></ul></li><li><p>역방향 전파를 통해 편미분 값들 $\frac{\delta}{\delta\theta_{jk}^{l}}{J(\theta)}$ 을 계산</p></li><li><p>optimizer를 통해 loss function을 최소화</p></li><li><p>어떤 중지 기준을 충족하거나 비용함수를 최소화 할 때까지 단계 2-5를 반복한다.</p><ul><li>한번 학습할때의 sample의 size 를 <code>batch</code> 라고 한다.</li><li>전체 sample에 대해 2-5 의 과정을 반복한 것을 <code>epoch</code>라고 한다.</li><li><code>iteration</code>은 batch 기준으로 학습의 횟수를 카운팅 한 것이다. 100개의 sample의 batch가 50이고 epoch를 50으로 할 경우 전체 iteration의 수는 100이 된다.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd">https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd</a></li><li><a href="https://edgeaiguru.com/Feedforward-and-Backpropagation">https://edgeaiguru.com/Feedforward-and-Backpropagation</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[SQL]서브쿼리 정리</title>
      <link href="/2021/08/17/data-engineering/DE-SQL-subquery/"/>
      <url>/2021/08/17/data-engineering/DE-SQL-subquery/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="간단한-서브쿼리-종류와-용법-정리"><a href="#간단한-서브쿼리-종류와-용법-정리" class="headerlink" title="간단한 서브쿼리 종류와 용법 정리"></a><strong>간단한 서브쿼리 종류와 용법 정리</strong></h2><h3 id="Subquery"><a href="#Subquery" class="headerlink" title="Subquery"></a>Subquery</h3><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>서브쿼리</strong> : 서브쿼리는 하나의 SQL쿼리 안에 포함된 다른 SQL쿼리를 말한다.</li></ul><hr><ul><li><p><strong>서브쿼리 사용상황</strong></p><ul><li>가장 기본적으로 알려지지 않은 조건을 사용해서 조회해야할 때</li><li>DB에 접근하는 속도를 향상시킬 때</li></ul></li><li><p><strong>사용시 주의점</strong></p><ul><li>항상 괄호로 감싸서 사용할 것</li><li>서브쿼리의 결과가 2건 이상이라면(다중행) <strong>반드시</strong> 비교연산자와 함께 사용한다, </li><li>서브쿼리 내에서는 order by 사용 못함( order by는 쿼리에서 하나만 사용)</li><li>서브쿼리는 메인쿼리의 컬럼을 모두 사용할 수 있지만, 메인쿼리는 서브쿼리의 컬럼을 사용할 수 없다.</li><li>질의 결과에 서브쿼리 컬럼을 표시해야 한다면 조인 방식으로 변환하거나 함수, 스칼라 서브쿼리 등을 사용해야 한다.</li></ul></li><li><p><strong>종류</strong></p><ul><li>단일 행 서브쿼리 : 특정 행을 반환. 이 행을 조건절도도 사용가능<ul><li>ex) 평균값알아내는 서브쿼리를 통해 평균값 이상의 그룹을 출력</li></ul></li></ul><ul><li>다중행 서브쿼리 : 결과가 2건이상 반환되는 서브쿼리. 반드시 비교연산자와 함께 사용. Where 절에 괄호로 들어간다.<ul><li>IN(서브쿼리) : 서브쿼리의 결과에 존재하는 값과 동일한 조건의미</li><li>ALL(서브쿼리) : 모든 값을 만족하는 조건</li><li>ANY(서브쿼리) : 비교연산자에 “&gt;” 를 썼다면 ANY가 어떤 하나라도 맞는지 조건이기 때문에 결과중에 가장 작은값보다 크면 만족한다.</li><li>EXIST(서브쿼리) :  서브쿼리의 결과를 만족하는 값이 존재하는지 여부 확인. 존재유무만 확인하기에 1건만 찾으면 더 이상검색안함</li></ul></li><li>다중 컬럼 서브쿼리 : 서브쿼리 결과로 <strong>여러 개의 컬럼이 반환</strong>되어 메인쿼리 조건과 동시에 비교되는 것.</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 다둥컬럼 서브퉈리 예시</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> ord_num, agent_code, ord_date, ord_amount</span><br><span class="line"><span class="keyword">from</span> orders</span><br><span class="line"><span class="keyword">where</span>(agent_code, ord_amount) <span class="keyword">IN</span></span><br><span class="line">(<span class="keyword">SELECT</span> agent_code, <span class="built_in">MIN</span>(ord_amount)</span><br><span class="line"><span class="keyword">FROM</span> orders </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> agent_code);  </span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h4 id="Where-절의-Subquery"><a href="#Where-절의-Subquery" class="headerlink" title="Where 절의 Subquery"></a>Where 절의 Subquery</h4><ul><li><p>비교연산자 IN 사용</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 특정 행 반환</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    employee_id, first_name, last_name</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    employees</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    department_id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> </span><br><span class="line">            department_id</span><br><span class="line">        <span class="keyword">FROM</span></span><br><span class="line">            departments</span><br><span class="line">        <span class="keyword">WHERE</span></span><br><span class="line">            location_id <span class="operator">=</span> &quot;찾는 아이디&quot;)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> first_name , last_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>MAX나 MIN 사용</p></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># <span class="keyword">where</span> 절에서 서브쿼리로 정의한 조건을 <span class="keyword">select</span> 절에 쓸 수 있다.</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    employee_id, first_name, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    employees</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    salary <span class="operator">=</span> (<span class="keyword">SELECT</span> </span><br><span class="line">            <span class="built_in">MAX</span>(salary)</span><br><span class="line">        <span class="keyword">FROM</span></span><br><span class="line">            employees)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> first_name , last_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>AVG로 조건걸기</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    employee_id, first_name, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    employees</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    salary <span class="operator">&gt;</span> (<span class="keyword">SELECT</span> </span><br><span class="line">            <span class="built_in">AVG</span>(salary)</span><br><span class="line">        <span class="keyword">FROM</span></span><br><span class="line">            employees);    </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>서브쿼리 조건문처럼 사용하기</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">  <span class="keyword">FROM</span> tutorial.sf_crime_incidents_2014_01</span><br><span class="line"> <span class="keyword">WHERE</span> <span class="type">Date</span> <span class="operator">=</span> (<span class="keyword">SELECT</span> <span class="built_in">MIN</span>(<span class="type">date</span>)</span><br><span class="line">                 <span class="keyword">FROM</span> tutorial.sf_crime_incidents_2014_01</span><br><span class="line">              )</span><br></pre></td></tr></table></figure><h4 id="FROM-절의-Subquery-Inline-View"><a href="#FROM-절의-Subquery-Inline-View" class="headerlink" title="FROM 절의 Subquery(Inline View)"></a>FROM 절의 Subquery(Inline View)</h4><ul><li>SQL이 실행될 때만 동적으로 생성되는 Inline view</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="built_in">MAX</span>(items), </span><br><span class="line">    <span class="built_in">MIN</span>(items), </span><br><span class="line">    <span class="built_in">FLOOR</span>(<span class="built_in">AVG</span>(items))</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    (<span class="keyword">SELECT</span> </span><br><span class="line">        orderNumber, <span class="built_in">COUNT</span>(orderNumber) <span class="keyword">AS</span> items</span><br><span class="line">    <span class="keyword">FROM</span></span><br><span class="line">        orderdetails</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> orderNumber) <span class="keyword">AS</span> lineitems;</span><br></pre></td></tr></table></figure><ul><li>파생테이블은 반드시 alias를 가진다,</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="built_in">substring</span>(address,<span class="number">1</span>,<span class="number">2</span>) <span class="keyword">as</span> region,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> review_count</span><br><span class="line"><span class="keyword">from</span> review <span class="keyword">as</span> r <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> <span class="keyword">member</span> <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">on</span> r.mem_id <span class="operator">=</span> m.id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="built_in">substring</span>(address,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">having</span> region <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line">    <span class="keyword">and</span> region <span class="operator">!=</span> <span class="string">&#x27;안드&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">avg</span>(review_count),</span><br><span class="line">       <span class="built_in">max</span>(review_count),</span><br><span class="line">       <span class="built_in">min</span>(review_count)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span></span><br><span class="line">    <span class="built_in">substring</span>(address,<span class="number">1</span>,<span class="number">2</span>) <span class="keyword">as</span> region,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> review_count</span><br><span class="line"><span class="keyword">from</span> review <span class="keyword">as</span> r <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> <span class="keyword">member</span> <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">on</span> r.mem_id <span class="operator">=</span> m.id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="built_in">substring</span>(address,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">having</span> region <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line">    <span class="keyword">and</span> region <span class="operator">!=</span> <span class="string">&#x27;안드&#x27;</span>) <span class="keyword">as</span> review_count_summary #서브쿼리로 탄생한 파생테이블은 반드시 alias를 가져야 한다</span><br></pre></td></tr></table></figure><p>– Join과 서브쿼리 같이 사용하기</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">  <span class="keyword">FROM</span> tutorial.sf_crime_incidents_2014_01 incidents</span><br><span class="line">  <span class="keyword">JOIN</span> ( <span class="keyword">SELECT</span> <span class="type">date</span></span><br><span class="line">           <span class="keyword">FROM</span> tutorial.sf_crime_incidents_2014_01</span><br><span class="line">          <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="type">date</span></span><br><span class="line">          LIMIT <span class="number">5</span></span><br><span class="line">       ) sub</span><br><span class="line">    <span class="keyword">ON</span> incidents.date <span class="operator">=</span> sub.date</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="SELECT-절의-Subquery-Scala-Subquery"><a href="#SELECT-절의-Subquery-Scala-Subquery" class="headerlink" title="SELECT 절의 Subquery(Scala Subquery)"></a>SELECT 절의 Subquery(Scala Subquery)</h4><ul><li>SELECT 절 안에 SELECT가 있을 경우 Scala 서브쿼리라 부르며 기본적으로 한 행만 리턴한다.</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> PLAYER, HEIGHT , (<span class="keyword">SELECT</span> <span class="built_in">AVG</span>(HEIGHT)</span><br><span class="line">                         <span class="keyword">FROM</span> PLAYER X</span><br><span class="line">                         <span class="keyword">WHERE</span> X.TEAM_ID <span class="operator">=</span> P.TEAM_ID)</span><br><span class="line"><span class="keyword">FROM</span> PLAYER_P</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>기본적으로 outer join이 적용되어 있다.</li><li>쿼리 수행 횟수를 최소화하기 위해서 입력값과 출력값을 내부 캐시에 저장한다.</li><li>대용량 데이터를 처리할 경우 속도가 느려질 수 있다.</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A.PKID</span><br><span class="line">    , A.TITLE</span><br><span class="line">    , NVL(B.NAME, <span class="string">&#x27;탈퇴한 회원&#x27;</span>), B.NAME</span><br><span class="line">    , (<span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> REPLY <span class="keyword">WHERE</span> P_PKID <span class="operator">=</span> B.PKID) <span class="keyword">AS</span> COUNT1</span><br><span class="line"><span class="keyword">FROM</span> BOARD B <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> <span class="keyword">MEMBER</span> M</span><br><span class="line">    <span class="keyword">ON</span> B.MEM_NO <span class="operator">=</span> M.PKID</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://mode.com/sql-tutorial/sql-sub-queries/">https://mode.com/sql-tutorial/sql-sub-queries/</a></li><li><a href="https://www.mysqltutorial.org/mysql-subquery/">https://www.mysqltutorial.org/mysql-subquery/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
            <tag> Subquery </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Probability]numpy와 scipy로 다항분포 간단하게 구현하기</title>
      <link href="/2021/08/10/statistics/Statistics-Prob-multinomial-dist/"/>
      <url>/2021/08/10/statistics/Statistics-Prob-multinomial-dist/</url>
      
        <content type="html"><![CDATA[<!--진짜 refhttps://www.statology.org/multinomial-distribution-in-python/https://boxnwhis.kr/2015/06/04/multinomial_dist_for_gachas.html다항로지스틱 머신러닝https://machinelearningmastery.com/multinomial-logistic-regression-with-python/확륳함수로부터 나오는 확률들의 패턴을 확률분포라 한다https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h4 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h4><ul><li><p>다항분포는 이항분포의 보다 일반화된 버전이다.(다항 분포에서 차원이 2인 경우 이항 분포가 된다.)</p></li><li><p><strong>다항 분포는 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포로, 여러 번의 독립적 시행에서 각각의 값이 특정 횟수가 나타날 확률을 정의한다.</strong><br>다항분포의 가장 쉬운 예시 중 하나는 주사위를 N 번 던저 각 면이 나오는 횟수 집합의 분포를 구하는 것이다.</p></li><li><p><strong>특정 확률변수 X가 다음의 조건을 충족할 경우 다항분포를 따른다.</strong></p><ul><li>k개의 class(발생가능한 결과, 카테고리 등)</li><li>각 trial은 독립적이다.</li><li>독립적인 각각의 trial에서 i번째 class가 나타날 확률읜 $p_{i}$로 고정한다.</li></ul></li></ul><h4 id="다항분포-공식"><a href="#다항분포-공식" class="headerlink" title="다항분포 공식"></a>다항분포 공식</h4><ul><li><p>다항분포의 PMF는 다음과 같이 정의된다. 식이 복잡해보이는 것은 단순히 나올 수 있는 결과의 조합이 복잡하기 때문이다.<br>$$f(x)&#x3D;\frac{n !}{x_{1} ! \cdots x_{k} !} p_{1}^{x_{1}} \cdots p_{k}^{x_{k}}$$</p></li><li><p>다항분포의 기댓값 :<br>$$E{X_{i}}&#x3D;np_{i}$$</p></li><li><p>다항분포의 분산 :<br>$\operatorname{Var}\left(X_{i}\right)&#x3D;n p_{i}\left(1-p_{i}\right)$</p></li></ul><h4 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h4><ul><li>numpy를 활용한 시뮬레이션</li></ul><p>두번째 인수에 tuple 형태로 각 class의 확률이 들어간다.<br>두번째 인수의 확률의 합은 반드시 1이여야 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 주사위 10번 던지는 시뮬레이션</span></span><br><span class="line">np.random.multinomial(<span class="number">10</span>, [<span class="number">1</span>/<span class="number">6.</span>]*<span class="number">6</span>, size=<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]]) <span class="comment"># random</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>scipy 예제</li></ul><p>주머니에 6개의 노란 구슬,2개의 빨간 구슬, 2개의 파란구슬이 있을 때<br>복원추출로 4개의 구슬을 뽑을 경우 모든 구슬이 빨간 색일 확률은 무엇인가?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> multinomial</span><br><span class="line"></span><br><span class="line">multinomial.pmf(x=[<span class="number">0</span>,<span class="number">4</span>,<span class="number">0</span>],n=<span class="number">4</span>,p = [<span class="number">.6</span>,<span class="number">.2</span>,<span class="number">.2</span>])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;<span class="number">0.1295999999999999</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://youtu.be/nMsCHfrt3Cw">https://youtu.be/nMsCHfrt3Cw</a></li><li><a href="https://www.statisticshowto.com/multinomial-distribution/">https://www.statisticshowto.com/multinomial-distribution/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Statistics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Probability </tag>
            
            <tag> Probability Distribution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Neural Network]Recurrent Neural Network</title>
      <link href="/2021/08/05/machine-learning/DL-RNN/"/>
      <url>/2021/08/05/machine-learning/DL-RNN/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk**굵은 글씨로 뭔가 쓴다.**#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[SQL]WHERE절의 이해</title>
      <link href="/2021/08/02/data-engineering/DE-SQL-Where/"/>
      <url>/2021/08/02/data-engineering/DE-SQL-Where/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Where-절"><a href="#Where-절" class="headerlink" title="Where 절"></a>Where 절</h2><p>조건생성을 위해 Where절을 사용한다.</p><h4 id="BETWEEN"><a href="#BETWEEN" class="headerlink" title="BETWEEN"></a>BETWEEN</h4><ul><li>특정 칼럼의 값이 시작점, 끝점인 데이터만 출력</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> ordersdetails</span><br><span class="line"><span class="keyword">where</span> priceeach <span class="keyword">between</span> <span class="number">30</span> <span class="keyword">and</span> <span class="number">50</span>;</span><br></pre></td></tr></table></figure><h4 id="IN"><a href="#IN" class="headerlink" title="IN"></a>IN</h4><ul><li>or 연산자</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> customernumber</span><br><span class="line"><span class="keyword">from</span> customers</span><br><span class="line"><span class="keyword">where</span> country <span class="keyword">in</span> (<span class="string">&#x27;USA&#x27;</span>,<span class="string">&#x27;CANADA&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="IS-NULL"><a href="#IS-NULL" class="headerlink" title="IS NULL"></a>IS NULL</h4><ul><li>null 데이터 출력</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> copang_main.member <span class="keyword">where</span> ADDRESS <span class="keyword">is</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> copang_main.member <span class="keyword">where</span> address <span class="keyword">is</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> copang_main.member <span class="keyword">where</span></span><br><span class="line">address <span class="keyword">is</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">OR</span> height <span class="keyword">IS</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">OR</span> weight <span class="keyword">IS</span> <span class="keyword">NULL</span>; # 세 컬럼중 하나라도 <span class="keyword">null</span>이 있는 로우만 조회</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> # coalesce</span><br><span class="line">    <span class="built_in">coalesce</span>(height,<span class="string">&#x27;####&#x27;</span>), # <span class="keyword">null</span>이 아닌 값은 그대로 반환, <span class="keyword">null</span>일 경우 입력한 값 반환</span><br><span class="line">    <span class="built_in">coalesce</span>(weight,<span class="string">&#x27;----&#x27;</span>),</span><br><span class="line">    <span class="built_in">coalesce</span>(address,<span class="string">&#x27;@@@@&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> copang_main.`<span class="keyword">member</span>`;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>NULL 변환함수</strong></p><ol><li><p>coalesce : 첫번째로 null이 아닌 값을 반환</p></li><li><p>ifnull : 첫번째 인자가 null인 경우 두번째 인자, 아닐 경우 해당 값 표현</p></li><li><p>if(a1,a2,a3) : ifelse 처럼 사용가능</p></li></ol><h4 id="LIKE"><a href="#LIKE" class="headerlink" title="LIKE"></a>LIKE</h4><ul><li>문자열 매칭하기</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> main.`<span class="keyword">member</span>` <span class="keyword">WHERE</span> address <span class="keyword">like</span> <span class="string">&#x27;서울%&#x27;</span>; # address가 서울로 시작하는 <span class="type">row</span> 조회</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> main.`<span class="keyword">member</span>` <span class="keyword">WHERE</span> address <span class="keyword">like</span> <span class="string">&#x27;%고양시%&#x27;</span>; # 고양시라는 단어 앞뒤로 임의의 길이를 가진 문자열 조건</span><br></pre></td></tr></table></figure><h4 id="이스케이핑-문제"><a href="#이스케이핑-문제" class="headerlink" title="이스케이핑 문제"></a>이스케이핑 문제</h4><ul><li>어떤 문자가 그것에 부여된 특정한 의미,기능으로 해석되는 것이 아니라 단순한 문자 하나도 해석되게끔 하는 것을 <code>이스케이핑</code>이라 한다.</li><li>‘ 이스케이핑 -&gt; select * from copang_main.test where sentence like ‘%&#39;%’</li><li>_ 이스케이핑 -&gt; select * from copang_main.test where sentence like ‘%_%’</li><li>“ 이스케이핑 -&gt; select * from copang_main.test where sentence like ‘%&quot;&quot;%’</li><li>대문자 제외 소문자 찾기 select * from copang_main.test where sentence like binary ‘%g%’</li></ul><h4 id="ANY"><a href="#ANY" class="headerlink" title="ANY"></a>ANY</h4><ul><li><strong>ANY는 나올 수 있는 모든 조건에 OR 연산을 수행한것과 동일한 결과 반환</strong></li><li>수량이 10개인 제품 전부 반환</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ProductName</span><br><span class="line"><span class="keyword">FROM</span> Products</span><br><span class="line"><span class="keyword">WHERE</span> ProductID <span class="operator">=</span> <span class="keyword">ANY</span></span><br><span class="line">  (<span class="keyword">SELECT</span> ProductID</span><br><span class="line">  <span class="keyword">FROM</span> OrderDetails</span><br><span class="line">  <span class="keyword">WHERE</span> Quantity <span class="operator">=</span> <span class="number">10</span>);</span><br></pre></td></tr></table></figure><ul><li>수량이 1000개 초과인 제품 전부 반환</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ProductName</span><br><span class="line"><span class="keyword">FROM</span> Products</span><br><span class="line"><span class="keyword">WHERE</span> ProductID <span class="operator">=</span> <span class="keyword">ANY</span></span><br><span class="line">  (<span class="keyword">SELECT</span> ProductID</span><br><span class="line">  <span class="keyword">FROM</span> OrderDetails</span><br><span class="line">  <span class="keyword">WHERE</span> Quantity <span class="operator">&gt;</span> <span class="number">1000</span>);</span><br></pre></td></tr></table></figure><h4 id="ALL"><a href="#ALL" class="headerlink" title="ALL"></a>ALL</h4><ul><li>조건을 모두 만족하는 행을 반환</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ProductName</span><br><span class="line"><span class="keyword">FROM</span> Products</span><br><span class="line"><span class="keyword">WHERE</span> ProductID <span class="operator">=</span> <span class="keyword">ALL</span></span><br><span class="line">  (<span class="keyword">SELECT</span> ProductID</span><br><span class="line">  <span class="keyword">FROM</span> OrderDetails</span><br><span class="line">  <span class="keyword">WHERE</span> Quantity <span class="operator">=</span> <span class="number">10</span>);</span><br></pre></td></tr></table></figure><h4 id="EXISTS"><a href="#EXISTS" class="headerlink" title="EXISTS"></a>EXISTS</h4><ul><li>EXISTS는 행의 존재 여부를 확인하여 True&#x2F;False 값을 반환</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> SupplierName</span><br><span class="line"><span class="keyword">FROM</span> Suppliers</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> ProductName <span class="keyword">FROM</span> Products <span class="keyword">WHERE</span> Products.SupplierID <span class="operator">=</span> Suppliers.supplierID <span class="keyword">AND</span> Price <span class="operator">=</span> <span class="number">22</span>);</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>SQL로 맛보는 데이터 전처리분석</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Deep Leearing] 학습 규제하기(Handling Overfitting)</title>
      <link href="/2021/08/02/machine-learning/DL-regularization/"/>
      <url>/2021/08/02/machine-learning/DL-regularization/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>과적합 방지를 위한 기법을 규제라고 부른다.</strong></p><ul><li><a href="#weight-decay">Weight Decay</a></li><li><a href="#weight-constraint">Weight Constraint</a></li><li><a href="#dropout">Dropout</a></li><li><a href="#"></a></li><li><a href="#%EC%B6%94%EA%B0%80-%ED%95%99%EC%8A%B5%EC%97%90-batch-size%EA%B0%80-%EB%AF%B8%EC%B9%98%EB%8A%94-%EC%98%81%ED%96%A5">[추가] 학습에 batch size가 미치는 영향</a></li><li><a href="#references">References</a></li></ul><hr><h2 id="Weight-Decay"><a href="#Weight-Decay" class="headerlink" title="Weight Decay"></a>Weight Decay</h2><p>학습은 </p><p>$$Loss &#x3D; MSE + \lambda \times  * {w}^2$$</p><p>왜 이런 조치를 하는 것이 overfitting을 줄여주는가?</p><p>어딘가에 Global minimum이 존재</p><p>하지만 이 Global minimum은 <code>학습한</code> training set에서만 적용</p><p>Regularization 항을 추가할 경우 원점에 loss surface가 하나 더 생김</p><p>Global minimum에 빠질 경우 overfitting 이 일어나는데 loss surface를 하나 더 만듦으로써 다른 training set에서도 해당 모형이 잘 적용될 수 있게끔하는 것이다.</p><h2 id="Weight-Constraint"><a href="#Weight-Constraint" class="headerlink" title="Weight Constraint"></a>Weight Constraint</h2><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="추가-학습에-batch-size가-미치는-영향"><a href="#추가-학습에-batch-size가-미치는-영향" class="headerlink" title="[추가] 학습에 batch size가 미치는 영향"></a>[추가] 학습에 batch size가 미치는 영향</h2><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e">batch size 관련</a> </li><li><a href="https://towardsdatascience.com/handling-overfitting-in-deep-learning-models-c760ee047c6e">overfitting in deeplearing models</a></li><li><a href="https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab">weight decay</a></li></ul><!--- [L1 & L2 Regularization](https://www.youtube.com/watch?v=_sz3KTyB9Lk&t=1063s)- [가중치 초기화 관련](https://youtu.be/ScWTYHQra5E)- [Dropout](https://www.youtube.com/watch?v=ajeliDMD86U)- [Ng 교수님의 하이퍼파라미터 설명](https://www.youtube.com/watch?v=wKkcBPp3F1Y)- [parameter와 hyperparameter 차이](https://youtu.be/Kh06wgGbi78?t=12)- [학습 규제 방식에 대한 설명 강의](https://youtu.be/_sz3KTyB9Lk?t=1005)- [L1/L2-regularization](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c)--><ul><li><a href="https://light-tree.tistory.com/125">L1 &amp; L2 용어정리</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Classification]로지스틱 회귀와 크로스엔트로피</title>
      <link href="/2021/08/02/machine-learning/ML-SP-logistic_regression/"/>
      <url>/2021/08/02/machine-learning/ML-SP-logistic_regression/</url>
      
        <content type="html"><![CDATA[<!--<center >Kaggle Customer Score Dataset</center>- Machine Learning- Deep Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p><strong>로지스틱회귀의 파라미터 추정은 Feature X에 대한 선형회귀모델을 X에 대한 target의 log odds에 Fitting하는 것이다.</strong></p><p><strong>Fitting의 방식</strong></p><p>Maximum Likelyhood를 최대화하는 것 &#x3D; 이항편차(binary deviance)를 줄이는 것 &#x3D; cross entropy loss 를 줄이는 것</p><p>MLE(Maximum Likelyhood Estimation)를 통해 이해할 수도 있지만 여기서는 Cross Entropy를 통한 최적화 관점에서의 Logistic 회귀를 주로 다룬다.</p><hr><p><strong><em>Concept</em></strong></p><ul><li><strong>Cross Entropy</strong> :두 개의 확률분포 p와 q에 대해 하나의 사건 X가 갖는 정보량<ul><li><strong>Cross Entropy</strong> 는 기본적으로 <strong>추정된 분포가 실제의 분포와 열마나 가까운지</strong> 를 결정한다.</li></ul></li><li><strong>sigmoid</strong> : input을 0과 1사이로 조정하여 반환하는 활성화 함수의 일종</li><li><strong>softmax</strong> : 로지스틱 회귀를 다중 클래스 분류로 확장할때 사용하는 활성화 함수.분류될 클래스가 n개라 할 때, n차원의 벡터를 입력받아, 각 클래스에 속할 확률을 추정한다.</li><li><strong>모수(Parameter)</strong> : 머신러닝에서 파라미터는 <strong>모델의 형태를 결정하는 값</strong>으로 정의할 수 있다. 예를 들어 y &#x3D; wx+b라는 모델이 주어졌을 때 w,b가 모델의 모수가 된다.</li><li><strong>우도</strong> : 확률 분포의 모수가, 어떤 확률변수의 표집값과 일관되는 정도를 나타내는 값. <strong>관측값이 고정되어있을 때</strong> 그 관측치가 어떤 확률분포에서 나왔는가의 문제 </li><li><strong>최대우도추정(Maxium Likelyhood Estimation)</strong> :얻어진 데이터를 토대로 그 확률변수의 모수를 구하는 방법이다. 어떤 모수가 주어졌을 때, 원하는 값들이 나올 우도함수를 최대로 만드는 <strong>모수를 선택하는 방법</strong>이다.<ul><li>**관측값(데이터) 가 주어진 상태에서 그 관측값이 나올 우도함수 **</li><li>– MLE관점에서 볼때 로지스틱회귀는 x와 w가 주어졌을 때 y의 확률. y의 확률이 나올 수 있는 w의 최대값을 구하는 문제이다.</li></ul></li><li>우도함수 :  가능도함수는 모수가 $\theta$일 때, 특정 표본 x 가 나타날 함수.</li></ul><hr><p><strong>정리</strong></p><ul><li>Linear regression 에서는 연속적인 값을 출력하는 반면 Logistic regression에서 기본적으로 기대되는 output은 확률이다.</li><li><strong>오차함수의 기본적인 검증 방식이 0이나 1로부터 예측값이 얼마나 떨어져 있는 지를 측정하는 것이다</strong></li><li>확률을 도출하기 위해 <strong>선형모델에 sigmoid 함수를 적용</strong>한다.</li><li>기본적으로 L2규제를 적욯하기 때문에 규제를 강하게 하면 계수가 0에 가깝게 되지만 완전히 0이 되지는 않는다.</li><li>설명하기 쉬운 모델을 원한다면 특성의 개수를 제한하는 L1규제를 사용한다. <ul><li>L1규제는 0이 많은 sparse data에 적합하다.</li></ul></li><li>Hyperparameter C를 통해 규제의 강도를 결정한다.</li><li>C는 Ridge나 Lasso에서의 규제강도인 alpha($\lambda$)의 inverse이다. 다시말해 <strong>C 값이 높을 수록 규제가 감소하고 C값이 낮으면 계수 벡터가 0에 가까워진다</strong>.(피쳐의 영향이 줄어든다.)</li><li>이는 C의 값이 낮다면 데이터 포인트를 다수에 맞추려고 하는 반면 C의 값이 높다면 개개의 데이터 포인트를 명확하게 분류하고자 하는 알고리즘으로 볼 수 있다.</li></ul><h4 id="Cost-function-in-Logistic-Regression-Cross-Entropy"><a href="#Cost-function-in-Logistic-Regression-Cross-Entropy" class="headerlink" title="Cost function in Logistic Regression (Cross Entropy)"></a>Cost function in Logistic Regression (Cross Entropy)</h4><ul><li><strong>Cross Entropy는 두 개의 확률분포 p와 q에 대해 하나의 사건 X가 갖는 정보량이다</strong>. 즉, 서로 다른 두 확률분포에 대해 같은 사건이 가지는 정보량을 계산한 것이다.</li><li>기본적으로 <strong>추정된 분포가 실제의 분포와 열마나 가까운지</strong> 를 결정한다.<ul><li>p(x)는 true label의 분포를 one-hot encoding 형식으로 나타낸 것이다.</li><li>q(x)는 현재 예측모델의 추정값의 분포이다.</li></ul></li><li>모형이 예측한 확률분포들 중 정답에 해당하는 위치의 뉴런에 -log를 취한 것이 출력값이 된다.</li><li><code>-log</code> 를 취하는 이유는 출력값이 0,1 사이의 확률값으로 나와하 하기때문이다.</li></ul><p><img src="https://i.stack.imgur.com/gNip2.png" alt="크로스 엔트로피 수식"></p><ul><li><p>MSE을 비용함수로 사용할 경우 국소 최소값에 빠질 가능성이 있어 크로스 엔트로피 함수를 사용한다.</p></li><li><p><strong>정답에 해당하는 뉴런값의 오차만 계산에 들어간다는 것이 특징이다.</strong></p></li><li><p>정답에 해당하는 위치의 뉴런이 0에 가까워 질수록 y값이 exponential하게 증가하게 된다.</p></li><li><p>Best case는 모델이 예측한 분포와 타겟의 분포가 같은 경우. 이 경우 오차가 0이된다.</p></li><li><p>worst case는 target 위치의 뉴런 값이 0인 경우이며 이 때 Cross Entropy 오차는 무한히 증가한다.</p></li></ul><p><img src="https://ml-cheatsheet.readthedocs.io/en/latest/_images/y1andy2_logistic_function.png" alt="크로스 엔트로피 오차"></p><ul><li>크로스 엔트로피 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">p = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])             <span class="comment"># True probability (one-hot)</span></span><br><span class="line">q = np.array([<span class="number">0.228</span>, <span class="number">0.619</span>, <span class="number">0.153</span>]) <span class="comment"># Predicted probability</span></span><br><span class="line"></span><br><span class="line">cross_entropy_loss = -np.<span class="built_in">sum</span>(p * np.log(q))</span><br><span class="line"><span class="built_in">print</span>(cross_entropy_loss)</span><br><span class="line"><span class="comment"># 0.47965000629754095</span></span><br></pre></td></tr></table></figure><ul><li>크로스 엔트로피 비용함수를 통해 로지스틱 회귀 모형의 목적함수를 정의할 수 있다.<ul><li>$\lambda \rVert W \rVert_2$ 는 l2 규제항이다.</li><li>$\lambda$ 가 0이 되면 규제항이 없는 단순 로지스틱회귀가 된다. </li><li>$\lambda$가 커질수록 W가 줄어든다.($\lambda$가 무한대로 가면 가중치는 0으로 수렴)</li><li>$\lambda$ 수치를 조정함으로서  fit과 magnitude 사이에서 균형을 맞출 수 있다.</li><li>C는 $\lambda$ 역수로 sklearn에서 hyperparameter로 쓰인다.</li></ul></li></ul><p>$$J(w) &#x3D; -\frac{1}{m} \sum_{i&#x3D;1}^{m} [y^{(i)}logH(x^{(i)}) + (1-y^{(i)})log(1-H(x^{(i)}))]+\lambda \rVert W \rVert_2$$</p><p>아래와 같이 보다 간소화 해서 작성할 수 있다.</p><p>$$J(w)&#x3D;\frac{1}{m} \sum_{i&#x3D;1}^{m} \operatorname{Cost}\left(h\left(x^{(i)}\right), y^{(i)}\right)+\frac{\lambda}{2 m} \sum_{j&#x3D;1}^{n} w_{j}^{2}$$</p><p>이 경우 업데이트 시 <strong>Gradiant를</strong> 아래아 같이 작성할 수 있다.</p><p>$$\frac{\partial}{\partial w_{i}} J(w)&#x3D;\frac{1}{m}\left[\sum_{j&#x3D;1}^{m}\left(h\left(x^{(j)}\right)-y^{(j)}\right) x_{i}^{(j)}+\lambda w_{i}\right]$$</p><h4 id="Sigmoid-Function"><a href="#Sigmoid-Function" class="headerlink" title="Sigmoid Function"></a>Sigmoid Function</h4><ul><li>input을 0과 1사이로 조정하여 반환하는 활성화 함수의 일종.</li><li>기준점인 0.5를 기준으로 출력값을 결정한다.</li><li>w가 커질수록 기울기가 커진다.</li><li>b의 크기에 따라 함수 자체가 이동한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 시그모이드 구현</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid non-convex logistic least squares cost function</span></span><br><span class="line"><span class="comment"># convex 한것은 비용함수가 구불구불해서 국소 최저점이 존재하는 것</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_least_squares</span>(<span class="params">w</span>):</span><br><span class="line">    cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(y.size):</span><br><span class="line">        x_p = x[:,p]</span><br><span class="line">        y_p = y[:,p]</span><br><span class="line">        cost += (sigmoid(w[<span class="number">0</span>] + w[<span class="number">1</span>]*x_p) - y_p)**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> cost/y.size</span><br></pre></td></tr></table></figure><p><img src="https://jermwatt.github.io/machine_learning_refined/mlrefined_images/superlearn_images/sigmoid.png"></p><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><ul><li>로지스틱 회귀를 다중클래스 분류로 확장한 것.</li><li>분류하고자 하는 클래스가 n개일 때, n차원의 벡터를 입력받아서 모든 벡터 원소의 값을 0과 1사이의 값으로 값을 변경하여 다시 k차원의 벡터를 리턴한다.</li><li>소프트맥스 함수는 분류될 클래스가 n개라 할 때, n차원의 벡터를 입력받아, 각 클래스에 속할 확률을 추정한다.</li></ul><p><img src="https://www.gstatic.com/education/formulas2/397133473/en/softmax_function.svg"></p><ul><li><p><strong>확률의 총합이 1이다.</strong></p></li><li><p>식 자체는 단순하게 <code>probability = exp(value) / sum v in list exp(v)</code> 로 나타낼 수 있다. <code>n번째 일 확률 / 전체 확률</code> 로 생각하면 된다. </p></li><li><p><a href="https://gooopy.tistory.com/53">지수함수(exp)가 식에 포함된 이유</a></p></li><li><p>softmax 구현</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">3</span>]: <span class="keyword">from</span> numpy <span class="keyword">import</span> exp</span><br><span class="line">   ...:</span><br><span class="line">   ...: </span><br><span class="line">   ...: <span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">vector</span>):</span><br><span class="line">   ...:   e = exp(vector)</span><br><span class="line">   ...:   <span class="keyword">return</span> e / e.<span class="built_in">sum</span>()</span><br><span class="line">   ...:</span><br><span class="line">   ...: </span><br><span class="line">   ...: data = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">   ...: <span class="comment"># convert list of numbers to a list of probabilities</span></span><br><span class="line">   ...: result = softmax(data)</span><br><span class="line">   ...: <span class="comment"># report the probabilities</span></span><br><span class="line">   ...: <span class="built_in">print</span>(result)</span><br><span class="line">   ...: <span class="comment"># report the sum of the probabilities</span></span><br><span class="line">   ...: <span class="built_in">print</span>(<span class="built_in">sum</span>(result))</span><br><span class="line">[<span class="number">0.09003057</span> <span class="number">0.66524096</span> <span class="number">0.24472847</span>]</span><br><span class="line"><span class="number">1.0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="구현"><a href="#구현" class="headerlink" title="구현"></a>구현</h3><ul><li><p>numpy를 활용한 구현</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 정확도를 측정하기 위한 accuracy 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_true,y_pred</span>):</span><br><span class="line">  accuracy = np.<span class="built_in">sum</span>(y_true==y_pred)/<span class="built_in">len</span>(y_true)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,lr=<span class="number">0.001</span>,n_iters=<span class="number">1000</span></span>):</span><br><span class="line">    self.lr = lr</span><br><span class="line">    self.n_iters = n_iters</span><br><span class="line">    self.weigts = <span class="literal">None</span></span><br><span class="line">    self.bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y</span>):</span><br><span class="line">    <span class="comment"># init parameters</span></span><br><span class="line"></span><br><span class="line">    n_samples, n_features = X.shape</span><br><span class="line"></span><br><span class="line">    self.weigts = np.zeros(n_features)</span><br><span class="line">    self.bias =<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradient descent</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iters):</span><br><span class="line">      linear_model = np.dot(X,self.weigts)+self.bias</span><br><span class="line"></span><br><span class="line">      y_pred = self._sigmoid(linear_model) <span class="comment"># 선형모델에 sigmoid 적용</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      dw = (<span class="number">1</span>/n_samples) * np.dot(X.T,(y_pred-y)) <span class="comment"># W에 대해 편미분</span></span><br><span class="line">      db = (<span class="number">1</span>/n_samples) * np.<span class="built_in">sum</span>(y_pred-y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      self.weigts = -= self.lr * dw</span><br><span class="line">      self.bias = -= self.lr*db</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">    linear_model = np.dot(X,self.weigts)+self.bias</span><br><span class="line">    y_pred = self._sigmoid(linear_model) <span class="comment"># 0~1 사이의 float을 반환</span></span><br><span class="line"></span><br><span class="line">    y_pred_class = [<span class="number">1</span> <span class="keyword">if</span> i &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> y_pred] <span class="comment"># 값을 0,1로 고정</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred_class</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">_sigmoid</span>(<span class="params">self,x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br></pre></td></tr></table></figure></li><li><p>sklearn을 활용한 구현</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">X, y = load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line">clf = LogisticRegression(random_state=<span class="number">0</span>).fit(X, y)</span><br><span class="line">clf.predict(X[:<span class="number">2</span>, :])</span><br><span class="line"></span><br><span class="line">clf.predict_proba(X[:<span class="number">2</span>, :]) <span class="comment"># 확률 출력</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clf.score(X, y)</span><br></pre></td></tr></table></figure><ul><li>tensorflow를 활용한 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">0.42264594</span>, <span class="number">0.4524148</span> , <span class="number">0.93797131</span>, <span class="number">0.36534474</span>, <span class="number">0.40276151</span>,<span class="number">0.29153749</span>, <span class="number">0.05982402</span>, <span class="number">0.24713247</span>, <span class="number">0.91650771</span>, <span class="number">0.45207763</span>])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]) </span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">1</span>, input_dim=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.001</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=sgd ,loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;binary_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x, y, epochs=<span class="number">200</span>)</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://stackoverflow.com/questions/41990250/what-is-cross-entropy/41990932">Cross Entropy</a></li><li><a href="https://youtu.be/yIYKR4sgzI8?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe">Logistic Regression</a></li><li><a href="https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html">로지스틱 회귀 구현</a></li><li><a href="https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax">소프트맥스</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Supervised Learning </tag>
            
            <tag> Logistic Regression </tag>
            
            <tag> Cross Entropy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Git]commit, push 제외 자주쓰는 git 명령어들</title>
      <link href="/2021/08/02/infra/git/git-log/"/>
      <url>/2021/08/02/infra/git/git-log/</url>
      
        <content type="html"><![CDATA[<!--merge 렉카 : https://kotlinworld.com/277merge flow :master 에서 출발나의 작업용 브랜치를 만들기 위해 master 에서 feature 브랜치를 생성feature 브랜치에서 add commit 등의 작업내가 지금까지 push했던것은 local에 있던 코드를 remote의 브랜치로 전달한것PR 메시지 작성remote feature 에서 remote master로 mergelocal master에서 최신의 remote master 내용을 반영하기 위해 git pull origin masterlocal feature 에서 최신이 된 local master 내용을 반영하기 위해 git merge master충돌 발생 (local feature 에서)충돌 해결 후 add ,commit => 새 변경 사항remote feature에 새 변경 사항을 push충돌 해결 (remote feture 에서)--><h4 id="Branch-생성"><a href="#Branch-생성" class="headerlink" title="Branch 생성"></a>Branch 생성</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><h4 id="생성한-Branch로-이동"><a href="#생성한-Branch로-이동" class="headerlink" title="생성한 Branch로 이동"></a>생성한 Branch로 이동</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git switch example</span><br></pre></td></tr></table></figure><ul><li>branch를 만들면서 현재 branch 변경</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git switch -c example2  <span class="comment"># c 는 아마 create를 의미</span></span><br></pre></td></tr></table></figure><h4 id="branch-삭제"><a href="#branch-삭제" class="headerlink" title="branch 삭제"></a>branch 삭제</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d example</span><br></pre></td></tr></table></figure><ul><li>merge가 정상적으로 안되는 branch를 강제 삭제할 겨우</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -D example</span><br></pre></td></tr></table></figure><ul><li>원격 브랜치를 삭제할 경우</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin --delete example</span><br></pre></td></tr></table></figure><h4 id="파일옮기기-이름-바꾸기"><a href="#파일옮기기-이름-바꾸기" class="headerlink" title="파일옮기기, 이름 바꾸기"></a>파일옮기기, 이름 바꾸기</h4><p>단순히 unix mv 명령어를 사용해도 된다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">mv</span>  old_file new file </span><br></pre></td></tr></table></figure><h4 id="커밋내역-확인하기"><a href="#커밋내역-확인하기" class="headerlink" title="커밋내역 확인하기"></a>커밋내역 확인하기</h4><p>log를 통해 이전 커밋 내역을 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span></span><br></pre></td></tr></table></figure><h4 id="커밋내역-삭제하기"><a href="#커밋내역-삭제하기" class="headerlink" title="커밋내역 삭제하기"></a>커밋내역 삭제하기</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD~n  최근 내역 n개 삭제</span><br><span class="line">git <span class="built_in">log</span>  <span class="comment"># 삭제된 커밋 확인</span></span><br></pre></td></tr></table></figure><h4 id="변경사항-복원하기"><a href="#변경사항-복원하기" class="headerlink" title="변경사항 복원하기"></a>변경사항 복원하기</h4><p>restore  :  변경 내역이 있는 파일을 복원할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git restore a_file </span><br></pre></td></tr></table></figure><ul><li>stage 된 파일 복원</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git restore --staged a_file</span><br></pre></td></tr></table></figure><h4 id="branch-합치기-merge"><a href="#branch-합치기-merge" class="headerlink" title="branch 합치기(merge)"></a>branch 합치기(merge)</h4><ul><li>여기서는 현재 branch의 commit을 대상이 되는 branch의 commit까지 옮기는 작업인 <code>Fast Forward Merge</code> 만 다룬다.</li><li><code>Fast Forward Merge</code>는 중간에 다른 커밋이 추가되면 충돌 오류가 발생한다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git switch example</span><br><span class="line">git merge example2</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://git-scm.com/book/ko/v2/Git-%EB%B8%8C%EB%9E%9C%EC%B9%98-%EB%B8%8C%EB%9E%9C%EC%B9%98%EC%99%80-Merge-%EC%9D%98-%EA%B8%B0%EC%B4%88">브랜치와 Merge의 기초</a></li><li><a href="https://git-scm.com/book/ko/v2">https://git-scm.com/book/ko/v2</a></li><li><a href="https://goddaehee.tistory.com/274">https://goddaehee.tistory.com/274</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Infra </category>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Neural Network]하이퍼파라미터</title>
      <link href="/2021/07/30/machine-learning/DL-hyperparameter/"/>
      <url>/2021/07/30/machine-learning/DL-hyperparameter/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>hyperparameter에 대해 알아보고 딥러닝에서 쓸 수 있는 hyperparameter tuning option에 대해 알아본다.</strong></p><ul><li>training epoch</li><li>batch_size</li><li>learning rate</li><li>optimization algorithms</li><li>momentum</li><li>activate function</li></ul><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[SQL]간단한 CASE WHEN 용법</title>
      <link href="/2021/07/21/data-engineering/DE-SQL-case-when/"/>
      <url>/2021/07/21/data-engineering/DE-SQL-case-when/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>간단한 mysql case when 용법 정리</strong></p><hr><h3 id="Case-When"><a href="#Case-When" class="headerlink" title="Case When"></a>Case When</h3><ul><li>기본적으로 파생변수(컬럼)를 생성하는데 사용한다.</li><li>파생변수이기 때문에 Select절 에 들어간다.</li></ul><h4 id="Case-When-용법"><a href="#Case-When-용법" class="headerlink" title="Case When 용법"></a>Case When 용법</h4><p>용법은 어렵지 않다. 파생변수 Select 절에 들어가는 것만 주의</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> player_name,</span><br><span class="line">       weight,</span><br><span class="line">       <span class="keyword">CASE</span> <span class="keyword">WHEN</span> weight <span class="operator">&gt;</span> <span class="number">250</span> <span class="keyword">THEN</span> <span class="string">&#x27;over 250&#x27;</span></span><br><span class="line">            <span class="keyword">WHEN</span> weight <span class="operator">&gt;</span> <span class="number">200</span> <span class="keyword">THEN</span> <span class="string">&#x27;201-250&#x27;</span></span><br><span class="line">            <span class="keyword">WHEN</span> weight <span class="operator">&gt;</span> <span class="number">175</span> <span class="keyword">THEN</span> <span class="string">&#x27;176-200&#x27;</span></span><br><span class="line">            <span class="keyword">ELSE</span> <span class="string">&#x27;175 or under&#x27;</span> <span class="keyword">END</span> <span class="keyword">AS</span> weight_group</span><br><span class="line">  <span class="keyword">FROM</span> benn.college_football_players</span><br></pre></td></tr></table></figure><ul><li>order by에 사용힐 컬럼 생성</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CustomerName, City, Country</span><br><span class="line"><span class="keyword">FROM</span> Customers</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">(<span class="keyword">CASE</span></span><br><span class="line">    <span class="keyword">WHEN</span> City <span class="keyword">IS</span> <span class="keyword">NULL</span> <span class="keyword">THEN</span> Country</span><br><span class="line">    <span class="keyword">ELSE</span> City</span><br><span class="line"><span class="keyword">END</span>);</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> animal_id, name,</span><br><span class="line"><span class="keyword">case</span> </span><br><span class="line">    <span class="keyword">when</span> sex_upon_intake <span class="keyword">like</span> &quot;Intact%&quot; <span class="keyword">then</span> &quot;O&quot;</span><br><span class="line">    <span class="keyword">else</span> &quot;X&quot; </span><br><span class="line"><span class="keyword">end</span> <span class="keyword">as</span> &quot;중성화&quot;</span><br><span class="line"><span class="keyword">from</span> animal_ins</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> animal_id</span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://www.w3schools.com/sql/sql_case.asp">https://www.w3schools.com/sql/sql_case.asp</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Git]간단한 Git 명령어 및 용법 정리</title>
      <link href="/2021/07/17/infra/git/git-basic/"/>
      <url>/2021/07/17/infra/git/git-basic/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/tony9402/baekjoon/blob/main/solution/data_structure/10828/main.py">https://github.com/tony9402/baekjoon/blob/main/solution/data_structure/10828/main.py</a></p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Git은 버전관리와 협업을 위한 툴입니다. 추후 참고할 수 있도록 간단히 내용을 정리하겠습니다.</p><hr><h2 id="Git-동작원리"><a href="#Git-동작원리" class="headerlink" title="Git 동작원리"></a>Git 동작원리</h2><h3 id="Git의-영역들"><a href="#Git의-영역들" class="headerlink" title="Git의 영역들"></a>Git의 영역들</h3><ul><li><strong>Project 영역(working tree)</strong> : 현재 프로젝트에 있는 파일들 전체입니다.</li><li><strong>Staging 영역(staging area)</strong> : Project 영역에서 변경된 사항들을 기록하는 index 입니다.</li><li><strong>Repository</strong> : 깃이 버전 관리를 하기 위해 필요한 데이터들을 저장하는 곳입니다.깃을 초기화해 버전관리를 한 시점부터 현 시점까지의 파일들이 저장되어 있습니다.<ul><li>local  : 사용자의 Local 머신에 저장된 레포지토리입니다.</li><li>remote : Github, Gitlab 등의 웹 저장소에 레포지토리 입니다.</li></ul></li></ul><h3 id="Git에서-수행하는-작업들"><a href="#Git에서-수행하는-작업들" class="headerlink" title="Git에서 수행하는 작업들"></a>Git에서 수행하는 작업들</h3><p>Git은 기본적으로 Project영역에서 수정작업을 한 뒤 index에 <code>staging</code>하고 이를 로컬저장소에 <code>commit</code>하고 원격저장소에 <code>push</code> 하는 절차를 거칩니다.</p><ul><li><strong>특정 프로젝트의 업데이트 내용 기록(버전관리)</strong><ul><li>git add</li><li>git status</li><li>git log</li><li>git commit</li></ul></li><li><strong>같은 파일을 여러 작업자가 수정 및 관리(협업)</strong><ul><li>git branch</li><li>git checkout</li><li>git remote add 저장소</li><li>git fetch</li><li>git merge</li><li>git pull</li><li>git push</li></ul></li></ul><p><img src="/git-simple.png" alt="ohno"><br><strong>&lt;그림 1 git 동작원리&gt;</strong></p><h3 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h3><p>간단한 연습용 프로젝트를 통해 Git을 이해해봅시다.<br>일단 적당히 디렉토리를 만들고 git을 초기화 합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> new_project</span><br><span class="line"><span class="built_in">cd</span> new_project</span><br><span class="line">git init</span><br></pre></td></tr></table></figure><p>적당한 파이썬 파일 하나를 디렉토리에 추가해 줍니다.<br><code>vim</code> 이나 <code>sublimetext</code> ,<code>vscode</code> 등의 편집기를 활용해 파일들을 수정할 수 있습니다.<br>여기서는 bash shell에서 간단한 명령을 추가했습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> this.py</span><br><span class="line"><span class="comment"># 파일 편집을 위한 적당한 명령 추가</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;import this&quot;</span> &gt;&gt; this.py</span><br></pre></td></tr></table></figure><p><code>git status</code> 를  통해  확인해보면 <code>commit</code> 할 파일이 없다고 나옵니다.<br>이는 파일이 아직 Staging 영역의 index에 올라가지 않아서 그렇습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">Untracked files:</span><br><span class="line">  (use <span class="string">&quot;git add &lt;file&gt;...&quot;</span> to include <span class="keyword">in</span> what will be committed)</span><br><span class="line">        this.py</span><br><span class="line"></span><br><span class="line">nothing added to commit but untracked files present (use <span class="string">&quot;git add&quot;</span> to track)</span><br></pre></td></tr></table></figure><p>방금 생성한 파일을 git이 추적하도록 git add를 해줍니다.<br>만약 폴더 내 여러 파일을 편집한 상황에서 모든 변경사항을 반영하고 싶다면 <code>git add .</code>를 해주면 됩니다. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add this.py</span><br></pre></td></tr></table></figure><p>이제 폴더 내 변경사항이 index에 staging되었으니까 local 저장소에 <code>commit</code>을 해줄 수 있습니다.<br><code>commit -m</code> 을 통해 어떤 부분이 변경되었는지 간단히 메시지를 적어줄 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m <span class="string">&quot;this.py 파일 추가&quot;</span></span><br></pre></td></tr></table></figure><p>여기까지가 <code>working directory</code> -&gt; <code>local repository</code>의 작업흐름입니다.</p><h3 id="git-remote"><a href="#git-remote" class="headerlink" title="git remote"></a>git remote</h3><p><code>remote repostory</code> 는 데이터가 웹 서버에 저장된다는 것을 제외하면 로컬의 그것과 다를게 없습니다. </p><p>서버에 저장소를 만들어 둠으로서 보다 여러 사람들이 저장소에 접근하고 수정할 수 있게끔 해서 소스코드 관리를 보다 편리하게 할 수있습니다.</p><p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http://cfile8.uf.tistory.com/image/27532A36575F3888290EC8"><br><strong>&lt;그림2 remote repository&gt;</strong></p><p><code>git remote add </code> 를 통해 로컬을 외부저장소와 연결할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin <span class="string">&#x27;외부저장소 링크&#x27;</span></span><br></pre></td></tr></table></figure><p><code>git push</code>  를 통해 로컬저장소의 내용을 서버의 외부저장소로 전송할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p><code>git fetch</code>  를 통해 외부저장소의 변경사항을 로컬로 가져올 수 있습니다.<br>이 변경사항을 로컬의 작업내역들과 비교할 수 있고 만약 누군가가 생성한 신규 커밋들이 로컬에서 작업한 부분과 중복되는 부분이 있다면 이를 알 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch <span class="string">&#x27;외부저장소명&#x27;</span> <span class="string">&#x27;브랜치명&#x27;</span></span><br></pre></td></tr></table></figure><p><code>git merge</code>  를 통해 외부저장소의 내용과 로컬의 내용을 동기화합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p><code>git pull</code>  를 통해 <code>git fetch</code>와 <code>merge</code>를 한번에 시행할 수 있습니다.<br><code>git fetch</code>를 통해 외부저장소의 변경사항을 확인하고 <code>git merge</code>를 통해 로컬과 외부저장소를 병합합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull</span><br></pre></td></tr></table></figure><h3 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h3><p><strong>branch는 git의 커밋과 커밋 사이를 이동할 수 있는 일종의 포인터 입니다.</strong> </p><p>git branch는 git의 버전관리와 협업의 핵심이 되는 컨셉입니다.</p><p>여러 작업자가 동시에 작업해야 하는 큰 프로젝트가 있을때 git branch를 사용해서 생산성을 높일 수 있습니다.</p><p><img src="/git-branch.png"></p><p><code>git branch</code> 를 통해 현재 branch들을 조회합니다. -a 를 통해 원격과 로컬 branch를 모두 조회할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><p>새 branch를 만듧니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch 브랜치명</span><br></pre></td></tr></table></figure><p>원래 branch를 새로운 branch로 변경합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -m 원래브랜치 새로운브랜치</span><br></pre></td></tr></table></figure><p>main에서 새로운 브랜치 new를 만듭니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch new main</span><br></pre></td></tr></table></figure><p>브랜치를 삭제합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d 브랜치</span><br></pre></td></tr></table></figure><p>해당 브랜치로 작업영역을 변경합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout 브랜치</span><br></pre></td></tr></table></figure><p>A 브랜치를 현재 브랜치로 합칩니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge A</span><br></pre></td></tr></table></figure><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://opentutorials.org/module/2676/15202">https://opentutorials.org/module/2676/15202</a></li><li><a href="https://dzone.com/articles/top-20-git-commands-with-examples">https://dzone.com/articles/top-20-git-commands-with-examples</a></li><li><a href="https://git-scm.com/book/ko/v2/Git-%EB%B8%8C%EB%9E%9C%EC%B9%98-%EB%B8%8C%EB%9E%9C%EC%B9%98%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80">https://git-scm.com/book/ko/v2/Git-%EB%B8%8C%EB%9E%9C%EC%B9%98-%EB%B8%8C%EB%9E%9C%EC%B9%98%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Infra </category>
          
          <category> git </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Git]기본적인 컨셉들</title>
      <link href="/2021/07/17/infra/git/git-commands/"/>
      <url>/2021/07/17/infra/git/git-commands/</url>
      
        <content type="html"><![CDATA[<h2 id="git-시작하기"><a href="#git-시작하기" class="headerlink" title="git 시작하기"></a>git 시작하기</h2><h3 id="git-init"><a href="#git-init" class="headerlink" title="git init"></a>git init</h3><blockquote><p>로컬에 저장소를 생성합니다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init &lt;생성할레포&gt;</span><br></pre></td></tr></table></figure><h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><blockquote><p>원격 저장소를 로컬에 복제 합니다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> &lt;클론할 레포&gt;</span><br></pre></td></tr></table></figure><h3 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h3><blockquote><p>git repository에 파일이나 파일에 대한 변경사항을 추가합니다. git을 add 한다는<br>것은 새로운 파일이나 수정사항을 커밋하기 위해 staging area에 변경사항을<br>추가하는 것을 의미합니다.</p></blockquote><h4 id="git-add-예제"><a href="#git-add-예제" class="headerlink" title="git add 예제"></a>git add 예제</h4><ul><li>테스트파일을 스테이징에 추가</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> test.md</span><br><span class="line">git add test.md</span><br></pre></td></tr></table></figure><ul><li>수정사항이 있는 모든 파일을 staging area에 추가<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure></li></ul><h2 id="컨셉"><a href="#컨셉" class="headerlink" title="컨셉"></a>컨셉</h2><h3 id="git의-4가지-영역"><a href="#git의-4가지-영역" class="headerlink" title="git의 4가지 영역"></a>git의 4가지 영역</h3><h3 id="staging-area"><a href="#staging-area" class="headerlink" title="staging area"></a>staging area</h3><p>git 의 핵심은 사용자가 관리하고 싶은 파일들만 변경사항을 관리할 수 있다는<br>것이다. 이를 위해 필요한 것이 staging area(index) 이다.</p><p>staging area는 코드를 커밋 하기 전에 사용하는 일종의 중간영역이다.</p><p>git add 명령을 사용해 개별 파일이나 디렉토리를 추가하거나 전체 또는 특정<br>디렉토리의 모든 변경사항을 추가하는 옵션을 사용할 수 있습니다.</p><h3 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h3><blockquote><p>변경사항을 git 저장소에 추가합니다. commit은 git에서 변경사항을 관리하는 가장<br>기본이 되는 단위입니다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m<span class="string">&quot;커밋메시지&quot;</span></span><br></pre></td></tr></table></figure><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><blockquote><p>commit 한 내용을 원격 저장소에 반영합니다.</p></blockquote><h3 id="git-pull"><a href="#git-pull" class="headerlink" title="git pull"></a>git pull</h3><blockquote><p>원격 저장소의 변경사항을 local 저장소에 반영한다. 기본적으로 git fetch와 git merge의 통합이다.</p></blockquote><h2 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h2><blockquote><p>현재 저장소 상태를 확인합니다. 상태를 확인한다는 것은 저장소의 head, staging<br>area를 확인한다는 것이다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><h3 id="working-tree"><a href="#working-tree" class="headerlink" title="working tree"></a>working tree</h3><p>git에서 working tree는 현재 작업하고 있는 디렉토리를 뜻합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> git status</span><br><span class="line">On branch main</span><br><span class="line">Your branch is up to <span class="built_in">date</span> with <span class="string">&#x27;origin/main&#x27;</span>.</span><br><span class="line"></span><br><span class="line">nothing to commit, working tree clean</span><br></pre></td></tr></table></figure><h3 id="head-개념"><a href="#head-개념" class="headerlink" title="head 개념"></a>head 개념</h3><p>git에서 heads는 현재 작업하고 있는 branch를 뜻합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">commit 273457e05c9a41180eafebd8009592312758b796 (HEAD -&gt; main, origin/main, origin/HEAD)</span><br><span class="line">Author: jinheonyoon &lt;yjinheon@gmail.com&gt;</span><br><span class="line">Date:   Mon Mar 28 16:49:38 2022 +0900</span><br></pre></td></tr></table></figure><h2 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h2><blockquote><p>git branch는 기능개발이나 이슈처리를 독립적으로 수행하기 위한 repository를<br>생성하고 관리하기 위한 명령어입니다.</p></blockquote><h3 id="branch-사용-이유"><a href="#branch-사용-이유" class="headerlink" title="branch 사용 이유"></a>branch 사용 이유</h3><blockquote><p>기본적으로 여러작업을 독립적으로 동시에 진행하기 위해 사용합니다. 예를 들어<br>feature를 추가하는 branch와 버그를 수정하는 branch를 따로 파고 나중에 merge<br>하는 방식으로 작업을 효율화하고 충돌을 방지할 수 있습니다.</p></blockquote><h3 id="branch-생성"><a href="#branch-생성" class="headerlink" title="branch 생성"></a>branch 생성</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch &lt;브랜치 명&gt;</span><br></pre></td></tr></table></figure><h3 id="branch-삭제"><a href="#branch-삭제" class="headerlink" title="branch 삭제"></a>branch 삭제</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d &lt;브랜치 명&gt;</span><br></pre></td></tr></table></figure><h3 id="branch-이름-변경"><a href="#branch-이름-변경" class="headerlink" title="branch 이름 변경"></a>branch 이름 변경</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -m &lt;브랜치 명&gt; &lt;새 브랜치 명&gt;</span><br></pre></td></tr></table></figure><h3 id="branch-목록-조회"><a href="#branch-목록-조회" class="headerlink" title="branch 목록 조회"></a>branch 목록 조회</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git branch -l(로컬 브랜치 목록 조회)</span><br><span class="line">git branch -r  (원격 브랜치 목록 조회)</span><br><span class="line">git branch -a  (모든 브랜치 목록 조회)</span><br></pre></td></tr></table></figure><h3 id="branch-이동"><a href="#branch-이동" class="headerlink" title="branch 이동"></a>branch 이동</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout &lt;이동 브랜치&gt;</span><br></pre></td></tr></table></figure><h3 id="특정-branch-생성-후-해당-branch로-이동"><a href="#특정-branch-생성-후-해당-branch로-이동" class="headerlink" title="특정 branch 생성 후 해당 branch로 이동"></a>특정 branch 생성 후 해당 branch로 이동</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b &#123;New Branch Name&#125;</span><br></pre></td></tr></table></figure><h3 id="모든-변경사항-취소"><a href="#모든-변경사항-취소" class="headerlink" title="모든 변경사항 취소"></a>모든 변경사항 취소</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout.</span><br></pre></td></tr></table></figure><h3 id="현재-branch-확인"><a href="#현재-branch-확인" class="headerlink" title="현재 branch 확인"></a>현재 branch 확인</h3><h2 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h2><blockquote><p>git merge는 기본적으로 다른 branch를 현재 checkout된 브랜치와 병합하는 명령어<br>이다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout master <span class="comment"># 마스터 브랜치로 이동</span></span><br><span class="line"></span><br><span class="line">git merge <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="git-remote"><a href="#git-remote" class="headerlink" title="git remote"></a>git remote</h2><blockquote><p>현재 프로젝트에 등록된 리모트 저장소를 확인하기 위해 git remote 명령어를 사용한다.</p></blockquote><hr><p><strong>NOTE</strong><br>refusing to merge unrelated histories 에러</p><p>git remote 저장소를 추가 한뒤 local에 있는 repository로 반영하려면  먼저 pull을 해서 프로젝트를 병합시켜줘야 한다.</p><p>단순히 git pull origin 브랜치 명을 사용하면 <code>refusing to merge unrelated histories</code> 에러가 발생하면서 병합이 되지 않는다.</p><p>이 때 서로 다른 두 레포지토리의 기록의 저장을 허용하는  <code>--allow-unrelated-histories</code> 옵션을 줘서 해결할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin 브런치명 --allow-unrelated-histories</span><br></pre></td></tr></table></figure><hr><h3 id="로컬-저장소와-리모트-저장소-연결"><a href="#로컬-저장소와-리모트-저장소-연결" class="headerlink" title="로컬 저장소와 리모트 저장소 연결"></a>로컬 저장소와 리모트 저장소 연결</h3><h3 id="리모트-저장소-추가"><a href="#리모트-저장소-추가" class="headerlink" title="리모트 저장소 추가"></a>리모트 저장소 추가</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">git remote add </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="리모트-저장소-확인"><a href="#리모트-저장소-확인" class="headerlink" title="리모트 저장소 확인"></a>리모트 저장소 확인</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="리모트-저장소-버전-확인"><a href="#리모트-저장소-버전-확인" class="headerlink" title="리모트 저장소 버전 확인"></a>리모트 저장소 버전 확인</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="git-merge-1"><a href="#git-merge-1" class="headerlink" title="git merge"></a>git merge</h2><h3 id="Merge-명령옵션"><a href="#Merge-명령옵션" class="headerlink" title="Merge 명령옵션"></a>Merge 명령옵션</h3><h4 id="–squash"><a href="#–squash" class="headerlink" title="–squash"></a>–squash</h4><p>%% 이 옵션은 대상 브랜치의 모든 커밋을 하나의 커밋으로 합쳐서 merge 하는<br>방식이다.</p><p>즉, 대상 브랜치에서 작업했던 히스토리를 하나의 메시지로 압축시키는 것이죠.</p><p>이 옵션은 테스트 브랜치에서 원래 브랜치에 병합할 때 유용한 방식입니다.</p><p>즉, 애초에 하나인 브랜치가 임시로 빠져나와서 다시 통합할 때 사용하는 것이<br>좋습니다.</p><p>예를 들어, master 브랜치가 있고, 이를 그대로 복사한 child 브랜치가 있다고<br>가정하겠습니다.</p><p>그리고 child 브랜치에서 커밋을 5번을 했다고 했을 때, 당연히 master branch보다<br>커밋 수가 앞서 있겠죠?</p><p>이 때 master 브랜치에서 –squash 옵션을 이용해서 child 브랜치를 병합하면, child<br>브랜치의 5번의 커밋 내역은 무시되고 파일 수정 이력만 받게 됩니다.</p><p>따라서 깔끔한 히스토리와 함께 merge를 할 수 있게 됩니다. %%</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge --suash child <span class="comment"># child의 commit을 한꺼번에 병합할 경우 사용</span></span><br></pre></td></tr></table></figure><h3 id="Fast-forword"><a href="#Fast-forword" class="headerlink" title="Fast forword"></a>Fast forword</h3><blockquote><p>merge할 브랜치 의 commit이 현재 branch (masger 브랜치) 의 commit 보다 앞서가<br>있는 경우 기준 브랜치의 커밋을 대상 브랜치 커밋으로 이동시키는 merge 방식을<br>fast forward라고 합니다.</p></blockquote><ul><li>기본적으로는 master branch의 head를 test branch의 head로 이동하는 것입니다.</li></ul><h2 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h2><blockquote><p>프로젝트 히스토리를 시간 역순으로 보여줍니다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> --<span class="built_in">stat</span></span><br></pre></td></tr></table></figure><p>최신커밋 확인하기</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> -n 1</span><br></pre></td></tr></table></figure><p><a href="https://lucas-owner.tistory.com/35">https://lucas-owner.tistory.com/35</a></p><h2 id="git-revert"><a href="#git-revert" class="headerlink" title="git revert"></a>git revert</h2><h2 id="git-config"><a href="#git-config" class="headerlink" title="git config"></a>git config</h2><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.lainyzine.com/ko/article/summary-of-how-to-use-git-for-source-code-management/">https://www.lainyzine.com/ko/article/summary-of-how-to-use-git-for-source-code-management/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Infra </category>
          
          <category> git </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Deep Learning]Loss function</title>
      <link href="/2021/07/15/machine-learning/DL-lossfunction/"/>
      <url>/2021/07/15/machine-learning/DL-lossfunction/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>굵은 글씨로 뭔가 쓴다.</strong></p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Deep Learning]Optimizer</title>
      <link href="/2021/07/10/machine-learning/DL-optimizer/"/>
      <url>/2021/07/10/machine-learning/DL-optimizer/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKkoptimizer란 optimizer 종류optimizer 선택 방법론구현#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>굵은 글씨로 뭔가 쓴다.</strong></p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Optimizer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anaconda 시작시 기본설정</title>
      <link href="/2021/07/08/infra/conda-install/"/>
      <url>/2021/07/08/infra/conda-install/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Anaconda를 자주 설치하고 지우기 때문에 Anaconda를 설치하면 하는 루틴들을 정리해두려고 합니다.</p><h2 id="주피터-시작경로-설정"><a href="#주피터-시작경로-설정" class="headerlink" title="주피터 시작경로 설정"></a>주피터 시작경로 설정</h2><ol><li><p>powershell에서 해당 명령어 실행</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook <span class="literal">--generate-config</span></span><br></pre></td></tr></table></figure></li><li><p>‘C:\Users\유저명.jupyter\jupyter_notebook_config.py’ 경로로 이동</p></li><li><p>#c.NotebookApp.notebook_dir&#x3D; ‘’  를 주석처리하고 원하는 경로 입력 </p></li><li><p>시작메뉴 주피터 속성 에서  <strong>%USERPROFILE%&#x2F;</strong> 과 <strong>%HOMEPATH%</strong> 삭제</p></li></ol><h2 id="Jupyterlab-바로가기-설청"><a href="#Jupyterlab-바로가기-설청" class="headerlink" title="Jupyterlab 바로가기 설청"></a>Jupyterlab 바로가기 설청</h2><ol><li><p>conda 설치경로\Script에 들어가서 activate.bat 파일을 연다.</p></li><li><p>activate.bat 파일을 다른 이름으로 저장한다(activate_jupyter).</p></li><li><p>다른이름으로 저장한 파일의 맨 아래에 다음 두 줄을 추가한다.</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;작업경로&gt;</span><br><span class="line">jupyter lab</span><br></pre></td></tr></table></figure></li><li><p>새로만든 파일의 바로가기를 만든다.</p></li><li><p>바로가기 아이콘을 jupyter lab 아이콘으로 변경한다.</p></li><li><p>시작메뉴에 바로가기를 추가한다.</p></li></ol><h2 id="Jupyterlab-theme-설치"><a href="#Jupyterlab-theme-설치" class="headerlink" title="Jupyterlab theme 설치"></a>Jupyterlab theme 설치</h2><h2 id="가상환경-생성-및-Jupyter-등록"><a href="#가상환경-생성-및-Jupyter-등록" class="headerlink" title="가상환경 생성 및 Jupyter 등록"></a>가상환경 생성 및 Jupyter 등록</h2><p>가상환경 자체는 단순히 자신이 필요한 python환경을 구축하기 위해 폴더 안에 필요한 패키지만을 모아 놓은 것이다. 보통 프로젝트 단위로 작업을 할때 패키지 의존성(dependancy)으로 인한 오류들을 줄이기 위해 사용한다. <code>vertualenv</code>로도 가상환경을 설치할 수 있지만 <code>conda</code>를 사용한다면 conda명령어를 통해 쉽게 가상환경을 설치하고 삭제할 수 있다.<br><img src="/conda_venv.png" alt="png"></p><h3 id="conda-가상환경-명령어"><a href="#conda-가상환경-명령어" class="headerlink" title="conda 가상환경 명령어"></a>conda 가상환경 명령어</h3><ol><li><p>가상환경 만들기 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create –n 가상환경이름 python=버전 </span><br></pre></td></tr></table></figure></li><li><p>가상환경 활성화  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate 가상환경이름</span><br></pre></td></tr></table></figure></li><li><p>가상환경 비활성화  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate 가상환경이름</span><br></pre></td></tr></table></figure></li><li><p>가상환경에 패키지 설치 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install 패키지이름 </span><br></pre></td></tr></table></figure></li><li><p>가상환경 정보 확인 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda info --enves </span><br></pre></td></tr></table></figure></li><li><p>가상환경 복사</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create –n 복사된 가상환경 --<span class="built_in">clone</span> 복사될 가상환경 </span><br></pre></td></tr></table></figure></li><li><p>가상환경 설치패키지 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 가상환경 활성화 시킨 후 시행</span></span><br><span class="line">conda list</span><br></pre></td></tr></table></figure></li><li><p>가상환경 삭제</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="built_in">env</span> remove -n 가상환경이름 </span><br></pre></td></tr></table></figure></li></ol><h3 id="주피터-커널-등록"><a href="#주피터-커널-등록" class="headerlink" title="주피터 커널 등록"></a>주피터 커널 등록</h3><ol><li><p>ipykernel 설치</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ipykernel</span><br></pre></td></tr></table></figure></li><li><p>가상환경 주피터 등록</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m ipykernel install --user --name 가상환경 이름 --display-name 커널 이름</span><br></pre></td></tr></table></figure></li><li><p>가상환경 주피터 커널 삭제</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter kernelspec uninstall 가상환경이름</span><br></pre></td></tr></table></figure></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://ooyoung.tistory.com/7">https://ooyoung.tistory.com/7</a></li><li><a href="https://django-easy-tutorial.blogspot.com/2015/08/python-virtual-environment-setup-in-ubuntu.html">https://django-easy-tutorial.blogspot.com/2015/08/python-virtual-environment-setup-in-ubuntu.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Infra </category>
          
          <category> Config </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[DDL]Table 구조 다루기</title>
      <link href="/2021/07/05/data-engineering/DE-SQL-DDL-tables/"/>
      <url>/2021/07/05/data-engineering/DE-SQL-DDL-tables/</url>
      
        <content type="html"><![CDATA[<!--<center>Kaggle Customer Score Dataset</center>- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Preprocessing#신경망이란 무엇인가?https://www.youtube.com/watch?v=aircAruvnKk#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><h2 id="Data-Definition"><a href="#Data-Definition" class="headerlink" title="Data Definition"></a>Data Definition</h2><ul><li><code>ALTER</code>는 DB구조를 변경하는데 쓴다.</li><li><code>TRUNCATE</code>는 데이터를 삭제하는데 쓴다.</li><li><code>DROP</code>은 테이블 자체를 삭제한다.</li></ul><h3 id="테이블-데이터-다루기"><a href="#테이블-데이터-다루기" class="headerlink" title="테이블 데이터 다루기"></a>테이블 데이터 다루기</h3><ul><li>테이블 생성</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t ( id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">                 name <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>, </span><br><span class="line">                 price <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>테이블 삭제</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> t;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>새 컬럼 추가</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t <span class="keyword">ADD</span> <span class="keyword">COLUMN</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>새 제약조건 추가</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>제약조건 삭제</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t <span class="keyword">DROP</span> <span class="keyword">CONSTRAINT</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>테이블명 변경</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t RENAME <span class="keyword">to</span> t2;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>컬럼명 변경</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">table</span> t1 RENAME c1 <span class="keyword">to</span> c2;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>테이블 데이터 삭제</li></ul><p>테이블 구조는 남기고 데이터를 전부 날린다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span> t;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="References-amp-annotation"><a href="#References-amp-annotation" class="headerlink" title="References &amp; annotation"></a><strong>References &amp; annotation</strong></h2><ul><li><a href="https://www.mysqltutorial.org/mysql-join/">mysql tutorial</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Neural Network]Perceptron의 이해</title>
      <link href="/2021/07/03/machine-learning/DL-perceptron/"/>
      <url>/2021/07/03/machine-learning/DL-perceptron/</url>
      
        <content type="html"><![CDATA[<!--- Machine Learning- Statistics , Math- Data Engineering- Programming- EDA & Visualization- Data Extraction & Wrangling**Perceptron은 딥러닝의 기초가 되는 알고리즘이다. 개념은 간단하지만 추후 나올 다른 신경망의 기원이 되는 알고리즘인 만큼 정확히 알 필요가 있다. 여기서는 최적화 관점에서의 Perceptron을 다룬다.**#참고https://cinema4dr12.tistory.com/1016?category=515283https://www.kdnuggets.com/2021/07/top-python-data-science-interview-questions.html--><p><strong>Perceptron은 딥러닝의 기초가 되는 중요한 알고리즘이지만 Percepton 자체는 그냥 인풋을 두 개의 클래스로 분류하는 이진분류에 속한다.<br>최적화 관점에서의 Perceptron을 알아보자</strong></p><ul><li><a href="#perceptron">Perceptron</a><ul><li><a href="#%EC%B5%9C%EC%A0%81%ED%99%94-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%EC%9D%98-perceptron">최적화 관점에서의 Perceptron</a></li><li><a href="#perception-as-linear-binary-classifier">Perception as Linear Binary Classifier</a></li></ul></li><li><a href="#%EB%85%BC%EB%A6%AC%EA%B2%8C%EC%9D%B4%ED%8A%B8">논리게이트</a></li><li><a href="#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98">활성화 함수</a><ul><li><a href="#step-function">Step Function</a></li><li><a href="#sigmoid-function">Sigmoid Function</a></li><li><a href="#relu-function">RelU Function</a></li></ul></li><li><a href="#python%EC%9C%BC%EB%A1%9C-perceptron-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0">Python으로 Perceptron 구현하기</a></li><li><a href="#%EC%A0%95%EB%A6%AC">정리</a></li><li><a href="#references">References</a></li></ul><hr><h2 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h2><p>Perceptron은 <strong>여러 신호를 입력으로 받아 하나의 신호를 출력하는 일종의 뉴런</strong>이다. 생물학에서 이야기하는 그 뉴런의 컨셉을 생각하면 이해가 쉽다.</p><ul><li>한개의 뉴런으로 여러 입력신호(x0, x1, …)가 입력되면 각각 고유한 가중치(weights, w0, w1, …)가 곱해지고 더해진다.</li><li>편향(bias)</li><li>가중치가 곱해진 값들은 모두 더해져 정해진 임계값(threshold)을 넘을 경우에만 다음 노드들이 있는 층(layer)으로 신호가 전해진다.</li></ul><p>아래 그림을 통해 기본적인 퍼셉트론 노드의 구조를 쉽게 이해할 수있다.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/f/ff/Rosenblattperceptron.png"></p><center><b>그림1. Perceptron 구조</b></center><p><strong>Perceptron은 정확히 말하면 Perceptron Learning Algorithm인데 이름에서 보다시피 알고리즘의 일종이다.</strong></p><p>기본적으로 SVM이나 Decision tree 처럼 학습을 하는 알고리즘이기 때문에 최적화 문제랑 같이보면 이해가 쉽다.</p><p><img src="/2021-08-10-10-47-38.png"></p><ol><li><p>가중치(w) 를 </p></li><li><p>가중치를 업데이트한다.</p><p>가중치</p></li></ol><p>\begin{align}<br> y &#x3D;activation(\sum(w_{1}x_{1} + w_{2}x_{2} + … + w_{n}x_{n}) + bias)<br>\end{align}</p><p><img src="/ML-DL-perceptron/perceptron_al.png"></p><center><b>그림2. Perceptron Learning Algorithm</b></center><h3 id="최적화-관점에서의-Perceptron"><a href="#최적화-관점에서의-Perceptron" class="headerlink" title="최적화 관점에서의 Perceptron"></a>최적화 관점에서의 Perceptron</h3><p>최적화 관점으로 생각하면 Perceptron 또한 비용함수인 $f(h)-y$ 를 최소화 하는 목적을 가지고 있다고 볼 수 있다.</p><p>Perceptron 알고리즘에서의 비욯함수는 <code>0-1 loss</code>인데 이는 단순히 잘못된 예측에 대해 1의 패널티를 부여하고 제대로된 예측은 그대로 놔두는 것이다.</p><p>이를 수식으로 나타내면 아래와 같다</p><p>$$<br>L(\hat{y}, y) &#x3D; I(\hat{y} \ne y)<br>$$</p><p>(여기서 I 는 indicator 함수로 0아니면 1의 결과를 반환한다.)</p><p>이러한 비용함수의 문제는 gradient descent 를 사용해 국소최적해(local optimum) 를 찾기 어렵다는 것이다.</p><h3 id="Perception-as-Linear-Binary-Classifier"><a href="#Perception-as-Linear-Binary-Classifier" class="headerlink" title="Perception as Linear Binary Classifier"></a>Perception as Linear Binary Classifier</h3><p>Perceptron의 컨셉을 다시 살펴보면 </p><h2 id="논리게이트"><a href="#논리게이트" class="headerlink" title="논리게이트"></a>논리게이트</h2><h2 id="활성화-함수"><a href="#활성화-함수" class="headerlink" title="활성화 함수"></a>활성화 함수</h2><p>활성화 함수는 입력벡터와 가중치벡터의 가중합인 net input을 받아 출력신호를 도출해내는 함수이다.</p><h3 id="Step-Function"><a href="#Step-Function" class="headerlink" title="Step Function"></a>Step Function</h3><h3 id="Sigmoid-Function"><a href="#Sigmoid-Function" class="headerlink" title="Sigmoid Function"></a>Sigmoid Function</h3><h3 id="RelU-Function"><a href="#RelU-Function" class="headerlink" title="RelU Function"></a>RelU Function</h3><h2 id="Python으로-Perceptron-구현하기"><a href="#Python으로-Perceptron-구현하기" class="headerlink" title="Python으로 Perceptron 구현하기"></a>Python으로 Perceptron 구현하기</h2><p>간단한 Perceptron을 Python으로 구현해보자</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="정리"><a href="#정리" class="headerlink" title="정리"></a>정리</h2><ul><li><p>퍼셉트론은 입출력을 가지는 일종의 알고리즘이다. 입력에 따라 정해진 규칙에 따른 값을 반환한다.</p></li><li><p>퍼셉트론은 가중치와 편향을 매개변수로 지정한다.</p><ul><li>가중치</li><li>편향</li></ul></li><li><p>퍼셉트론으로 논리회로를 표현할 수 있다.</p></li><li><p>XOR 게이트의 경우 단층 퍼셉트론을 사</p></li><li><p>퍼셉트론은 샘플을 입력받아 가중치 w를 연결하여 net input을 계산한다. </p></li><li><p>net input은 입력벡터와 가중치 벡터의 내적이다. </p></li><li><p>net input은 activation 함수로 전달되어</p></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a></li><li><a href="https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975">https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>[Python]단순선형회귀 구현하기(Simple Regression)</title>
      <link href="/2021/06/08/machine-learning/ML-SP-simple_regression/"/>
      <url>/2021/06/08/machine-learning/ML-SP-simple_regression/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><ul><li>Python 선형회귀 연습하기</li><li>nbconvert를 활용해 ipynb파일을 마크다운 파일로 변환</li></ul><h2 id="scikit-learn을-활용한-단순선형회귀"><a href="#scikit-learn을-활용한-단순선형회귀" class="headerlink" title="scikit-learn을 활용한 단순선형회귀"></a>scikit-learn을 활용한 단순선형회귀</h2><h3 id="데이터-불러오기-및-전처리"><a href="#데이터-불러오기-및-전처리" class="headerlink" title="데이터 불러오기 및 전처리"></a>데이터 불러오기 및 전처리</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;../data/kc_house_data.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>date</th>      <th>price</th>      <th>bedrooms</th>      <th>bathrooms</th>      <th>sqft_living</th>      <th>sqft_lot</th>      <th>floors</th>      <th>waterfront</th>      <th>view</th>      <th>...</th>      <th>grade</th>      <th>sqft_above</th>      <th>sqft_basement</th>      <th>yr_built</th>      <th>yr_renovated</th>      <th>zipcode</th>      <th>lat</th>      <th>long</th>      <th>sqft_living15</th>      <th>sqft_lot15</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>7129300520</td>      <td>20141013T000000</td>      <td>221900.0</td>      <td>3</td>      <td>1.00</td>      <td>1180</td>      <td>5650</td>      <td>1.0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>7</td>      <td>1180.0</td>      <td>0</td>      <td>1955</td>      <td>0</td>      <td>98178</td>      <td>47.5112</td>      <td>-122.257</td>      <td>1340</td>      <td>5650</td>    </tr>    <tr>      <th>1</th>      <td>6414100192</td>      <td>20141209T000000</td>      <td>538000.0</td>      <td>3</td>      <td>2.25</td>      <td>2570</td>      <td>7242</td>      <td>2.0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>7</td>      <td>2170.0</td>      <td>400</td>      <td>1951</td>      <td>1991</td>      <td>98125</td>      <td>47.7210</td>      <td>-122.319</td>      <td>1690</td>      <td>7639</td>    </tr>    <tr>      <th>2</th>      <td>5631500400</td>      <td>20150225T000000</td>      <td>180000.0</td>      <td>2</td>      <td>1.00</td>      <td>770</td>      <td>10000</td>      <td>1.0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>6</td>      <td>770.0</td>      <td>0</td>      <td>1933</td>      <td>0</td>      <td>98028</td>      <td>47.7379</td>      <td>-122.233</td>      <td>2720</td>      <td>8062</td>    </tr>    <tr>      <th>3</th>      <td>2487200875</td>      <td>20141209T000000</td>      <td>604000.0</td>      <td>4</td>      <td>3.00</td>      <td>1960</td>      <td>5000</td>      <td>1.0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>7</td>      <td>1050.0</td>      <td>910</td>      <td>1965</td>      <td>0</td>      <td>98136</td>      <td>47.5208</td>      <td>-122.393</td>      <td>1360</td>      <td>5000</td>    </tr>    <tr>      <th>4</th>      <td>1954400510</td>      <td>20150218T000000</td>      <td>510000.0</td>      <td>3</td>      <td>2.00</td>      <td>1680</td>      <td>8080</td>      <td>1.0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>8</td>      <td>1680.0</td>      <td>0</td>      <td>1987</td>      <td>0</td>      <td>98074</td>      <td>47.6168</td>      <td>-122.045</td>      <td>1800</td>      <td>7503</td>    </tr>  </tbody></table><p>5 rows × 21 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># * 가 파이썬에서 뭘 의미하는지 찾아보자</span></span><br><span class="line"><span class="comment"># https://mingrammer.com/understanding-the-asterisk-of-python/</span></span><br><span class="line"><span class="comment"># https://treyhunner.com/2018/10/asterisks-in-python-what-they-are-and-how-to-use-them/</span></span><br><span class="line">use_col = df.columns.tolist()[<span class="number">3</span>:]</span><br><span class="line"><span class="built_in">print</span>(*use_col, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>bedroomsbathroomssqft_livingsqft_lotfloorswaterfrontviewconditiongradesqft_abovesqft_basementyr_builtyr_renovatedzipcodelatlongsqft_living15sqft_lot15</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 상관행렬 구하기</span></span><br><span class="line">corrMatrix = df.corr()</span><br><span class="line"><span class="comment"># 상관행렬에서 타겟변수 추출</span></span><br><span class="line">price_col = corrMatrix[<span class="string">&#x27;price&#x27;</span>].to_frame().reset_index()</span><br><span class="line"><span class="comment"># 상관계수높은 순으로 정렬</span></span><br><span class="line">price_col.sort_values(<span class="string">&#x27;price&#x27;</span>,ascending=<span class="literal">False</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">price_col.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>index</th>      <th>price</th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>price</td>      <td>1.000000</td>    </tr>    <tr>      <th>4</th>      <td>sqft_living</td>      <td>0.702035</td>    </tr>    <tr>      <th>10</th>      <td>grade</td>      <td>0.667434</td>    </tr>    <tr>      <th>11</th>      <td>sqft_above</td>      <td>0.605567</td>    </tr>    <tr>      <th>18</th>      <td>sqft_living15</td>      <td>0.585379</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 가장 상관관계가 높은 변수 시각화</span></span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&#x27;whitegrid&#x27;</span>, context=<span class="string">&#x27;notebook&#x27;</span>)</span><br><span class="line">g=sns.pairplot(df[[<span class="string">&#x27;price&#x27;</span>,<span class="string">&#x27;sqft_living&#x27;</span>]])</span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> g.axes.flatten(): <span class="comment"># y축 한정 과학적 표기법을 일반 표기법으로 바꿔주기</span></span><br><span class="line">    ax.ticklabel_format(style=<span class="string">&#x27;plain&#x27;</span>, scilimits=(<span class="number">0</span>,<span class="number">0</span>), axis=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.ticklabel_format(style=&#x27;plain&#x27;, axis=&#x27;y&#x27;)</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/ML-SP-simple_regression/1_simple-regression_6_0.png" alt="png"></p><h3 id="Baseline-Model-만들기"><a href="#Baseline-Model-만들기" class="headerlink" title="Baseline Model 만들기"></a>Baseline Model 만들기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get baseline model</span></span><br><span class="line">baseline = df[<span class="string">&#x27;price&#x27;</span>].mean()</span><br><span class="line">errors = df[<span class="string">&#x27;price&#x27;</span>] - baseline</span><br><span class="line">mae = errors.<span class="built_in">abs</span>().mean()</span><br><span class="line"></span><br><span class="line">sns.lineplot(x=df[<span class="string">&#x27;grade&#x27;</span>], y=baseline, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">sns.scatterplot(data=df, x=<span class="string">&quot;grade&quot;</span>, y=<span class="string">&quot;price&quot;</span>)</span><br><span class="line">plt.ticklabel_format(style=<span class="string">&#x27;plain&#x27;</span>, axis=<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/ML-SP-simple_regression/1_simple-regression_8_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#기본적으로 모델이 다중회귀를 가정하기 때문에 Feature의 선언을 배열로 해줘야 한다.</span></span><br><span class="line"></span><br><span class="line">X = df[[<span class="string">&#x27;sqft_living&#x27;</span>]] </span><br><span class="line">y = df[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line">m = LinearRegression()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m.fit(X,y)</span><br></pre></td></tr></table></figure><pre><code>LinearRegression()</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_test = [[<span class="number">6000</span>]]</span><br><span class="line">y_pred = m.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;sqft_living이 <span class="subst">&#123;X_test[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>인 경우의 예상 가격은 <span class="subst">&#123;<span class="built_in">int</span>(y_pred)&#125;</span>로 나타남&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>sqft_living이 6000인 경우의 예상 가격은 1640160로 나타남</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 통계량 확인</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;coefficient-score : &quot;</span>,m.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;intercept : &quot;</span> , m.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;coefficient of determination: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(m.score(X,y)))</span><br></pre></td></tr></table></figure><pre><code>coefficient-score :  [280.6235679]intercept :  -43580.74309447361coefficient of determination: 0.49</code></pre><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://scikit-learn.org/stable/modules/linear_model.html">https://scikit-learn.org/stable/modules/linear_model.html</a></li><li><a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py">https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Supervised Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Unsupervised Learning]주성분분석(PCA)의 이해</title>
      <link href="/2021/05/29/machine-learning/ML-US-PCA/"/>
      <url>/2021/05/29/machine-learning/ML-US-PCA/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>비지도학습은 라벨이 달린 데이터를 이용해 데이터를 학습하는 과정 없이 데이터로부터 의미를 추출하는 것이다.</strong></li><li><strong>비지도학습의 목적은 크게 차원축소와 클러스터링 두 가지로 나눌 수 있다.</strong></li></ul><hr><ul><li><strong>비지도학습</strong><ul><li><strong>차원축소(PCA)</strong> : 데이터의 변수를 관리 가능한 수준으로 차원을 줄이는 것, 변수와 레코드의 수가 아주 큰 상황이라면 차원축소를을 EDA의 연장으로 볼 수있다. <ul><li>PCA</li><li>LDA</li><li>SVD</li><li>요인분석</li><li>etc</li></ul></li><li><strong>클러스터링</strong>: 라벨이 정해진 응답변수가 없는 상황에서 예측 규칙을 만드는 것(그룹화)<ul><li>K평균 클러스터링</li><li>계층적 클러스터링</li><li>모델기반 클러스터링</li><li>etc</li></ul></li></ul></li></ul><h2 id="주성분분석-PCA"><a href="#주성분분석-PCA" class="headerlink" title="주성분분석(PCA)"></a>주성분분석(PCA)</h2><blockquote><p><strong>주성분분석은 데이터의 차원을 줄이기 위해, 공분산 행렬에서 고유 벡터&#x2F;고유값을 구하고 가장 분산이 큰 방향을 가진 고유벡터에 입력데이터를 선형변환하는 것이다.</strong></p></blockquote><p>위 말을 이해하기 위해서는 차원축소를 하는 이유와 선형대수 관련 개념을 조금 알아야 한다.</p><h3 id="차원을-줄이는-이유"><a href="#차원을-줄이는-이유" class="headerlink" title="차원을 줄이는 이유"></a>차원을 줄이는 이유</h3><p>차원을 줄이는 이유는 크게 두 가지가 있는데 하나는 메모리 소모를 줄이기 위해서고 다른 하나는 차원의 저주 때문이다.</p><p><strong>메모리 소모 문제</strong><br>R을 생각해보자. R을 써본 사람은 알겠지만 정말 개같이 느린 언어이다. 이는 R이 물리적 메모리를 저장하는 방식을 사용하기 때문이다.물론 파이썬도 그렇게 빠른 언어는 아니다. 넘파이가 빠른거지 파이썬이 빠른게 아니다. 그리고 넘파이는 C랑 포트란으로 짜여졌다.<br>이처럼 수치해석을 하기에는 너무나도 느린 언어들로 큰 데이터를 분석하다보면 시간은 시간대로 날려먹고 제대로된 결과를 뽑지 못할 가능성이 높다. 따라서 데이터양이(정확히는 데이터 n값과 predictor의 수의 곱이) 너무 많을 경우 PCA등의 차원축소기법을 사용해 데이터의 차원을 줄여 분석에 쓰이는 연산량을 줄이는 방법을 사용한다.</p><p><strong>차원의 저주(curse of demention)</strong><br>데이터의 수보다 데이터의 차원이 더 큰 경우를 차원의 저주라고 하는데 이경우 모델링이 복잡해지고 예측력이 낮아진다. 이러면 모델링 자체가 쓸모없어지기에 차원이 너무 많은 경우 Feature Selection이나 Feature Extraction 등을 통해 사전 처리를 해줄 필요가 있다. </p><h3 id="공분산행렬"><a href="#공분산행렬" class="headerlink" title="공분산행렬"></a><strong>공분산행렬</strong></h3><p>공분산행렬만 이해하면 PCA는 사실 그렇게 어렵지는 않다. PCA는 단순히 공분산행렬의 고유벡터를 기저벡터로 바꾼 것에 불과하다.일단 공분산이 뭔지 알아야 한다.<br>공분산은 교차곱편차의 평균이다. 이는 각 변수들의 편차들의 곱들을 모두 더해 n으로 나눈 값을 의미한다.</p><p>데이터 매트릭스 X에 대해서 공분산행렬을 아래와 같이 나타낼 수 있다.(자유도때문에 n-1로 나눠줌)</p><p>$$Cov(X) &#x3D; \frac{1}{n-1}X^TX$$</p><p>공분산은 <strong>기본적으로 변수들이 함께 변화하는 정도</strong>이다.</p><p>공분산행렬은 <strong>대각성분을 설명변수의 분산으로 채우고 나머지를 공분산으로 채운 행렬이다.</strong></p><p><img src="/images/../ML-US-PCA/covariance_matrix.png"></p><p><strong>그림1. 한번에 이해하는 공분산 행렬</strong></p><h3 id="선형변환"><a href="#선형변환" class="headerlink" title="선형변환"></a>선형변환</h3><ul><li><strong>행렬은 선형변환을 나타낸다.</strong></li><li>선형은 곱하고 더하는 것으로만 이루어져 있다.(문과식 이해의 한계)</li><li>벡터 <code>[a,b]</code> 의 와 행렬 M을 곱해 벡터 <code>[c,d]</code>가 나왔을 경우 </li><li><code>[c,d]</code>는 유닛 벡터 <code>[x,y]</code> 의 의 a배와 b 배의 합으로 이해할 수 있다. </li><li>이처럼 선형변환은 기본적으로 행렬과 벡터의 곱의 형태로 나타낼 수잇다.</li></ul><p>다시 생각해 보면 다음과 같다.</p><ul><li><code>f</code> 라는 어떤 매핑을 사용하여 </li><li>임의의 벡터 <code>[a, b]</code>에 대해서, </li><li><code>[2a + b, a -2b ]</code>로 바꾼다는 것은 아래와 같이 나타낼 수 있다.</li></ul><p>$$\begin{align}<br>f(\begin{bmatrix}a \ b \end{bmatrix}) &#x3D; \begin{bmatrix} 2a + b \ a -2b \  \end{bmatrix}<br>\end{align}$$</p><p>여기서 <code>[2a + b, a -2b ]</code>는 <code>[c,d]</code> 이며 특정 유닛벡터 (여기서는 <code>[2+b/a, a/b-2]</code>) 에 각각 a배, b배 한 값이 된다.</p><p><strong>여기서 <code>f</code>를 행렬을 곱하는 것으로 생각하면 놀랍게도 행렬과 벡터의 곱이 벡터의 선형변환과 동일하다는 것을 알 수 있다.</strong></p><h3 id="Eigenvalue-Eigenvector"><a href="#Eigenvalue-Eigenvector" class="headerlink" title="Eigenvalue,Eigenvector"></a><strong>Eigenvalue,Eigenvector</strong></h3><ul><li>일단 행렬이 선형변환이라는 것을 알아야 한다. <a href="https://angeloyeo.github.io/2019/07/15/Matrix_as_Linear_Transformation.html">진짜 설명 오지는 레퍼런스</a>를 읽어보자.</li><li>Eigenvector 는 특정 벡터에 대해 선형변환을 했을 때 크기만 바뀌고 방향은 바뀌지 않는 벡터(축)이다.(행렬의 방향성을 유지하는 선형변환의 주축)</li><li>Eigenvector 는 행렬이 벡터에 작용하는 주축이다.</li><li><strong>Eigenvector 는 어떤 행렬이 벡터에 작용하는 힘의 방향을 나타낸다.</strong><ul><li>만약 그 행렬이 공분산 행렬일 경우 그 공분산 행렬의 고유 벡터는 데이터가 어떤 방향으로 분산되어 있는지, 즉 어떤 방향으로 힘이 작용하는 지 나타낸다.-&gt; 공분산행렬의 Eigenvector가 원데이터의 분산이 최대가 되는 축이다.</li></ul></li><li><strong>Eigenvalue는 Eigenvector의 방향으로 크기가 얼마나 변화하는 지를 나타내는 값이다.</strong></li></ul><!--$$ T \cdot v = v' = \lambda \cdot v $$--><p>$$A &#x3D; cov(v)$$</p><p>$$Ax &#x3D; \lambda x$$</p><ul><li>A는 행렬 v의 공분산행렬이다.</li><li>여기서의 $\lambda$가 Eigenvalue이다.</li><li>x가 Eigenvector이다.</li></ul><p>x가 0이 아니여야 식이 성립하기 때문에 행렬식을 활용해 다음을 만족하는 벡터를 찾는다.</p><p>$$(A-\lambda I)\vec{x}&#x3D;0$$</p><p>$$det(A−\lambda I)&#x3D;0$$</p><p>$$\begin{bmatrix} a &amp; b \ c &amp; d \end{bmatrix}\begin{bmatrix} x \ y \end{bmatrix} &#x3D; \begin{bmatrix} ax+by \ cx+dy \end{bmatrix} &#x3D; \lambda \begin{bmatrix} x \ y \end{bmatrix}<br>$$</p><h3 id="주성분"><a href="#주성분" class="headerlink" title="주성분"></a><strong>주성분</strong></h3><p>결국 PCA에서 하고자 하는 것은 차원을 축소하면서 데이터 벡터를 <strong>어떤 벡터</strong>에 내적하는 것이 가능한 정보량(분산)을 유지하는 것인지 알아내는 것이다. 차원을 축소하면서 정보손실을 적게 하려면 원데이터의 분산이 최대가 되는 축을 찾아야 한다. 여기서 축이 되는 <strong>어떤 벡터</strong>가 주성분이며 공분산행렬의 eigenvector이다. </p><p><strong>linear combination</strong><br>주성분은 변수들의 선형 결합으로 표현된다. 이는 어떤 주성분 PC1이 있다고 했을때 이 PC1는 마치 다중회귀식마냥 기존 변수들의 조합으로 표현된다는 것이다.</p><p><img src="/PCA_lc.png"><br><strong>그림2. 선형결합으로서의 주성분</strong></p><h3 id="Feature-Selection-amp-Extraction"><a href="#Feature-Selection-amp-Extraction" class="headerlink" title="Feature Selection &amp; Extraction"></a><strong>Feature Selection &amp; Extraction</strong></h3><p>차원축소는 크게 변수선택과 변수추출로 나뉘며 PCA는 그 중 변수 추출에 속한다.</p><ul><li><strong>변수선택</strong><ul><li>덜 중요한 피처를 제거하는 방식으로 차원을 축소하는 방식</li><li>ex) <code>Lasso</code>,<code>Generic algorithm</code></li></ul></li><li><strong>변수추출</strong><ul><li>기존변수를 조합해서 새 변수를 만드는 방식</li><li>변수간 연관성을 고려할 수있다</li><li>해석이 어렵다.</li></ul></li></ul><p><img src="/FS_FE.png"><br><strong>그림3 변수선택과 변수추출의 직관적 이해</strong></p><h3 id="정리"><a href="#정리" class="headerlink" title="정리"></a><strong>정리</strong></h3><ul><li><p><strong>선형변환</strong></p><ul><li>행렬은 선형변환이다.</li><li>즉, 임의의 $\mathbb{R}^2$ 벡터를 다른 $\mathbb{R}^2$ 내부의 벡터로 변환 하는 과정은 특정 $M$라는 매트릭스를 곱하는 것과 같다.</li></ul></li><li><p><strong>공분산행렬</strong></p><ul><li>공분산은 교차곱편차의 평균이며 각 변수들이 얼마나 함께 변화하는 지를 나타낸다.</li><li>공분산을 표준화하면 상관계수이다. </li><li>공분산행렬은 각 feature들의 변동이 얼마나 유사한지를 나타낸다.</li><li>공분산행렬 자체는 단순히 정사각행렬의 대각성분을 각 변수의 분산으로 채우고 나머지를 공분산으로 채운 것이다.</li><li>공분산행렬의 서로다른 eigenvector 끼리는 직교한다.따라서 해당 eigenvector를 기저벡터로 하게끔 좌표축이 바뀐 데이터는 서로 상관이 없게 된다.</li></ul></li><li><p><strong>고윳값&#x2F;고유벡터</strong></p><ul><li>고윳값은 벡터의 크기이다</li><li>고유벡터는 특정 벡터에 선형변환을 했을 때 크기만 바뀌고 뱡향은 바뀌지않는 벡터이다. 기본적으로 방향이다.</li><li>공분산행렬의 고유벡터의 열벡터가 주성분이다.</li><li>고유값은 기존벡터에서 고유벡터로 정사영했을 때의 분산이다.따라서 고유벡터로 사영할 경우 분산이 최대가 된다.</li></ul></li><li><p><strong>주성분분석</strong></p><ul><li>주성분은 수치형 예측변수의 선형결합(linear combination)이다.</li><li>주성분은 공분산행렬의 eigenvector이다.</li><li>주성분은 서로간의 상관관계가 최소화 되어 중복성이 줄어들도록 한다 </li><li>차원의 수만큼 주성분이 존재하며 모든 차원의 주성분의 설명량은 1이다.</li><li>주성분의 일부만으로도 전체 분산의 대부분을 설명할 수 있다.</li><li>첫번째 주성분이 가장 큰 분산을 가지고 있고 두번째 주성분은 첫번째 주성분과 직교한다는 전제 하에 두번째로 큰 분산을 가지고 있다.</li><li>부하(loading)는 예측변수들을 주성분으로 변동할때 쓰이는 가중치이다. 계수이다.</li><li>Screeplot은 성분들의 변동을 나타낸다. 정확히는 성분의 수에 따른 분산의 변화량을 나타낸다. </li><li>다음의 두 가지 경우 PCA의 적용이 어렵다<ul><li>데이터의 분포가 정규성을 띄지 않는 경우 적용 어려움<ul><li>이 경우 커널 PCA 사용</li></ul></li><li>분류 &#x2F; 예측 문제에 대해서 데이터의 라벨을 고려하지 않기 때문에 효과적 분리가 어려움<ul><li>이 경우 PLS 사용</li></ul></li></ul></li></ul></li></ul><h2 id="구현하기-R-Python"><a href="#구현하기-R-Python" class="headerlink" title="구현하기(R, Python)"></a>구현하기(R, Python)</h2><blockquote><p>사실 이해하는게 어렵지 다른 대부분의 분석들과 마찬가지로 구현 자체는 매우 쉽다.</p></blockquote><h3 id="Eigenvalue-Eigenvector-구하기"><a href="#Eigenvalue-Eigenvector-구하기" class="headerlink" title="Eigenvalue, Eigenvector 구하기"></a>Eigenvalue, Eigenvector 구하기</h3><ul><li>R을 활용한 Eigenvalue, Eigenvector 계산 <figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># eigen()을 사용해 매우 쉽게 구할 수 있다</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> M <span class="operator">&lt;-</span> as.matrix<span class="punctuation">(</span>data.frame<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">)</span><span class="punctuation">,</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span><span class="built_in">c</span><span class="punctuation">(</span><span class="operator">-</span><span class="number">2</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> M</span><br><span class="line">     c.1...1..0. c.1..2..1. c..2..1...1.</span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>           <span class="number">1</span>          <span class="number">1</span>           <span class="operator">-</span><span class="number">2</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>          <span class="operator">-</span><span class="number">1</span>          <span class="number">2</span>            <span class="number">1</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>           <span class="number">0</span>          <span class="number">1</span>           <span class="operator">-</span><span class="number">1</span></span><br><span class="line"><span class="operator">&gt;</span> eigen<span class="punctuation">(</span>M<span class="punctuation">)</span></span><br><span class="line">eigen<span class="punctuation">(</span><span class="punctuation">)</span> decomposition</span><br><span class="line"><span class="operator">$</span>values</span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="number">2</span>  <span class="number">1</span> <span class="operator">-</span><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="operator">$</span>vectors</span><br><span class="line">          <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span>       <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span>          <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.3015113</span> <span class="operator">-</span><span class="number">0.8017837</span>  <span class="number">7.071068e-01</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.9045340</span> <span class="operator">-</span><span class="number">0.5345225</span> <span class="operator">-</span><span class="number">1.922963e-16</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.3015113</span> <span class="operator">-</span><span class="number">0.2672612</span>  <span class="number">7.071068e-01</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="공분산행렬-구하기"><a href="#공분산행렬-구하기" class="headerlink" title="공분산행렬 구하기"></a>공분산행렬 구하기</h3><ul><li>R을 활용한 Eigenvalue, Eigenvector 계산 <figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">- R을 활용한 Eigenvalue, Eigenvector 계산 </span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="PCA구현하기"><a href="#PCA구현하기" class="headerlink" title="PCA구현하기"></a>PCA구현하기</h3><ul><li><p>R을 활용한 pca</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df <span class="operator">&lt;-</span> data<span class="punctuation">[</span><span class="punctuation">,</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">&#x27;a&#x27;</span><span class="punctuation">,</span><span class="string">&#x27;b&#x27;</span><span class="punctuation">)</span><span class="punctuation">]</span></span><br><span class="line">pca<span class="operator">&lt;-</span>princomp<span class="punctuation">(</span>df<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">pca<span class="operator">$</span>loadings <span class="comment"># 주성분 부하량 확인</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>python을 활용한 pca</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>) <span class="comment"># n_components로 주성분의 수를 지정할 수 있다.</span></span><br><span class="line">pca_values = pca.fit_transform(data_use) <span class="comment"># 설명량</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;누적설명량 &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">sum</span>(pca.explained_variance_ratio_)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;각 차원의 설명량 &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(pca.explained_variance_ratio_))</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="PCA-시각화-관련-참고"><a href="#PCA-시각화-관련-참고" class="headerlink" title="PCA 시각화 관련 참고"></a>PCA 시각화 관련 참고</h3><ul><li>seaborn을 활용한 시각화<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seaborn을 활용한 시각화</span></span><br><span class="line"></span><br><span class="line">sns.scatterplot(pca_v[<span class="number">0</span>],pca_v[<span class="number">1</span>],data=pca_v,hue = <span class="string">&#x27;target&#x27;</span>,</span><br><span class="line">style = <span class="string">&#x27;target&#x27;</span>,</span><br><span class="line">s = <span class="number">100</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>matplotlib을 활용한 시각화(1)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">df = px.data.iris()</span><br><span class="line">features = [<span class="string">&quot;sepal_width&quot;</span>, <span class="string">&quot;sepal_length&quot;</span>, <span class="string">&quot;petal_width&quot;</span>, <span class="string">&quot;petal_length&quot;</span>]</span><br><span class="line"></span><br><span class="line">pca = PCA()</span><br><span class="line">components = pca.fit_transform(df[features])</span><br><span class="line">labels = &#123;</span><br><span class="line">    <span class="built_in">str</span>(i): <span class="string">f&quot;PC <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> (<span class="subst">&#123;var:<span class="number">.1</span>f&#125;</span>%)&quot;</span></span><br><span class="line">    <span class="keyword">for</span> i, var <span class="keyword">in</span> <span class="built_in">enumerate</span>(pca.explained_variance_ratio_ * <span class="number">100</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fig = px.scatter_matrix(</span><br><span class="line">    components,</span><br><span class="line">    labels=labels,</span><br><span class="line">    dimensions=<span class="built_in">range</span>(<span class="number">4</span>),</span><br><span class="line">    color=df[<span class="string">&quot;species&quot;</span>]</span><br><span class="line">)</span><br><span class="line">fig.update_traces(diagonal_visible=<span class="literal">False</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure></li><li>matplotlib을 활용한 시각화(2)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize = (<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>) </span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Principal Component 1&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Principal Component 2&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;2 component PCA&#x27;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">targets = [<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>]</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> target, color <span class="keyword">in</span> <span class="built_in">zip</span>(targets,colors):</span><br><span class="line">    indicesToKeep = finalDf[<span class="string">&#x27;target&#x27;</span>] == target</span><br><span class="line">    ax.scatter(finalDf.loc[indicesToKeep, <span class="string">&#x27;principal component 1&#x27;</span>]</span><br><span class="line">               , finalDf.loc[indicesToKeep, <span class="string">&#x27;principal component 2&#x27;</span>]</span><br><span class="line">               , c = color</span><br><span class="line">               , s = <span class="number">50</span>)</span><br><span class="line">ax.legend(targets)</span><br><span class="line">ax.grid()</span><br></pre></td></tr></table></figure></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>책<ul><li>Practical Statistics for Data Science</li></ul></li><li>블로그<ul><li><a href="https://wiserloner.tistory.com/1297">https://wiserloner.tistory.com/1297</a> # 고유값과 고유벡터</li><li><a href="https://huidea.tistory.com/126">https://huidea.tistory.com/126</a> #기술면접 참고</li><li><a href="https://rfriend.tistory.com/380">https://rfriend.tistory.com/380</a> #python 선형대수 함수</li><li><a href="https://rfriend.tistory.com/181">https://rfriend.tistory.com/181</a> #고유값과 고유벡터 구현</li><li><a href="https://youtu.be/jNwf-JUGWgg">https://youtu.be/jNwf-JUGWgg</a> # 공분산행렬의 이해</li><li><a href="https://ratsgo.github.io/linear%20algebra/2017/03/14/operations/">https://ratsgo.github.io/linear%20algebra/2017/03/14/operations/</a> # 행렬연산과 공분산행렬</li><li>시각화<ul><li><a href="https://plotly.com/python/pca-visualization/">https://plotly.com/python/pca-visualization/</a></li><li><a href="https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60">https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60</a></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[R]특별한 R 연산자들(Binary Oerators)</title>
      <link href="/2021/03/02/programming/R-Programming-operators/"/>
      <url>/2021/03/02/programming/R-Programming-operators/</url>
      
        <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>R로 분석을 하다보면 자연스럽게 손에 익게 되는 몇가지 연산자들이 있습니다. 이 포스팅에서는 R에서 사용되는 특별한 연산자들과 특정 연산자를 단축키로 Rstudio에 추가하는 법을 다룹니다.</p><h2 id="연산자들"><a href="#연산자들" class="headerlink" title="연산자들"></a>연산자들</h2><h3 id="in-matching-연산자"><a href="#in-matching-연산자" class="headerlink" title="%in% (matching 연산자)"></a>%in% (matching 연산자)</h3><p><strong>특정 vector 내에 원하는 요소가 있는지 확인하고 이를 반환할 때 사용합니다.</strong> x%in%y 일 경우 x 기준으로 y와 매칭되는 값에 대한 논리값을 반환합니다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a <span class="operator">&lt;-</span> seq<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">)</span></span><br><span class="line">b <span class="operator">&lt;-</span> seq<span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span> <span class="number">12</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> b <span class="operator">%in%</span> a  </span><br><span class="line"> <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="literal">TRUE</span>  <span class="literal">TRUE</span>  <span class="literal">TRUE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span></span><br><span class="line"><span class="operator">&gt;</span> a <span class="operator">%in%</span> b</span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span>  <span class="literal">TRUE</span>  <span class="literal">TRUE</span>  <span class="literal">TRUE</span></span><br></pre></td></tr></table></figure><h3 id="gt-pipe"><a href="#gt-pipe" class="headerlink" title="%&gt;% (pipe)"></a>%&gt;% (pipe)</h3><p>tidyverse에 포함되어 있어 아마도 가장 유명할 연산자인 pipe operator입니다.</p><p>자주 쓰이기 때문에 Rstudio에 ctrl+shift+m으로 단축키가 지정되어 있습니다.</p><p><strong>기능은 함수들을 연결해 직관적으로 전달하는 것입니다.</strong> f(g(x)) 와 같은 합성함수를 R 코드 상에서 직관적으로 구현한 것이라고 이해하면 될 것 같습니다.</p><p>이 연산자는 특히 데이터 분석에 유용한데 파이프 연산자를 사용하면 코드 가독성을 저해하는 분석 과정상에서의 중간 객체를 만들 필요가 없어지기 때문입니다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris <span class="operator">%&gt;%</span> <span class="comment"># df에 연속적으로 함수를 전달함</span></span><br><span class="line">  subset<span class="punctuation">(</span>Sepal.Length <span class="operator">&gt;</span> <span class="number">3</span><span class="punctuation">)</span> <span class="operator">%&gt;%</span></span><br><span class="line">  aggregate<span class="punctuation">(</span>. <span class="operator">~</span> Species<span class="punctuation">,</span> .<span class="punctuation">,</span> mean<span class="punctuation">)</span></span><br></pre></td></tr></table></figure><h3 id="lt-unpacking"><a href="#lt-unpacking" class="headerlink" title="%&lt;-% (unpacking)"></a>%&lt;-% (unpacking)</h3><p>생각보다 자주 사용하게 되는 unpacking 연산자 입니다. <strong>기능은 list나 vector를 분해해서 이름을 할당하는 것입니다.</strong> list object인 선형회귀 모형의 특정 요소들을 불러와 이름을 할당해 독립적인 객체로 만들 수 있습니다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>zeallot<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">m<span class="operator">&lt;-</span> lm<span class="punctuation">(</span>hp <span class="operator">~</span> gear<span class="punctuation">,</span> data <span class="operator">=</span> mtcars<span class="punctuation">)</span></span><br><span class="line"><span class="built_in">c</span><span class="punctuation">(</span>mcall<span class="punctuation">,</span>...<span class="punctuation">,</span>mdf<span class="punctuation">,</span>mstat<span class="punctuation">)</span> <span class="operator">%&lt;-%</span> summary<span class="punctuation">(</span>m<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">mcall <span class="comment"># 모델식</span></span><br><span class="line">lm<span class="punctuation">(</span>formula <span class="operator">=</span> hp <span class="operator">~</span> gear<span class="punctuation">,</span> data <span class="operator">=</span> mtcars<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> mdf <span class="comment"># 자유도</span></span><br><span class="line">     value      numdf      dendf </span><br><span class="line"> <span class="number">0.4816578</span>  <span class="number">1.0000000</span> <span class="number">30.0000000</span> </span><br><span class="line"><span class="operator">&gt;</span> mstat <span class="comment"># 통계량</span></span><br><span class="line">            <span class="punctuation">(</span>Intercept<span class="punctuation">)</span>        gear</span><br><span class="line"><span class="punctuation">(</span>Intercept<span class="punctuation">)</span>   <span class="number">0.8370370</span> <span class="operator">-</span><span class="number">0.21851852</span></span><br><span class="line">gear         <span class="operator">-</span><span class="number">0.2185185</span>  <span class="number">0.05925926</span></span><br></pre></td></tr></table></figure><h3 id="x-행렬곱-벡터의-내적"><a href="#x-행렬곱-벡터의-내적" class="headerlink" title="%x% (행렬곱-벡터의 내적)"></a>%x% (행렬곱-벡터의 내적)</h3><p><strong>%x%는 벡터의 내적을 반환합니다.</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">c</span> <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">4</span><span class="punctuation">,</span>nrow <span class="operator">=</span> <span class="number">2</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="built_in">c</span> <span class="operator">%*%</span> <span class="built_in">c</span></span><br><span class="line">     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">7</span>   <span class="number">15</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>   <span class="number">10</span>   <span class="number">22</span></span><br></pre></td></tr></table></figure><h3 id="o-행렬곱-벡터의-외적"><a href="#o-행렬곱-벡터의-외적" class="headerlink" title="%o% (행렬곱-벡터의 외적)"></a>%o% (행렬곱-벡터의 외적)</h3><p><strong>%o%는 벡터의 외적을 반환합니다.</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> d <span class="operator">&lt;-</span> 1<span class="operator">:</span><span class="number">3</span></span><br><span class="line"><span class="operator">&gt;</span> d <span class="operator">%o%</span> d</span><br><span class="line">     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">1</span>    <span class="number">2</span>    <span class="number">3</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">3</span>    <span class="number">6</span>    <span class="number">9</span></span><br></pre></td></tr></table></figure><h3 id="값-할당하기"><a href="#값-할당하기" class="headerlink" title="%$% (값 할당하기)"></a>%$% (값 할당하기)</h3><p><strong>magrittr</strong> 패키지의 %$% 연산자는 데이터 프레임이 중심이 되는 분석을 할때 사용하는 단순하지만 유용한 연산자입니다. <strong>기능은 데이터 프레임에서 단순히 특정 변수를 추출하는 것입니다.</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>magrittr<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">mtcars <span class="operator">%$%</span></span><br><span class="line">  cor<span class="punctuation">(</span>disp<span class="punctuation">,</span> mpg<span class="punctuation">)</span></span><br></pre></td></tr></table></figure><hr><h2 id="특정-단축키를-addin으로-Rstudio에-추가하기"><a href="#특정-단축키를-addin으로-Rstudio에-추가하기" class="headerlink" title="특정 단축키를 addin으로 Rstudio에 추가하기"></a>특정 단축키를 addin으로 Rstudio에 추가하기</h2><p>특별한 연산자들은 유용하지만 %&gt;%와 같이 Rstudio에서 미리 단축키로 지정해놓지 않은 연산자들을 매번 타이핑해서 사용하는 것은 귀찮은 일입니다.<br>따라서 자주 사용하는 연산자의 경우 Rstudio addin을 사용해 %in% 처럼 단축키를 만들어 주는 것을 고려해볼 수 있습니다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 사용자 정의 단축키를 추가하는 Rstudio addin 설치</span></span><br><span class="line"></span><br><span class="line">devtools<span class="operator">::</span>install_github<span class="punctuation">(</span><span class="string">&quot;rstudio/addinexamples&quot;</span><span class="punctuation">,</span> type <span class="operator">=</span> <span class="string">&quot;source&quot;</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p><strong>References &amp; annotation</strong></p><ul><li><a href="https://www.datamentor.io/r-programming/infix-operator/">https://www.datamentor.io/r-programming/infix-operator/</a></li><li><a href="https://github.com/r-lib/zeallot">https://github.com/r-lib/zeallot</a></li><li><a href="https://rfriend.tistory.com/35">https://rfriend.tistory.com/35</a></li><li><a href="https://stackoverflow.com/questions/25179457/r-what-are-operators-like-in-called-and-how-can-i-learn-about-them">https://stackoverflow.com/questions/25179457/r-what-are-operators-like-in-called-and-how-can-i-learn-about-them</a> # Binary operator에 대한 자세한 설명이 나와있습니다.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
          <category> R </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
